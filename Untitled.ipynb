{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3de2584b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# \"\"\"PDB dataset loader.\"\"\"\n",
    "# import math\n",
    "# from typing import Optional\n",
    "\n",
    "# import torch\n",
    "# import torch.distributed as dist\n",
    "\n",
    "# import tree\n",
    "# import numpy as np\n",
    "# import torch\n",
    "# import pandas as pd\n",
    "# import logging\n",
    "# import random\n",
    "# import functools as fn\n",
    "\n",
    "# from torch.utils import data\n",
    "# from data import utils as du\n",
    "# from openfold.data import data_transforms\n",
    "# from openfold.np import residue_constants\n",
    "# from openfold.utils import rigid_utils\n",
    "\n",
    "# from sklearn.preprocessing import PolynomialFeatures\n",
    "# from sklearn.linear_model import LinearRegression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "28b5ad6a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from openfold.np import residue_constants"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c54836d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "711cb211",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "import torch\n",
    "import tree\n",
    "#clear memory better\n",
    "with torch.no_grad():\n",
    "    torch.cuda.empty_cache()\n",
    "import numpy as np\n",
    "import util.npose_util as nu\n",
    "import os\n",
    "import pathlib\n",
    "import dgl\n",
    "from dgl import backend as F\n",
    "import torch_geometric\n",
    "from torch.utils.data import random_split, DataLoader, Dataset\n",
    "from typing import Dict\n",
    "from torch import Tensor\n",
    "from dgl import DGLGraph\n",
    "from torch import nn\n",
    "# from chemical import cos_ideal_NCAC #from RoseTTAFold2\n",
    "from torch import einsum\n",
    "import time\n",
    "import random\n",
    "torch.cuda.is_available()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "09df63cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import se3_diffuse.utils as du\n",
    "from data_rigid_diffuser.diffuser import FrameDiffNoise\n",
    "from gudiff_model import Data_Graph\n",
    "from gudiff_model.Data_Graph import build_npose_from_coords, dump_coord_pdb, define_graph_edges, make_pe_encoding\n",
    "from gudiff_model.Data_Graph import Helix4_Dataset, Make_KNN_MP_Graphs\n",
    "from se3_transformer.model.basis import get_basis, update_basis_with_fused\n",
    "from se3_transformer.model.transformer import Sequential, SE3Transformer\n",
    "from se3_transformer.model.transformer_topk import SE3Transformer_topK\n",
    "from se3_transformer.model.FAPE_Loss import FAPE_loss, Qs2Rs, normQ\n",
    "from se3_transformer.model.layers.attentiontopK import AttentionBlockSE3\n",
    "from se3_transformer.model.layers.linear import LinearSE3\n",
    "from se3_transformer.model.layers.convolution import ConvSE3, ConvSE3FuseLevel\n",
    "from se3_transformer.model.layers.norm import NormSE3\n",
    "from se3_transformer.model.layers.pooling import GPooling, Latent_Unpool, Unpool_Layer\n",
    "from se3_transformer.runtime.utils import str2bool, to_cuda\n",
    "from se3_transformer.model.fiber import Fiber\n",
    "from se3_transformer.model.transformer import get_populated_edge_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "6dffe08a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#indices for, unsure if needed\n",
    "CA = Data_Graph.CA\n",
    "N = Data_Graph.N\n",
    "C = Data_Graph.C\n",
    "\n",
    "#find better way to incorporate coord_scale\n",
    "\n",
    "#needed\n",
    "N_CA_dist = (Data_Graph.N_CA_dist/10.).to('cuda')\n",
    "C_CA_dist = (Data_Graph.C_CA_dist/10.).to('cuda')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "b8ed61fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "#basically a I just need data loader to grab coordinates from datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "9da631a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "#########CURRENTLY REWRITING THIS######\n",
    "\n",
    "def torch_normalize(v, eps=1e-6):\n",
    "    \"\"\"Normalize vector in last axis\"\"\"\n",
    "    norm = torch.linalg.vector_norm(v, dim=len(v.shape)-1)+eps\n",
    "    return v / norm[...,None]\n",
    "def gudiff_parse_chain_feats(chain_feats, scale_factor=10., cast_type=torch.float32):\n",
    "    ca_idx = residue_constants.atom_order['CA']\n",
    "    n_idx = residue_constants.atom_order['N']\n",
    "    c_idx = residue_constants.atom_order['C']\n",
    "    chain_feats['bb_mask'] = chain_feats['atom_mask'][:, ca_idx]\n",
    "    \n",
    "    bb_pos = chain_feats['atom_positions'][:, ca_idx]/scale_factor #scale factor mod\n",
    "    bb_center = np.sum(bb_pos, axis=0) / (np.sum(chain_feats['bb_mask']) + 1e-5)\n",
    "    centered_pos = chain_feats['atom_positions'] - bb_center[None, None, :]\n",
    "    \n",
    "    \n",
    "    coordinates = centered_pos/scale_factor\n",
    "    #unsqueeze to stack together later\n",
    "    N_CA_vec = torch.tensor(coordinates[:,N] - coordinates[:,ca_idx], dtype=cast_type)\n",
    "    C_CA_vec = torch.tensor(coordinates[:,C] - coordinates[:,ca_idx], dtype=cast_type)\n",
    "        \n",
    "    N_CA_vec = torch_normalize(N_CA_vec)#.unsqueeze(2) #do the unsqueeze later\n",
    "    C_CA_vec = torch_normalize(C_CA_vec)#.unsqueeze(2)\n",
    "\n",
    "    scaled_pos = centered_pos / scale_factor\n",
    "    chain_feats['atom_positions'] = scaled_pos * chain_feats['atom_mask'][..., None]\n",
    "    \n",
    "    chain_feats['CA'] = torch.tensor(coordinates[:,ca_idx],dtype=cast_type)\n",
    "    chain_feats['N_CA_vec'] = N_CA_vec\n",
    "    chain_feats['C_CA_vec'] = C_CA_vec\n",
    "    return chain_feats\n",
    "\n",
    "\n",
    "\n",
    "class smallPDBDataset(torch.utils.data.Dataset):\n",
    "    def __init__(\n",
    "            self,\n",
    "            diffuser,\n",
    "            meta_data_path = '/mnt/h/datasets/p200/metadata.csv',\n",
    "            filter_dict=True,\n",
    "            maxlen=None,\n",
    "            is_training=True\n",
    "        ):\n",
    "        #self._log = logging.getLogger(__name__)\n",
    "        self._is_training = is_training\n",
    "        self.meta_data_path = meta_data_path\n",
    "        self._init_metadata(filter_dict=filter_dict,maxlen=maxlen) #includes create split that saves self.csv\n",
    "        self._diffuser = diffuser\n",
    "        \n",
    "    @property\n",
    "    def is_training(self):\n",
    "        return self._is_training\n",
    "\n",
    "    @property\n",
    "    def diffuser(self):\n",
    "        return self._diffuser\n",
    "\n",
    "    @property\n",
    "    def data_conf(self):\n",
    "        return self._data_conf\n",
    "\n",
    "    def _init_metadata(self, filter_dict=True, maxlen=None):\n",
    "        \"\"\"Initialize metadata.\"\"\"\n",
    "        \n",
    "        #meta_data_path = '/mnt/h/datasets/p200/metadata.csv'\n",
    "        pdb_csv = pd.read_csv(self.meta_data_path)\n",
    "        \n",
    "        if filter_dict:\n",
    "            filter_conf = {'allowed_oligomer': ['monomeric'],\n",
    "                           'max_loop_percent': 0.75}\n",
    "            pdb_csv = pdb_csv[pdb_csv.oligomeric_detail.isin(filter_conf['allowed_oligomer'])]\n",
    "            pdb_csv = pdb_csv[pdb_csv.coil_percent < filter_conf['max_loop_percent']]\n",
    "            pdb_csv = pdb_csv.sort_values('modeled_seq_len', ascending=False)\n",
    "            \n",
    "        if maxlen is not None:\n",
    "            pdb_csv = pdb_csv\n",
    "        #self._create_split(pdb_csv)\n",
    "        self.csv = pdb_csv\n",
    "    def _create_split(self, pdb_csv):\n",
    "        # Training or validation specific logic.\n",
    "        #if self.is_training:\n",
    "        self.csv = pdb_csv\n",
    "        #self._log.info(\n",
    "        #    f'Training: {len(self.csv)} examples')\n",
    "#         else:\n",
    "#             all_lengths = np.sort(pdb_csv.modeled_seq_len.unique())\n",
    "#             length_indices = (len(all_lengths) - 1) * np.linspace(\n",
    "#                 0.0, 1.0, self._data_conf.num_eval_lengths)\n",
    "#             length_indices = length_indices.astype(int)\n",
    "            \n",
    "#             if self._simple:\n",
    "#                 eval_lengths = np.array([65]).astype(int)\n",
    "#             else:\n",
    "#                 eval_lengths = all_lengths[length_indices]\n",
    "                \n",
    "#             eval_csv = pdb_csv[pdb_csv.modeled_seq_len.isin(eval_lengths)]\n",
    "#             # Fix a random seed to get the same split each time.\n",
    "#             eval_csv = eval_csv.groupby('modeled_seq_len').sample(\n",
    "#                 self._data_conf.samples_per_eval_length, replace=True, random_state=123)\n",
    "#             eval_csv = eval_csv.sort_values('modeled_seq_len', ascending=False)\n",
    "#             self.csv = eval_csv\n",
    "#             self._log.info(\n",
    "#                 f'Validation: {len(self.csv)} examples with lengths {eval_lengths}')\n",
    "    # cache make the same sample in same batch \n",
    "    #@fn.lru_cache(maxsize=100)\n",
    "    def _process_csv_row(self, processed_file_path):\n",
    "        \n",
    "        processed_feats = du.read_pkl(processed_file_path)\n",
    "        chain_feats = gudiff_parse_chain_feats(processed_feats,scale_factor=10.)\n",
    "        \n",
    "        # Only take modeled residues.\n",
    "        modeled_idx = processed_feats['modeled_idx']\n",
    "        min_idx = np.min(modeled_idx)\n",
    "        max_idx = np.max(modeled_idx)\n",
    "        del processed_feats['modeled_idx']\n",
    "        processed_feats = tree.map_structure(\n",
    "            lambda x: x[min_idx:(max_idx+1)], processed_feats)\n",
    "        chain_feats = tree.map_structure(\n",
    "            lambda x: x[min_idx:(max_idx+1)], chain_feats)\n",
    "        \n",
    "\n",
    "        # Run through OpenFold data transforms.\n",
    "        # Re-number residue indices for each chain such that it starts from 1.\n",
    "        # Randomize chain indices.\n",
    "        chain_idx = processed_feats[\"chain_index\"]\n",
    "        res_idx = processed_feats['residue_index']\n",
    "        new_res_idx = np.zeros_like(res_idx)\n",
    "        new_chain_idx = np.zeros_like(res_idx)\n",
    "        all_chain_idx = np.unique(chain_idx).tolist()\n",
    "        shuffled_chain_idx = np.array(\n",
    "            random.sample(all_chain_idx, len(all_chain_idx))) - np.min(all_chain_idx) + 1\n",
    "        for i,chain_id in enumerate(all_chain_idx):\n",
    "            chain_mask = (chain_idx == chain_id).astype(int)\n",
    "            chain_min_idx = np.min(res_idx + (1 - chain_mask) * 1e3).astype(int)\n",
    "            new_res_idx = new_res_idx + (res_idx - chain_min_idx + 1) * chain_mask\n",
    "\n",
    "            # Shuffle chain_index\n",
    "            replacement_chain_id = shuffled_chain_idx[i]\n",
    "            new_chain_idx = new_chain_idx + replacement_chain_id * chain_mask\n",
    "\n",
    "        # To speed up processing, only take necessary features\n",
    "        final_feats = {\n",
    "            'chain_idx': new_chain_idx,\n",
    "            'residue_index': processed_feats['residue_index'],\n",
    "            'res_mask': processed_feats['bb_mask'],\n",
    "            'CA':   chain_feats['CA'],\n",
    "            'N_CA': chain_feats['N_CA_vec'], #when unsqueeze? later maybe take time to change this behavior\n",
    "            'C_CA': chain_feats['C_CA_vec']\n",
    "        }\n",
    "        return final_feats\n",
    "        \n",
    "    def __getitem__(self, idx):\n",
    "        #######workign on this\n",
    "        # Sample data example.\n",
    "        example_idx = idx\n",
    "        csv_row = self.csv.iloc[example_idx]\n",
    "        if 'pdb_name' in csv_row:\n",
    "            pdb_name = csv_row['pdb_name']\n",
    "        elif 'chain_name' in csv_row:\n",
    "            pdb_name = csv_row['chain_name']\n",
    "        else:\n",
    "            raise ValueError('Need chain identifier.')\n",
    "        processed_file_path = csv_row['processed_path']\n",
    "        chain_feats = self._process_csv_row(processed_file_path)\n",
    "\n",
    "        # Use a fixed seed for evaluation.\n",
    "#         if self.is_training:\n",
    "        rng = np.random.default_rng(None)\n",
    "#         else:\n",
    "#             rng = np.random.default_rng(idx)\n",
    "\n",
    "        # Sample t and diffuse.\n",
    "#         if self.is_training:\n",
    "        t = rng.uniform(1e-3, 1.0)\n",
    "        bb_noised =  self._diffuser.forward(chain_feats, t=t)\n",
    "#         else:\n",
    "#             t = 1.0\n",
    "#             diff_feats_t = self.diffuser.sample_ref(\n",
    "#                 n_samples=gt_bb_rigid.shape[0],\n",
    "#                 impute=gt_bb_rigid,\n",
    "#                 diffuse_mask=None,\n",
    "#                 as_tensor_7=True,\n",
    "#             )\n",
    "        chain_feats.update(bb_noised)\n",
    "\n",
    "        # Convert all features to tensors.\n",
    "        final_feats = tree.map_structure(\n",
    "            lambda x: x if torch.is_tensor(x) else torch.tensor(x), chain_feats)\n",
    "        #final_feats = du.pad_feats(final_feats, csv_row['modeled_seq_len'])\n",
    "        #if self.is_training:\n",
    "#         else:\n",
    "#             return final_feats, pdb_name\n",
    "        \n",
    "        return final_feats\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.csv)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "387ae865",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from torch.utils import data\n",
    "\n",
    "class TrainSampler(torch.utils.data.Sampler):\n",
    "\n",
    "    def __init__(self, batch_size, dataset,\n",
    "                 sample_mode='length_batch'):\n",
    "        \n",
    "        self.dataset = dataset\n",
    "        self._data_csv = dataset.csv\n",
    "        self._dataset_indices = list(range(len(self._data_csv)))\n",
    "        self._data_csv['index'] = self._dataset_indices\n",
    "        self._batch_size = batch_size\n",
    "        self.epoch = 0\n",
    "        self._sample_mode = sample_mode\n",
    "        self.sampler_len = len(self._dataset_indices) * self._batch_size\n",
    "        self.min_t = 1e-3\n",
    "        #self._log = logging.getLogger(__name__)\n",
    "        #self._data_conf = data_conf\n",
    "        #self._dataset = dataset\n",
    "        #self._data_csv = self._dataset.csv\n",
    "    def __iter__(self):\n",
    "        if self._sample_mode == 'length_batch':\n",
    "            # Each batch contains multiple proteins of the same length.\n",
    "            sampled_order = self._data_csv.groupby('modeled_seq_len').sample(\n",
    "                self._batch_size, replace=True, random_state=self.epoch) #one batch per length\n",
    "            return iter(sampled_order['index'].tolist())\n",
    "        elif self._sample_mode == 'single_length':\n",
    "            rand_index = self._data_csv['index'].to_numpy()\n",
    "            np.random.shuffle(rand_index)\n",
    "            #num_batches = int(rand_index.shape[0]/self._batch_size)\n",
    "            #rand_index = rand_index[:(num_batches*self._batch_size)] #drop last batch\n",
    "            return iter(rand_index)\n",
    "        else:\n",
    "            raise ValueError(f'Invalid sample mode: {self._sample_mode}')\n",
    "    \n",
    "#     def getbb(self, idx):\n",
    "#         csv_row = self._data_csv.iloc[idx]\n",
    "#         processed_file_path = csv_row['processed_path']\n",
    "#         chain_feats = self.dataset._process_csv_row(processed_file_path)\n",
    "#         return chain_feats  \n",
    "            \n",
    "    def __len__(self):\n",
    "        return len(self.csv)\n",
    "\n",
    "    def set_epoch(self, epoch):\n",
    "        self.epoch = epoch\n",
    "\n",
    "    def __len__(self):\n",
    "        return self.sampler_len"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "8ccb8820",
   "metadata": {},
   "outputs": [],
   "source": [
    "from gudiff_model.Graph_UNet import GraphUNet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "72647f52",
   "metadata": {},
   "outputs": [],
   "source": [
    "def model_step(batch_feats, noised_dict, graph_maker, graph_unet, train=True):\n",
    "    L = batch_feats['CA'].shape[1]\n",
    "    B = batch_feats['CA'].shape[0]\n",
    "    CA_t  = batch_feats['CA']\n",
    "    NC_t = CA_t +  batch_feats['N_CA']\n",
    "    CC_t = CA_t +  batch_feats['C_CA']\n",
    "    true =  torch.cat((NC_t,CA_t,CC_t),dim=2).reshape(B,L,3,3)\n",
    "\n",
    "    CA_n  = batch_feats['CA_noised'].reshape(B, L, 3)#.to('cuda')\n",
    "    NC_n = CA_n + batch_feats['N_CA_noised'].reshape(B, L, 3)#.to('cuda')\n",
    "    CC_n = CA_n + batch_feats['C_CA_noised'].reshape(B, L, 3)#.to('cuda')\n",
    "    noise_xyz =  torch.cat((NC_n,CA_n,CC_n),dim=2).reshape(B,L,3,3)\n",
    "    \n",
    "    x = gm.prep_for_network(noised_dict)\n",
    "    out = gu(x, batch_feats['t'])\n",
    "    CA_p = out['1'][:,0,:].reshape(B, L, 3) + CA_n #translation of Calpha\n",
    "    Qs = out['1'][:,1,:] # rotation of frame\n",
    "    Qs = Qs.unsqueeze(1).repeat((1,2,1))\n",
    "    Qs = torch.cat((torch.ones((B*L,2,1),device=Qs.device),Qs),dim=-1).reshape(B,L,2,4)\n",
    "    Qs = normQ(Qs)\n",
    "    Rs = Qs2Rs(Qs)\n",
    "    N_C_to_Rot = torch.cat((noised_dict['N_CA'].reshape(B, L, 3),\n",
    "                            noised_dict['C_CA'].reshape(B, L, 3)),dim=2).reshape(B,L,2,1,3)\n",
    "    \n",
    "    rot_vecs = einsum('bnkij,bnkhj->bnki',Rs, N_C_to_Rot)\n",
    "    NC_p = CA_p + rot_vecs[:,:,0,:]*N_CA_dist #remove bc who cares? me maybe\n",
    "    CC_p = CA_p + rot_vecs[:,:,1,:]*C_CA_dist #remove maybe\n",
    "\n",
    "    pred = torch.cat((NC_p,CA_p,CC_p),dim=2).reshape(B,L,3,3)\n",
    "\n",
    "    tloss, loss = FAPE_loss(pred.unsqueeze(0), true, batch_feats['score_scale'])\n",
    "    \n",
    "    return pred, tloss\n",
    "\n",
    "def get_noise_pred_true(batch_feats, noised_dict, graph_maker, graph_unet, scale=10):\n",
    "    \n",
    "    L = batch_feats['CA'].shape[1]\n",
    "    B = batch_feats['CA'].shape[0]\n",
    "    CA_t  = batch_feats['CA']\n",
    "    NC_t = CA_t +  batch_feats['N_CA']\n",
    "    CC_t = CA_t +  batch_feats['C_CA']\n",
    "    true =  torch.cat((NC_t,CA_t,CC_t),dim=2).reshape(B,L,3,3)\n",
    "\n",
    "    CA_n  = batch_feats['CA_noised'].reshape(B, L, 3)#.to('cuda')\n",
    "    NC_n = CA_n + batch_feats['N_CA_noised'].reshape(B, L, 3)#.to('cuda')\n",
    "    CC_n = CA_n + batch_feats['C_CA_noised'].reshape(B, L, 3)#.to('cuda')\n",
    "    noise_xyz =  torch.cat((NC_n,CA_n,CC_n),dim=2).reshape(B,L,3,3)\n",
    "    \n",
    "    x = graph_maker.prep_for_network(noised_dict)\n",
    "    out = graph_unet(x, batch_feats['t'])\n",
    "    CA_p = out['1'][:,0,:].reshape(B, L, 3) + CA_n #translation of Calpha\n",
    "    Qs = out['1'][:,1,:] # rotation of frame\n",
    "    Qs = Qs.unsqueeze(1).repeat((1,2,1))\n",
    "    Qs = torch.cat((torch.ones((B*L,2,1),device=Qs.device),Qs),dim=-1).reshape(B,L,2,4)\n",
    "    Qs = normQ(Qs)\n",
    "    Rs = Qs2Rs(Qs)\n",
    "    N_C_to_Rot = torch.cat((noised_dict['N_CA'].reshape(B, L, 3),\n",
    "                            noised_dict['C_CA'].reshape(B, L, 3)),dim=2).reshape(B,L,2,1,3)\n",
    "    \n",
    "    rot_vecs = einsum('bnkij,bnkhj->bnki',Rs, N_C_to_Rot)\n",
    "    NC_p = CA_p + rot_vecs[:,:,0,:]*N_CA_dist #remove bc who cares? me maybe\n",
    "    CC_p = CA_p + rot_vecs[:,:,1,:]*C_CA_dist #remove maybe\n",
    "\n",
    "    pred = torch.cat((NC_p,CA_p,CC_p),dim=2).reshape(B,L,3,3)\n",
    "    \n",
    "    return true.to('cpu').numpy()*scale, noise_xyz.to('cpu').numpy()*scale, pred.detach().to('cpu').numpy()*scale\n",
    "\n",
    "def dump_tnp(true, noise, pred, t_val, e=0, numOut=1,outdir='output/'):\n",
    "    \n",
    "    if numOut>true.shape[0]:\n",
    "        numOut = true.shape[0]\n",
    "    \n",
    "    for x in range(numOut):\n",
    "        dump_coord_pdb(true[x], fileOut=f'{outdir}/true_{t_val[x]*100:.0f}_e{e}_{x}.pdb')\n",
    "        dump_coord_pdb(noise[x], fileOut=f'{outdir}/noise_{t_val[x]*100:.0f}_e{e}_{x}.pdb')\n",
    "        dump_coord_pdb(pred[x], fileOut=f'{outdir}/pred_{t_val[x]*100:.0f}_e{e}_{x}.pdb')\n",
    "        \n",
    "def visualize_model(bb_dict, noised_bb, batched_t, epoch, numOut=1, outdir='output/'):\n",
    "    true, noise, pred = get_noise_pred_true(bb_dict, noised_bb, batched_t, gm, gu)\n",
    "    dump_tnp(true,noise,pred, batched_t, e=epoch, numOut=numOut, outdir=f'{outdir}/models/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "0452154b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_save_folder(name=''):\n",
    "    base_folder = time.strftime(f'log/%y%b%d_%I%M%p_{name}/', time.localtime())\n",
    "    if not os.path.exists(base_folder):\n",
    "        os.makedirs(base_folder)\n",
    "    subfolders = ['models']\n",
    "    for subfolder in subfolders:\n",
    "        if not os.path.exists(base_folder + subfolder):\n",
    "            os.makedirs(base_folder + subfolder)\n",
    "            \n",
    "    return base_folder\n",
    "        \n",
    "def save_chkpt(model_path, model, optimizer, epoch, batch, val_losses, train_losses):\n",
    "    \"\"\"Save a training checkpoint\n",
    "    Args:\n",
    "        model_path (str): the path to save the model to\n",
    "        model (nn.Module): the model to save\n",
    "        optimizer (torch.optim.Optimizer): the optimizer to save\n",
    "        epoch (int): the current epoch\n",
    "        batch (int): the current batch in the epoch\n",
    "        loss_domain (list of int): a list of the shared domain for val and training \n",
    "            losses\n",
    "        val_losses (list of float): a list containing the validation losses\n",
    "        train_losses (list of float): a list containing the training losses\n",
    "    \"\"\"\n",
    "    os.makedirs(os.path.dirname(model_path), exist_ok=True)\n",
    "    state_dict = dict()\n",
    "    state_dict.update({'model':model.state_dict(),\n",
    "                       'optimizer':optimizer.state_dict(),\n",
    "                       'epoch':epoch,\n",
    "                       'batch':batch,\n",
    "                       'train_losses':train_losses,\n",
    "                       'val_losses':val_losses\n",
    "                       })\n",
    "    torch.save(state_dict, f'{model_path}model_e{epoch}')\n",
    "    \n",
    "def load_model(model_path, model_class):\n",
    "    \"\"\"Load a saved model\"\"\"\n",
    "    \n",
    "    device = 'cuda:0'\n",
    "    model = model_class()\n",
    "    model.load_state_dict(torch.load(model_path)['model'])\n",
    "    model.to(device)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "e0174936",
   "metadata": {},
   "outputs": [],
   "source": [
    "#since length list is all the same is that the problem"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "bba3980d",
   "metadata": {},
   "outputs": [],
   "source": [
    "fdn = FrameDiffNoise()\n",
    "B = 2\n",
    "sd = smallPDBDataset(fdn , meta_data_path = '/mnt/h/datasets/bCov_4H/metadata.csv', filter_dict=False, maxlen=500)\n",
    "ts = TrainSampler(B,sd, sample_mode='single_length')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "770d5f98",
   "metadata": {},
   "outputs": [],
   "source": [
    "#ts = TrainSampler(B,sd, sample_mode='length_batch')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "91d5f736",
   "metadata": {},
   "outputs": [],
   "source": [
    "gu = GraphUNet(batch_size = B, num_layers_ca = 2).to('cuda')\n",
    "opti = torch.optim.Adam(gu.parameters(), lr=0.0005, weight_decay=5e-6) #prev lr=0.0005\n",
    "gm = Make_KNN_MP_Graphs() #consider precalculating graphs for training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "920c0ed1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "27894"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(sd)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "be9541ef",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "55788"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(ts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "3f404ce3",
   "metadata": {},
   "outputs": [],
   "source": [
    "dL = torch.utils.data.DataLoader(sd,\n",
    "        sampler=ts,\n",
    "        batch_size=B,\n",
    "        shuffle=False,\n",
    "        collate_fn=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "1c421b0a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "t\n",
      "t\n",
      "t\n",
      "t\n",
      "t\n",
      "t\n",
      "t\n",
      "t\n",
      "t\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[79], line 14\u001b[0m\n\u001b[1;32m      8\u001b[0m batch_feats\u001b[38;5;241m=\u001b[39m tree\u001b[38;5;241m.\u001b[39mmap_structure(\n\u001b[1;32m      9\u001b[0m                 \u001b[38;5;28;01mlambda\u001b[39;00m x: x\u001b[38;5;241m.\u001b[39mto(device), batch_feats)\n\u001b[1;32m     10\u001b[0m noised_dict \u001b[38;5;241m=\u001b[39m   {\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mCA\u001b[39m\u001b[38;5;124m'\u001b[39m: batch_feats[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mCA_noised\u001b[39m\u001b[38;5;124m'\u001b[39m] ,\n\u001b[1;32m     11\u001b[0m                  \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mN_CA\u001b[39m\u001b[38;5;124m'\u001b[39m: batch_feats[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mN_CA_noised\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39munsqueeze(\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m2\u001b[39m) ,\n\u001b[1;32m     12\u001b[0m                  \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mC_CA\u001b[39m\u001b[38;5;124m'\u001b[39m: batch_feats[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mC_CA_noised\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39munsqueeze(\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m2\u001b[39m)  }\n\u001b[0;32m---> 14\u001b[0m pred, train_loss \u001b[38;5;241m=\u001b[39m \u001b[43mmodel_step\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbatch_feats\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnoised_dict\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgm\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgu\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrain\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[1;32m     15\u001b[0m opti\u001b[38;5;241m.\u001b[39mzero_grad()\n\u001b[1;32m     16\u001b[0m train_loss\u001b[38;5;241m.\u001b[39mbackward()\n",
      "Cell \u001b[0;32mIn[69], line 14\u001b[0m, in \u001b[0;36mmodel_step\u001b[0;34m(batch_feats, noised_dict, graph_maker, graph_unet, train)\u001b[0m\n\u001b[1;32m     11\u001b[0m CC_n \u001b[38;5;241m=\u001b[39m CA_n \u001b[38;5;241m+\u001b[39m batch_feats[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mC_CA_noised\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39mreshape(B, L, \u001b[38;5;241m3\u001b[39m)\u001b[38;5;66;03m#.to('cuda')\u001b[39;00m\n\u001b[1;32m     12\u001b[0m noise_xyz \u001b[38;5;241m=\u001b[39m  torch\u001b[38;5;241m.\u001b[39mcat((NC_n,CA_n,CC_n),dim\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m2\u001b[39m)\u001b[38;5;241m.\u001b[39mreshape(B,L,\u001b[38;5;241m3\u001b[39m,\u001b[38;5;241m3\u001b[39m)\n\u001b[0;32m---> 14\u001b[0m x \u001b[38;5;241m=\u001b[39m \u001b[43mgm\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mprep_for_network\u001b[49m\u001b[43m(\u001b[49m\u001b[43mnoised_dict\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     15\u001b[0m out \u001b[38;5;241m=\u001b[39m gu(x, batch_feats[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mt\u001b[39m\u001b[38;5;124m'\u001b[39m])\n\u001b[1;32m     16\u001b[0m CA_p \u001b[38;5;241m=\u001b[39m out[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m1\u001b[39m\u001b[38;5;124m'\u001b[39m][:,\u001b[38;5;241m0\u001b[39m,:]\u001b[38;5;241m.\u001b[39mreshape(B, L, \u001b[38;5;241m3\u001b[39m) \u001b[38;5;241m+\u001b[39m CA_n \u001b[38;5;66;03m#translation of Calpha\u001b[39;00m\n",
      "File \u001b[0;32m/mnt/c/Users/nwood/OneDrive/Desktop/gudiff/gudiff_model/Data_Graph.py:323\u001b[0m, in \u001b[0;36mMake_KNN_MP_Graphs.prep_for_network\u001b[0;34m(self, bb_dict, cuda)\u001b[0m\n\u001b[1;32m    321\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mprep_for_network\u001b[39m(\u001b[38;5;28mself\u001b[39m, bb_dict, cuda\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m):\n\u001b[0;32m--> 323\u001b[0m     batched_graph, batched_mpgraph, batched_mpself_graph, batched_mpRevgraph \u001b[38;5;241m=\u001b[39m  \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcreate_and_batch\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbb_dict\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    325\u001b[0m     edge_feats        \u001b[38;5;241m=\u001b[39m    {\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m0\u001b[39m\u001b[38;5;124m'\u001b[39m:   batched_graph\u001b[38;5;241m.\u001b[39medata[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcon\u001b[39m\u001b[38;5;124m'\u001b[39m][:, :\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mEDGE_FEATURE_DIM, \u001b[38;5;28;01mNone\u001b[39;00m]}\n\u001b[1;32m    326\u001b[0m     edge_feats_mp     \u001b[38;5;241m=\u001b[39m {\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m0\u001b[39m\u001b[38;5;124m'\u001b[39m: batched_mpgraph\u001b[38;5;241m.\u001b[39medata[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcon\u001b[39m\u001b[38;5;124m'\u001b[39m][:, :\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mEDGE_FEATURE_DIM, \u001b[38;5;28;01mNone\u001b[39;00m]} \u001b[38;5;66;03m#def all zero now\u001b[39;00m\n",
      "File \u001b[0;32m/mnt/c/Users/nwood/OneDrive/Desktop/gudiff/gudiff_model/Data_Graph.py:271\u001b[0m, in \u001b[0;36mMake_KNN_MP_Graphs.create_and_batch\u001b[0;34m(self, bb_dict)\u001b[0m\n\u001b[1;32m    269\u001b[0m i\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0\u001b[39m\u001b[38;5;66;03m#mp list counter\u001b[39;00m\n\u001b[1;32m    270\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m x \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;241m0\u001b[39m,\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mn_nodes, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmp_stride):\n\u001b[0;32m--> 271\u001b[0m     src, dst \u001b[38;5;241m=\u001b[39m \u001b[43mgraph\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43min_edges\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;66;03m#dst repeats x\u001b[39;00m\n\u001b[1;32m    272\u001b[0m     n_tot \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mcat((torch\u001b[38;5;241m.\u001b[39mtensor(x,device\u001b[38;5;241m=\u001b[39mcaXYZ\u001b[38;5;241m.\u001b[39mdevice)\u001b[38;5;241m.\u001b[39munsqueeze(\u001b[38;5;241m0\u001b[39m),src)) \u001b[38;5;66;03m#add x to node list\u001b[39;00m\n\u001b[1;32m    273\u001b[0m     mp_list[i] \u001b[38;5;241m=\u001b[39m caXYZ[n_tot]\u001b[38;5;241m.\u001b[39msum(axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0\u001b[39m)\u001b[38;5;241m/\u001b[39mn_tot\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m0\u001b[39m]\n",
      "File \u001b[0;32m~/miniconda3/envs/se33/lib/python3.9/site-packages/dgl/heterograph.py:3416\u001b[0m, in \u001b[0;36mDGLGraph.in_edges\u001b[0;34m(self, v, form, etype)\u001b[0m\n\u001b[1;32m   3343\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Return the incoming edges of the given nodes.\u001b[39;00m\n\u001b[1;32m   3344\u001b[0m \n\u001b[1;32m   3345\u001b[0m \u001b[38;5;124;03mParameters\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   3413\u001b[0m \u001b[38;5;124;03mout_edges\u001b[39;00m\n\u001b[1;32m   3414\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m   3415\u001b[0m v \u001b[38;5;241m=\u001b[39m utils\u001b[38;5;241m.\u001b[39mprepare_tensor(\u001b[38;5;28mself\u001b[39m, v, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mv\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m-> 3416\u001b[0m src, dst, eid \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_graph\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43min_edges\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_etype_id\u001b[49m\u001b[43m(\u001b[49m\u001b[43metype\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mv\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   3417\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m form \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mall\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[1;32m   3418\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m src, dst, eid\n",
      "File \u001b[0;32m~/miniconda3/envs/se33/lib/python3.9/site-packages/dgl/heterograph_index.py:633\u001b[0m, in \u001b[0;36mHeteroGraphIndex.in_edges\u001b[0;34m(self, etype, v)\u001b[0m\n\u001b[1;32m    612\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21min_edges\u001b[39m(\u001b[38;5;28mself\u001b[39m, etype, v):\n\u001b[1;32m    613\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Return the in edges of the node(s).\u001b[39;00m\n\u001b[1;32m    614\u001b[0m \n\u001b[1;32m    615\u001b[0m \u001b[38;5;124;03m    Assume that node_type(v) == dst_type(etype). Thus, the ntype argument is omitted.\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    631\u001b[0m \u001b[38;5;124;03m        The edge ids.\u001b[39;00m\n\u001b[1;32m    632\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 633\u001b[0m     edge_array \u001b[38;5;241m=\u001b[39m \u001b[43m_CAPI_DGLHeteroInEdges_2\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mint\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43metype\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mF\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mto_dgl_nd\u001b[49m\u001b[43m(\u001b[49m\u001b[43mv\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    634\u001b[0m     src \u001b[38;5;241m=\u001b[39m F\u001b[38;5;241m.\u001b[39mfrom_dgl_nd(edge_array(\u001b[38;5;241m0\u001b[39m))\n\u001b[1;32m    635\u001b[0m     dst \u001b[38;5;241m=\u001b[39m F\u001b[38;5;241m.\u001b[39mfrom_dgl_nd(edge_array(\u001b[38;5;241m1\u001b[39m))\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "e=0\n",
    "running_tloss = 0 \n",
    "start = time.time()\n",
    "\n",
    "for batch_feats in dL:\n",
    "    \n",
    "    device='cuda'\n",
    "    batch_feats= tree.map_structure(\n",
    "                    lambda x: x.to(device), batch_feats)\n",
    "    noised_dict =   {'CA': batch_feats['CA_noised'] ,\n",
    "                     'N_CA': batch_feats['N_CA_noised'].unsqueeze(-2) ,\n",
    "                     'C_CA': batch_feats['C_CA_noised'].unsqueeze(-2)  }\n",
    "    \n",
    "    pred, train_loss = model_step(batch_feats, noised_dict, gm, gu, train=True)\n",
    "    opti.zero_grad()\n",
    "    train_loss.backward()\n",
    "    opti.step()\n",
    "    \n",
    "    running_tloss += train_loss.detach().cpu()\n",
    "    print('t')\n",
    "    \n",
    "    #n,p,t = get_noise_pred_true(batch_feats, noised_dict, gm, gu, scale=10)\n",
    "\n",
    "end = time.time()\n",
    "avg_tloss = running_tloss#/(i+1)\n",
    "print(f'Average Train Loss Epoch {e}: {avg_tloss};   Epoch time: {end-start:.0f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "381a3514",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[81], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i,batch_feats \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(dL):\n\u001b[1;32m      2\u001b[0m     \u001b[38;5;28mprint\u001b[39m(batch_feats[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mCA\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m0\u001b[39m])\n",
      "File \u001b[0;32m~/miniconda3/envs/se33/lib/python3.9/site-packages/torch/utils/data/dataloader.py:633\u001b[0m, in \u001b[0;36m_BaseDataLoaderIter.__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    630\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_sampler_iter \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    631\u001b[0m     \u001b[38;5;66;03m# TODO(https://github.com/pytorch/pytorch/issues/76750)\u001b[39;00m\n\u001b[1;32m    632\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_reset()  \u001b[38;5;66;03m# type: ignore[call-arg]\u001b[39;00m\n\u001b[0;32m--> 633\u001b[0m data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_next_data\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    634\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_num_yielded \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[1;32m    635\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_dataset_kind \u001b[38;5;241m==\u001b[39m _DatasetKind\u001b[38;5;241m.\u001b[39mIterable \u001b[38;5;129;01mand\u001b[39;00m \\\n\u001b[1;32m    636\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_IterableDataset_len_called \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m \\\n\u001b[1;32m    637\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_num_yielded \u001b[38;5;241m>\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_IterableDataset_len_called:\n",
      "File \u001b[0;32m~/miniconda3/envs/se33/lib/python3.9/site-packages/torch/utils/data/dataloader.py:677\u001b[0m, in \u001b[0;36m_SingleProcessDataLoaderIter._next_data\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    675\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_next_data\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[1;32m    676\u001b[0m     index \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_next_index()  \u001b[38;5;66;03m# may raise StopIteration\u001b[39;00m\n\u001b[0;32m--> 677\u001b[0m     data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_dataset_fetcher\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfetch\u001b[49m\u001b[43m(\u001b[49m\u001b[43mindex\u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# may raise StopIteration\u001b[39;00m\n\u001b[1;32m    678\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_pin_memory:\n\u001b[1;32m    679\u001b[0m         data \u001b[38;5;241m=\u001b[39m _utils\u001b[38;5;241m.\u001b[39mpin_memory\u001b[38;5;241m.\u001b[39mpin_memory(data, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_pin_memory_device)\n",
      "File \u001b[0;32m~/miniconda3/envs/se33/lib/python3.9/site-packages/torch/utils/data/_utils/fetch.py:51\u001b[0m, in \u001b[0;36m_MapDatasetFetcher.fetch\u001b[0;34m(self, possibly_batched_index)\u001b[0m\n\u001b[1;32m     49\u001b[0m         data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset\u001b[38;5;241m.\u001b[39m__getitems__(possibly_batched_index)\n\u001b[1;32m     50\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m---> 51\u001b[0m         data \u001b[38;5;241m=\u001b[39m [\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset[idx] \u001b[38;5;28;01mfor\u001b[39;00m idx \u001b[38;5;129;01min\u001b[39;00m possibly_batched_index]\n\u001b[1;32m     52\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m     53\u001b[0m     data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset[possibly_batched_index]\n",
      "File \u001b[0;32m~/miniconda3/envs/se33/lib/python3.9/site-packages/torch/utils/data/_utils/fetch.py:51\u001b[0m, in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m     49\u001b[0m         data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset\u001b[38;5;241m.\u001b[39m__getitems__(possibly_batched_index)\n\u001b[1;32m     50\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m---> 51\u001b[0m         data \u001b[38;5;241m=\u001b[39m [\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdataset\u001b[49m\u001b[43m[\u001b[49m\u001b[43midx\u001b[49m\u001b[43m]\u001b[49m \u001b[38;5;28;01mfor\u001b[39;00m idx \u001b[38;5;129;01min\u001b[39;00m possibly_batched_index]\n\u001b[1;32m     52\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m     53\u001b[0m     data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset[possibly_batched_index]\n",
      "Cell \u001b[0;32mIn[8], line 165\u001b[0m, in \u001b[0;36msmallPDBDataset.__getitem__\u001b[0;34m(self, idx)\u001b[0m\n\u001b[1;32m    163\u001b[0m             \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mNeed chain identifier.\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m    164\u001b[0m         processed_file_path \u001b[38;5;241m=\u001b[39m csv_row[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mprocessed_path\u001b[39m\u001b[38;5;124m'\u001b[39m]\n\u001b[0;32m--> 165\u001b[0m         chain_feats \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_process_csv_row\u001b[49m\u001b[43m(\u001b[49m\u001b[43mprocessed_file_path\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    167\u001b[0m         \u001b[38;5;66;03m# Use a fixed seed for evaluation.\u001b[39;00m\n\u001b[1;32m    168\u001b[0m \u001b[38;5;66;03m#         if self.is_training:\u001b[39;00m\n\u001b[1;32m    169\u001b[0m         rng \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mrandom\u001b[38;5;241m.\u001b[39mdefault_rng(\u001b[38;5;28;01mNone\u001b[39;00m)\n",
      "Cell \u001b[0;32mIn[8], line 109\u001b[0m, in \u001b[0;36msmallPDBDataset._process_csv_row\u001b[0;34m(self, processed_file_path)\u001b[0m\n\u001b[1;32m    107\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_process_csv_row\u001b[39m(\u001b[38;5;28mself\u001b[39m, processed_file_path):\n\u001b[0;32m--> 109\u001b[0m     processed_feats \u001b[38;5;241m=\u001b[39m \u001b[43mdu\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread_pkl\u001b[49m\u001b[43m(\u001b[49m\u001b[43mprocessed_file_path\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    110\u001b[0m     chain_feats \u001b[38;5;241m=\u001b[39m gudiff_parse_chain_feats(processed_feats,scale_factor\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m10.\u001b[39m)\n\u001b[1;32m    112\u001b[0m     \u001b[38;5;66;03m# Only take modeled residues.\u001b[39;00m\n",
      "File \u001b[0;32m/mnt/c/Users/nwood/OneDrive/Desktop/gudiff/se3_diffuse/utils.py:81\u001b[0m, in \u001b[0;36mread_pkl\u001b[0;34m(read_path, verbose, use_torch, map_location)\u001b[0m\n\u001b[1;32m     79\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m     80\u001b[0m         \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mopen\u001b[39m(read_path, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mrb\u001b[39m\u001b[38;5;124m'\u001b[39m) \u001b[38;5;28;01mas\u001b[39;00m handle:\n\u001b[0;32m---> 81\u001b[0m             \u001b[38;5;28;01mreturn\u001b[39;00m pickle\u001b[38;5;241m.\u001b[39mload(handle)\n\u001b[1;32m     82\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m     83\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "for i,batch_feats in enumerate(dL):\n",
    "    print(batch_feats['CA'].shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2fb8b9c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "t=0.05\n",
    "t_vec = np.ones((B,))*t\n",
    "print(t_vec)\n",
    "model_path = make_save_folder(name=f'fdiff_modelStep_doublecheck')\n",
    "num_epochs = 50\n",
    "e_start= 0\n",
    "save_per=10\n",
    "avg_vloss=0\n",
    "\n",
    "for e in range(e_start, e_start+num_epochs):\n",
    "    \n",
    "    running_tloss = 0 \n",
    "    start = time.time()\n",
    "    for i, bb_dict in enumerate(train_dL):\n",
    "        noised_bb, tv, ss = fdn.forward_fixed_nodes(bb_dict,t_vec=t_vec, useR3=useR3)\n",
    "        tv = tv.to('cuda')\n",
    "        ss = ss.to('cuda')\n",
    "        train_loss = model_step(bb_dict, noised_bb, tv, ss, gm, gu)\n",
    "        opti.zero_grad()\n",
    "        train_loss.backward()\n",
    "        opti.step()\n",
    "\n",
    "        running_tloss += train_loss.detach().cpu()\n",
    "    \n",
    "    end = time.time()\n",
    "    avg_tloss = running_tloss/(i+1)\n",
    "    print(f'Average Train Loss Epoch {e}: {avg_tloss};   Epoch time: {end-start:.0f}')\n",
    "\n",
    "    if e %save_per==save_per-1:\n",
    "        with torch.no_grad():\n",
    "            running_vloss = 0\n",
    "            for i, bb_dictv in enumerate(val_dL):\n",
    "                noised_bb, tv, ss = fdn.forward_fixed_nodes(bb_dictv,t_vec=None, useR3=useR3) #this does the opposite of traditional, upweighting lower\n",
    "                tv = tv.to('cuda')\n",
    "                ss = ss.to('cuda')\n",
    "                valid_loss = model_step(bb_dictv, noised_bb, tv, ss, gm, gu)\n",
    "                running_vloss += valid_loss\n",
    "                \n",
    "        avg_vloss = running_vloss/(i+1)\n",
    "        print(f'Average Valid Loss Epoch {e}: {avg_vloss}')\n",
    "                \n",
    "        noised_bb, tv, ss = fdn.forward_fixed_nodes(bb_dict, t_vec=vis_t)\n",
    "        tv = tv.to('cuda')\n",
    "        visualize_model(bb_dict, noised_bb, tv, e, numOut=8,outdir=f'{model_path}')\n",
    "        save_chkpt(f'{model_path}', gu, opti, e, B, avg_vloss, avg_tloss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d886a502",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3c9db18",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "se33",
   "language": "python",
   "name": "se33"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
