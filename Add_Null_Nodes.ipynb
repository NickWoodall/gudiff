{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "a02a1c0f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 99,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "#clear memory better\n",
    "with torch.no_grad():\n",
    "    torch.cuda.empty_cache()\n",
    "import numpy as np\n",
    "import util.npose_util as nu\n",
    "import os\n",
    "import pathlib\n",
    "import dgl\n",
    "from dgl import backend as F\n",
    "import torch_geometric\n",
    "from torch.utils.data import random_split, DataLoader, Dataset\n",
    "from typing import Dict\n",
    "from torch import Tensor\n",
    "from dgl import DGLGraph\n",
    "from torch import nn\n",
    "# from chemical import cos_ideal_NCAC #from RoseTTAFold2\n",
    "from torch import einsum\n",
    "import time\n",
    "torch.cuda.is_available()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "33e16cff",
   "metadata": {},
   "outputs": [],
   "source": [
    "import se3_diffuse.utils as du"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "id": "6a31f547",
   "metadata": {},
   "outputs": [],
   "source": [
    "from data_rigid_diffuser import so3_diffuser\n",
    "from data_rigid_diffuser import r3_diffuser\n",
    "from data_rigid_diffuser import oneHot_diffuser\n",
    "from scipy.spatial.transform import Rotation\n",
    "from data_rigid_diffuser import rigid_utils as ru\n",
    "import yaml\n",
    "from data_rigid_diffuser.diffuser import FrameDiffNoise\n",
    "from gudiff_model import Data_Graph\n",
    "from gudiff_model.Data_Graph import build_npose_from_coords, dump_coord_pdb, define_graph_edges, make_pe_encoding\n",
    "from gudiff_model.Data_Graph import Helix4_Dataset, Make_KNN_MP_Graphs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "id": "bf443f63",
   "metadata": {},
   "outputs": [],
   "source": [
    "from se3_transformer.model.basis import get_basis, update_basis_with_fused\n",
    "from se3_transformer.model.transformer import Sequential, SE3Transformer\n",
    "from se3_transformer.model.transformer_topk import SE3Transformer_topK\n",
    "from se3_transformer.model.FAPE_Loss import FAPE_loss, Qs2Rs, normQ\n",
    "from se3_transformer.model.layers.attentiontopK import AttentionBlockSE3\n",
    "from se3_transformer.model.layers.linear import LinearSE3\n",
    "from se3_transformer.model.layers.convolution import ConvSE3, ConvSE3FuseLevel\n",
    "from se3_transformer.model.layers.norm import NormSE3\n",
    "from se3_transformer.model.layers.pooling import GPooling, Latent_Unpool, Unpool_Layer\n",
    "from se3_transformer.runtime.utils import str2bool, to_cuda\n",
    "from se3_transformer.model.fiber import Fiber\n",
    "from se3_transformer.model.transformer import get_populated_edge_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "id": "c0babffd",
   "metadata": {},
   "outputs": [],
   "source": [
    "#indices for, unsure if needed\n",
    "CA = Data_Graph.CA\n",
    "N = Data_Graph.N\n",
    "C = Data_Graph.C\n",
    "\n",
    "# #find better way to incorporate coord_scale\n",
    "\n",
    "# #needed\n",
    "# N_CA_dist = (Data_Graph.N_CA_dist/10.).to('cuda')\n",
    "# C_CA_dist = (Data_Graph.C_CA_dist/10.).to('cuda')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "id": "e213e885",
   "metadata": {},
   "outputs": [],
   "source": [
    "# data_path_str  = 'data/h4_ca_coords.npz'\n",
    "# test_limit = 1028\n",
    "# rr = np.load(data_path_str)\n",
    "# ca_coords = [rr[f] for f in rr.files][0][:test_limit,:,:3]\n",
    "# ca_coords.shape\n",
    "\n",
    "# getting N-Ca, Ca-C vectors to add as typeI features\n",
    "#apa = apart helices for val/train split\n",
    "#tog = together helices for val/train split\n",
    "\n",
    "#mode for tablet\n",
    "apa_path_str  = 'data_npose/h4_apa_coords.npz'\n",
    "tog_path_str  = 'data_npose/h4_tog_coords.npz'\n",
    "\n",
    "#grab the first 3 atoms which are N,CA,C\n",
    "test_limit = 256\n",
    "rr = np.load(apa_path_str)\n",
    "coords_apa = [rr[f] for f in rr.files][0][:test_limit,:]\n",
    "\n",
    "rr = np.load(tog_path_str)\n",
    "coords_tog = [rr[f] for f in rr.files][0][:test_limit,:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "id": "f3eae2f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "B = 2\n",
    "L=65\n",
    "limit = 128\n",
    "h4_trainData = Helix4_Dataset(coords_tog[:limit])\n",
    "h4_valData = Helix4_Dataset(coords_apa[:limit])\n",
    "train_dL = DataLoader(h4_trainData, batch_size=B, shuffle=True, drop_last=True)\n",
    "val_dL   = DataLoader(h4_valData, batch_size=B, shuffle=True, drop_last=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "id": "7c785856",
   "metadata": {},
   "outputs": [],
   "source": [
    "L=65\n",
    "limit = 128\n",
    "prot_trainData = Data_Graph.ProteinBB_Dataset(coords_tog[:limit], n_nodes=128,\n",
    "              n_atoms=5, coord_div=10, cast_type=torch.float32)\n",
    "train_dL = DataLoader(prot_trainData, batch_size=B, shuffle=True, drop_last=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "id": "3fbf8e13",
   "metadata": {},
   "outputs": [],
   "source": [
    "testiter = iter(train_dL)\n",
    "bb_dict = next(testiter)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "id": "87f67d73",
   "metadata": {},
   "outputs": [],
   "source": [
    "from data_rigid_diffuser import diffuser"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "id": "24472ad5",
   "metadata": {},
   "outputs": [],
   "source": [
    "config_path='data_rigid_diffuser/base.yaml'\n",
    "\n",
    "        \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "id": "b2ac30f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "fnd = FrameDiffNoise(config_path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "id": "1f5d7d4f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def circular_pe_encoding(n_nodes=128,embed_dim=12, cast_type=torch.float32):\n",
    "    #positional encoding of node, all repeat every n_nodes\n",
    "    i_array = np.arange(1,(embed_dim/2)+1)\n",
    "    period = 2*np.pi\n",
    "    wk = period/(n_nodes)*i_array**2\n",
    "    t_array = np.arange(n_nodes)\n",
    "    si = torch.tensor(np.sin(wk*t_array.reshape((-1,1))))\n",
    "    ci = torch.tensor(np.cos(wk*t_array.reshape((-1,1))))\n",
    "    pe = torch.stack((si,ci),axis=2).reshape(t_array.shape[0],embed_dim).type(cast_type)\n",
    "    \n",
    "    return pe\n",
    "\n",
    "def monomer_null_knngraph(xyz,real_mask, k=2):\n",
    "    \"\"\"Takes in array of XYZ coordinates with null nodes repeated at termini.\n",
    "    \n",
    "    #Parameters\n",
    "    real_mask: mask determining residues of real and null nodes\n",
    "    \n",
    "    Returns Graph that has a linear connections between all nodes indices and knn graph based on real nodes distance\"\"\"\n",
    "    \n",
    "    #make knn_graph from real nodes only\n",
    "    #THERE ARE k PREDECESSORS FOR EACH NODE, SO CHECK DST \n",
    "    g_knn=dgl.knn_graph(xyz[real_mask],k=k,exclude_self=True) #this will make a batched 3d tensor if youwant\n",
    "\n",
    "    #prepare adjacent node graph that connects real to null and (all nodes)\n",
    "    n_nodes = xyz.shape[0]\n",
    "\n",
    "\n",
    "    #create arrays to shift node indices_ from knn_graph based at zero back to original number\n",
    "    knn_shift = torch.zeros((n_nodes,))\n",
    "\n",
    "    #use mask to assign nodes as real or null\n",
    "    #pulls the nodes out, as the real nodes will be assigned 0-len(real_nodes), and len(real_nodes) to end\n",
    "    #like what happens with g_knn graph creation, where index of real_nodes_src convert to node numbering in graph\n",
    "    #then null_nodes_src indexing + (len(real_nodes)) is equal to null node numbering in graph\n",
    "    node_index =  torch.arange(n_nodes)\n",
    "    real_nodes = node_index[real_mask==True]\n",
    "    null_nodes = node_index[real_mask==False]\n",
    "\n",
    "    # add null nodes to the end\n",
    "    g_knn.add_nodes(len(null_nodes))\n",
    "    #assign shifts as described above, from creating the graph will real nodes first then adding null nodes\n",
    "    #the real nodes will be assigned 0-len(real_nodes), and len(real_nodes) to end\n",
    "    knn_shift[:len(real_nodes)] = real_nodes\n",
    "    knn_shift[len(real_nodes):] = null_nodes\n",
    "\n",
    "    #convert the edges of knn_real+graph with adjacent graph added on top using knn_shift\n",
    "    #to a new src, dst graph (src_conv,dst_conv) that refers to the original node numbering\n",
    "    g_knn_src, g_knn_dst = g_knn.edges()\n",
    "\n",
    "    conv_src = torch.ones_like(g_knn_src,dtype=torch.int)\n",
    "    conv_dst = torch.ones_like(g_knn_dst,dtype=torch.int)\n",
    "\n",
    "    #index i of src_knn_shift = (new knn_graph node numbering, value at )\n",
    "    #(old graph node number) =  src_knn_shift[i] \n",
    "    #the real nodes will be assigned 0-len(real_nodes), and len(real_nodes) to end for null nodes\n",
    "    #set the real nodes first, then the null nodes\n",
    "    for i in range(real_nodes.shape[0]):\n",
    "        conv_src[g_knn_src==i] = knn_shift[i]\n",
    "        conv_dst[g_knn_dst==i] = knn_shift[i]\n",
    "\n",
    "    for j in range(1,null_nodes.shape[0]+1):\n",
    "        conv_src[g_knn_src==(i+j)] = knn_shift[i+j]\n",
    "        conv_dst[g_knn_dst==(i+j)] = knn_shift[i+j]\n",
    "\n",
    "\n",
    "\n",
    "    g = dgl.graph((conv_src,conv_dst))\n",
    "\n",
    "    src_start = torch.arange(n_nodes,dtype=torch.int) #positive direction\n",
    "    dst_start = torch.roll(src_start,-1) #negative dir\n",
    "    #add adjacent graph on top, simple remove repeats\n",
    "    g.add_edges(src_start,dst_start)\n",
    "    g_out = dgl.to_simple(g)\n",
    "    return g_out\n",
    "\n",
    "def decirc(graph_in):\n",
    "    \"\"\"Remove circular connections. Last node to first node\"\"\"\n",
    "    src,dst = graph_in.edges()\n",
    "\n",
    "    circfw = (src==graph_in.nodes().max()) & (dst==0) \n",
    "    circbw = (src==0) & (dst==graph_in.nodes().max())\n",
    "    both_circ = circfw | circbw\n",
    "    \n",
    "    src_out = src[~both_circ]\n",
    "    dst_out = dst[~both_circ]\n",
    "    \n",
    "    return dgl.graph((src_out,dst_out))\n",
    "\n",
    "def concat_monomer_graphs(graph_list):\n",
    "    \"\"\"Add single connection between each graph\"\"\"\n",
    "    \n",
    "    batched_graph = dgl.batch([decirc(g) for g in graph_list])\n",
    "    src = torch.zeros((len(graph_list),),dtype=torch.int64) \n",
    "    dst = torch.zeros_like(src)\n",
    "    \n",
    "    #recirc concats\n",
    "    nindex = 0\n",
    "    src[nindex] = 0\n",
    "    dst[nindex] = len(batched_graph.nodes())-1 #\n",
    "    \n",
    "    \n",
    "    for i in range(1,len(graph_list)):\n",
    "        src[i] = graph_list[nindex].nodes().max()+nindex\n",
    "        dst[i] = src[i]+1\n",
    "        nindex = src[i]\n",
    "    \n",
    "    \n",
    "    batched_graph.add_edges(src,dst)\n",
    "    batched_graph.add_edges(dst,src)\n",
    "    \n",
    "    return batched_graph\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 411,
   "id": "20303394",
   "metadata": {},
   "outputs": [],
   "source": [
    "#this should probably be already transferred to GPU for speed\n",
    "class Make_nullKNN_MP_Graphs():\n",
    "    \n",
    "    #8 long positional encoding\n",
    "    NODE_FEATURE_DIM_0 = 12\n",
    "    EDGE_FEATURE_DIM = 1 # 0 or 1 primary seq connection or not\n",
    "    NODE_FEATURE_DIM_1 = 2\n",
    "    \n",
    "    def __init__(self, KNN=30, mp_stride=4, n_nodes=128, coord_div=10, \n",
    "                       cast_type=torch.float32, channels_start=32,\n",
    "                       ndf1=6, ndf0=32,cuda=True):\n",
    "        \n",
    "        self.KNN = KNN\n",
    "        self.n_nodes = n_nodes\n",
    "        self.pe = circular_pe_encoding(n_nodes=n_nodes,embed_dim=12, cast_type=torch.float32)\n",
    "        self.mp_stride = mp_stride\n",
    "        self.null_stride = mp_stride*2\n",
    "        self.cast_type = cast_type\n",
    "        self.channels_start = channels_start\n",
    "        \n",
    "        self.cuda = cuda\n",
    "        self.ndf1 = ndf1 #awkard adding of nodes features to mpGraph\n",
    "        self.ndf0 = ndf0\n",
    "        \n",
    "        \n",
    "    def create_and_batch(self, bb_dict, print_out=False):\n",
    "\n",
    "        graphList = []\n",
    "        mpGraphList = []\n",
    "        mpRevGraphList = []\n",
    "        mpSelfGraphList = []\n",
    "        \n",
    "        for j, caXYZ in enumerate(bb_dict['bb_noised']['CA']):\n",
    "            #round nodes to be real (1) or (null 0)\n",
    "            #get null node indices from mask\n",
    "            real_nodes_feats = torch.round(bb_dict['real_nodes_noise'][j]).clamp(0,1)\n",
    "            real_nodes_mask = real_nodes_feats.sum(-1)>1.99\n",
    "            \n",
    "            #make a knn graph form the real nodes only\n",
    "            graph = monomer_null_knngraph(caXYZ, real_nodes_mask, k=self.KNN)\n",
    "            graph.ndata['pe'] = torch.cat((self.pe,real_nodes_feats),dim=-1)\n",
    "            graph.ndata['pos'] = caXYZ\n",
    "            graph.ndata['bb_ori'] = torch.cat((bb_dict['bb_noised']['N_CA'][j], bb_dict['bb_noised']['C_CA'][j]),axis=1)\n",
    "            graph.ndata['real_nodes_mask']=real_nodes_mask\n",
    "            \n",
    "            #gather edge data from all possible noised edges produced\n",
    "            gsrc, gdst = graph.edges()\n",
    "            num_edges = len(gsrc)\n",
    "\n",
    "            #adjacent AA are one apart, or the loop connection from zero node to the last node\n",
    "            adj_nodes_mask = ((torch.abs(gsrc-gdst)==1) | (torch.abs(gsrc-gdst)==len(gsrc)-1)) \n",
    "\n",
    "            #actually we need to determine\n",
    "            null_nodes = torch.arange(self.n_nodes,dtype=torch.int)[~real_nodes_mask]\n",
    "            real_nodes = torch.arange(self.n_nodes,dtype=torch.int)[real_nodes_mask]\n",
    "\n",
    "            #broadcast each src/dst node against all null nodes, if any match along node dimension is a null edge\n",
    "            gsrc_compare = (gsrc[:,None] - null_nodes[None,:])\n",
    "            gdst_compare = (gdst[:,None] - null_nodes[None,:])\n",
    "            null_edges_src_ind = torch.where(gsrc_compare==0,True,False).any(dim=1)\n",
    "            null_edges_dst_ind = torch.where(gdst_compare==0,True,False).any(dim=1)\n",
    "\n",
    "            #broadcast each src/dst node against all real or null nodes, if any match along node dimension is a null edge\n",
    "            gsrc_compare = (gsrc[:,None] - real_nodes[None,:])\n",
    "            gdst_compare = (gdst[:,None] - real_nodes[None,:])\n",
    "            real_edges_src_ind = torch.where(gsrc_compare==0,True,False).any(dim=1)\n",
    "            real_edges_dst_ind = torch.where(gdst_compare==0,True,False).any(dim=1)\n",
    "            #null edges connect to any null nodes (|), real edges must both be real (&)\n",
    "            null_edges = null_edges_src_ind | null_edges_dst_ind\n",
    "            real_edges = real_edges_src_ind & real_edges_dst_ind\n",
    "            adj_real = adj_nodes_mask&real_edges\n",
    "\n",
    "            #is this needed, taken care of a node\n",
    "\n",
    "            EDGE_DIM=1\n",
    "\n",
    "            ###\n",
    "#             enoised = noised_dict['edge_cons'][j]\n",
    "#             enoised = enoised.reshape((-1,EDGE_DIM,2))[:num_edges]\n",
    "            edata = torch.zeros(gsrc.shape+(EDGE_DIM,))\n",
    "            # oh1_mask = torch.tensor([1,0,0]).unsqueeze(-1)\n",
    "            # oh2_mask = torch.tensor([0,1,0]).unsqueeze(-1)\n",
    "            # oh3_mask = torch.tensor([0,0,1]).unsqueeze(-1)\n",
    "\n",
    "\n",
    "            # #needs to add - /+ N/C directon for this data????, or is this covered by pe encoding\n",
    "            # edata[real_edges] = torch.gather(enoised[real_edges],2,oh2_mask.repeat(real_edges.sum(),1,1))[:,:,0]\n",
    "            # edata[adj_real] = torch.gather(enoised[adj_real],2,oh1_mask.repeat(adj_real.sum(),1,1))[:,:,0]\n",
    "            # edata[null_edges] = torch.gather(enoised[null_edges],2,oh3_mask.repeat(null_edges.sum(),1,1))[:,:,0]\n",
    "\n",
    "            # edge_dir = torch.ones_like(gsrc,dtype=torch.long) #NotC direction off AA sequence\n",
    "            # edge_dir[gdst<gsrc]=-1 # #NotC; reverse direction \n",
    "            # edata[adj_nodes_mask]=edata[adj_nodes_mask]*edge_dir\n",
    "\n",
    "            graph.edata['con'] = edata\n",
    "\n",
    "            #way to get real_edges and null edges in loop code\n",
    "            # null_edges = torch.zeros_like(gsrc)\n",
    "            # for i,x in enumerate(gsrc):\n",
    "            #     if gsrc[i] in null_nodes or gdst[i] in null_nodes:\n",
    "            #         null_edges[i] = 1\n",
    "\n",
    "            # real_edges = torch.zeros_like(gsrc)\n",
    "            # for i,x in enumerate(gsrc):\n",
    "            #     if gsrc[i] in real_nodes and gdst[i] in real_nodes:\n",
    "            #         real_edges[i] = 1\n",
    "\n",
    "            mp_list = torch.zeros((len(list(range(0,len(real_nodes), self.mp_stride)))),caXYZ.shape[1])\n",
    "\n",
    "            new_src = torch.tensor([],dtype=torch.int)\n",
    "            new_dst = torch.tensor([],dtype=torch.int)\n",
    "\n",
    "\n",
    "            new_src_rev = torch.tensor([], dtype=torch.int)\n",
    "            new_dst_rev = torch.tensor([], dtype=torch.int)\n",
    "\n",
    "            #create\n",
    "            i=0#mp list counter\n",
    "            for real_index in range(0,len(real_nodes), self.mp_stride):\n",
    "                x = real_nodes[real_index] #convert to match torch.int from\n",
    "                src, dst = graph.in_edges(x) #dst repeats x, this grab null nodes too\n",
    "                \n",
    "                n_tot = torch.cat((x.unsqueeze(0),src)) #add x to node list\n",
    "                mp_list[i] = caXYZ[n_tot].sum(axis=0)/n_tot.shape[0]\n",
    "                mp_node = i + graph.num_nodes() #add midpoints nodes at end of graph\n",
    "                #define edges between midpoint nodes and nodes defining midpoint for midpointGraph\n",
    "\n",
    "                new_src = torch.cat((new_src,n_tot))\n",
    "                new_dst = torch.cat((new_dst,\n",
    "                                     (torch.tensor(mp_node,dtype=torch.int).unsqueeze(0).repeat(n_tot.shape[0]))))\n",
    "                \n",
    "#                 #and reverse graph for coming off\n",
    "#                 new_src_rev = torch.cat((new_src_rev,\n",
    "#                                          (torch.tensor(mp_node,dtype=torch.int).unsqueeze(0).repeat(n_tot.shape[0]))))\n",
    "#                 new_dst_rev = torch.cat((new_dst_rev,n_tot))\n",
    "\n",
    "                i+=1\n",
    "                \n",
    "            #remove extra null nodes from .in_edges call\n",
    "            \n",
    "            #remove edges that are null node connections,\n",
    "            #dst are the midpoint nodes for mpGraph, src are mp nodes for mpGraphRev\n",
    "            #only remove non-mp nodes\n",
    "            \n",
    "            real_mask_rem1 = torch.isin(new_src,real_nodes)\n",
    "#             real_mask_rem2 = torch.isin(new_dst_rev,real_nodes) \n",
    "            new_src = new_src[real_mask_rem1]\n",
    "            new_dst = new_dst[real_mask_rem1]\n",
    "#             new_src_rev = new_src_rev[real_mask_rem2]\n",
    "#             new_dst_rev = new_dst_rev[real_mask_rem2]\n",
    "                \n",
    "                \n",
    "            #collapse collected null nodes onto null mp of contingous sections \n",
    "            end_p = ((null_nodes.roll(1)-null_nodes)==-1) #consecutive are equal to negative one (look right)\n",
    "            start_p = ((null_nodes.roll(-1)-null_nodes)==1) #consecutive are equal to one (look left)\n",
    "            startend = (start_p != end_p) #remove overlap of interior consecutive nodes\n",
    "            start = start_p == startend #just get the starts\n",
    "            end  = end_p == startend #just get the ends\n",
    "            si = torch.arange(len(start),dtype=torch.int)[start]# indices of start of consecutive nodes\n",
    "            ei = torch.arange((len(end)),dtype=torch.int)[end] # indices of end of cone\n",
    "\n",
    "            #connect first and last groups if approriate\n",
    "            if null_nodes[0]==0 and null_nodes[-1]==self.n_nodes-1:\n",
    "                #roll last group across barrier\n",
    "                roll_con = len(start)-si[-1]\n",
    "                null_nodes = null_nodes.roll(int(roll_con))\n",
    "                #update end index and start index by roll and remove groups (one from end)\n",
    "                #add zero to start and remove last start (rolled)\n",
    "                ei = (ei+roll_con)[:-1]\n",
    "                sic=torch.zeros_like(si[1:])\n",
    "                sic[1:] = si[1:-1]+roll_con\n",
    "                si = sic\n",
    "\n",
    "            mp_list_null  = torch.ones((si.shape[0],caXYZ.shape[1]))*-1e9\n",
    "\n",
    "            counter_mp_index = 0 #mp list counter\n",
    "            counter_mp_node = 0 #counter for number of mp nodes added, \n",
    "            tot_indices = si.shape[0]\n",
    "            while counter_mp_index < tot_indices:\n",
    "                #coll\n",
    "                #print(null_nodes[si[counter_mp_index]:ei[counter_mp_index]+1])\n",
    "                n_tot = null_nodes[si[counter_mp_index]:ei[counter_mp_index]+1]\n",
    "            #                 print(len(n_tot))\n",
    "                while len(n_tot) <  mkg.mp_stride and counter_mp_index+1<tot_indices:\n",
    "                    counter_mp_index=counter_mp_index+1\n",
    "                    n_tot = torch.cat([n_tot,null_nodes[si[counter_mp_index]:ei[counter_mp_index]+1]],axis=0)\n",
    "\n",
    "                mp_list_null[counter_mp_index] = caXYZ[n_tot].sum(axis=0)/n_tot.shape[0]\n",
    "                mp_node = counter_mp_node + i + graph.num_nodes() #add midpoints nodes at end of graph\n",
    "                counter_mp_node += 1\n",
    "\n",
    "                #from null nodes to new mp_node\n",
    "                new_src = torch.cat((new_src,n_tot))\n",
    "                new_dst = torch.cat((new_dst,\n",
    "                                     (torch.tensor(mp_node,dtype=torch.int).unsqueeze(0).repeat(n_tot.shape[0]))))\n",
    "                #and reverse graph for coming off\n",
    "                new_src_rev = torch.cat((new_src_rev,\n",
    "                                         (torch.tensor(mp_node,dtype=torch.int).unsqueeze(0).repeat(n_tot.shape[0]))))\n",
    "                new_dst_rev = torch.cat((new_dst_rev,n_tot))\n",
    "\n",
    "                counter_mp_index=counter_mp_index+1\n",
    "\n",
    "            mp_list_null = mp_list_null[(mp_list_null>-1e8).any(axis=1)]\n",
    "            mp_list_real_null = torch.cat([mp_list,mp_list_null])\n",
    "            mp_node_indx = torch.arange(0,i+len(mp_list_null)).type(torch.int)\n",
    "\n",
    "            mpGraph = dgl.graph((new_src,new_dst))\n",
    "            mp_pos = torch.cat((caXYZ,mp_list_real_null),axis=0).type(self.cast_type)\n",
    "\n",
    "            mpGraph = dgl.graph((new_src,new_dst))\n",
    "            mpGraph.ndata['pos'] = torch.cat((caXYZ,mp_list_real_null),axis=0).type(self.cast_type)\n",
    "            \n",
    "            #mp real/ null nodes\n",
    "            mp_node_real_mask = torch.zeros(mp_list_real_null.shape[0],dtype=torch.int)\n",
    "            mp_node_real_mask[:len(mp_list)] = 1\n",
    "            mpGraph.ndata['mp_node_real_mask'] = torch.cat([real_nodes_mask,mp_node_real_mask])\n",
    "            #match output shape of first transformer\n",
    "            pe_mp = torch.cat((self.pe,torch.zeros((self.pe.shape[0], self.channels_start-self.pe.shape[1]))),axis=1)\n",
    "            mpGraph.ndata['pe'] = torch.cat((pe_mp,pe_mp[mp_node_indx]))\n",
    "            mpGraph.edata['con'] = torch.zeros((mpGraph.num_edges(),1))\n",
    "\n",
    "            #mpGraph_rev = dgl.graph((new_src_rev,new_dst_rev))\n",
    "            mpGraph_rev = dgl.graph((new_dst,new_src))\n",
    "            mpGraph_rev.ndata['pos'] = torch.cat((caXYZ, mp_list_real_null),axis=0).type(self.cast_type)\n",
    "            mpGraph_rev.ndata['pe'] = torch.cat((pe_mp,pe_mp[mp_node_indx]))\n",
    "            mpGraph_rev.edata['con'] = torch.zeros((mpGraph_rev.num_edges(),1))\n",
    "            mpGraph_rev.ndata['mp_node_real_mask'] = torch.cat([real_nodes_mask,mp_node_real_mask])\n",
    "\n",
    "            #make graph for self interaction of midpoints\n",
    "            v1,v2,edge_data, ind = define_graph_edges(len(mp_list_real_null))\n",
    "            mpSelfGraph = dgl.graph((v1,v2))\n",
    "            mpSelfGraph.edata['con'] = edge_data.reshape((-1,1))\n",
    "            mpSelfGraph.ndata['pe'] = self.pe[mp_node_indx] #not really needed\n",
    "            mpSelfGraph.ndata['pos'] = mp_list_real_null.type(self.cast_type)\n",
    "\n",
    "\n",
    "\n",
    "            mpSelfGraphList.append(mpSelfGraph)\n",
    "            mpGraphList.append(mpGraph)\n",
    "            mpRevGraphList.append(mpGraph_rev)\n",
    "            graphList.append(graph)\n",
    "       \n",
    "        return dgl.batch(graphList), dgl.batch(mpGraphList), dgl.batch(mpSelfGraphList), dgl.batch(mpRevGraphList)\n",
    "        \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 412,
   "id": "42d1e972",
   "metadata": {},
   "outputs": [],
   "source": [
    "noised_dict = fnd.forward(bb_dict,t_vec=np.ones((B,))*0.0001)\n",
    "#edges are Batch, Length, KNN, 3, bool  \n",
    "#each edge represents real adj, fake dist\n",
    "mkg = Make_nullKNN_MP_Graphs()\n",
    " #real and direct connect, real and non-direct, false and direct # no false and not direct"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 413,
   "id": "71ce0392",
   "metadata": {},
   "outputs": [],
   "source": [
    "mpSelfGraph,mpGraph,mpGraph_rev,graph = mkg.create_and_batch(noised_dict,print_out=True)\n",
    "# np.arange(len(graph.nodes()))[graph.ndata['real_nodes_mask']]\n",
    "# s,d = graph.edges()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "se33",
   "language": "python",
   "name": "se33"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
