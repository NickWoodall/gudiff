{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a02a1c0f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "#clear memory better\n",
    "with torch.no_grad():\n",
    "    torch.cuda.empty_cache()\n",
    "import numpy as np\n",
    "import util.npose_util as nu\n",
    "import os\n",
    "import pathlib\n",
    "import dgl\n",
    "from dgl import backend as F\n",
    "import torch_geometric\n",
    "from torch.utils.data import random_split, DataLoader, Dataset\n",
    "from typing import Dict\n",
    "from torch import Tensor\n",
    "from dgl import DGLGraph\n",
    "from torch import nn\n",
    "# from chemical import cos_ideal_NCAC #from RoseTTAFold2\n",
    "from torch import einsum\n",
    "import time\n",
    "torch.cuda.is_available()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "33e16cff",
   "metadata": {},
   "outputs": [],
   "source": [
    "import se3_diffuse.utils as du"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "6a31f547",
   "metadata": {},
   "outputs": [],
   "source": [
    "from data_rigid_diffuser import so3_diffuser\n",
    "from data_rigid_diffuser import r3_diffuser\n",
    "from data_rigid_diffuser import oneHot_diffuser\n",
    "from scipy.spatial.transform import Rotation\n",
    "from data_rigid_diffuser import rigid_utils as ru\n",
    "import yaml\n",
    "from data_rigid_diffuser.diffuser import FrameDiffNoise\n",
    "from gudiff_model import Data_Graph\n",
    "from gudiff_model.Data_Graph import build_npose_from_coords, dump_coord_pdb, define_graph_edges, make_pe_encoding\n",
    "from gudiff_model.Data_Graph import Helix4_Dataset, Make_KNN_MP_Graphs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "bf443f63",
   "metadata": {},
   "outputs": [],
   "source": [
    "from se3_transformer.model.basis import get_basis, update_basis_with_fused\n",
    "from se3_transformer.model.transformer import Sequential, SE3Transformer\n",
    "from se3_transformer.model.transformer_topk import SE3Transformer_topK\n",
    "from se3_transformer.model.FAPE_Loss import FAPE_loss, Qs2Rs, normQ\n",
    "from se3_transformer.model.layers.attentiontopK import AttentionBlockSE3\n",
    "from se3_transformer.model.layers.linear import LinearSE3\n",
    "from se3_transformer.model.layers.convolution import ConvSE3, ConvSE3FuseLevel\n",
    "from se3_transformer.model.layers.norm import NormSE3\n",
    "from se3_transformer.model.layers.pooling import GPooling, Latent_Unpool, Unpool_Layer\n",
    "from se3_transformer.runtime.utils import str2bool, to_cuda\n",
    "from se3_transformer.model.fiber import Fiber\n",
    "from se3_transformer.model.transformer import get_populated_edge_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "c0babffd",
   "metadata": {},
   "outputs": [],
   "source": [
    "#indices for, unsure if needed\n",
    "CA = Data_Graph.CA\n",
    "N = Data_Graph.N\n",
    "C = Data_Graph.C\n",
    "\n",
    "# #find better way to incorporate coord_scale\n",
    "\n",
    "# #needed\n",
    "# N_CA_dist = (Data_Graph.N_CA_dist/10.).to('cuda')\n",
    "# C_CA_dist = (Data_Graph.C_CA_dist/10.).to('cuda')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "e213e885",
   "metadata": {},
   "outputs": [],
   "source": [
    "# data_path_str  = 'data/h4_ca_coords.npz'\n",
    "# test_limit = 1028\n",
    "# rr = np.load(data_path_str)\n",
    "# ca_coords = [rr[f] for f in rr.files][0][:test_limit,:,:3]\n",
    "# ca_coords.shape\n",
    "\n",
    "# getting N-Ca, Ca-C vectors to add as typeI features\n",
    "#apa = apart helices for val/train split\n",
    "#tog = together helices for val/train split\n",
    "\n",
    "#mode for tablet\n",
    "apa_path_str  = 'data_npose/h4_apa_coords.npz'\n",
    "tog_path_str  = 'data_npose/h4_tog_coords.npz'\n",
    "\n",
    "#grab the first 3 atoms which are N,CA,C\n",
    "test_limit = 256\n",
    "rr = np.load(apa_path_str)\n",
    "coords_apa = [rr[f] for f in rr.files][0][:test_limit,:]\n",
    "\n",
    "rr = np.load(tog_path_str)\n",
    "coords_tog = [rr[f] for f in rr.files][0][:test_limit,:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "f3eae2f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "B = 32\n",
    "L=65\n",
    "limit = 128\n",
    "h4_trainData = Helix4_Dataset(coords_tog[:limit])\n",
    "h4_valData = Helix4_Dataset(coords_apa[:limit])\n",
    "train_dL = DataLoader(h4_trainData, batch_size=B, shuffle=True, drop_last=True)\n",
    "val_dL   = DataLoader(h4_valData, batch_size=B, shuffle=True, drop_last=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "7c785856",
   "metadata": {},
   "outputs": [],
   "source": [
    "B = 32\n",
    "L=65\n",
    "limit = 128\n",
    "prot_trainData = Data_Graph.ProteinBB_Dataset(coords_tog[:limit], n_nodes=128,\n",
    "              n_atoms=5, coord_div=10, cast_type=torch.float32)\n",
    "train_dL = DataLoader(prot_trainData, batch_size=B, shuffle=True, drop_last=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "3fbf8e13",
   "metadata": {},
   "outputs": [],
   "source": [
    "testiter = iter(train_dL)\n",
    "bb_dict = next(testiter)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "87f67d73",
   "metadata": {},
   "outputs": [],
   "source": [
    "from data_rigid_diffuser import diffuser"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "24472ad5",
   "metadata": {},
   "outputs": [],
   "source": [
    "config_path='data_rigid_diffuser/base.yaml'\n",
    "\n",
    "        \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "b2ac30f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "fnd = FrameDiffNoise(config_path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "669a2fac",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/mnt/c/Users/nwood/OneDrive/Desktop/gudiff/data_rigid_diffuser/diffuser.py:209: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at /opt/conda/conda-bld/pytorch_1682343997789/work/torch/csrc/utils/tensor_new.cpp:245.)\n",
      "  node_type_noised = torch.tensor([self.ohd.forward_marginal(expand_node_type[i].numpy(),t)[0] for i,t in enumerate(t_vec)])\n"
     ]
    }
   ],
   "source": [
    "noised_dict = fnd.forward(bb_dict,t_vec=np.ones((B,))*0.03)\n",
    "#edges are Batch, Length, KNN, 3, bool  \n",
    "#each edge represents real adj, fake dist\n",
    "\n",
    " #real and direct connect, real and non-direct, false and direct # no false and not direct"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "1f5d7d4f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def circular_pe_encoding(n_nodes=128,embed_dim=12, cast_type=torch.float32):\n",
    "    #positional encoding of node, all repeat every n_nodes\n",
    "    i_array = np.arange(1,(embed_dim/2)+1)\n",
    "    period = 2*np.pi\n",
    "    wk = period/(n_nodes)*i_array**2\n",
    "    t_array = np.arange(n_nodes)\n",
    "    si = torch.tensor(np.sin(wk*t_array.reshape((-1,1))))\n",
    "    ci = torch.tensor(np.cos(wk*t_array.reshape((-1,1))))\n",
    "    pe = torch.stack((si,ci),axis=2).reshape(t_array.shape[0],embed_dim).type(cast_type)\n",
    "    \n",
    "    return pe\n",
    "\n",
    "#test code\n",
    "#n_nodes = 6\n",
    "#src_start = torch.arange(n_nodes) #positive direction\n",
    "#dst_start = torch.roll(src_start,-1) #negative dir\n",
    "#xyz = torch.arange(n_nodes)[:,None].repeat((1,3))\n",
    "#xyz[-1] = torch.tensor([4,4,4])\n",
    "#xyz[0] = torch.tensor([1,1,1])\n",
    "#mask = torch.tensor([False,True,True,True,True,False])\n",
    "#mask = torch.tensor([False,True,False,True,True,False])\n",
    "\n",
    "\n",
    "def monomer_knngraph(xyz,real_mask, k=2):\n",
    "    \"\"\"Takes in array of XYZ coordinates with null nodes repeated at termini.\n",
    "    \n",
    "    #Parameters\n",
    "    real_mask: mask determining residues of real and null nodes\n",
    "    \n",
    "    Returns Graph that has a linear connections between all nodes indices\"\"\"\n",
    "    \n",
    "    n_nodes = xyz.shape[0]\n",
    "    src_start = torch.arange(n_nodes) #positive direction\n",
    "    dst_start = torch.roll(src_start,-1) #negative dir\n",
    "    \n",
    "    #ma\n",
    "    real_nodes_src = src_start[real_mask==True]\n",
    "    null_nodes_src = src_start[real_mask==False]\n",
    "    real_nodes_dst = dst_start[real_mask==True]\n",
    "    null_nodes_dst = dst_start[real_mask==False]\n",
    "\n",
    "    g_knn=dgl.knn_graph(xyz[real_mask],k=k,exclude_self=True) # normal graph\n",
    "    g_knn.add_nodes(len(null_nodes_src)) # null nodes to the end\n",
    "\n",
    "    src_knn_shift = torch.zeros_like(src_start)\n",
    "    dst_knn_shift = torch.zeros_like(dst_start)\n",
    "\n",
    "    src_knn_shift[:len(real_nodes_src)] = real_nodes_src\n",
    "    src_knn_shift[len(real_nodes_src):] = null_nodes_src\n",
    "    dst_knn_shift[:len(real_nodes_src)] = real_nodes_dst\n",
    "    dst_knn_shift[len(real_nodes_src):] = null_nodes_dst\n",
    "\n",
    "    g_nodes_index = src_start#torch.arange(n_nodes) \n",
    "    src = g_nodes_index[src_knn_shift]\n",
    "    dst = g_nodes_index[dst_knn_shift]\n",
    "    \n",
    "    knn_src, knn_dst = g_knn.edges()\n",
    "    for i,nullnode in enumerate(null_nodes_src):\n",
    "        knn_src[knn_src==null_nodes_src[i]] = real_nodes_src[i]\n",
    "        knn_dst[knn_dst==null_nodes_dst[i]] = real_nodes_dst[i]\n",
    "    \n",
    "    g = dgl.graph((knn_src,knn_dst))\n",
    "\n",
    "    #can just add edges on top, simple to delete parallel; \n",
    "    g.add_edges(src,dst) \n",
    "    g.add_edges(dst,src)\n",
    "    g = dgl.to_simple(g)\n",
    "\n",
    "    return g\n",
    "\n",
    "def decirc(graph_in):\n",
    "    \"\"\"Remove circular connections. Last node to first node\"\"\"\n",
    "    src,dst = graph_in.edges()\n",
    "\n",
    "    circfw = (src==graph_in.nodes().max()) & (dst==0) \n",
    "    circbw = (src==0) & (dst==graph_in.nodes().max())\n",
    "    both_circ = circfw | circbw\n",
    "    \n",
    "    src_out = src[~both_circ]\n",
    "    dst_out = dst[~both_circ]\n",
    "    \n",
    "    return dgl.graph((src_out,dst_out))\n",
    "\n",
    "def concat_monomer_graphs(graph_list):\n",
    "    \"\"\"Add single connection between each graph\"\"\"\n",
    "    \n",
    "    batched_graph = dgl.batch([decirc(g) for g in graph_list])\n",
    "    src = torch.zeros((len(graph_list),),dtype=torch.int64) \n",
    "    dst = torch.zeros_like(src)\n",
    "    \n",
    "    #recirc concats\n",
    "    nindex = 0\n",
    "    src[nindex] = 0\n",
    "    dst[nindex] = len(batched_graph.nodes())-1 #\n",
    "    \n",
    "    \n",
    "    for i in range(1,len(graph_list)):\n",
    "        src[i] = graph_list[nindex].nodes().max()+nindex\n",
    "        dst[i] = src[i]+1\n",
    "        nindex = src[i]\n",
    "    \n",
    "    \n",
    "    batched_graph.add_edges(src,dst)\n",
    "    batched_graph.add_edges(dst,src)\n",
    "    \n",
    "    return batched_graph\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "20303394",
   "metadata": {},
   "outputs": [],
   "source": [
    "#this should probably be already transferred to GPU for speed\n",
    "class Make_nullKNN_MP_Graphs():\n",
    "    \n",
    "    #8 long positional encoding\n",
    "    NODE_FEATURE_DIM_0 = 12\n",
    "    EDGE_FEATURE_DIM = 1 # 0 or 1 primary seq connection or not\n",
    "    NODE_FEATURE_DIM_1 = 2\n",
    "    \n",
    "    def __init__(self, KNN=30, mp_stride=4, n_nodes=128, coord_div=10, \n",
    "                       cast_type=torch.float32, channels_start=32,\n",
    "                       ndf1=6, ndf0=32,cuda=True):\n",
    "        \n",
    "        self.KNN = KNN\n",
    "        self.n_nodes = n_nodes\n",
    "        self.pe = circular_pe_encoding(n_nodes=n_nodes,embed_dim=12, cast_type=torch.float32)\n",
    "        self.mp_stride = mp_stride\n",
    "        self.cast_type = cast_type\n",
    "        self.channels_start = channels_start\n",
    "        \n",
    "        self.cuda = cuda\n",
    "        self.ndf1 = ndf1 #awkard adding of nodes features to mpGraph\n",
    "        self.ndf0 = ndf0\n",
    "        \n",
    "        \n",
    "    def create_and_batch(self, bb_dict):\n",
    "        \n",
    "        graphList = []\n",
    "        mpGraphList = []\n",
    "        mpRevGraphList = []\n",
    "        mpSelfGraphList = []\n",
    "        \n",
    "        for j, caXYZ in enumerate(bb_dict['bb_noised']['CA']):\n",
    "            #round nodes to be real (1) or (null 0)\n",
    "            #get null node indices from mask\n",
    "            real_nodes_feats = torch.round(noised_dict['real_nodes_noise'][0]).clamp(0,1)\n",
    "            real_nodes_mask = real_nodes_feats.sum(-1)>2.99\n",
    "            print(real_nodes_mask)\n",
    "            \n",
    "            graph = monomer_knngraph(caXYZ, real_nodes_mask, k=self.KNN)\n",
    "            graph.ndata['pe'] = torch.cat((self.pe,real_nodes_feats),dim=-1)\n",
    "            graph.ndata['pos'] = caXYZ\n",
    "            graph.ndata['bb_ori'] = torch.cat((bb_dict['bb_noised']['N_CA'][j],  bb_dict['bb_noised']['C_CA'][j]),axis=1)\n",
    "            \n",
    "            #gather edge data from all possible noised edges produced\n",
    "            gsrc, gdst = graph.edges()\n",
    "            num_edges = len(gsrc)\n",
    "            \n",
    "            #adjacent AA are one apart, or the loop connection from zero node to the last node\n",
    "            adj_nodes_mask = ((torch.abs(gsrc-gdst)==1) | (torch.abs(gsrc-gdst)==len(gsrc)-1)) \n",
    "\n",
    "            \n",
    "            \n",
    "            #actually we need to determine\n",
    "            null_nodes = torch.arange(self.n_nodes)[~real_nodes_mask]\n",
    "            real_nodes = torch.arange(self.n_nodes)[real_nodes_mask]\n",
    "            graph.ndata['real_nodes'] = ~real_nodes_mask\n",
    "            graph.ndata['null_nodes'] =  real_nodes_mask\n",
    "\n",
    "            #broadcast each src/dst node against all null nodes, if any match along node dimension is a null edge\n",
    "            gsrc_compare = (gsrc[:,None] - null_nodes[None,:])\n",
    "            gdst_compare = (gdst[:,None] - null_nodes[None,:])\n",
    "            null_edges_src_ind = torch.where(gsrc_compare==0,True,False).any(dim=1)\n",
    "            null_edges_dst_ind = torch.where(gdst_compare==0,True,False).any(dim=1)\n",
    "            \n",
    "            #broadcast each src/dst node against all real or null nodes, if any match along node dimension is a null edge\n",
    "            gsrc_compare = (gsrc[:,None] - real_nodes[None,:])\n",
    "            gdst_compare = (gdst[:,None] - real_nodes[None,:])\n",
    "            real_edges_src_ind = torch.where(gsrc_compare==0,True,False).any(dim=1)\n",
    "            real_edges_dst_ind = torch.where(gdst_compare==0,True,False).any(dim=1)\n",
    "\n",
    "            null_edges = null_edges_src_ind | null_edges_dst_ind\n",
    "            real_edges = real_edges_src_ind & real_edges_dst_ind\n",
    "            adj_real = adj_nodes_mask&real_edges\n",
    "            \n",
    "            ###\n",
    "            enoised = noised_dict['edge_cons'][j]\n",
    "            enoised = enoised.reshape((-1,EDGE_DIM,2))[:num_edges]\n",
    "            edata = torch.zeros(gsrc.shape+(EDGE_DIM,))\n",
    "            oh1_mask = torch.tensor([1,0,0]).unsqueeze(-1)\n",
    "            oh2_mask = torch.tensor([0,1,0]).unsqueeze(-1)\n",
    "            oh3_mask = torch.tensor([0,0,1]).unsqueeze(-1)\n",
    "            \n",
    "            \n",
    "            #needs to add - /+ N/C directon for this data\n",
    "            \n",
    "            \n",
    "            edata[real_edges] = torch.gather(enoised[real_edges],2,oh2_mask.repeat(real_edges.sum(),1,1))[:,:,0]\n",
    "            edata[adj_real] = torch.gather(enoised[adj_real],2,oh1_mask.repeat(adj_real.sum(),1,1))[:,:,0]\n",
    "            edata[null_edges] = torch.gather(enoised[null_edges],2,oh3_mask.repeat(null_edges.sum(),1,1))[:,:,0]\n",
    "            \n",
    "            \n",
    "            graph.edata['con'] = edata\n",
    "            \n",
    "            #way to get real_edges and null edges in loop code\n",
    "            # null_edges = torch.zeros_like(gsrc)\n",
    "            # for i,x in enumerate(gsrc):\n",
    "            #     if gsrc[i] in null_nodes or gdst[i] in null_nodes:\n",
    "            #         null_edges[i] = 1\n",
    "\n",
    "            # real_edges = torch.zeros_like(gsrc)\n",
    "            # for i,x in enumerate(gsrc):\n",
    "            #     if gsrc[i] in real_nodes and gdst[i] in real_nodes:\n",
    "            #         real_edges[i] = 1\n",
    "\n",
    "            return graph, real_nodes, null_nodes\n",
    "        \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "8c1d429c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([False, False, False, False, False, False, False, False, False, False,\n",
      "        False, False, False, False, False, False, False, False, False, False,\n",
      "        False, False, False, False, False, False, False, False, False, False,\n",
      "        False, False, False, False, False, False, False, False,  True,  True,\n",
      "         True,  True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
      "         True,  True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
      "         True,  True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
      "         True,  True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
      "         True,  True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
      "         True,  True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
      "         True,  True,  True, False, False, False, False, False, False, False,\n",
      "        False, False, False, False, False, False, False, False, False, False,\n",
      "        False, False, False, False, False, False, False, False])\n"
     ]
    }
   ],
   "source": [
    "\n",
    "nkg = Make_nullKNN_MP_Graphs()\n",
    "EDGE_DIM = 3\n",
    "g,rn,nn =nkg.create_and_batch(noised_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "d8654034",
   "metadata": {},
   "outputs": [],
   "source": [
    "ge = g.edata['con']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "fd3978c3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([128, 30, 3, 2])"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "noised_dict['edge_cons'][0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "b25d2cff",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(1571)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.round(ge[:,0:2]).type(torch.bool).any(dim=1).sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "d6373745",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(128.)"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.round(ge[:,0].unsqueeze(-1)).sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "36425f48",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Graph(num_nodes=128, num_edges=1699,\n",
       "      ndata_schemes={}\n",
       "      edata_schemes={'count': Scheme(shape=(), dtype=torch.int64)})"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#remake graph based on noised_edge data, should this data be on the nodes?\n",
    "real_nodes_edges = torch.round(ge[:,0].unsqueeze(-1)).any(dim=1) #grab the adjacent real nodes from edge data\n",
    "src, dst = g.edges()\n",
    "real_nodes=src[real_nodes_edges].unique() #find real nodes form edges\n",
    "\n",
    "combined = torch.cat((real_nodes, torch.arange(nkg.n_nodes)))\n",
    "uniques, counts = combined.unique(return_counts=True)\n",
    "null_nodes = uniques[counts == 1]\n",
    "\n",
    "real_mask = torch.zeros((nkg.n_nodes,),dtype=torch.bool)\n",
    "real_mask[real_nodes]=1\n",
    "\n",
    "#make graph again based on the edge data pulled\n",
    "\n",
    "monomer_knngraph(g.ndata['pos'],real_mask, k=30)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "b2c89c6f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([32, 128, 5])"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.ones_like(fnd.mask_shift.unsqueeze(-1)).repeat((1,)*len(fnd.mask_shift.shape)+(5,)).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "af8f2d01",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([32, 128])"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fnd.mask_shift.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "id": "bdddc7eb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51,\n",
       "        52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69,\n",
       "        70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83, 84, 85, 86, 87,\n",
       "        88, 89, 90, 91, 92, 93, 94, 95, 96, 97, 98])"
      ]
     },
     "execution_count": 131,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "src[real_nodes].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "9e64cf2a",
   "metadata": {},
   "outputs": [],
   "source": [
    "fuck should I be predicting null/read nodes only... fuck\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "25521b06",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([  0,   0,   1,  ..., 126, 127, 127])"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "src"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f98763cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "def graph_from_noised_edges(prev_graph,)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "7e5e8943",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-0., 1., 0.],\n",
       "        [-0., 1., 0.],\n",
       "        [0., 1., -0.],\n",
       "        ...,\n",
       "        [-0., 1., -0.],\n",
       "        [-0., 1., 0.],\n",
       "        [-0., 1., -0.]])"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#real and direct connect, [1,0,0]\n",
    "#real and non-direct, [0,1,0]\n",
    "#false and direct # no false and not direct[0,0,1]\n",
    "np.round(ge).clamp(0,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "520d6933",
   "metadata": {},
   "outputs": [],
   "source": [
    "def softmax(xs):\n",
    "    return np.exp(xs) / sum(np.exp(xs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91cef8f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "#now we need to do midpoint graph:\n",
    "#we need another object to make a graph from the noised edges\n",
    "#instead of pulling from enoised pull from raw onehots\n",
    "#during inference time just pull from edges to start\n",
    "\n",
    "\n",
    "#i think knn graph but but with null nodes group as 1 (up to make connected as 1?)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07277242",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "5ac66e30",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Make_KNN_MP_Graphs():\n",
    "    \n",
    "    #8 long positional encoding\n",
    "    NODE_FEATURE_DIM_0 = 12\n",
    "    EDGE_FEATURE_DIM = 1 # 0 or 1 primary seq connection or not\n",
    "    NODE_FEATURE_DIM_1 = 2\n",
    "    \n",
    "    def __init__(self, mp_stride=4, n_nodes=65, radius=15, coord_div=10, cast_type=torch.float32, channels_start=32,\n",
    "                       ndf1=6, ndf0=32,cuda=True):\n",
    "        \n",
    "        self.KNN = 30\n",
    "        self.n_nodes = n_nodes\n",
    "        self.pe = make_pe_encoding(n_nodes=n_nodes)\n",
    "        self.mp_stride = mp_stride\n",
    "        self.cast_type = cast_type\n",
    "        self.channels_start = channels_start\n",
    "        \n",
    "        self.cuda = cuda\n",
    "        self.ndf1 = ndf1 #awkard adding of nodes features to mpGraph\n",
    "        self.ndf0 = ndf0\n",
    "        \n",
    "    def create_and_batch(self, bb_dict):\n",
    "        \n",
    "        graphList = []\n",
    "        mpGraphList = []\n",
    "        mpRevGraphList = []\n",
    "        mpSelfGraphList = []\n",
    "        \n",
    "        for j, caXYZ in enumerate(bb_dict['CA']):\n",
    "            graph = dgl.knn_graph(caXYZ, self.KNN)\n",
    "            graph.ndata['pe'] = self.pe\n",
    "            graph.ndata['pos'] = caXYZ\n",
    "            graph.ndata['bb_ori'] = torch.cat((bb_dict['N_CA'][j],  bb_dict['C_CA'][j]),axis=1)\n",
    "            \n",
    "            #define covalent connections\n",
    "            esrc, edst = graph.edges()\n",
    "            graph.edata['con'] = (torch.abs(esrc-edst)==1).type(self.cast_type).reshape((-1,1))\n",
    "            \n",
    "            mp_list = torch.zeros((len(list(range(0,self.n_nodes, self.mp_stride))),caXYZ.shape[1]))\n",
    "            \n",
    "            new_src = torch.tensor([],dtype=torch.int)\n",
    "            new_dst = torch.tensor([],dtype=torch.int)\n",
    "            \n",
    "            new_src_rev = torch.tensor([], dtype=torch.int)\n",
    "            new_dst_rev = torch.tensor([], dtype=torch.int)\n",
    "           \n",
    "            i=0#mp list counter\n",
    "            for x in range(0,self.n_nodes, self.mp_stride):\n",
    "                src, dst = graph.in_edges(x) #dst repeats x\n",
    "                n_tot = torch.cat((torch.tensor(x).unsqueeze(0),src)) #add x to node list\n",
    "                mp_list[i] = caXYZ[n_tot].sum(axis=0)/n_tot.shape[0]\n",
    "                mp_node = i + graph.num_nodes() #add midpoints nodes at end of graph\n",
    "                #define edges between midpoint nodes and nodes defining midpoint for midpointGraph\n",
    "                \n",
    "                new_src = torch.cat((new_src,n_tot))\n",
    "                new_dst = torch.cat((new_dst,\n",
    "                                     (torch.tensor(mp_node).unsqueeze(0).repeat(n_tot.shape[0]))))\n",
    "                #and reverse graph for coming off\n",
    "                new_src_rev = torch.cat((new_src_rev,\n",
    "                                         (torch.tensor(mp_node).unsqueeze(0).repeat(n_tot.shape[0]))))\n",
    "                new_dst_rev = torch.cat((new_dst_rev,n_tot))\n",
    "                \n",
    "                i+=1\n",
    "                \n",
    "            mpGraph = dgl.graph((new_src,new_dst))\n",
    "            mpGraph.ndata['pos'] = torch.cat((caXYZ,mp_list),axis=0).type(self.cast_type)\n",
    "            mp_node_indx = torch.arange(0,self.n_nodes, self.mp_stride).type(torch.int)\n",
    "            #match output shape of first transformer\n",
    "            pe_mp = torch.cat((self.pe,torch.zeros((self.pe.shape[0],self.channels_start-self.pe.shape[1]))),axis=1)\n",
    "            mpGraph.ndata['pe'] = torch.cat((pe_mp,pe_mp[mp_node_indx]))\n",
    "            mpGraph.edata['con'] = torch.zeros((mpGraph.num_edges(),1))\n",
    "            \n",
    "            mpGraph_rev = dgl.graph((new_src_rev,new_dst_rev))\n",
    "            mpGraph_rev.ndata['pos'] = torch.cat((caXYZ,mp_list),axis=0).type(self.cast_type)\n",
    "            mpGraph_rev.ndata['pe'] = torch.cat((pe_mp,pe_mp[mp_node_indx]))\n",
    "            mpGraph_rev.edata['con'] = torch.zeros((mpGraph_rev.num_edges(),1))\n",
    "            \n",
    "            #make graph for self interaction of midpoints\n",
    "            v1,v2,edge_data, ind = define_graph_edges(len(mp_list))\n",
    "            mpSelfGraph = dgl.graph((v1,v2))\n",
    "            mpSelfGraph.edata['con'] = edge_data.reshape((-1,1))\n",
    "            mpSelfGraph.ndata['pe'] = self.pe[mp_node_indx] #not really needed\n",
    "            mpSelfGraph.ndata['pos'] = mp_list.type(self.cast_type)\n",
    "            \n",
    "            \n",
    "            mpSelfGraphList.append(mpSelfGraph) \n",
    "            mpGraphList.append(mpGraph)\n",
    "            mpRevGraphList.append(mpGraph_rev)\n",
    "            graphList.append(graph)\n",
    "        \n",
    "        return dgl.batch(graphList), dgl.batch(mpGraphList), dgl.batch(mpSelfGraphList), dgl.batch(mpRevGraphList)\n",
    "    \n",
    "    def prep_for_network(self, bb_dict, cuda=True):\n",
    "    \n",
    "        batched_graph, batched_mpgraph, batched_mpself_graph, batched_mpRevgraph =  self.create_and_batch(bb_dict)\n",
    "        \n",
    "        edge_feats        =    {'0':   batched_graph.edata['con'][:, :self.EDGE_FEATURE_DIM, None]}\n",
    "        edge_feats_mp     = {'0': batched_mpgraph.edata['con'][:, :self.EDGE_FEATURE_DIM, None]} #def all zero now\n",
    "        edge_feats_mpself = {'0': batched_mpself_graph.edata['con'][:, :self.EDGE_FEATURE_DIM, None]}\n",
    "#         edge_feats_mp     = {'0': batched_mpRevgraph.edata['con'][:, :self.EDGE_FEATURE_DIM, None]}\n",
    "        batched_graph.edata['rel_pos']   = _get_relative_pos(batched_graph)\n",
    "        batched_mpgraph.edata['rel_pos'] = _get_relative_pos(batched_mpgraph)\n",
    "        batched_mpself_graph.edata['rel_pos'] = _get_relative_pos(batched_mpself_graph)\n",
    "        batched_mpRevgraph.edata['rel_pos'] = _get_relative_pos(batched_mpRevgraph)\n",
    "        # get node features\n",
    "        node_feats =         {'0': batched_graph.ndata['pe'][:, :self.NODE_FEATURE_DIM_0, None],\n",
    "                              '1': batched_graph.ndata['bb_ori'][:,:self.NODE_FEATURE_DIM_1, :3]}\n",
    "        node_feats_mp =      {'0': batched_mpgraph.ndata['pe'][:, :self.ndf0, None],\n",
    "                              '1': torch.ones((batched_mpgraph.num_nodes(),self.ndf1,3))}\n",
    "        #unused\n",
    "        node_feats_mpself =  {'0': batched_mpself_graph.ndata['pe'][:, :self.NODE_FEATURE_DIM_0, None]}\n",
    "        \n",
    "        if cuda:\n",
    "            bg,nf,ef = to_cuda(batched_graph), to_cuda(node_feats), to_cuda(edge_feats)\n",
    "            bg_mp, nf_mp, ef_mp = to_cuda(batched_mpgraph), to_cuda(node_feats_mp), to_cuda(edge_feats_mp)\n",
    "            bg_mps, nf_mps, ef_mps = to_cuda(batched_mpself_graph), to_cuda(node_feats_mpself), to_cuda(edge_feats_mpself)\n",
    "            bg_mpRev = to_cuda(batched_mpRevgraph)\n",
    "            \n",
    "            return bg,nf,ef, bg_mp, nf_mp, ef_mp, bg_mps, nf_mps, ef_mps, bg_mpRev\n",
    "        \n",
    "        else:\n",
    "            bg,nf,ef = batched_graph, node_feats, edge_feats\n",
    "            bg_mp, nf_mp, ef_mp = batched_mpgraph, node_feats_mp, edge_feats_mp\n",
    "            bg_mps, nf_mps, ef_mps = batched_mpself_graph, node_feats_mpself, edge_feats_mpself\n",
    "            bg_mpRev = batched_mpRevgraph\n",
    "            \n",
    "            return bg,nf,ef, bg_mp, nf_mp, ef_mp, bg_mps, nf_mps, ef_mps, bg_mpRev\n",
    "        \n",
    "            \n",
    "\n",
    "def get_edge_features(graph,edge_feature_dim=1):\n",
    "    return {'0': graph.edata['con'][:, :edge_feature_dim, None]}\n",
    "\n",
    "def define_poolGraph(n_nodes, batch_size, cast_type=torch.float32, cuda_out=True ):\n",
    "    \n",
    "    v1,v2,edge_data, ind = define_graph_edges(n_nodes)\n",
    "    #pe = make_pe_encoding(n_nodes=n_nodes)#pe e\n",
    "    \n",
    "    graphList = []\n",
    "    \n",
    "    for i in range(batch_size):\n",
    "        \n",
    "        g = dgl.graph((v1,v2))\n",
    "        g.edata['con'] = edge_data.type(cast_type).reshape((-1,1))\n",
    "        g.ndata['pos'] = torch.zeros((n_nodes,3),dtype=torch.float32)\n",
    "\n",
    "        graphList.append(g)\n",
    "        \n",
    "    batched_graph = dgl.batch(graphList)\n",
    "    \n",
    "    if cuda_out:\n",
    "        return to_cuda(batched_graph)\n",
    "    else:\n",
    "        return batched_graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2dd286f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "c7a840f1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1, 1, 1],\n",
       "        [1, 1, 1],\n",
       "        [2, 2, 2],\n",
       "        [3, 3, 3],\n",
       "        [4, 4, 4],\n",
       "        [4, 4, 4]])"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xyz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0017f85",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "aa7f641a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([2, 3, 4, 5, 1, 0])"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dst"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "se33",
   "language": "python",
   "name": "se33"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
