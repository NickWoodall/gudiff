{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a02a1c0f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "#clear memory better\n",
    "with torch.no_grad():\n",
    "    torch.cuda.empty_cache()\n",
    "import numpy as np\n",
    "import util.npose_util as nu\n",
    "import os\n",
    "import pathlib\n",
    "import dgl\n",
    "from dgl import backend as F\n",
    "import torch_geometric\n",
    "from torch.utils.data import random_split, DataLoader, Dataset\n",
    "from typing import Dict\n",
    "from torch import Tensor\n",
    "from dgl import DGLGraph\n",
    "from torch import nn\n",
    "# from chemical import cos_ideal_NCAC #from RoseTTAFold2\n",
    "from torch import einsum\n",
    "import time\n",
    "torch.cuda.is_available()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "33e16cff",
   "metadata": {},
   "outputs": [],
   "source": [
    "import se3_diffuse.utils as du"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6a31f547",
   "metadata": {},
   "outputs": [],
   "source": [
    "from data_rigid_diffuser import so3_diffuser\n",
    "from data_rigid_diffuser import r3_diffuser\n",
    "from data_rigid_diffuser import oneHot_diffuser\n",
    "from scipy.spatial.transform import Rotation\n",
    "from data_rigid_diffuser import rigid_utils as ru\n",
    "import yaml\n",
    "from data_rigid_diffuser.diffuser import FrameDiffNoise\n",
    "from gudiff_model import Data_Graph\n",
    "from gudiff_model.Data_Graph import build_npose_from_coords, dump_coord_pdb, define_graph_edges, make_pe_encoding\n",
    "from gudiff_model.Data_Graph import Helix4_Dataset, Make_KNN_MP_Graphs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "bf443f63",
   "metadata": {},
   "outputs": [],
   "source": [
    "from se3_transformer.model.basis import get_basis, update_basis_with_fused\n",
    "from se3_transformer.model.transformer import Sequential, SE3Transformer\n",
    "from se3_transformer.model.transformer_topk import SE3Transformer_topK\n",
    "from se3_transformer.model.FAPE_Loss import FAPE_loss, Qs2Rs, normQ\n",
    "from se3_transformer.model.layers.attentiontopK import AttentionBlockSE3\n",
    "from se3_transformer.model.layers.linear import LinearSE3\n",
    "from se3_transformer.model.layers.convolution import ConvSE3, ConvSE3FuseLevel\n",
    "from se3_transformer.model.layers.norm import NormSE3\n",
    "from se3_transformer.model.layers.pooling import GPooling, Latent_Unpool, Unpool_Layer\n",
    "from se3_transformer.runtime.utils import str2bool, to_cuda\n",
    "from se3_transformer.model.fiber import Fiber\n",
    "from se3_transformer.model.transformer import get_populated_edge_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c0babffd",
   "metadata": {},
   "outputs": [],
   "source": [
    "#indices for, unsure if needed\n",
    "CA = Data_Graph.CA\n",
    "N = Data_Graph.N\n",
    "C = Data_Graph.C\n",
    "\n",
    "# #find better way to incorporate coord_scale\n",
    "\n",
    "# #needed\n",
    "# N_CA_dist = (Data_Graph.N_CA_dist/10.).to('cuda')\n",
    "# C_CA_dist = (Data_Graph.C_CA_dist/10.).to('cuda')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e213e885",
   "metadata": {},
   "outputs": [],
   "source": [
    "# data_path_str  = 'data/h4_ca_coords.npz'\n",
    "# test_limit = 1028\n",
    "# rr = np.load(data_path_str)\n",
    "# ca_coords = [rr[f] for f in rr.files][0][:test_limit,:,:3]\n",
    "# ca_coords.shape\n",
    "\n",
    "# getting N-Ca, Ca-C vectors to add as typeI features\n",
    "#apa = apart helices for val/train split\n",
    "#tog = together helices for val/train split\n",
    "\n",
    "#mode for tablet\n",
    "apa_path_str  = 'data_npose/h4_apa_coords.npz'\n",
    "tog_path_str  = 'data_npose/h4_tog_coords.npz'\n",
    "\n",
    "#grab the first 3 atoms which are N,CA,C\n",
    "test_limit = 256\n",
    "rr = np.load(apa_path_str)\n",
    "coords_apa = [rr[f] for f in rr.files][0][:test_limit,:]\n",
    "\n",
    "rr = np.load(tog_path_str)\n",
    "coords_tog = [rr[f] for f in rr.files][0][:test_limit,:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f3eae2f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "B = 32\n",
    "L=65\n",
    "limit = 128\n",
    "h4_trainData = Helix4_Dataset(coords_tog[:limit])\n",
    "h4_valData = Helix4_Dataset(coords_apa[:limit])\n",
    "train_dL = DataLoader(h4_trainData, batch_size=B, shuffle=True, drop_last=True)\n",
    "val_dL   = DataLoader(h4_valData, batch_size=B, shuffle=True, drop_last=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "7c785856",
   "metadata": {},
   "outputs": [],
   "source": [
    "B = 32\n",
    "L=65\n",
    "limit = 128\n",
    "prot_trainData = Data_Graph.ProteinBB_Dataset(coords_tog[:limit], n_nodes=128,\n",
    "              n_atoms=5, coord_div=10, cast_type=torch.float32)\n",
    "train_dL = DataLoader(prot_trainData, batch_size=B, shuffle=True, drop_last=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "3fbf8e13",
   "metadata": {},
   "outputs": [],
   "source": [
    "testiter = iter(train_dL)\n",
    "bb_dict = next(testiter)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "87f67d73",
   "metadata": {},
   "outputs": [],
   "source": [
    "from data_rigid_diffuser import diffuser"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "d785b3d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "fdn_an = FrameDiffNoise()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "24472ad5",
   "metadata": {},
   "outputs": [],
   "source": [
    "config_path='data_rigid_diffuser/base.yaml'\n",
    "\n",
    "        \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "b2ac30f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "fnd = FrameDiffNoise(config_path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "669a2fac",
   "metadata": {},
   "outputs": [],
   "source": [
    "noised_dict = fnd.forward(bb_dict,t_vec=np.ones((B,))*0.03)\n",
    "#edges are Batch, Length, KNN, 3, bool  \n",
    "#each edge represents real adj, fake dist\n",
    "\n",
    " #real and direct connect, real and non-direct, false and direct # no false and not direct"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "153d15d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "ed = noised_dict['edges_noised']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "1f5d7d4f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def circular_pe_encoding(n_nodes=128,embed_dim=12, cast_type=torch.float32):\n",
    "    #positional encoding of node, all repeat every n_nodes\n",
    "    i_array = np.arange(1,(embed_dim/2)+1)\n",
    "    period = 2*np.pi\n",
    "    wk = period/(n_nodes)*i_array**2\n",
    "    t_array = np.arange(n_nodes)\n",
    "    si = torch.tensor(np.sin(wk*t_array.reshape((-1,1))))\n",
    "    ci = torch.tensor(np.cos(wk*t_array.reshape((-1,1))))\n",
    "    pe = torch.stack((si,ci),axis=2).reshape(t_array.shape[0],embed_dim).type(cast_type)\n",
    "    \n",
    "    return pe\n",
    "\n",
    "#test code\n",
    "#n_nodes = 6\n",
    "#src_start = torch.arange(n_nodes) #positive direction\n",
    "#dst_start = torch.roll(src_start,-1) #negative dir\n",
    "#xyz = torch.arange(n_nodes)[:,None].repeat((1,3))\n",
    "#xyz[-1] = torch.tensor([4,4,4])\n",
    "#xyz[0] = torch.tensor([1,1,1])\n",
    "#mask = torch.tensor([False,True,True,True,True,False])\n",
    "#mask = torch.tensor([False,True,False,True,True,False])\n",
    "\n",
    "\n",
    "def monomer_knngraph(xyz,real_mask, k=2):\n",
    "    \"\"\"Takes in array of XYZ coordinates with null nodes repeated at termini.\n",
    "    \n",
    "    #Parameters\n",
    "    real_mask: mask determining residues of real and null nodes\n",
    "    \n",
    "    Returns Graph that has a linear connections between all nodes indices\"\"\"\n",
    "    \n",
    "    n_nodes = xyz.shape[0]\n",
    "    src_start = torch.arange(n_nodes) #positive direction\n",
    "    dst_start = torch.roll(src_start,-1) #negative dir\n",
    "    \n",
    "    #ma\n",
    "    real_nodes_src = src_start[real_mask==True]\n",
    "    null_nodes_src = src_start[real_mask==False]\n",
    "    real_nodes_dst = dst_start[real_mask==True]\n",
    "    null_nodes_dst = dst_start[real_mask==False]\n",
    "\n",
    "    g_knn=dgl.knn_graph(xyz[real_mask],k=k,exclude_self=True) # normal graph\n",
    "    g_knn.add_nodes(len(null_nodes_src)) # null nodes to the end\n",
    "\n",
    "    src_knn_shift = torch.zeros_like(src_start)\n",
    "    dst_knn_shift = torch.zeros_like(dst_start)\n",
    "\n",
    "    src_knn_shift[:len(real_nodes_src)] = real_nodes_src\n",
    "    src_knn_shift[len(real_nodes_src):] = null_nodes_src\n",
    "    dst_knn_shift[:len(real_nodes_src)] = real_nodes_dst\n",
    "    dst_knn_shift[len(real_nodes_src):] = null_nodes_dst\n",
    "\n",
    "    g_nodes_index = src_start#torch.arange(n_nodes) \n",
    "    src = g_nodes_index[src_knn_shift]\n",
    "    dst = g_nodes_index[dst_knn_shift]\n",
    "    \n",
    "    knn_src, knn_dst = g_knn.edges()\n",
    "    for i,nullnode in enumerate(null_nodes_src):\n",
    "        knn_src[knn_src==null_nodes_src[i]] = real_nodes_src[i]\n",
    "        knn_dst[knn_dst==null_nodes_dst[i]] = real_nodes_dst[i]\n",
    "    \n",
    "    g = dgl.graph((knn_src,knn_dst))\n",
    "\n",
    "    #can just add edges on top, simple to delete parallel; \n",
    "    g.add_edges(src,dst) \n",
    "    g.add_edges(dst,src)\n",
    "    g = dgl.to_simple(g)\n",
    "\n",
    "    return g\n",
    "\n",
    "def decirc(graph_in):\n",
    "    \"\"\"Remove circular connections. Last node to first node\"\"\"\n",
    "    src,dst = graph_in.edges()\n",
    "\n",
    "    circfw = (src==graph_in.nodes().max()) & (dst==0) \n",
    "    circbw = (src==0) & (dst==graph_in.nodes().max())\n",
    "    both_circ = circfw | circbw\n",
    "    \n",
    "    src_out = src[~both_circ]\n",
    "    dst_out = dst[~both_circ]\n",
    "    \n",
    "    return dgl.graph((src_out,dst_out))\n",
    "\n",
    "def concat_monomer_graphs(graph_list):\n",
    "    \"\"\"Add single connection between each graph\"\"\"\n",
    "    \n",
    "    batched_graph = dgl.batch([decirc(g) for g in graph_list])\n",
    "    src = torch.zeros((len(graph_list),),dtype=torch.int64) \n",
    "    dst = torch.zeros_like(src)\n",
    "    \n",
    "    #recirc concats\n",
    "    nindex = 0\n",
    "    src[nindex] = 0\n",
    "    dst[nindex] = len(batched_graph.nodes())-1 #\n",
    "    \n",
    "    \n",
    "    for i in range(1,len(graph_list)):\n",
    "        src[i] = graph_list[nindex].nodes().max()+nindex\n",
    "        dst[i] = src[i]+1\n",
    "        nindex = src[i]\n",
    "    \n",
    "    \n",
    "    batched_graph.add_edges(src,dst)\n",
    "    batched_graph.add_edges(dst,src)\n",
    "    \n",
    "    return batched_graph\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "20303394",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Make_nullKNN_MP_Graphs():\n",
    "    \n",
    "    #8 long positional encoding\n",
    "    NODE_FEATURE_DIM_0 = 12\n",
    "    EDGE_FEATURE_DIM = 1 # 0 or 1 primary seq connection or not\n",
    "    NODE_FEATURE_DIM_1 = 2\n",
    "    \n",
    "    def __init__(self, KNN=30, mp_stride=4, n_nodes=128, coord_div=10, \n",
    "                       cast_type=torch.float32, channels_start=32,\n",
    "                       ndf1=6, ndf0=32,cuda=True):\n",
    "        \n",
    "        self.KNN = KNN\n",
    "        self.n_nodes = n_nodes\n",
    "        self.pe = circular_pe_encoding(n_nodes=n_nodes,embed_dim=12, cast_type=torch.float32)\n",
    "        self.mp_stride = mp_stride\n",
    "        self.cast_type = cast_type\n",
    "        self.channels_start = channels_start\n",
    "        \n",
    "        self.cuda = cuda\n",
    "        self.ndf1 = ndf1 #awkard adding of nodes features to mpGraph\n",
    "        self.ndf0 = ndf0\n",
    "        \n",
    "    def create_and_batch(self, bb_dict):\n",
    "        \n",
    "        graphList = []\n",
    "        mpGraphList = []\n",
    "        mpRevGraphList = []\n",
    "        mpSelfGraphList = []\n",
    "        \n",
    "        for j, caXYZ in enumerate(bb_dict['bb_noised']['CA']):\n",
    "            graph = monomer_knngraph(caXYZ,bb_dict['null_mask'][j], k=self.KNN)\n",
    "            graph.ndata['pe'] = self.pe\n",
    "            graph.ndata['pos'] = caXYZ\n",
    "            graph.ndata['bb_ori'] = torch.cat((bb_dict['bb_noised']['N_CA'][j],  bb_dict['bb_noised']['C_CA'][j]),axis=1)\n",
    "            \n",
    "            #gather edge data from all possible noised edges produced\n",
    "            gsrc, gdst = g.edges()\n",
    "            num_edges = len(gsrc)\n",
    "            \n",
    "            #adjacent AA are one apart, or the loop connection from zero node to the last node\n",
    "            adj_nodes_mask = ((torch.abs(gsrc-gdst)==1) | (torch.abs(gsrc-gdst)==len(gsrc)-1)) \n",
    "            \n",
    "            #get null node indices from mask\n",
    "            null_mask = noised_dict['null_mask'][j]\n",
    "            #actually we need to determine\n",
    "            null_nodes = torch.arange(nkg.n_nodes)[~null_mask]\n",
    "            real_nodes = torch.arange(nkg.n_nodes)[null_mask]\n",
    "\n",
    "            #broadcast each src/dst node against all null nodes, if any match along node dimension is a null edge\n",
    "            gsrc_compare = (gsrc[:,None] - null_nodes[None,:])\n",
    "            gdst_compare = (gdst[:,None] - null_nodes[None,:])\n",
    "            null_edges_src_ind = torch.where(gsrc_compare==0,True,False).any(dim=1)\n",
    "            null_edges_dst_ind = torch.where(gdst_compare==0,True,False).any(dim=1)\n",
    "            \n",
    "            #broadcast each src/dst node against all real or null nodes, if any match along node dimension is a null edge\n",
    "            gsrc_compare = (gsrc[:,None] - real_nodes[None,:])\n",
    "            gdst_compare = (gdst[:,None] - real_nodes[None,:])\n",
    "            real_edges_src_ind = torch.where(gsrc_compare==0,True,False).any(dim=1)\n",
    "            real_edges_dst_ind = torch.where(gdst_compare==0,True,False).any(dim=1)\n",
    "\n",
    "            null_edges = null_edges_src_ind | null_edges_dst_ind\n",
    "            real_edges = real_edges_src_ind & real_edges_dst_ind\n",
    "            adj_real = adj_nodes_mask&real_edges \n",
    "\n",
    "            oh3_mask = torch.tensor([[0],[0],[1]]).repeat(num_edges,1,1)\n",
    "            oh2_mask = torch.tensor([[0],[1],[0]]).repeat(num_edges,1,1)\n",
    "            oh1_mask = torch.tensor([[1],[0],[0]]).repeat(num_edges,1,1)\n",
    "\n",
    "            enoised = noised_dict['edges_noised'][j]\n",
    "            enoised = enoised.reshape((-1,EDGE_DIM,2))[:num_edges]\n",
    "            edata = torch.zeros(gsrc.shape+(EDGE_DIM,))\n",
    "            oh3_mask = torch.tensor([0,0,1]).unsqueeze(-1)\n",
    "            oh2_mask = torch.tensor([0,1,0]).unsqueeze(-1)\n",
    "            oh1_mask = torch.tensor([1,0,0]).unsqueeze(-1)\n",
    "            \n",
    "            edata[null_edges] = torch.gather(enoised[null_edges],2,oh2_mask.repeat(null_edges.sum(),1,1))[:,:,0]\n",
    "            edata[real_edges] = torch.gather(enoised[real_edges],2,oh3_mask.repeat(real_edges.sum(),1,1))[:,:,0]\n",
    "            edata[adj_real] = torch.gather(enoised[adj_real],2,oh1_mask.repeat(adj_real.sum(),1,1))[:,:,0]\n",
    "            \n",
    "            graph.edata['con'] = edata\n",
    "            \n",
    "            #way to get real_edges and null edges in loop code\n",
    "            # null_edges = torch.zeros_like(gsrc)\n",
    "            # for i,x in enumerate(gsrc):\n",
    "            #     if gsrc[i] in null_nodes or gdst[i] in null_nodes:\n",
    "            #         null_edges[i] = 1\n",
    "\n",
    "            # real_edges = torch.zeros_like(gsrc)\n",
    "            # for i,x in enumerate(gsrc):\n",
    "            #     if gsrc[i] in real_nodes and gdst[i] in real_nodes:\n",
    "            #         real_edges[i] = 1\n",
    "\n",
    "            return graph\n",
    "        \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "8c1d429c",
   "metadata": {},
   "outputs": [],
   "source": [
    "EDGE_DIM = 3\n",
    "g =nkg.create_and_batch(noised_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91cef8f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "#now we need to do midpoint graph:\n",
    "#we need another object to make a graph from the noised edges\n",
    "#instead of pulling from enoised pull from raw onehots\n",
    "#during inference time just pull from edges to start\n",
    "\n",
    "\n",
    "#i think knn graph but but with null nodes group as 1 (up to make connected as 1?)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07277242",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "5ac66e30",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Make_KNN_MP_Graphs():\n",
    "    \n",
    "    #8 long positional encoding\n",
    "    NODE_FEATURE_DIM_0 = 12\n",
    "    EDGE_FEATURE_DIM = 1 # 0 or 1 primary seq connection or not\n",
    "    NODE_FEATURE_DIM_1 = 2\n",
    "    \n",
    "    def __init__(self, mp_stride=4, n_nodes=65, radius=15, coord_div=10, cast_type=torch.float32, channels_start=32,\n",
    "                       ndf1=6, ndf0=32,cuda=True):\n",
    "        \n",
    "        self.KNN = 30\n",
    "        self.n_nodes = n_nodes\n",
    "        self.pe = make_pe_encoding(n_nodes=n_nodes)\n",
    "        self.mp_stride = mp_stride\n",
    "        self.cast_type = cast_type\n",
    "        self.channels_start = channels_start\n",
    "        \n",
    "        self.cuda = cuda\n",
    "        self.ndf1 = ndf1 #awkard adding of nodes features to mpGraph\n",
    "        self.ndf0 = ndf0\n",
    "        \n",
    "    def create_and_batch(self, bb_dict):\n",
    "        \n",
    "        graphList = []\n",
    "        mpGraphList = []\n",
    "        mpRevGraphList = []\n",
    "        mpSelfGraphList = []\n",
    "        \n",
    "        for j, caXYZ in enumerate(bb_dict['CA']):\n",
    "            graph = dgl.knn_graph(caXYZ, self.KNN)\n",
    "            graph.ndata['pe'] = self.pe\n",
    "            graph.ndata['pos'] = caXYZ\n",
    "            graph.ndata['bb_ori'] = torch.cat((bb_dict['N_CA'][j],  bb_dict['C_CA'][j]),axis=1)\n",
    "            \n",
    "            #define covalent connections\n",
    "            esrc, edst = graph.edges()\n",
    "            graph.edata['con'] = (torch.abs(esrc-edst)==1).type(self.cast_type).reshape((-1,1))\n",
    "            \n",
    "            mp_list = torch.zeros((len(list(range(0,self.n_nodes, self.mp_stride))),caXYZ.shape[1]))\n",
    "            \n",
    "            new_src = torch.tensor([],dtype=torch.int)\n",
    "            new_dst = torch.tensor([],dtype=torch.int)\n",
    "            \n",
    "            new_src_rev = torch.tensor([], dtype=torch.int)\n",
    "            new_dst_rev = torch.tensor([], dtype=torch.int)\n",
    "           \n",
    "            i=0#mp list counter\n",
    "            for x in range(0,self.n_nodes, self.mp_stride):\n",
    "                src, dst = graph.in_edges(x) #dst repeats x\n",
    "                n_tot = torch.cat((torch.tensor(x).unsqueeze(0),src)) #add x to node list\n",
    "                mp_list[i] = caXYZ[n_tot].sum(axis=0)/n_tot.shape[0]\n",
    "                mp_node = i + graph.num_nodes() #add midpoints nodes at end of graph\n",
    "                #define edges between midpoint nodes and nodes defining midpoint for midpointGraph\n",
    "                \n",
    "                new_src = torch.cat((new_src,n_tot))\n",
    "                new_dst = torch.cat((new_dst,\n",
    "                                     (torch.tensor(mp_node).unsqueeze(0).repeat(n_tot.shape[0]))))\n",
    "                #and reverse graph for coming off\n",
    "                new_src_rev = torch.cat((new_src_rev,\n",
    "                                         (torch.tensor(mp_node).unsqueeze(0).repeat(n_tot.shape[0]))))\n",
    "                new_dst_rev = torch.cat((new_dst_rev,n_tot))\n",
    "                \n",
    "                i+=1\n",
    "                \n",
    "            mpGraph = dgl.graph((new_src,new_dst))\n",
    "            mpGraph.ndata['pos'] = torch.cat((caXYZ,mp_list),axis=0).type(self.cast_type)\n",
    "            mp_node_indx = torch.arange(0,self.n_nodes, self.mp_stride).type(torch.int)\n",
    "            #match output shape of first transformer\n",
    "            pe_mp = torch.cat((self.pe,torch.zeros((self.pe.shape[0],self.channels_start-self.pe.shape[1]))),axis=1)\n",
    "            mpGraph.ndata['pe'] = torch.cat((pe_mp,pe_mp[mp_node_indx]))\n",
    "            mpGraph.edata['con'] = torch.zeros((mpGraph.num_edges(),1))\n",
    "            \n",
    "            mpGraph_rev = dgl.graph((new_src_rev,new_dst_rev))\n",
    "            mpGraph_rev.ndata['pos'] = torch.cat((caXYZ,mp_list),axis=0).type(self.cast_type)\n",
    "            mpGraph_rev.ndata['pe'] = torch.cat((pe_mp,pe_mp[mp_node_indx]))\n",
    "            mpGraph_rev.edata['con'] = torch.zeros((mpGraph_rev.num_edges(),1))\n",
    "            \n",
    "            #make graph for self interaction of midpoints\n",
    "            v1,v2,edge_data, ind = define_graph_edges(len(mp_list))\n",
    "            mpSelfGraph = dgl.graph((v1,v2))\n",
    "            mpSelfGraph.edata['con'] = edge_data.reshape((-1,1))\n",
    "            mpSelfGraph.ndata['pe'] = self.pe[mp_node_indx] #not really needed\n",
    "            mpSelfGraph.ndata['pos'] = mp_list.type(self.cast_type)\n",
    "            \n",
    "            \n",
    "            mpSelfGraphList.append(mpSelfGraph) \n",
    "            mpGraphList.append(mpGraph)\n",
    "            mpRevGraphList.append(mpGraph_rev)\n",
    "            graphList.append(graph)\n",
    "        \n",
    "        return dgl.batch(graphList), dgl.batch(mpGraphList), dgl.batch(mpSelfGraphList), dgl.batch(mpRevGraphList)\n",
    "    \n",
    "    def prep_for_network(self, bb_dict, cuda=True):\n",
    "    \n",
    "        batched_graph, batched_mpgraph, batched_mpself_graph, batched_mpRevgraph =  self.create_and_batch(bb_dict)\n",
    "        \n",
    "        edge_feats        =    {'0':   batched_graph.edata['con'][:, :self.EDGE_FEATURE_DIM, None]}\n",
    "        edge_feats_mp     = {'0': batched_mpgraph.edata['con'][:, :self.EDGE_FEATURE_DIM, None]} #def all zero now\n",
    "        edge_feats_mpself = {'0': batched_mpself_graph.edata['con'][:, :self.EDGE_FEATURE_DIM, None]}\n",
    "#         edge_feats_mp     = {'0': batched_mpRevgraph.edata['con'][:, :self.EDGE_FEATURE_DIM, None]}\n",
    "        batched_graph.edata['rel_pos']   = _get_relative_pos(batched_graph)\n",
    "        batched_mpgraph.edata['rel_pos'] = _get_relative_pos(batched_mpgraph)\n",
    "        batched_mpself_graph.edata['rel_pos'] = _get_relative_pos(batched_mpself_graph)\n",
    "        batched_mpRevgraph.edata['rel_pos'] = _get_relative_pos(batched_mpRevgraph)\n",
    "        # get node features\n",
    "        node_feats =         {'0': batched_graph.ndata['pe'][:, :self.NODE_FEATURE_DIM_0, None],\n",
    "                              '1': batched_graph.ndata['bb_ori'][:,:self.NODE_FEATURE_DIM_1, :3]}\n",
    "        node_feats_mp =      {'0': batched_mpgraph.ndata['pe'][:, :self.ndf0, None],\n",
    "                              '1': torch.ones((batched_mpgraph.num_nodes(),self.ndf1,3))}\n",
    "        #unused\n",
    "        node_feats_mpself =  {'0': batched_mpself_graph.ndata['pe'][:, :self.NODE_FEATURE_DIM_0, None]}\n",
    "        \n",
    "        if cuda:\n",
    "            bg,nf,ef = to_cuda(batched_graph), to_cuda(node_feats), to_cuda(edge_feats)\n",
    "            bg_mp, nf_mp, ef_mp = to_cuda(batched_mpgraph), to_cuda(node_feats_mp), to_cuda(edge_feats_mp)\n",
    "            bg_mps, nf_mps, ef_mps = to_cuda(batched_mpself_graph), to_cuda(node_feats_mpself), to_cuda(edge_feats_mpself)\n",
    "            bg_mpRev = to_cuda(batched_mpRevgraph)\n",
    "            \n",
    "            return bg,nf,ef, bg_mp, nf_mp, ef_mp, bg_mps, nf_mps, ef_mps, bg_mpRev\n",
    "        \n",
    "        else:\n",
    "            bg,nf,ef = batched_graph, node_feats, edge_feats\n",
    "            bg_mp, nf_mp, ef_mp = batched_mpgraph, node_feats_mp, edge_feats_mp\n",
    "            bg_mps, nf_mps, ef_mps = batched_mpself_graph, node_feats_mpself, edge_feats_mpself\n",
    "            bg_mpRev = batched_mpRevgraph\n",
    "            \n",
    "            return bg,nf,ef, bg_mp, nf_mp, ef_mp, bg_mps, nf_mps, ef_mps, bg_mpRev\n",
    "        \n",
    "            \n",
    "\n",
    "def get_edge_features(graph,edge_feature_dim=1):\n",
    "    return {'0': graph.edata['con'][:, :edge_feature_dim, None]}\n",
    "\n",
    "def define_poolGraph(n_nodes, batch_size, cast_type=torch.float32, cuda_out=True ):\n",
    "    \n",
    "    v1,v2,edge_data, ind = define_graph_edges(n_nodes)\n",
    "    #pe = make_pe_encoding(n_nodes=n_nodes)#pe e\n",
    "    \n",
    "    graphList = []\n",
    "    \n",
    "    for i in range(batch_size):\n",
    "        \n",
    "        g = dgl.graph((v1,v2))\n",
    "        g.edata['con'] = edge_data.type(cast_type).reshape((-1,1))\n",
    "        g.ndata['pos'] = torch.zeros((n_nodes,3),dtype=torch.float32)\n",
    "\n",
    "        graphList.append(g)\n",
    "        \n",
    "    batched_graph = dgl.batch(graphList)\n",
    "    \n",
    "    if cuda_out:\n",
    "        return to_cuda(batched_graph)\n",
    "    else:\n",
    "        return batched_graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2dd286f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "c7a840f1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1, 1, 1],\n",
       "        [1, 1, 1],\n",
       "        [2, 2, 2],\n",
       "        [3, 3, 3],\n",
       "        [4, 4, 4],\n",
       "        [4, 4, 4]])"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xyz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0017f85",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "aa7f641a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([2, 3, 4, 5, 1, 0])"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dst"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "se33",
   "language": "python",
   "name": "se33"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
