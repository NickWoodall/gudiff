{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a02a1c0f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "import util.npose_util as nu\n",
    "import pathlib\n",
    "import dgl\n",
    "from dgl import backend as F\n",
    "import torch_geometric\n",
    "from torch.utils.data import random_split, DataLoader, Dataset\n",
    "from typing import Dict\n",
    "from torch import Tensor\n",
    "from dgl import DGLGraph\n",
    "from torch import nn\n",
    "from chemical import cos_ideal_NCAC #from RoseTTAFold2\n",
    "from torch import einsum\n",
    "torch.cuda.is_available()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4128b44f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "bf443f63",
   "metadata": {},
   "outputs": [],
   "source": [
    "from se3_transformer.model.basis import get_basis, update_basis_with_fused\n",
    "from se3_transformer.model.transformer import Sequential\n",
    "from se3_transformer.model.layers.attentiontopK import AttentionBlockSE3\n",
    "from se3_transformer.model.layers.linear import LinearSE3\n",
    "from se3_transformer.model.layers.convolution import ConvSE3, ConvSE3FuseLevel\n",
    "from se3_transformer.model.layers.norm import NormSE3\n",
    "from se3_transformer.model.layers.pooling import GPooling\n",
    "from se3_transformer.runtime.utils import str2bool, to_cuda\n",
    "from se3_transformer.model.fiber import Fiber\n",
    "from se3_transformer.model.transformer import get_populated_edge_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2511634d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "# Useful numbers\n",
    "# N [-1.45837285,  0 , 0]\n",
    "# CA [0., 0., 0.]\n",
    "# C [0.55221403, 1.41890368, 0.        ]\n",
    "# CB [ 0.52892494, -0.77445692, -1.19923854]\n",
    "\n",
    "if ( hasattr(os, 'ATOM_NAMES') ):\n",
    "    assert( hasattr(os, 'PDB_ORDER') )\n",
    "\n",
    "    ATOM_NAMES = os.ATOM_NAMES\n",
    "    PDB_ORDER = os.PDB_ORDER\n",
    "else:\n",
    "    ATOM_NAMES=['N', 'CA', 'CB', 'C', 'O']\n",
    "    PDB_ORDER = ['N', 'CA', 'C', 'O', 'CB']\n",
    "\n",
    "_byte_atom_names = []\n",
    "_atom_names = []\n",
    "for i, atom_name in enumerate(ATOM_NAMES):\n",
    "    long_name = \" \" + atom_name + \"       \"\n",
    "    _atom_names.append(long_name[:4])\n",
    "    _byte_atom_names.append(atom_name.encode())\n",
    "\n",
    "    globals()[atom_name] = i\n",
    "\n",
    "R = len(ATOM_NAMES)\n",
    "\n",
    "if ( \"N\" not in globals() ):\n",
    "    N = -1\n",
    "if ( \"C\" not in globals() ):\n",
    "    C = -1\n",
    "if ( \"CB\" not in globals() ):\n",
    "    CB = -1\n",
    "\n",
    "\n",
    "_pdb_order = []\n",
    "for name in PDB_ORDER:\n",
    "    _pdb_order.append( ATOM_NAMES.index(name) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e213e885",
   "metadata": {},
   "outputs": [],
   "source": [
    "# data_path_str  = 'data/h4_ca_coords.npz'\n",
    "# test_limit = 1028\n",
    "# rr = np.load(data_path_str)\n",
    "# ca_coords = [rr[f] for f in rr.files][0][:test_limit,:,:3]\n",
    "# ca_coords.shape\n",
    "\n",
    "# getting N-Ca, Ca-C vectors to add as typeI features\n",
    "#apa = apart helices for test/train split\n",
    "#tog = together helices for test/train split\n",
    "apa_path_str  = 'data/h4_apa_coords.npz'\n",
    "tog_path_str  = 'data/h4_tog_coords.npz'\n",
    "\n",
    "#grab the first 3 atoms which are N,CA,C\n",
    "test_limit = 1028\n",
    "rr = np.load(apa_path_str)\n",
    "coords_apa = [rr[f] for f in rr.files][0][:test_limit,:]\n",
    "\n",
    "rr = np.load(tog_path_str)\n",
    "coords_tog = [rr[f] for f in rr.files][0][:test_limit,:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d4c2ed33",
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_npose_from_coords(coords_in):\n",
    "    \"\"\"Use N, CA, C coordinates to generate O an CB atoms\"\"\"\n",
    "    rot_mat_cat = np.ones(sum((coords_in.shape[:-1], (1,)), ()))\n",
    "    \n",
    "    coords = np.concatenate((coords_in,rot_mat_cat),axis=-1)\n",
    "    \n",
    "    npose = np.ones((coords_in.shape[0]*5,4)) #5 is atoms per res\n",
    "\n",
    "    by_res = npose.reshape(-1, 5, 4)\n",
    "    \n",
    "    if ( \"N\" in ATOM_NAMES ):\n",
    "        by_res[:,N,:3] = coords_in[:,0,:3]\n",
    "    if ( \"CA\" in ATOM_NAMES ):\n",
    "        by_res[:,CA,:3] = coords_in[:,1,:3]\n",
    "    if ( \"C\" in ATOM_NAMES ):\n",
    "        by_res[:,C,:3] = coords_in[:,2,:3]\n",
    "    if ( \"O\" in ATOM_NAMES ):\n",
    "        by_res[:,O,:3] = nu.build_O(npose)\n",
    "    if ( \"CB\" in ATOM_NAMES ):\n",
    "        tpose = nu.tpose_from_npose(npose)\n",
    "        by_res[:,CB,:] = nu.build_CB(tpose)\n",
    "\n",
    "    return npose\n",
    "\n",
    "def dump_coord_pdb(coords_in, fileOut='fileOut.pdb'):\n",
    "    \n",
    "    npose =  build_npose_from_coords(coords_in)\n",
    "    nu.dump_npdb(npose,fileOut)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "508327fa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([0., 1., 0., 1., 0., 1., 0., 1., 0., 1., 0., 1.])\n",
      "tensor([0.6000, 0.8000, 0.4000, 0.9000, 0.3000, 1.0000, 0.2000, 1.0000, 0.1000,\n",
      "        1.0000, 0.1000, 1.0000])\n",
      "tensor([1.0000, 0.2000, 0.8000, 0.6000, 0.6000, 0.8000, 0.4000, 0.9000, 0.3000,\n",
      "        1.0000, 0.2000, 1.0000])\n",
      "tensor([ 0.9000, -0.5000,  1.0000,  0.2000,  0.8000,  0.6000,  0.6000,  0.8000,\n",
      "         0.4000,  0.9000,  0.3000,  1.0000])\n",
      "tensor([ 0.4000, -0.9000,  1.0000, -0.3000,  1.0000,  0.3000,  0.8000,  0.7000,\n",
      "         0.6000,  0.8000,  0.4000,  0.9000])\n"
     ]
    }
   ],
   "source": [
    "#goal define edges of\n",
    "#connected backbone 1, \n",
    "#unconnected atoms 0,\n",
    "\n",
    "\n",
    "def get_midpoint(ep_in):\n",
    "    \"\"\"Get midpoint, of each batched set of points\"\"\"\n",
    "    \n",
    "    #calculate midpoint\n",
    "    midpoint = ep_in.sum(axis=1)/np.repeat(ep_in.shape[1], ep_in.shape[2])\n",
    "    \n",
    "    return midpoint\n",
    "\n",
    "\n",
    "def normalize_points(input_xyz, print_dist=False):\n",
    "    \n",
    "    #broadcast to distance matrix [Batch, M, R3] to [Batch,M,1, R3] to [Batch,1,M, R3] to [Batch, M,M, R3] \n",
    "    vec_diff = input_xyz[...,None,:]-input_xyz[...,None,:,:]\n",
    "    dist = np.sqrt(np.sum(np.square(vec_diff),axis=len(input_xyz.shape)))\n",
    "    furthest_dist = np.max(dist)\n",
    "    centroid  = get_midpoint(input_xyz)\n",
    "    if print_dist:\n",
    "        print(f'largest distance {furthest_dist:0.1f}')\n",
    "    \n",
    "    xyz_mean_zero = input_xyz - centroid[:,None,:]\n",
    "    return xyz_mean_zero/furthest_dist\n",
    "\n",
    "def normalize(v):\n",
    "    norm = np.linalg.norm(v)\n",
    "    if norm == 0: \n",
    "        return v\n",
    "    return v / norm\n",
    "\n",
    "def define_graph_edges(n_nodes):\n",
    "    #connected backbone\n",
    "\n",
    "    con_v1 = np.arange(n_nodes-1) #vertex 1 of edges in chronological order\n",
    "    con_v2 = np.arange(1,n_nodes) #vertex 2 of edges in chronological order\n",
    "\n",
    "    ind = con_v1*(n_nodes-1)+con_v2-1 #account for removed self connections (-1)\n",
    "\n",
    "\n",
    "    #unconnected backbone\n",
    "\n",
    "    nodes = np.arange(n_nodes)\n",
    "    v1 = np.repeat(nodes,n_nodes-1) #starting vertices, same number repeated for each edge\n",
    "\n",
    "    start_v2 = np.repeat(np.arange(n_nodes)[None,:],n_nodes,axis=0)\n",
    "    diag_ind = np.diag_indices(n_nodes)\n",
    "    start_v2[diag_ind] = -1 #diagonal of matrix is self connections which we remove (self connections are managed by SE3 Conv channels)\n",
    "    v2 = start_v2[start_v2>-0.5] #remove diagonal and flatten\n",
    "\n",
    "    edge_data = torch.zeros(len(v2))\n",
    "    edge_data[ind] = 1\n",
    "    \n",
    "    return v1,v2,edge_data, ind\n",
    "\n",
    "def make_pe_encoding(n_nodes=65, embed_dim = 12, scale = 1000, cast_type=torch.float32, print_out=False):\n",
    "    #positional encoding of node\n",
    "    i_array = np.arange(1,(embed_dim/2)+1)\n",
    "    wk = (1/(scale**(i_array*2/embed_dim)))\n",
    "    t_array = np.arange(n_nodes)\n",
    "    si = torch.tensor(np.sin(wk*t_array.reshape((-1,1))))\n",
    "    ci = torch.tensor(np.cos(wk*t_array.reshape((-1,1))))\n",
    "    pe = torch.stack((si,ci),axis=2).reshape(t_array.shape[0],embed_dim).type(cast_type)\n",
    "    \n",
    "    if print_out == True:\n",
    "        for x in range(int(n_nodes/12)):\n",
    "            print(np.round(pe[x],1))\n",
    "    \n",
    "    return pe\n",
    "    \n",
    "    \n",
    "#v1,v2,edge_data, ind = define_graph_edges(n_nodes)\n",
    "#norm_p = normalize_points(ca_coords,print_dist=True)\n",
    "pe = make_pe_encoding(n_nodes=65, embed_dim = 12, scale = 10, print_out=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "d9979efa",
   "metadata": {},
   "outputs": [],
   "source": [
    "#v1,v2,edge_data, ind = define_graph_edges(4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "321dc5e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "#?dgl.nn.pytorch.KNNGraph, nearest neighbor graph maker\n",
    "def define_graph(batch_size=8,n_nodes=65):\n",
    "    \n",
    "    v1,v2,edge_data, ind = define_graph_edges(n_nodes)\n",
    "    pe = make_pe_encoding(n_nodes=n_nodes)\n",
    "    \n",
    "    graphList = []\n",
    "    \n",
    "    for i in range(batch_size):\n",
    "        \n",
    "        g = dgl.graph((v1,v2))\n",
    "        g.edata['con'] = edge_data\n",
    "        g.ndata['pe'] = pe\n",
    "\n",
    "        graphList.append(g)\n",
    "        \n",
    "    batched_graph = dgl.batch(graphList)\n",
    "\n",
    "    return batched_graph\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "5cc4e2ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "def define_UGraph(n_nodes, batch_size, cast_type=torch.float32, cuda_out=True ):\n",
    "    \n",
    "    v1,v2,edge_data, ind = define_graph_edges(n_nodes)\n",
    "    #pe = make_pe_encoding(n_nodes=n_nodes)#pe e\n",
    "    \n",
    "    graphList = []\n",
    "    \n",
    "    for i in range(batch_size):\n",
    "        \n",
    "        g = dgl.graph((v1,v2))\n",
    "        g.edata['con'] = edge_data.type(cast_type).reshape((-1,1))\n",
    "        g.ndata['pos'] = torch.zeros((n_nodes,3),dtype=torch.float32)\n",
    "\n",
    "        graphList.append(g)\n",
    "        \n",
    "    batched_graph = dgl.batch(graphList)\n",
    "    \n",
    "    if cuda_out:\n",
    "        return to_cuda(batched_graph)\n",
    "    else:\n",
    "        return batched_graph\n",
    "\n",
    "def get_edge_features(graph,edge_feature_dim=1):\n",
    "    return {'0': graph.edata['con'][:, :edge_feature_dim, None]}\n",
    "\n",
    "class Graph_4H_Dataset(Dataset):\n",
    "    def __init__(self, coordinates, cast_type=torch.float32):\n",
    "                                    #prots,#length_prot in aa, #residues/aa, #xyz per atom\n",
    "            \n",
    "        #alphaFold reduce by 10\n",
    "        coordinates = coordinates/10\n",
    "            \n",
    "        self.ca_coords = coordinates[:,:,CA,:]\n",
    "        #unsqueeze to stack together later\n",
    "        self.N_CA_vec = torch.tensor(coordinates[:,:,N,:] - coordinates[:,:,CA,:], dtype=cast_type).unsqueeze(2)\n",
    "        self.C_CA_vec = torch.tensor(coordinates[:,:,C,:] - coordinates[:,:,CA,:], dtype=cast_type).unsqueeze(2)\n",
    "        \n",
    "        #set mean to zero and max_distance between points to 1, is this necessary? since se3 transforms distances\n",
    "        #self.norm_ca = normalize_points(self.ca_coords)\n",
    "        \n",
    "        \n",
    "        n_nodes = self.ca_coords.shape[1] \n",
    "        \n",
    "        v1,v2,edge_data, ind = define_graph_edges(n_nodes)\n",
    "        pe = make_pe_encoding(n_nodes=n_nodes)\n",
    "\n",
    "        graphList = []\n",
    "\n",
    "        for i,c in enumerate(self.ca_coords):\n",
    "\n",
    "            g = dgl.graph((v1,v2))\n",
    "            g.edata['con'] = edge_data.type(cast_type).reshape((-1,1))\n",
    "            g.ndata['pe'] = pe\n",
    "            g.ndata['pos'] = torch.tensor(c,dtype=cast_type)\n",
    "            g.ndata['bb_ori'] = torch.cat((self.N_CA_vec[i],self.C_CA_vec[i]),axis=1)\n",
    "            graphList.append(g)\n",
    "        \n",
    "        self.graphList = graphList\n",
    "\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.graphList)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        return self.graphList[idx]\n",
    "\n",
    "def _get_relative_pos(graph_in: dgl.DGLGraph) -> torch.Tensor:\n",
    "    x = graph_in.ndata['pos']\n",
    "    src, dst = graph_in.edges()\n",
    "    rel_pos = x[dst] - x[src]\n",
    "    return rel_pos\n",
    "    \n",
    "#needs to be done\n",
    "class H4_DataModule():\n",
    "    \"\"\"\n",
    "    Datamodule wrapping hGen data set. 8 Helical endpoints defining a four helix protein.\n",
    "    \"\"\"\n",
    "    #8 long positional encoding\n",
    "    NODE_FEATURE_DIM_0 = 12\n",
    "    EDGE_FEATURE_DIM = 1 # 0 or 1 helix or loop\n",
    "    NODE_FEATURE_DIM_1 = 2\n",
    "    \n",
    "\n",
    "    def __init__(self,\n",
    "                 coords: np.array, batch_size=8):\n",
    "        \n",
    "        self.GraphDatasetObj = Graph_4H_Dataset(coords)\n",
    "        self.gds = DataLoader(self.GraphDatasetObj, batch_size=batch_size, shuffle=True, drop_last=True,\n",
    "                              collate_fn=self._collate)\n",
    "        \n",
    "    \n",
    "        \n",
    "    def _collate(self, graphs):\n",
    "        batched_graph = dgl.batch(graphs)\n",
    "        #reshape that batched graph to redivide into the individual graphs\n",
    "        edge_feats = {'0': batched_graph.edata['con'][:, :self.EDGE_FEATURE_DIM, None]}\n",
    "        batched_graph.edata['rel_pos'] = _get_relative_pos(batched_graph)\n",
    "        # get node features\n",
    "        node_feats = {'0': batched_graph.ndata['pe'][:, :self.NODE_FEATURE_DIM_0, None],\n",
    "                      '1': batched_graph.ndata['bb_ori'][:,:self.NODE_FEATURE_DIM_1, :3]}\n",
    "        \n",
    "        return (batched_graph, node_feats, edge_feats)\n",
    "    \n",
    "class GaussianNoise(nn.Module):\n",
    "    \"\"\"Gaussian noise regularizer.\n",
    "\n",
    "    Args:\n",
    "        sigma (float, optional): relative standard deviation used to generate the\n",
    "            noise. Relative means that it will be multiplied by the magnitude of\n",
    "            the value your are adding the noise to. This means that sigma can be\n",
    "            the same regardless of the scale of the vector.\n",
    "        is_relative_detach (bool, optional): whether to detach the variable before\n",
    "            computing the scale of the noise. If `False` then the scale of the noise\n",
    "            won't be seen as a constant but something to optimize: this will bias the\n",
    "            network to generate vectors with smaller values.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, sigma=0.1):\n",
    "        super().__init__()\n",
    "        self.sigma = sigma\n",
    "        self.noise = torch.tensor(0,dtype=torch.float)\n",
    "\n",
    "    def forward(self,x,scale=1.0):\n",
    "        if self.sigma != 0:\n",
    "            #without modifer mult, mean=0, std_dev=1\n",
    "            sampled_noise = (self.noise.repeat(*x.size()).normal_() * self.sigma*scale).to(x.device)\n",
    "            x = x + sampled_noise\n",
    "        return x, sampled_noise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "e69a49f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def topK_se3(graph, feat, xi, k):\n",
    "    #remove this read from graph code, since se3 transformer natively uses pulled out feats from graph\n",
    "    # READOUT_ON_ATTRS = {\n",
    "    #     \"nodes\": (\"ndata\", \"batch_num_nodes\", \"number_of_nodes\"),\n",
    "    #     \"edges\": (\"edata\", \"batch_num_edges\", \"number_of_edges\"),\n",
    "    # }\n",
    "    # _, batch_num_objs_attr, _ = READOUT_ON_ATTRS[\"nodes\"]\n",
    "\n",
    "    # #this is a fancy way of saying 'batch_num_nodes\n",
    "    # data = getattr(bg, \"nodes\")[None].data\n",
    "    # if F.ndim(data[feat]) > 2:\n",
    "    #     raise DGLError(\n",
    "    #         \"Only support {} feature `{}` with dimension less than or\"\n",
    "    #         \" equal to 2\".format(typestr, feat)\n",
    "    #     )\n",
    "    # feat = data[feat]\n",
    "\n",
    "\n",
    "    hidden_size = feat.shape[-1]\n",
    "    batch_num_objs = getattr(graph, 'batch_num_nodes')(None)\n",
    "    batch_size = len(batch_num_objs)\n",
    "    descending = True\n",
    "\n",
    "    length = max(max(F.asnumpy(batch_num_objs)), k) #max k or batch of nodes size\n",
    "    fill_val = -float(\"inf\") if descending else float(\"inf\")\n",
    "    \n",
    "    feat_y = F.pad_packed_tensor(\n",
    "        feat, batch_num_objs, fill_val, l_min=k\n",
    "    )  # (batch_size, l, d)\n",
    "\n",
    "    order = F.argsort(feat_y, 1, descending=descending)\n",
    "    topk_indices_unsort_batch = F.slice_axis(order, 1, 0, k)\n",
    "    #sort to matches original connectivity with define_graph_edges, likely change but probably won't hurt now\n",
    "    topk_indices, tpk_ind = torch.sort(topk_indices_unsort_batch,dim=1) \n",
    "\n",
    "    #get batch shifts\n",
    "    feat_ = F.reshape(feat_y, (-1,))\n",
    "    shift = F.repeat(\n",
    "        F.arange(0, batch_size), k * hidden_size, -1\n",
    "    ) * length * hidden_size + F.cat(\n",
    "        [F.arange(0, hidden_size)] * batch_size * k, -1\n",
    "    )\n",
    "    \n",
    "    shift = F.copy_to(shift, F.context(feat))\n",
    "    topk_indices_ = F.reshape(topk_indices, (-1,)) * hidden_size + shift\n",
    "    #trainable params gather\n",
    "    out_y = F.reshape(F.gather_row(feat_, topk_indices_), (batch_size*k, -1))\n",
    "    out_y = F.replace_inf_with_zero(out_y)\n",
    "    #nodes features gather\n",
    "    out_xi = F.reshape(F.gather_row(xi, topk_indices_), (batch_size*k, -1))\n",
    "    out_xi = F.replace_inf_with_zero(out_xi)\n",
    "    return out_y, out_xi, topk_indices_\n",
    "\n",
    "\n",
    "class TopK_Pool(torch.nn.Module):\n",
    "    \"\"\"\n",
    "    https://arxiv.org/pdf/1905.05178.pdf\n",
    "    Project Node Features to 1D for topK pooling using trainable weights\n",
    "    #code from Linear Layer SE3 add topK_se3 method\n",
    "    Only type '0' features coded so far, no interactions between types on linear layers\n",
    "    \"\"\"\n",
    "    \n",
    "    #in the future can I pool '1' features\n",
    "\n",
    "    def __init__(self, fiber_in: Fiber, k=5):\n",
    "        super().__init__()\n",
    "        self.k = k\n",
    "        fiber_out = Fiber({0: 1}) #convert to 1D of nodes for topK selection\n",
    "        self.weights = torch.nn.ParameterDict({\n",
    "            str(degree_out): torch.nn.Parameter(\n",
    "                torch.randn(channels_out, fiber_in[degree_out]) / np.sqrt(fiber_in[degree_out]))\n",
    "            for degree_out, channels_out in fiber_out\n",
    "        })\n",
    "        \n",
    "\n",
    "\n",
    "    def forward(self, features: Dict[str, Tensor], graph: DGLGraph) -> Dict[str, Tensor]:\n",
    "        #add topK selection, sigmoid, return nodes\n",
    "        yi = {\n",
    "            degree: torch.div(self.weights[degree] @ features[degree], self.weights[degree].norm())\n",
    "            for degree, weight in self.weights.items()\n",
    "        }\n",
    "        y_selected, feats_selected, topk_indices_batched = topK_se3(graph, yi['0'], features['0'], self.k)\n",
    "        return {'0':(torch.sigmoid(y_selected)*feats_selected).unsqueeze(-1)}, topk_indices_batched\n",
    "    \n",
    "class Unpool(torch.nn.Module):\n",
    "    \"\"\"\n",
    "    Place features into torch.zeros array\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "\n",
    "    def forward(self, features: Dict[str, Tensor], graph: DGLGraph, idx: Tensor, u_features: Dict[str, Tensor]):\n",
    "        out_feats = {}\n",
    "        for key,val in features.items():\n",
    "            new_h = val.new_zeros([graph.num_nodes(), val.shape[1], 1])\n",
    "            out_feats[key] = F.scatter_row(new_h,idx,val)\n",
    "            out_feats[key] = torch.add(out_feats[key],u_features[key])\n",
    "        return out_feats\n",
    "    \n",
    "class Latent_Unpool(torch.nn.Module):\n",
    "    \"\"\"\n",
    "    Duplicate Latent onto Graph\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "\n",
    "    def forward(self, features: Dict[str, Tensor], graph: DGLGraph, u_features: Dict[str, Tensor]):\n",
    "        out_feats = {}\n",
    "        for key,val in features.items():\n",
    "            new_h = val.repeat_interleave(int(graph.num_nodes()/val.shape[0]),0)\n",
    "            out_feats[key] = torch.add(new_h,u_features[key])\n",
    "        return out_feats\n",
    "    \n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "64c7f35d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# More complicated version splits error in CA-N and CA-C (giving more accurate CB position)\n",
    "# It returns the rigid transformation from local frame to global frame\n",
    "\n",
    "\n",
    "def rigid_from_3_points(N, Ca, C, non_ideal=False, eps=1e-8):\n",
    "    #N, Ca, C - [B,L, 3]\n",
    "    #R - [B,L, 3, 3], det(R)=1, inv(R) = R.T, R is a rotation matrix\n",
    "    B,L = N.shape[:2]\n",
    "    \n",
    "    v1 = C-Ca\n",
    "    v2 = N-Ca\n",
    "    e1 = v1/(torch.norm(v1, dim=-1, keepdim=True)+eps)\n",
    "    u2 = v2-(torch.einsum('bli, bli -> bl', e1, v2)[...,None]*e1)\n",
    "    e2 = u2/(torch.norm(u2, dim=-1, keepdim=True)+eps)\n",
    "    e3 = torch.cross(e1, e2, dim=-1)\n",
    "    R = torch.cat([e1[...,None], e2[...,None], e3[...,None]], axis=-1) #[B,L,3,3] - rotation matrix\n",
    "    \n",
    "    if non_ideal:\n",
    "        v2 = v2/(torch.norm(v2, dim=-1, keepdim=True)+eps)\n",
    "        cosref = torch.clamp( torch.sum(e1*v2, dim=-1), min=-1.0, max=1.0) # cosine of current N-CA-C bond angle\n",
    "        costgt = cos_ideal_NCAC.item()\n",
    "        cos2del = torch.clamp( cosref*costgt + torch.sqrt((1-cosref*cosref)*(1-costgt*costgt)+eps), min=-1.0, max=1.0 )\n",
    "        cosdel = torch.sqrt(0.5*(1+cos2del)+eps)\n",
    "        sindel = torch.sign(costgt-cosref) * torch.sqrt(1-0.5*(1+cos2del)+eps)\n",
    "        Rp = torch.eye(3, device=N.device).repeat(B,L,1,1)\n",
    "        Rp[:,:,0,0] = cosdel\n",
    "        Rp[:,:,0,1] = -sindel\n",
    "        Rp[:,:,1,0] = sindel\n",
    "        Rp[:,:,1,1] = cosdel\n",
    "    \n",
    "        R = torch.einsum('blij,bljk->blik', R,Rp)\n",
    "\n",
    "    return R, Ca\n",
    "\n",
    "def get_t(N, Ca, C, non_ideal=False, eps=1e-5):\n",
    "    I,B,L=N.shape[:3]\n",
    "    Rs,Ts = rigid_from_3_points(N.view(I*B,L,3), Ca.view(I*B,L,3), C.view(I*B,L,3), non_ideal=non_ideal, eps=eps)\n",
    "    Rs = Rs.view(I,B,L,3,3)\n",
    "    Ts = Ts.view(I,B,L,3)\n",
    "    t = Ts[:,:,None] - Ts[:,:,:,None] # t[0,1] = residue 0 -> residue 1 vector\n",
    "    return einsum('iblkj, iblmk -> iblmj', Rs, t) # (I,B,L,L,3)\n",
    "\n",
    "def FAPE_loss(pred, true,  d_clamp=10.0, d_clamp_inter=30.0, A=10.0, gamma=1.0, eps=1e-6):\n",
    "    '''\n",
    "    Calculate Backbone FAPE loss from RosettaTTAFold\n",
    "    https://github.com/uw-ipd/RoseTTAFold2/blob/main/network/loss.py\n",
    "    Input:\n",
    "        - pred: predicted coordinates (I, B, L, n_atom, 3)\n",
    "        - true: true coordinates (B, L, n_atom, 3)\n",
    "    Output: str loss\n",
    "    '''\n",
    "    I = pred.shape[0]\n",
    "    true = true.unsqueeze(0)\n",
    "    t_tilde_ij = get_t(true[:,:,:,0], true[:,:,:,1], true[:,:,:,2])\n",
    "    t_ij = get_t(pred[:,:,:,0], pred[:,:,:,1], pred[:,:,:,2])\n",
    "\n",
    "    difference = torch.sqrt(torch.square(t_tilde_ij-t_ij).sum(dim=-1) + eps)\n",
    "    eij_label = difference[-1].clone().detach()\n",
    "\n",
    "    clamp = torch.zeros_like(difference)\n",
    "\n",
    "    # intra vs inter#me coded\n",
    "    clamp[:,True] = d_clamp\n",
    "\n",
    "    difference = torch.clamp(difference, max=clamp)\n",
    "    loss = difference / A # (I, B, L, L)\n",
    "\n",
    "    # calculate masked loss (ignore missing regions when calculate loss)\n",
    "    loss = (loss[:,True]).sum(dim=-1) / (torch.ones_like(loss).sum()+eps) # (I)\n",
    "\n",
    "    # weighting loss\n",
    "    w_loss = torch.pow(torch.full((I,), gamma, device=pred.device), torch.arange(I, device=pred.device))\n",
    "    w_loss = torch.flip(w_loss, (0,))\n",
    "    w_loss = w_loss / w_loss.sum()\n",
    "\n",
    "    tot_loss = (w_loss * loss).sum()\n",
    "    \n",
    "    return tot_loss, loss.detach()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "71dcb7b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def pull_edge_features(graph, edge_feat_dim=1):\n",
    "    return {'0': graph.edata['con'][:, :edge_feat_dim, None]}\n",
    "\n",
    "def prep_for_gcn(graph, xyz_pos, edge_feats_input, idx, max_degree=3, comp_grad=True):\n",
    "    \n",
    "    src, dst = graph.edges()\n",
    "    \n",
    "    new_pos = F.gather_row(xyz_pos, idx)\n",
    "    rel_pos = F.gather_row(new_pos,dst) - F.gather_row(new_pos,src) \n",
    "    \n",
    "    basis_out = get_basis(rel_pos, max_degree=max_degree,\n",
    "                                   compute_gradients=comp_grad,\n",
    "                                   use_pad_trick=False)\n",
    "    basis_out = update_basis_with_fused(basis_out, max_degree, use_pad_trick=False,\n",
    "                                            fully_fused=False)\n",
    "    edge_feats_out = get_populated_edge_features(rel_pos, edge_feats_input)\n",
    "    return edge_feats_out, basis_out, new_pos\n",
    "\n",
    "\n",
    "class GraphUNet(torch.nn.Module):\n",
    "    def __init__(self, \n",
    "                 pred_fiber=Fiber({0: 12, 1:12}),\n",
    "                 ks = [5],\n",
    "                 batch_size = 8,\n",
    "                 in_dim=12,\n",
    "                 ndf_mult=4,\n",
    "                 max_degree=3,\n",
    "                 num_heads = 8,\n",
    "                 channels_div=2,\n",
    "                 max_nodes = 65,\n",
    "                 cuda_out=True,\n",
    "                 comp_basis_grad=True):\n",
    "        super(GraphUNet, self).__init__()\n",
    "        self.edge_feature_dim = 1\n",
    "        \n",
    "        self.comp_basis_grad = comp_basis_grad\n",
    "        self.ks = ks\n",
    "        \n",
    "        self.down_gcns = nn.ModuleList()\n",
    "        self.up_gcns = nn.ModuleList()\n",
    "        self.pools = nn.ModuleList()\n",
    "        self.unpools = nn.ModuleList()\n",
    "        \n",
    "        self.l_n = len(ks)\n",
    "        \n",
    "        out_dim = in_dim*ndf_mult\n",
    "        \n",
    "        for i in range(self.l_n):\n",
    "            self.down_gcns.append(AttentionBlockSE3(fiber_in= Fiber({0: in_dim, 1: 2}),\n",
    "                                                     fiber_out  = Fiber({0: out_dim}),\n",
    "                                                     fiber_edge = Fiber({0: self.edge_feature_dim}),\n",
    "                                                     num_heads=num_heads,\n",
    "                                                     channels_div=channels_div,\n",
    "                                                     use_layer_norm=True,\n",
    "                                                     max_degree=max_degree,\n",
    "                                                     fuse_level=ConvSE3FuseLevel.NONE,\n",
    "                                                     low_memory='True'))\n",
    "        \n",
    "            self.pools.append(TopK_Pool(Fiber({0: out_dim}), k=ks[i]))\n",
    "                                  \n",
    "            in_dim = out_dim\n",
    "            out_dim = in_dim*ndf_mult\n",
    "                                  \n",
    "        self.bottom_gcn = AttentionBlockSE3( fiber_in= Fiber({0: in_dim}),\n",
    "                                                     fiber_out  = Fiber({0: out_dim}),\n",
    "                                                     fiber_edge = Fiber({0: self.edge_feature_dim}),\n",
    "                                                     num_heads=num_heads,\n",
    "                                                     channels_div=channels_div,\n",
    "                                                     use_layer_norm=True,\n",
    "                                                     max_degree=max_degree,\n",
    "                                                     fuse_level=ConvSE3FuseLevel.NONE,\n",
    "                                                     low_memory='True')\n",
    "        \n",
    "        self.global_pool = GPooling(pool='avg', feat_type=0)\n",
    "        self.latent_unpool = Latent_Unpool()\n",
    "        \n",
    "        in_dim = out_dim\n",
    "        out_dim = out_dim/ndf_mult\n",
    "                                          \n",
    "        for i in range(self.l_n):\n",
    "            self.up_gcns.append(AttentionBlockSE3( fiber_in= Fiber({0: in_dim}),\n",
    "                                                     fiber_out  = Fiber({0: out_dim}),\n",
    "                                                     fiber_edge = Fiber({0: self.edge_feature_dim}),\n",
    "                                                     num_heads=num_heads,\n",
    "                                                     channels_div=channels_div,\n",
    "                                                     use_layer_norm=True,\n",
    "                                                     max_degree=max_degree,\n",
    "                                                     fuse_level=ConvSE3FuseLevel.NONE,\n",
    "                                                     low_memory='True'))\n",
    "        \n",
    "            self.unpools.append(Unpool())\n",
    "            \n",
    "            in_dim = out_dim\n",
    "            out_dim = out_dim/ndf_mult\n",
    "            \n",
    "        #channels div set at num head here\n",
    "        self.top_gcn = AttentionBlockSE3( fiber_in= Fiber({0: in_dim}),\n",
    "                                                     fiber_out  = pred_fiber,\n",
    "                                                     fiber_edge = Fiber({0: self.edge_feature_dim}),\n",
    "                                                     num_heads=4,\n",
    "                                                     channels_div=2,\n",
    "                                                     use_layer_norm=True,\n",
    "                                                     max_degree=max_degree,\n",
    "                                                     fuse_level=ConvSE3FuseLevel.NONE,\n",
    "                                                     low_memory='True')\n",
    "        \n",
    "#         self.pred_gcn = AttentionBlockSE3( fiber_in= Fiber({0: 24}),\n",
    "#                                                      fiber_out  = pred_fiber ,\n",
    "#                                                      fiber_edge = Fiber({0: self.edge_feature_dim}),\n",
    "#                                                      num_heads=16,\n",
    "#                                                      channels_div=2,\n",
    "#                                                      use_layer_norm=True,\n",
    "#                                                      max_degree=max_degree,\n",
    "#                                                      fuse_level=ConvSE3FuseLevel.NONE,\n",
    "#                                                      low_memory='True')\n",
    "#         self.final_conv   =   ConvSE3(fiber_in=pred_fiber,\n",
    "#                                       fiber_out= Fiber({0:1,1:2}),\n",
    "#                                       fiber_edge= Fiber({0: self.edge_feature_dim}),\n",
    "#                                       self_interaction=True,\n",
    "#                                       use_layer_norm=True,\n",
    "#                                       max_degree=max_degree,\n",
    "#                                       low_memory=False)\n",
    "        \n",
    "        self.final = LinearSE3(fiber_in=pred_fiber,fiber_out= Fiber({0:1,1:3}))\n",
    "\n",
    "        \n",
    "        self.graph_list = [define_UGraph(max_nodes, batch_size, cast_type=torch.float32, cuda_out=cuda_out )]\n",
    "        self.edge_pre = [pull_edge_features(self.graph_list[-1], edge_feat_dim=1)] #define edge feats here from graph definitions\n",
    "        for i in range(self.l_n):\n",
    "            max_nodes = ks[i]\n",
    "            self.graph_list.append(define_UGraph(max_nodes, batch_size, cast_type=torch.float32, cuda_out=cuda_out))\n",
    "            self.edge_pre.append(pull_edge_features(self.graph_list[-1], edge_feat_dim=1))\n",
    "            \n",
    "\n",
    "            \n",
    "    def forward(self, node_feats_in, batched_graph):\n",
    "        \n",
    "        indices_list = [batched_graph.num_nodes()]\n",
    "        down_gcn_in = [node_feats_in] #node features from gcn outputs\n",
    "        down_gcn_out = []\n",
    "        down_pools = []\n",
    "        \n",
    "        up_gcn_in = []\n",
    "        up_gcn_out = []\n",
    "        \n",
    "        pos = [batched_graph.ndata['pos']]\n",
    "        edge_basis_pos_post = []\n",
    "        \n",
    "        #gcn and down pooling\n",
    "        for i in range(self.l_n):\n",
    "            #define basis (spherical harmonics) from xyz_positions, pull edge connections connectivity\n",
    "            edge_basis_pos_post.append(prep_for_gcn(gu.graph_list[i], pos[i], self.edge_pre[i], gu.graph_list[i].nodes(),\n",
    "                                                    comp_grad = self.comp_basis_grad))\n",
    "\n",
    "            down_gcn_out.append(gu.down_gcns[i].forward(down_gcn_in[i], edge_basis_pos_post[i][0],\n",
    "                                                        graph=gu.graph_list[i],basis=edge_basis_pos_post[i][1]))\n",
    "            #top k pool, save indices pooled for unpooling\n",
    "            out_and_indx = gu.pools[i](down_gcn_out[i], gu.graph_list[i])\n",
    "            #save indices, level outputs (topk pool node features), and positions for other side of unet (unpooling and adding)\n",
    "            #and use in lower levels\n",
    "            down_gcn_in.append(out_and_indx[0])\n",
    "            indices_list.append(out_and_indx[1])\n",
    "            pos.append(edge_basis_pos_post[i][2])\n",
    "          \n",
    "        edge_basis_pos_post.append(prep_for_gcn(gu.graph_list[-1], pos[-1], self.edge_pre[-1], gu.graph_list[-1].nodes(),\n",
    "                                               comp_grad = self.comp_basis_grad))\n",
    "        \n",
    "        \n",
    "        bottom_out = self.bottom_gcn.forward(down_gcn_in[-1], edge_basis_pos_post[-1][0],\n",
    "                                graph=gu.graph_list[-1],basis=edge_basis_pos_post[-1][1])\n",
    "        \n",
    "        latent = {'0':self.global_pool(bottom_out, graph=gu.graph_list[-1]).unsqueeze(-1)}\n",
    "        up_gcn_in.append(gu.latent_unpool(latent, graph=gu.graph_list[-1],u_features=bottom_out))\n",
    "        \n",
    "        reverse_counter = self.l_n\n",
    "        #up gcns\n",
    "        for i in range(self.l_n):\n",
    "            up_gcn_out.append(gu.up_gcns[i].forward(up_gcn_in[i],edge_basis_pos_post[reverse_counter-i][0],\n",
    "                                                    graph=gu.graph_list[reverse_counter-i],\n",
    "                                                    basis=edge_basis_pos_post[reverse_counter-i][1]))\n",
    "            \n",
    "            up_gcn_in.append(gu.unpools[i](up_gcn_out[i],graph=gu.graph_list[i],\n",
    "                                           idx = indices_list[reverse_counter-i],\n",
    "                                           u_features=down_gcn_out[reverse_counter-i-1])) #add from level up\n",
    "            \n",
    "        \n",
    "        final = self.top_gcn(up_gcn_in[-1],edge_basis_pos_post[0][0],\n",
    "                     graph=gu.graph_list[0],basis=edge_basis_pos_post[0][1])\n",
    "        \n",
    "#         pred_move = self.pred_gcn(final,edge_basis_pos_post[0][0],\n",
    "#                      graph=gu.graph_list[0],basis=edge_basis_pos_post[0][1])\n",
    "        \n",
    "        final2 =   self.final(final,edge_basis_pos_post[0][0])\n",
    "        \n",
    "        #add NC_ CA Vecs back to start\n",
    "        final2['1'][:,1,:] = final2['1'][:,1,:] + down_gcn_in[0]['1'][:,0,:]\n",
    "        final2['1'][:,2,:] = final2['1'][:,2,:] + down_gcn_in[0]['1'][:,1,:]\n",
    "        \n",
    "        return final2\n",
    "        \n",
    "            \n",
    "        \n",
    "#         for i in range(self.l_n):\n",
    "#             feats\n",
    "        \n",
    "#         def forward(self, g, h):\n",
    "#         adj_ms = []\n",
    "#         indices_list = []\n",
    "#         down_outs = []\n",
    "#         hs = []\n",
    "#         org_h = h\n",
    "#         for i in range(self.l_n):\n",
    "            \n",
    "#             basis = get_basis(rel_pos, max_degree=max_degree,\n",
    "#                                    compute_gradients=True,\n",
    "#                                    use_pad_trick=False)\n",
    "            \n",
    "#             h = self.down_gcns[i](self.graph_list[i], h)\n",
    "            \n",
    "            \n",
    "#             adj_ms.append(g)\n",
    "#             down_outs.append(h)\n",
    "#             g, h, idx = self.pools[i](g, h)\n",
    "#             indices_list.append(idx)\n",
    "#         h = self.bottom_gcn(g, h)\n",
    "#         for i in range(self.l_n):\n",
    "#             up_idx = self.l_n - i - 1\n",
    "#             g, idx = adj_ms[up_idx], indices_list[up_idx]\n",
    "#             g, h = self.unpools[i](g, h, down_outs[up_idx], idx)\n",
    "#             h = self.up_gcns[i](g, h)\n",
    "#             h = h.add(down_outs[up_idx])\n",
    "#             hs.append(h)\n",
    "#         h = h.add(org_h)\n",
    "#         hs.append(h)\n",
    "#         return hs\n",
    "    \n",
    "def train_step(batched_graph, node_feats, gauss_noise, graph_unet):\n",
    "    \n",
    "    true_pos = batched_graph.ndata['pos'].clone()\n",
    "\n",
    "    #add vectors for \n",
    "    CA_t  = true_pos.reshape(B, L, 3)\n",
    "    NC_t = CA_t + node_feats['1'][:,0,:].reshape(B, L, 3)\n",
    "    CC_t = CA_t + node_feats['1'][:,1,:].reshape(B, L, 3)\n",
    "    true =  torch.cat((NC_t,CA_t,CC_t),dim=2).reshape(B,L,3,3)\n",
    "\n",
    "    \n",
    "    batched_graph.ndata['pos'], noise = gauss_noise.forward(batched_graph.ndata['pos'])\n",
    "\n",
    "\n",
    "    shift=gu.forward(node_feats,  batched_graph)\n",
    "    #offset = shift['1'].reshape(B, L, 3)\n",
    "    #pred = torch.add(Ts.reshape(B, L, 3), batched_graph.ndata['pos'].reshape(B, L, 3))\n",
    "    \n",
    "    CA_p = shift['1'][:,0,:].reshape(B, L, 3)+batched_graph.ndata['pos'].reshape(B, L, 3)\n",
    "    NC_p = shift['1'][:,1,:].reshape(B, L, 3)+batched_graph.ndata['pos'].reshape(B, L, 3)\n",
    "    CC_p = shift['1'][:,2,:].reshape(B, L, 3)+batched_graph.ndata['pos'].reshape(B, L, 3)\n",
    "    pred = torch.cat((NC_p,CA_p,CC_p),dim=2).reshape(B,L,3,3)\n",
    "\n",
    "    tloss, loss = FAPE_loss(pred.unsqueeze(0), true)\n",
    "    \n",
    "    opti.zero_grad()\n",
    "    tloss.backward()\n",
    "    opti.step()\n",
    "    \n",
    "    return tloss.detach()\n",
    "                            \n",
    "        \n",
    "        \n",
    "            \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "104e9f6e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_noise_pred_true(batched_graph, node_feats, gauss_noise, model, B, L=65):\n",
    "    \n",
    "    true_pos = batched_graph.ndata['pos'].clone()\n",
    "\n",
    "    #add vectors for N and C atomts\n",
    "    CA_t  = true_pos.reshape(B, L, 3)\n",
    "    NC_t = CA_t + node_feats['1'][:,0,:].reshape(B, L, 3)\n",
    "    CC_t = CA_t + node_feats['1'][:,1,:].reshape(B, L, 3)\n",
    "    true =  torch.cat((NC_t,CA_t,CC_t),dim=2).reshape(B,L,3,3)\n",
    "\n",
    "    \n",
    "    batched_graph.ndata['pos'], noise = gauss_noise.forward(batched_graph.ndata['pos'])\n",
    "    \n",
    "    CA_n = batched_graph.ndata['pos'].clone().reshape(B, L, 3)\n",
    "    NC_n = CA_n + node_feats['1'][:,0,:].reshape(B, L, 3)\n",
    "    CC_n = CA_n + node_feats['1'][:,1,:].reshape(B, L, 3)\n",
    "    noise_xyz =  torch.cat((NC_n,CA_n,CC_n),dim=2).reshape(B,L,3,3)\n",
    "\n",
    "\n",
    "    shift= model.forward(node_feats, batched_graph)\n",
    "    #offset = shift['1'].reshape(B, L, 3)\n",
    "    #pred = torch.add(Ts.reshape(B, L, 3), batched_graph.ndata['pos'].reshape(B, L, 3))\n",
    "    \n",
    "    CA_p = shift['1'][:,0,:].reshape(B, L, 3)+batched_graph.ndata['pos'].reshape(B, L, 3)\n",
    "    NC_p = shift['1'][:,1,:].reshape(B, L, 3)+batched_graph.ndata['pos'].reshape(B, L, 3)\n",
    "    CC_p = shift['1'][:,2,:].reshape(B, L, 3)+batched_graph.ndata['pos'].reshape(B, L, 3)\n",
    "    pred = torch.cat((NC_p,CA_p,CC_p),dim=2).reshape(B,L,3,3)\n",
    "    \n",
    "    return true.to('cpu').numpy()*10, noise_xyz.to('cpu').numpy()*10, pred.detach().to('cpu').numpy()*10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "cd9bff8d",
   "metadata": {},
   "outputs": [],
   "source": [
    "B=32\n",
    "L=65\n",
    "gu = GraphUNet(pred_fiber = Fiber({0:24,1:24}), max_degree=3,batch_size=B,cuda_out=True, comp_basis_grad=False).to('cuda')\n",
    "dm = H4_DataModule(coords_tog,batch_size=B)\n",
    "gn = GaussianNoise(sigma=0.05).to('cuda')\n",
    "opti = torch.optim.Adam(gu.parameters(), lr=0.001, weight_decay=5e-6)\n",
    "loss = nn.MSELoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "03abb03d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0.0210, device='cuda:0')\n",
      "tensor(0.0151, device='cuda:0')\n",
      "tensor(0.0135, device='cuda:0')\n",
      "tensor(0.0130, device='cuda:0')\n",
      "tensor(0.0126, device='cuda:0')\n",
      "tensor(0.0124, device='cuda:0')\n",
      "tensor(0.0123, device='cuda:0')\n",
      "tensor(0.0121, device='cuda:0')\n",
      "tensor(0.0121, device='cuda:0')\n",
      "tensor(0.0119, device='cuda:0')\n",
      "tensor(0.0118, device='cuda:0')\n",
      "tensor(0.0117, device='cuda:0')\n",
      "tensor(0.0116, device='cuda:0')\n",
      "tensor(0.0115, device='cuda:0')\n",
      "tensor(0.0115, device='cuda:0')\n",
      "tensor(0.0114, device='cuda:0')\n",
      "tensor(0.0112, device='cuda:0')\n",
      "tensor(0.0112, device='cuda:0')\n",
      "tensor(0.0109, device='cuda:0')\n",
      "tensor(0.0107, device='cuda:0')\n",
      "tensor(0.0104, device='cuda:0')\n",
      "tensor(0.0104, device='cuda:0')\n",
      "tensor(0.0102, device='cuda:0')\n",
      "tensor(0.0100, device='cuda:0')\n",
      "tensor(0.0100, device='cuda:0')\n",
      "tensor(0.0098, device='cuda:0')\n",
      "tensor(0.0098, device='cuda:0')\n",
      "tensor(0.0097, device='cuda:0')\n",
      "tensor(0.0097, device='cuda:0')\n",
      "tensor(0.0096, device='cuda:0')\n",
      "tensor(0.0096, device='cuda:0')\n",
      "tensor(0.0095, device='cuda:0')\n",
      "tensor(0.0095, device='cuda:0')\n",
      "tensor(0.0094, device='cuda:0')\n",
      "tensor(0.0094, device='cuda:0')\n",
      "tensor(0.0094, device='cuda:0')\n",
      "tensor(0.0093, device='cuda:0')\n",
      "tensor(0.0093, device='cuda:0')\n",
      "tensor(0.0093, device='cuda:0')\n",
      "tensor(0.0093, device='cuda:0')\n",
      "tensor(0.0092, device='cuda:0')\n",
      "tensor(0.0092, device='cuda:0')\n",
      "tensor(0.0091, device='cuda:0')\n",
      "tensor(0.0090, device='cuda:0')\n",
      "tensor(0.0091, device='cuda:0')\n",
      "tensor(0.0090, device='cuda:0')\n",
      "tensor(0.0091, device='cuda:0')\n",
      "tensor(0.0090, device='cuda:0')\n",
      "tensor(0.0089, device='cuda:0')\n",
      "tensor(0.0090, device='cuda:0')\n",
      "tensor(0.0089, device='cuda:0')\n",
      "tensor(0.0090, device='cuda:0')\n",
      "tensor(0.0089, device='cuda:0')\n",
      "tensor(0.0088, device='cuda:0')\n",
      "tensor(0.0089, device='cuda:0')\n",
      "tensor(0.0088, device='cuda:0')\n",
      "tensor(0.0088, device='cuda:0')\n",
      "tensor(0.0087, device='cuda:0')\n",
      "tensor(0.0088, device='cuda:0')\n",
      "tensor(0.0088, device='cuda:0')\n",
      "tensor(0.0088, device='cuda:0')\n",
      "tensor(0.0086, device='cuda:0')\n",
      "tensor(0.0086, device='cuda:0')\n",
      "tensor(0.0086, device='cuda:0')\n",
      "tensor(0.0086, device='cuda:0')\n",
      "tensor(0.0085, device='cuda:0')\n",
      "tensor(0.0086, device='cuda:0')\n",
      "tensor(0.0085, device='cuda:0')\n",
      "tensor(0.0084, device='cuda:0')\n",
      "tensor(0.0084, device='cuda:0')\n",
      "tensor(0.0084, device='cuda:0')\n",
      "tensor(0.0084, device='cuda:0')\n",
      "tensor(0.0084, device='cuda:0')\n",
      "tensor(0.0084, device='cuda:0')\n",
      "tensor(0.0083, device='cuda:0')\n",
      "tensor(0.0083, device='cuda:0')\n",
      "tensor(0.0083, device='cuda:0')\n",
      "tensor(0.0082, device='cuda:0')\n",
      "tensor(0.0083, device='cuda:0')\n",
      "tensor(0.0083, device='cuda:0')\n",
      "tensor(0.0082, device='cuda:0')\n",
      "tensor(0.0082, device='cuda:0')\n",
      "tensor(0.0082, device='cuda:0')\n",
      "tensor(0.0082, device='cuda:0')\n",
      "tensor(0.0081, device='cuda:0')\n",
      "tensor(0.0081, device='cuda:0')\n",
      "tensor(0.0082, device='cuda:0')\n",
      "tensor(0.0082, device='cuda:0')\n",
      "tensor(0.0081, device='cuda:0')\n",
      "tensor(0.0081, device='cuda:0')\n",
      "tensor(0.0081, device='cuda:0')\n",
      "tensor(0.0082, device='cuda:0')\n",
      "tensor(0.0081, device='cuda:0')\n",
      "tensor(0.0080, device='cuda:0')\n",
      "tensor(0.0080, device='cuda:0')\n",
      "tensor(0.0080, device='cuda:0')\n",
      "tensor(0.0080, device='cuda:0')\n",
      "tensor(0.0080, device='cuda:0')\n",
      "tensor(0.0080, device='cuda:0')\n",
      "tensor(0.0080, device='cuda:0')\n",
      "tensor(0.0079, device='cuda:0')\n",
      "tensor(0.0079, device='cuda:0')\n",
      "tensor(0.0079, device='cuda:0')\n",
      "tensor(0.0079, device='cuda:0')\n",
      "tensor(0.0079, device='cuda:0')\n",
      "tensor(0.0078, device='cuda:0')\n",
      "tensor(0.0078, device='cuda:0')\n",
      "tensor(0.0078, device='cuda:0')\n",
      "tensor(0.0078, device='cuda:0')\n",
      "tensor(0.0077, device='cuda:0')\n",
      "tensor(0.0078, device='cuda:0')\n",
      "tensor(0.0077, device='cuda:0')\n",
      "tensor(0.0077, device='cuda:0')\n",
      "tensor(0.0077, device='cuda:0')\n",
      "tensor(0.0077, device='cuda:0')\n",
      "tensor(0.0077, device='cuda:0')\n",
      "tensor(0.0077, device='cuda:0')\n",
      "tensor(0.0077, device='cuda:0')\n",
      "tensor(0.0076, device='cuda:0')\n",
      "tensor(0.0076, device='cuda:0')\n",
      "tensor(0.0076, device='cuda:0')\n",
      "tensor(0.0076, device='cuda:0')\n",
      "tensor(0.0076, device='cuda:0')\n",
      "tensor(0.0076, device='cuda:0')\n",
      "tensor(0.0076, device='cuda:0')\n",
      "tensor(0.0076, device='cuda:0')\n",
      "tensor(0.0076, device='cuda:0')\n",
      "tensor(0.0076, device='cuda:0')\n",
      "tensor(0.0076, device='cuda:0')\n",
      "tensor(0.0075, device='cuda:0')\n",
      "tensor(0.0075, device='cuda:0')\n",
      "tensor(0.0076, device='cuda:0')\n",
      "tensor(0.0075, device='cuda:0')\n",
      "tensor(0.0076, device='cuda:0')\n",
      "tensor(0.0075, device='cuda:0')\n",
      "tensor(0.0075, device='cuda:0')\n",
      "tensor(0.0075, device='cuda:0')\n",
      "tensor(0.0075, device='cuda:0')\n",
      "tensor(0.0075, device='cuda:0')\n",
      "tensor(0.0075, device='cuda:0')\n",
      "tensor(0.0074, device='cuda:0')\n",
      "tensor(0.0075, device='cuda:0')\n",
      "tensor(0.0075, device='cuda:0')\n",
      "tensor(0.0075, device='cuda:0')\n",
      "tensor(0.0075, device='cuda:0')\n",
      "tensor(0.0075, device='cuda:0')\n",
      "tensor(0.0075, device='cuda:0')\n",
      "tensor(0.0075, device='cuda:0')\n",
      "tensor(0.0075, device='cuda:0')\n",
      "tensor(0.0075, device='cuda:0')\n",
      "tensor(0.0075, device='cuda:0')\n",
      "tensor(0.0074, device='cuda:0')\n",
      "tensor(0.0075, device='cuda:0')\n",
      "tensor(0.0075, device='cuda:0')\n",
      "tensor(0.0074, device='cuda:0')\n",
      "tensor(0.0074, device='cuda:0')\n",
      "tensor(0.0074, device='cuda:0')\n",
      "tensor(0.0074, device='cuda:0')\n",
      "tensor(0.0074, device='cuda:0')\n",
      "tensor(0.0074, device='cuda:0')\n",
      "tensor(0.0074, device='cuda:0')\n",
      "tensor(0.0074, device='cuda:0')\n",
      "tensor(0.0074, device='cuda:0')\n",
      "tensor(0.0074, device='cuda:0')\n",
      "tensor(0.0074, device='cuda:0')\n",
      "tensor(0.0074, device='cuda:0')\n",
      "tensor(0.0074, device='cuda:0')\n",
      "tensor(0.0074, device='cuda:0')\n",
      "tensor(0.0074, device='cuda:0')\n",
      "tensor(0.0074, device='cuda:0')\n",
      "tensor(0.0074, device='cuda:0')\n",
      "tensor(0.0074, device='cuda:0')\n",
      "tensor(0.0074, device='cuda:0')\n",
      "tensor(0.0074, device='cuda:0')\n",
      "tensor(0.0074, device='cuda:0')\n",
      "tensor(0.0074, device='cuda:0')\n",
      "tensor(0.0074, device='cuda:0')\n",
      "tensor(0.0074, device='cuda:0')\n",
      "tensor(0.0073, device='cuda:0')\n",
      "tensor(0.0074, device='cuda:0')\n",
      "tensor(0.0074, device='cuda:0')\n",
      "tensor(0.0074, device='cuda:0')\n",
      "tensor(0.0074, device='cuda:0')\n",
      "tensor(0.0074, device='cuda:0')\n",
      "tensor(0.0074, device='cuda:0')\n",
      "tensor(0.0074, device='cuda:0')\n",
      "tensor(0.0073, device='cuda:0')\n",
      "tensor(0.0074, device='cuda:0')\n",
      "tensor(0.0074, device='cuda:0')\n",
      "tensor(0.0074, device='cuda:0')\n",
      "tensor(0.0073, device='cuda:0')\n",
      "tensor(0.0074, device='cuda:0')\n",
      "tensor(0.0073, device='cuda:0')\n",
      "tensor(0.0073, device='cuda:0')\n",
      "tensor(0.0073, device='cuda:0')\n",
      "tensor(0.0073, device='cuda:0')\n",
      "tensor(0.0073, device='cuda:0')\n",
      "tensor(0.0073, device='cuda:0')\n",
      "tensor(0.0073, device='cuda:0')\n",
      "tensor(0.0073, device='cuda:0')\n",
      "tensor(0.0073, device='cuda:0')\n",
      "tensor(0.0073, device='cuda:0')\n",
      "tensor(0.0074, device='cuda:0')\n",
      "tensor(0.0073, device='cuda:0')\n",
      "tensor(0.0073, device='cuda:0')\n",
      "tensor(0.0073, device='cuda:0')\n",
      "tensor(0.0073, device='cuda:0')\n",
      "tensor(0.0073, device='cuda:0')\n",
      "tensor(0.0073, device='cuda:0')\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[17], line 7\u001b[0m\n\u001b[1;32m      5\u001b[0m     bg \u001b[38;5;241m=\u001b[39m to_cuda(batched_graph)\n\u001b[1;32m      6\u001b[0m     nf \u001b[38;5;241m=\u001b[39m to_cuda(node_feats)\n\u001b[0;32m----> 7\u001b[0m     out \u001b[38;5;241m=\u001b[39m \u001b[43mtrain_step\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbg\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnf\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgn\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgu\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      8\u001b[0m     lsum \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m out\n\u001b[1;32m     10\u001b[0m \u001b[38;5;28mprint\u001b[39m(lsum\u001b[38;5;241m/\u001b[39mi)\n",
      "Cell \u001b[0;32mIn[12], line 263\u001b[0m, in \u001b[0;36mtrain_step\u001b[0;34m(batched_graph, node_feats, gauss_noise, graph_unet)\u001b[0m\n\u001b[1;32m    260\u001b[0m tloss, loss \u001b[38;5;241m=\u001b[39m FAPE_loss(pred\u001b[38;5;241m.\u001b[39munsqueeze(\u001b[38;5;241m0\u001b[39m), true)\n\u001b[1;32m    262\u001b[0m opti\u001b[38;5;241m.\u001b[39mzero_grad()\n\u001b[0;32m--> 263\u001b[0m \u001b[43mtloss\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbackward\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    264\u001b[0m opti\u001b[38;5;241m.\u001b[39mstep()\n\u001b[1;32m    266\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m tloss\u001b[38;5;241m.\u001b[39mdetach()\n",
      "File \u001b[0;32m~/miniconda3/envs/se33/lib/python3.9/site-packages/torch/_tensor.py:487\u001b[0m, in \u001b[0;36mTensor.backward\u001b[0;34m(self, gradient, retain_graph, create_graph, inputs)\u001b[0m\n\u001b[1;32m    477\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m has_torch_function_unary(\u001b[38;5;28mself\u001b[39m):\n\u001b[1;32m    478\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m handle_torch_function(\n\u001b[1;32m    479\u001b[0m         Tensor\u001b[38;5;241m.\u001b[39mbackward,\n\u001b[1;32m    480\u001b[0m         (\u001b[38;5;28mself\u001b[39m,),\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    485\u001b[0m         inputs\u001b[38;5;241m=\u001b[39minputs,\n\u001b[1;32m    486\u001b[0m     )\n\u001b[0;32m--> 487\u001b[0m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mautograd\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbackward\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    488\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgradient\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mretain_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcreate_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minputs\u001b[49m\n\u001b[1;32m    489\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/envs/se33/lib/python3.9/site-packages/torch/autograd/__init__.py:200\u001b[0m, in \u001b[0;36mbackward\u001b[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001b[0m\n\u001b[1;32m    195\u001b[0m     retain_graph \u001b[38;5;241m=\u001b[39m create_graph\n\u001b[1;32m    197\u001b[0m \u001b[38;5;66;03m# The reason we repeat same the comment below is that\u001b[39;00m\n\u001b[1;32m    198\u001b[0m \u001b[38;5;66;03m# some Python versions print out the first line of a multi-line function\u001b[39;00m\n\u001b[1;32m    199\u001b[0m \u001b[38;5;66;03m# calls in the traceback and some print out the last line\u001b[39;00m\n\u001b[0;32m--> 200\u001b[0m \u001b[43mVariable\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_execution_engine\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun_backward\u001b[49m\u001b[43m(\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# Calls into the C++ engine to run the backward pass\u001b[39;49;00m\n\u001b[1;32m    201\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtensors\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgrad_tensors_\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mretain_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcreate_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    202\u001b[0m \u001b[43m    \u001b[49m\u001b[43mallow_unreachable\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maccumulate_grad\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "for e in range(300):\n",
    "    lsum = 0\n",
    "    for i, inp in enumerate(dm.gds):\n",
    "        batched_graph, node_feats, edge_feats = inp\n",
    "        bg = to_cuda(batched_graph)\n",
    "        nf = to_cuda(node_feats)\n",
    "        out = train_step(bg, nf, gn, gu)\n",
    "        lsum += out\n",
    "\n",
    "    print(lsum/i)\n",
    "    if e%5 ==0:\n",
    "        for y, inp in enumerate(dm.gds):\n",
    "            batched_graph, node_feats, edge_feats = inp\n",
    "            bg = to_cuda(batched_graph)\n",
    "            nf = to_cuda(node_feats)\n",
    "\n",
    "            true, noise, pred= get_noise_pred_true(bg,nf,gn,gu,B)\n",
    "\n",
    "\n",
    "\n",
    "            dump_coord_pdb(true[y],f'output/true_{e}.pdb')\n",
    "            dump_coord_pdb(noise[y],f'output/noised_{e}.pdb')\n",
    "            dump_coord_pdb(pred[y],fileOut=f'output/after_{e}.pdb')\n",
    "\n",
    "            break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "ac0d214a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# for i, inp in enumerate(dm.gds):\n",
    "#     batched_graph, node_feats, edge_feats = inp\n",
    "#     bg = to_cuda(batched_graph)\n",
    "#     nf = to_cuda(node_feats)\n",
    "    \n",
    "#     xyz_noise, noise, true_pos, noisexyz_N_C = get_noise(bg,nf,gn)\n",
    "#     out = pred_CA(bg,nf,gn,gu)\n",
    "#     for x in range(4):\n",
    "#         dump_coord_pdb(true_pos.to('cpu').numpy()[x]*10,f'output/true_{x}.pdb')\n",
    "#         dump_coord_pdb(noisexyz_N_C.to('cpu').numpy()[x]*10,f'output/noised_{x}.pdb')\n",
    "#         dump_coord_pdb(out.to('cpu').numpy()[x]*10,fileOut=f'output/after_{x}.pdb')\n",
    "    \n",
    "#     break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7f3b076",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "74dd2260",
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "The following operation failed in the TorchScript interpreter.\nTraceback of TorchScript (most recent call last):\n  File \"/mnt/c/Users/nwood/OneDrive/Desktop/gudiff/se3_transformer/model/basis.py\", line 114, in update_basis_with_fused\n    for d_out in range(max_degree + 1):\n        sum_freq = sum([degree_to_dim(min(d, d_out)) for d in range(max_degree + 1)])\n        basis_fused = torch.zeros(num_edges, sum_dim, sum_freq, degree_to_dim(d_out) + int(use_pad_trick),\n                      ~~~~~~~~~~~ <--- HERE\n                                  device=device, dtype=dtype)\n        acc_d, acc_f = 0, 0\nRuntimeError: CUDA error: unknown error\nCUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\nFor debugging consider passing CUDA_LAUNCH_BLOCKING=1.\nCompile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[43], line 6\u001b[0m\n\u001b[1;32m      3\u001b[0m bg \u001b[38;5;241m=\u001b[39m to_cuda(batched_graph)\n\u001b[1;32m      4\u001b[0m nf \u001b[38;5;241m=\u001b[39m to_cuda(node_feats)\n\u001b[0;32m----> 6\u001b[0m true, noise, pred\u001b[38;5;241m=\u001b[39m \u001b[43mget_noise_pred_true\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbg\u001b[49m\u001b[43m,\u001b[49m\u001b[43mnf\u001b[49m\u001b[43m,\u001b[49m\u001b[43mgn\u001b[49m\u001b[43m,\u001b[49m\u001b[43mgu\u001b[49m\u001b[43m,\u001b[49m\u001b[43mB\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      8\u001b[0m desired_outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m4\u001b[39m\n\u001b[1;32m      9\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m x \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(desired_outputs):\n",
      "Cell \u001b[0;32mIn[23], line 20\u001b[0m, in \u001b[0;36mget_noise_pred_true\u001b[0;34m(batched_graph, node_feats, gauss_noise, model, B, L)\u001b[0m\n\u001b[1;32m     16\u001b[0m CC_n \u001b[38;5;241m=\u001b[39m CA_n \u001b[38;5;241m+\u001b[39m node_feats[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m1\u001b[39m\u001b[38;5;124m'\u001b[39m][:,\u001b[38;5;241m1\u001b[39m,:]\u001b[38;5;241m.\u001b[39mreshape(B, L, \u001b[38;5;241m3\u001b[39m)\n\u001b[1;32m     17\u001b[0m noise_xyz \u001b[38;5;241m=\u001b[39m  torch\u001b[38;5;241m.\u001b[39mcat((NC_n,CA_n,CC_n),dim\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m2\u001b[39m)\u001b[38;5;241m.\u001b[39mreshape(B,L,\u001b[38;5;241m3\u001b[39m,\u001b[38;5;241m3\u001b[39m)\n\u001b[0;32m---> 20\u001b[0m shift\u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mforward\u001b[49m\u001b[43m(\u001b[49m\u001b[43mnode_feats\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbatched_graph\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     21\u001b[0m \u001b[38;5;66;03m#offset = shift['1'].reshape(B, L, 3)\u001b[39;00m\n\u001b[1;32m     22\u001b[0m \u001b[38;5;66;03m#pred = torch.add(Ts.reshape(B, L, 3), batched_graph.ndata['pos'].reshape(B, L, 3))\u001b[39;00m\n\u001b[1;32m     24\u001b[0m CA_p \u001b[38;5;241m=\u001b[39m shift[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m1\u001b[39m\u001b[38;5;124m'\u001b[39m][:,\u001b[38;5;241m0\u001b[39m,:]\u001b[38;5;241m.\u001b[39mreshape(B, L, \u001b[38;5;241m3\u001b[39m)\u001b[38;5;241m+\u001b[39mbatched_graph\u001b[38;5;241m.\u001b[39mndata[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mpos\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39mreshape(B, L, \u001b[38;5;241m3\u001b[39m)\n",
      "Cell \u001b[0;32mIn[12], line 152\u001b[0m, in \u001b[0;36mGraphUNet.forward\u001b[0;34m(self, node_feats_in, batched_graph)\u001b[0m\n\u001b[1;32m    149\u001b[0m \u001b[38;5;66;03m#gcn and down pooling\u001b[39;00m\n\u001b[1;32m    150\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39ml_n):\n\u001b[1;32m    151\u001b[0m     \u001b[38;5;66;03m#define basis (spherical harmonics) from xyz_positions, pull edge connections connectivity\u001b[39;00m\n\u001b[0;32m--> 152\u001b[0m     edge_basis_pos_post\u001b[38;5;241m.\u001b[39mappend(\u001b[43mprep_for_gcn\u001b[49m\u001b[43m(\u001b[49m\u001b[43mgu\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgraph_list\u001b[49m\u001b[43m[\u001b[49m\u001b[43mi\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpos\u001b[49m\u001b[43m[\u001b[49m\u001b[43mi\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43medge_pre\u001b[49m\u001b[43m[\u001b[49m\u001b[43mi\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgu\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgraph_list\u001b[49m\u001b[43m[\u001b[49m\u001b[43mi\u001b[49m\u001b[43m]\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mnodes\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    153\u001b[0m \u001b[43m                                            \u001b[49m\u001b[43mcomp_grad\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcomp_basis_grad\u001b[49m\u001b[43m)\u001b[49m)\n\u001b[1;32m    155\u001b[0m     down_gcn_out\u001b[38;5;241m.\u001b[39mappend(gu\u001b[38;5;241m.\u001b[39mdown_gcns[i]\u001b[38;5;241m.\u001b[39mforward(down_gcn_in[i], edge_basis_pos_post[i][\u001b[38;5;241m0\u001b[39m],\n\u001b[1;32m    156\u001b[0m                                                 graph\u001b[38;5;241m=\u001b[39mgu\u001b[38;5;241m.\u001b[39mgraph_list[i],basis\u001b[38;5;241m=\u001b[39medge_basis_pos_post[i][\u001b[38;5;241m1\u001b[39m]))\n\u001b[1;32m    157\u001b[0m     \u001b[38;5;66;03m#top k pool, save indices pooled for unpooling\u001b[39;00m\n",
      "Cell \u001b[0;32mIn[12], line 14\u001b[0m, in \u001b[0;36mprep_for_gcn\u001b[0;34m(graph, xyz_pos, edge_feats_input, idx, max_degree, comp_grad)\u001b[0m\n\u001b[1;32m      9\u001b[0m rel_pos \u001b[38;5;241m=\u001b[39m F\u001b[38;5;241m.\u001b[39mgather_row(new_pos,dst) \u001b[38;5;241m-\u001b[39m F\u001b[38;5;241m.\u001b[39mgather_row(new_pos,src) \n\u001b[1;32m     11\u001b[0m basis_out \u001b[38;5;241m=\u001b[39m get_basis(rel_pos, max_degree\u001b[38;5;241m=\u001b[39mmax_degree,\n\u001b[1;32m     12\u001b[0m                                compute_gradients\u001b[38;5;241m=\u001b[39mcomp_grad,\n\u001b[1;32m     13\u001b[0m                                use_pad_trick\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\n\u001b[0;32m---> 14\u001b[0m basis_out \u001b[38;5;241m=\u001b[39m \u001b[43mupdate_basis_with_fused\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbasis_out\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmax_degree\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43muse_pad_trick\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m     15\u001b[0m \u001b[43m                                        \u001b[49m\u001b[43mfully_fused\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[1;32m     16\u001b[0m edge_feats_out \u001b[38;5;241m=\u001b[39m get_populated_edge_features(rel_pos, edge_feats_input)\n\u001b[1;32m     17\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m edge_feats_out, basis_out, new_pos\n",
      "\u001b[0;31mRuntimeError\u001b[0m: The following operation failed in the TorchScript interpreter.\nTraceback of TorchScript (most recent call last):\n  File \"/mnt/c/Users/nwood/OneDrive/Desktop/gudiff/se3_transformer/model/basis.py\", line 114, in update_basis_with_fused\n    for d_out in range(max_degree + 1):\n        sum_freq = sum([degree_to_dim(min(d, d_out)) for d in range(max_degree + 1)])\n        basis_fused = torch.zeros(num_edges, sum_dim, sum_freq, degree_to_dim(d_out) + int(use_pad_trick),\n                      ~~~~~~~~~~~ <--- HERE\n                                  device=device, dtype=dtype)\n        acc_d, acc_f = 0, 0\nRuntimeError: CUDA error: unknown error\nCUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\nFor debugging consider passing CUDA_LAUNCH_BLOCKING=1.\nCompile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n\n"
     ]
    }
   ],
   "source": [
    "for i, inp in enumerate(dm.gds):\n",
    "    batched_graph, node_feats, edge_feats = inp\n",
    "    bg = to_cuda(batched_graph)\n",
    "    nf = to_cuda(node_feats)\n",
    "\n",
    "    true, noise, pred= get_noise_pred_true(bg,nf,gn,gu,B)\n",
    "    \n",
    "    desired_outputs = 4\n",
    "    for x in range(desired_outputs):\n",
    "        dump_coord_pdb(true[x],f'output/true_{x}.pdb')\n",
    "        dump_coord_pdb(noise[x],f'output/noised_{x}.pdb')\n",
    "        dump_coord_pdb(pred[x],fileOut=f'output/after_{x}.pdb')\n",
    "\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "53d9c990",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Graph(num_nodes=65, num_edges=4160,\n",
       "      ndata_schemes={'pe': Scheme(shape=(12,), dtype=torch.float32), 'pos': Scheme(shape=(3,), dtype=torch.float32), 'bb_ori': Scheme(shape=(2, 3), dtype=torch.float32)}\n",
       "      edata_schemes={'con': Scheme(shape=(1,), dtype=torch.float32)})"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dm.gds.dataset[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d08017d4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1eb5010a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "b741d817",
   "metadata": {},
   "outputs": [],
   "source": [
    "# B=32\n",
    "# L=65\n",
    "# gu = GraphUNet(pred_fiber = Fiber({0:32,1:32}), max_degree=4,batch_size=B,cuda_out=False, comp_basis_grad=False)\n",
    "# dm = H4_DataModule(coords_tog,batch_size=B)\n",
    "# gn = GaussianNoise(sigma=0.5)\n",
    "# opti = torch.optim.Adam(gu.parameters(), lr=0.0005, weight_decay=0.00008)\n",
    "# #loss = nn.MSELoss()\n",
    "# for e in range(100):\n",
    "#     lsum = 0\n",
    "#     for i, inp in enumerate(dm.gds):\n",
    "#         batched_graph, node_feats, edge_feats = inp\n",
    "#         out = train_step(batched_graph, node_feats, gn, gu)\n",
    "#         lsum += out\n",
    "#         print(lsum/(i+1))\n",
    "\n",
    "#     print(lsum/i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "8b53d0b9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0.2224)\n",
      "tensor(0.2151)\n",
      "tensor(0.2123)\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[45], line 5\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i, inp \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(dm\u001b[38;5;241m.\u001b[39mgds):\n\u001b[1;32m      4\u001b[0m     batched_graph, node_feats, edge_feats \u001b[38;5;241m=\u001b[39m inp\n\u001b[0;32m----> 5\u001b[0m     out \u001b[38;5;241m=\u001b[39m \u001b[43mtrain_step\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbatched_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnode_feats\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgn\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgu\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      6\u001b[0m     lsum \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m out\n\u001b[1;32m      7\u001b[0m     \u001b[38;5;28mprint\u001b[39m(lsum\u001b[38;5;241m/\u001b[39m(i\u001b[38;5;241m+\u001b[39m\u001b[38;5;241m1\u001b[39m))\n",
      "Cell \u001b[0;32mIn[41], line 282\u001b[0m, in \u001b[0;36mtrain_step\u001b[0;34m(batched_graph, node_feats, gauss_noise, graph_unet)\u001b[0m\n\u001b[1;32m    279\u001b[0m tloss, loss \u001b[38;5;241m=\u001b[39m FAPE_loss(pred\u001b[38;5;241m.\u001b[39munsqueeze(\u001b[38;5;241m0\u001b[39m), true)\n\u001b[1;32m    281\u001b[0m opti\u001b[38;5;241m.\u001b[39mzero_grad()\n\u001b[0;32m--> 282\u001b[0m \u001b[43mtloss\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbackward\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    283\u001b[0m opti\u001b[38;5;241m.\u001b[39mstep()\n\u001b[1;32m    285\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m tloss\u001b[38;5;241m.\u001b[39mdetach()\n",
      "File \u001b[0;32m~/miniconda3/envs/se33/lib/python3.9/site-packages/torch/_tensor.py:487\u001b[0m, in \u001b[0;36mTensor.backward\u001b[0;34m(self, gradient, retain_graph, create_graph, inputs)\u001b[0m\n\u001b[1;32m    477\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m has_torch_function_unary(\u001b[38;5;28mself\u001b[39m):\n\u001b[1;32m    478\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m handle_torch_function(\n\u001b[1;32m    479\u001b[0m         Tensor\u001b[38;5;241m.\u001b[39mbackward,\n\u001b[1;32m    480\u001b[0m         (\u001b[38;5;28mself\u001b[39m,),\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    485\u001b[0m         inputs\u001b[38;5;241m=\u001b[39minputs,\n\u001b[1;32m    486\u001b[0m     )\n\u001b[0;32m--> 487\u001b[0m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mautograd\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbackward\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    488\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgradient\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mretain_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcreate_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minputs\u001b[49m\n\u001b[1;32m    489\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/envs/se33/lib/python3.9/site-packages/torch/autograd/__init__.py:200\u001b[0m, in \u001b[0;36mbackward\u001b[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001b[0m\n\u001b[1;32m    195\u001b[0m     retain_graph \u001b[38;5;241m=\u001b[39m create_graph\n\u001b[1;32m    197\u001b[0m \u001b[38;5;66;03m# The reason we repeat same the comment below is that\u001b[39;00m\n\u001b[1;32m    198\u001b[0m \u001b[38;5;66;03m# some Python versions print out the first line of a multi-line function\u001b[39;00m\n\u001b[1;32m    199\u001b[0m \u001b[38;5;66;03m# calls in the traceback and some print out the last line\u001b[39;00m\n\u001b[0;32m--> 200\u001b[0m \u001b[43mVariable\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_execution_engine\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun_backward\u001b[49m\u001b[43m(\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# Calls into the C++ engine to run the backward pass\u001b[39;49;00m\n\u001b[1;32m    201\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtensors\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgrad_tensors_\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mretain_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcreate_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    202\u001b[0m \u001b[43m    \u001b[49m\u001b[43mallow_unreachable\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maccumulate_grad\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/envs/se33/lib/python3.9/site-packages/torch/autograd/function.py:274\u001b[0m, in \u001b[0;36mBackwardCFunction.apply\u001b[0;34m(self, *args)\u001b[0m\n\u001b[1;32m    270\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mImplementing both \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mbackward\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m and \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mvjp\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m for a custom \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    271\u001b[0m                        \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mFunction is not allowed. You should only implement one \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    272\u001b[0m                        \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mof them.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    273\u001b[0m user_fn \u001b[38;5;241m=\u001b[39m vjp_fn \u001b[38;5;28;01mif\u001b[39;00m vjp_fn \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m Function\u001b[38;5;241m.\u001b[39mvjp \u001b[38;5;28;01melse\u001b[39;00m backward_fn\n\u001b[0;32m--> 274\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43muser_fn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/envs/se33/lib/python3.9/site-packages/torch/utils/checkpoint.py:157\u001b[0m, in \u001b[0;36mCheckpointFunction.backward\u001b[0;34m(ctx, *args)\u001b[0m\n\u001b[1;32m    153\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(outputs_with_grad) \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[1;32m    154\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\n\u001b[1;32m    155\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnone of output has requires_grad=True,\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    156\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m this checkpoint() is not necessary\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m--> 157\u001b[0m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mautograd\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbackward\u001b[49m\u001b[43m(\u001b[49m\u001b[43moutputs_with_grad\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43margs_with_grad\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    158\u001b[0m grads \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mtuple\u001b[39m(inp\u001b[38;5;241m.\u001b[39mgrad \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(inp, torch\u001b[38;5;241m.\u001b[39mTensor) \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    159\u001b[0m               \u001b[38;5;28;01mfor\u001b[39;00m inp \u001b[38;5;129;01min\u001b[39;00m detached_inputs)\n\u001b[1;32m    161\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m (\u001b[38;5;28;01mNone\u001b[39;00m, \u001b[38;5;28;01mNone\u001b[39;00m) \u001b[38;5;241m+\u001b[39m grads\n",
      "File \u001b[0;32m~/miniconda3/envs/se33/lib/python3.9/site-packages/torch/autograd/__init__.py:200\u001b[0m, in \u001b[0;36mbackward\u001b[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001b[0m\n\u001b[1;32m    195\u001b[0m     retain_graph \u001b[38;5;241m=\u001b[39m create_graph\n\u001b[1;32m    197\u001b[0m \u001b[38;5;66;03m# The reason we repeat same the comment below is that\u001b[39;00m\n\u001b[1;32m    198\u001b[0m \u001b[38;5;66;03m# some Python versions print out the first line of a multi-line function\u001b[39;00m\n\u001b[1;32m    199\u001b[0m \u001b[38;5;66;03m# calls in the traceback and some print out the last line\u001b[39;00m\n\u001b[0;32m--> 200\u001b[0m \u001b[43mVariable\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_execution_engine\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun_backward\u001b[49m\u001b[43m(\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# Calls into the C++ engine to run the backward pass\u001b[39;49;00m\n\u001b[1;32m    201\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtensors\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgrad_tensors_\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mretain_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcreate_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    202\u001b[0m \u001b[43m    \u001b[49m\u001b[43mallow_unreachable\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maccumulate_grad\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "89ddb8a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# for i, inp in enumerate(dm.gds):\n",
    "#     batched_graph, node_feats, edge_feats = inp\n",
    "#     bg = to_cuda(batched_graph)\n",
    "#     nf = to_cuda(node_feats)\n",
    "    \n",
    "#     xyz_noise, noise, true_pos, noisexyz_N_C = get_noise(bg,nf,gn)\n",
    "#     out = pred(bg,nf,gn,gu)\n",
    "#     for x in range(8):\n",
    "#         dump_coord_pdb(true_pos.to('cpu').numpy()[x],f'output/true_{x}.pdb')\n",
    "#         dump_coord_pdb(noisexyz_N_C.to('cpu').numpy()[x],f'output/noised_{x}.pdb')\n",
    "#         dump_coord_pdb(out.to('cpu').numpy()[x],fileOut=f'output/after_{x}.pdb')\n",
    "    \n",
    "#     break\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "64bd542f",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "The following operation failed in the TorchScript interpreter.\nTraceback of TorchScript (most recent call last):\n  File \"/mnt/c/Users/nwood/OneDrive/Desktop/gudiff/se3_transformer/model/basis.py\", line 129, in update_basis_with_fused\n    for d_in in range(max_degree + 1):\n        sum_freq = sum([degree_to_dim(min(d, d_in)) for d in range(max_degree + 1)])\n        basis_fused = torch.zeros(num_edges, degree_to_dim(d_in), sum_freq, sum_dim,\n                      ~~~~~~~~~~~ <--- HERE\n                                  device=device, dtype=dtype)\n        acc_d, acc_f = 0, 0\nRuntimeError: CUDA error: unknown error\nCUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\nFor debugging consider passing CUDA_LAUNCH_BLOCKING=1.\nCompile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[37], line 7\u001b[0m\n\u001b[1;32m      5\u001b[0m     bg \u001b[38;5;241m=\u001b[39m to_cuda(batched_graph)\n\u001b[1;32m      6\u001b[0m     nf \u001b[38;5;241m=\u001b[39m to_cuda(node_feats)\n\u001b[0;32m----> 7\u001b[0m     out \u001b[38;5;241m=\u001b[39m \u001b[43mtrain_step\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbg\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnf\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgn\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgu\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      8\u001b[0m     lsum \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m out\n\u001b[1;32m     10\u001b[0m \u001b[38;5;28mprint\u001b[39m(lsum\u001b[38;5;241m/\u001b[39mi)\n",
      "Cell \u001b[0;32mIn[34], line 270\u001b[0m, in \u001b[0;36mtrain_step\u001b[0;34m(batched_graph, node_feats, gauss_noise, graph_unet)\u001b[0m\n\u001b[1;32m    264\u001b[0m true \u001b[38;5;241m=\u001b[39m  torch\u001b[38;5;241m.\u001b[39mcat((NC_t,CA_t,CC_t),dim\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m2\u001b[39m)\u001b[38;5;241m.\u001b[39mreshape(B,L,\u001b[38;5;241m3\u001b[39m,\u001b[38;5;241m3\u001b[39m)\n\u001b[1;32m    267\u001b[0m batched_graph\u001b[38;5;241m.\u001b[39mndata[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mpos\u001b[39m\u001b[38;5;124m'\u001b[39m], noise \u001b[38;5;241m=\u001b[39m gauss_noise\u001b[38;5;241m.\u001b[39mforward(batched_graph\u001b[38;5;241m.\u001b[39mndata[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mpos\u001b[39m\u001b[38;5;124m'\u001b[39m])\n\u001b[0;32m--> 270\u001b[0m shift\u001b[38;5;241m=\u001b[39m\u001b[43mgu\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mforward\u001b[49m\u001b[43m(\u001b[49m\u001b[43mnode_feats\u001b[49m\u001b[43m,\u001b[49m\u001b[43m  \u001b[49m\u001b[43mbatched_graph\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    271\u001b[0m \u001b[38;5;66;03m#offset = shift['1'].reshape(B, L, 3)\u001b[39;00m\n\u001b[1;32m    272\u001b[0m \u001b[38;5;66;03m#pred = torch.add(Ts.reshape(B, L, 3), batched_graph.ndata['pos'].reshape(B, L, 3))\u001b[39;00m\n\u001b[1;32m    274\u001b[0m CA_p \u001b[38;5;241m=\u001b[39m shift[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m1\u001b[39m\u001b[38;5;124m'\u001b[39m][:,\u001b[38;5;241m0\u001b[39m,:]\u001b[38;5;241m.\u001b[39mreshape(B, L, \u001b[38;5;241m3\u001b[39m)\u001b[38;5;241m+\u001b[39mbatched_graph\u001b[38;5;241m.\u001b[39mndata[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mpos\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39mreshape(B, L, \u001b[38;5;241m3\u001b[39m)\n",
      "Cell \u001b[0;32mIn[34], line 152\u001b[0m, in \u001b[0;36mGraphUNet.forward\u001b[0;34m(self, node_feats_in, batched_graph)\u001b[0m\n\u001b[1;32m    149\u001b[0m \u001b[38;5;66;03m#gcn and down pooling\u001b[39;00m\n\u001b[1;32m    150\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39ml_n):\n\u001b[1;32m    151\u001b[0m     \u001b[38;5;66;03m#define basis (spherical harmonics) from xyz_positions, pull edge connections connectivity\u001b[39;00m\n\u001b[0;32m--> 152\u001b[0m     edge_basis_pos_post\u001b[38;5;241m.\u001b[39mappend(\u001b[43mprep_for_gcn\u001b[49m\u001b[43m(\u001b[49m\u001b[43mgu\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgraph_list\u001b[49m\u001b[43m[\u001b[49m\u001b[43mi\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpos\u001b[49m\u001b[43m[\u001b[49m\u001b[43mi\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43medge_pre\u001b[49m\u001b[43m[\u001b[49m\u001b[43mi\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgu\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgraph_list\u001b[49m\u001b[43m[\u001b[49m\u001b[43mi\u001b[49m\u001b[43m]\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mnodes\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    153\u001b[0m \u001b[43m                                            \u001b[49m\u001b[43mcomp_grad\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcomp_basis_grad\u001b[49m\u001b[43m)\u001b[49m)\n\u001b[1;32m    155\u001b[0m     down_gcn_out\u001b[38;5;241m.\u001b[39mappend(gu\u001b[38;5;241m.\u001b[39mdown_gcns[i]\u001b[38;5;241m.\u001b[39mforward(down_gcn_in[i], edge_basis_pos_post[i][\u001b[38;5;241m0\u001b[39m],\n\u001b[1;32m    156\u001b[0m                                                 graph\u001b[38;5;241m=\u001b[39mgu\u001b[38;5;241m.\u001b[39mgraph_list[i],basis\u001b[38;5;241m=\u001b[39medge_basis_pos_post[i][\u001b[38;5;241m1\u001b[39m]))\n\u001b[1;32m    157\u001b[0m     \u001b[38;5;66;03m#top k pool, save indices pooled for unpooling\u001b[39;00m\n",
      "Cell \u001b[0;32mIn[34], line 14\u001b[0m, in \u001b[0;36mprep_for_gcn\u001b[0;34m(graph, xyz_pos, edge_feats_input, idx, max_degree, comp_grad)\u001b[0m\n\u001b[1;32m      9\u001b[0m rel_pos \u001b[38;5;241m=\u001b[39m F\u001b[38;5;241m.\u001b[39mgather_row(new_pos,dst) \u001b[38;5;241m-\u001b[39m F\u001b[38;5;241m.\u001b[39mgather_row(new_pos,src) \n\u001b[1;32m     11\u001b[0m basis_out \u001b[38;5;241m=\u001b[39m get_basis(rel_pos, max_degree\u001b[38;5;241m=\u001b[39mmax_degree,\n\u001b[1;32m     12\u001b[0m                                compute_gradients\u001b[38;5;241m=\u001b[39mcomp_grad,\n\u001b[1;32m     13\u001b[0m                                use_pad_trick\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\n\u001b[0;32m---> 14\u001b[0m basis_out \u001b[38;5;241m=\u001b[39m \u001b[43mupdate_basis_with_fused\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbasis_out\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmax_degree\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43muse_pad_trick\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m     15\u001b[0m \u001b[43m                                        \u001b[49m\u001b[43mfully_fused\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[1;32m     16\u001b[0m edge_feats_out \u001b[38;5;241m=\u001b[39m get_populated_edge_features(rel_pos, edge_feats_input)\n\u001b[1;32m     17\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m edge_feats_out, basis_out, new_pos\n",
      "\u001b[0;31mRuntimeError\u001b[0m: The following operation failed in the TorchScript interpreter.\nTraceback of TorchScript (most recent call last):\n  File \"/mnt/c/Users/nwood/OneDrive/Desktop/gudiff/se3_transformer/model/basis.py\", line 129, in update_basis_with_fused\n    for d_in in range(max_degree + 1):\n        sum_freq = sum([degree_to_dim(min(d, d_in)) for d in range(max_degree + 1)])\n        basis_fused = torch.zeros(num_edges, degree_to_dim(d_in), sum_freq, sum_dim,\n                      ~~~~~~~~~~~ <--- HERE\n                                  device=device, dtype=dtype)\n        acc_d, acc_f = 0, 0\nRuntimeError: CUDA error: unknown error\nCUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\nFor debugging consider passing CUDA_LAUNCH_BLOCKING=1.\nCompile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n\n"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "e75bf210",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Graph(num_nodes=520, num_edges=33280,\n",
       "      ndata_schemes={'pe': Scheme(shape=(12,), dtype=torch.float32), 'pos': Scheme(shape=(3,), dtype=torch.float32), 'bb_ori': Scheme(shape=(2, 3), dtype=torch.float32)}\n",
       "      edata_schemes={'con': Scheme(shape=(1,), dtype=torch.float32), 'rel_pos': Scheme(shape=(3,), dtype=torch.float32)})"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "batched_graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "9ca0821d",
   "metadata": {},
   "outputs": [],
   "source": [
    "out = pred(bg,nf,gn,gu)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "0053295e",
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "shape '[8, 65, 3]' is invalid for input of size 6240",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[97], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m xyz_noise, noise, true_pos, noisexyz_N_C \u001b[38;5;241m=\u001b[39m \u001b[43mget_noise\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbg\u001b[49m\u001b[43m,\u001b[49m\u001b[43mnf\u001b[49m\u001b[43m,\u001b[49m\u001b[43mgn\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[0;32mIn[80], line 238\u001b[0m, in \u001b[0;36mget_noise\u001b[0;34m(batched_graph, node_feats, gauss_noise)\u001b[0m\n\u001b[1;32m    235\u001b[0m true_pos \u001b[38;5;241m=\u001b[39m batched_graph\u001b[38;5;241m.\u001b[39mndata[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mpos\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39mclone()\n\u001b[1;32m    237\u001b[0m \u001b[38;5;66;03m#add vectors for \u001b[39;00m\n\u001b[0;32m--> 238\u001b[0m CA_t  \u001b[38;5;241m=\u001b[39m \u001b[43mtrue_pos\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mreshape\u001b[49m\u001b[43m(\u001b[49m\u001b[43mB\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mL\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m3\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m    239\u001b[0m NC_t \u001b[38;5;241m=\u001b[39m CA_t \u001b[38;5;241m+\u001b[39m nf[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m1\u001b[39m\u001b[38;5;124m'\u001b[39m][:,\u001b[38;5;241m0\u001b[39m,:]\u001b[38;5;241m.\u001b[39mreshape(B, L, \u001b[38;5;241m3\u001b[39m)\n\u001b[1;32m    240\u001b[0m CC_t \u001b[38;5;241m=\u001b[39m CA_t \u001b[38;5;241m+\u001b[39m nf[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m1\u001b[39m\u001b[38;5;124m'\u001b[39m][:,\u001b[38;5;241m1\u001b[39m,:]\u001b[38;5;241m.\u001b[39mreshape(B, L, \u001b[38;5;241m3\u001b[39m)\n",
      "\u001b[0;31mRuntimeError\u001b[0m: shape '[8, 65, 3]' is invalid for input of size 6240"
     ]
    }
   ],
   "source": [
    "xyz_noise, noise, true_pos, noisexyz_N_C = get_noise(bg,nf,gn)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "11d64c99",
   "metadata": {},
   "outputs": [],
   "source": [
    "dump_coord_pdb(noisexyz_N_C.to('cpu').numpy()[0],'output/before.pdb')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "7c3a2f66",
   "metadata": {},
   "outputs": [],
   "source": [
    "dump_coord_pdb(out.to('cpu').numpy()[0],fileOut='output/after.pdb')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "2638b24b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Graph(num_nodes=2080, num_edges=133120,\n",
       "      ndata_schemes={'pe': Scheme(shape=(12,), dtype=torch.float32), 'pos': Scheme(shape=(3,), dtype=torch.float32), 'bb_ori': Scheme(shape=(2, 3), dtype=torch.float32)}\n",
       "      edata_schemes={'con': Scheme(shape=(1,), dtype=torch.float32), 'rel_pos': Scheme(shape=(3,), dtype=torch.float32)})"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    " batched_graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92721bc8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3df59152",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1ce5983",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f965b87",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b13ef78d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "id": "e96636a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "true_pos = bg.ndata['pos'].clone()\n",
    "bg.ndata['pos'], noise = gn.forward(bg.ndata['pos'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "id": "32f9ccf6",
   "metadata": {},
   "outputs": [],
   "source": [
    "B=8\n",
    "L=65\n",
    "\n",
    "shift=gu.forward(nf,  bg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "id": "29a3ccb4",
   "metadata": {},
   "outputs": [],
   "source": [
    "CA_p = shift['1'][:,0,:].reshape(B, L, 3)+bg.ndata['pos'].reshape(B, L, 3)\n",
    "NC_p = shift['1'][:,1,:].reshape(B, L, 3)+bg.ndata['pos'].reshape(B, L, 3)\n",
    "CC_p = shift['1'][:,2,:].reshape(B, L, 3)+bg.ndata['pos'].reshape(B, L, 3)\n",
    "\n",
    "\n",
    "CA_t  = true_pos.reshape(B, L, 3)\n",
    "NC_t = CA_t + nf['1'][:,0,:].reshape(B, L, 3)\n",
    "CC_t = CA_t + nf['1'][:,1,:].reshape(B, L, 3)\n",
    "\n",
    "\n",
    "\n",
    "pred = torch.cat((NC_p,CA_p,CC_p),dim=2).reshape(B,L,3,3)\n",
    "true =  torch.cat((NC_t,CA_t,CC_t),dim=2).reshape(B,L,3,3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "id": "2e7b57ef",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([8, 65, 3, 3])"
      ]
     },
     "execution_count": 122,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "id": "cd0d400c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([8, 65, 3, 3])"
      ]
     },
     "execution_count": 123,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "true.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "id": "69c5ec98",
   "metadata": {},
   "outputs": [],
   "source": [
    "tot_loss, loss = FAPE_loss(pred.unsqueeze(0), true)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "id": "836ae14a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(0.8654, device='cuda:0', grad_fn=<SumBackward0>)"
      ]
     },
     "execution_count": 125,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tot_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "id": "d4b9005d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([8, 65, 3, 3])"
      ]
     },
     "execution_count": 126,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "true.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "id": "9641f2e3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "id": "8171dcf5",
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[130], line 7\u001b[0m\n\u001b[1;32m      5\u001b[0m     bg \u001b[38;5;241m=\u001b[39m to_cuda(batched_graph)\n\u001b[1;32m      6\u001b[0m     nf \u001b[38;5;241m=\u001b[39m to_cuda(node_feats)\n\u001b[0;32m----> 7\u001b[0m     out \u001b[38;5;241m=\u001b[39m \u001b[43mtrain_step\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbg\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnf\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgn\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgu\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      8\u001b[0m     lsum \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m out\n\u001b[1;32m     10\u001b[0m \u001b[38;5;28mprint\u001b[39m(lsum\u001b[38;5;241m/\u001b[39mi)\n",
      "Cell \u001b[0;32mIn[127], line 17\u001b[0m, in \u001b[0;36mtrain_step\u001b[0;34m(batched_graph, node_feats, gauss_noise, graph_unet)\u001b[0m\n\u001b[1;32m     11\u001b[0m true \u001b[38;5;241m=\u001b[39m  torch\u001b[38;5;241m.\u001b[39mcat((NC_t,CA_t,CC_t),dim\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m2\u001b[39m)\u001b[38;5;241m.\u001b[39mreshape(B,L,\u001b[38;5;241m3\u001b[39m,\u001b[38;5;241m3\u001b[39m)\n\u001b[1;32m     14\u001b[0m batched_graph\u001b[38;5;241m.\u001b[39mndata[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mpos\u001b[39m\u001b[38;5;124m'\u001b[39m], noise \u001b[38;5;241m=\u001b[39m gauss_noise\u001b[38;5;241m.\u001b[39mforward(batched_graph\u001b[38;5;241m.\u001b[39mndata[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mpos\u001b[39m\u001b[38;5;124m'\u001b[39m])\n\u001b[0;32m---> 17\u001b[0m shift\u001b[38;5;241m=\u001b[39m\u001b[43mgu\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mforward\u001b[49m\u001b[43m(\u001b[49m\u001b[43mnode_feats\u001b[49m\u001b[43m,\u001b[49m\u001b[43m  \u001b[49m\u001b[43mbatched_graph\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     18\u001b[0m \u001b[38;5;66;03m#offset = shift['1'].reshape(B, L, 3)\u001b[39;00m\n\u001b[1;32m     19\u001b[0m \u001b[38;5;66;03m#pred = torch.add(Ts.reshape(B, L, 3), batched_graph.ndata['pos'].reshape(B, L, 3))\u001b[39;00m\n\u001b[1;32m     21\u001b[0m CA_p \u001b[38;5;241m=\u001b[39m shift[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m1\u001b[39m\u001b[38;5;124m'\u001b[39m][:,\u001b[38;5;241m0\u001b[39m,:]\u001b[38;5;241m.\u001b[39mreshape(B, L, \u001b[38;5;241m3\u001b[39m)\u001b[38;5;241m+\u001b[39mbatched_graph\u001b[38;5;241m.\u001b[39mndata[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mpos\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39mreshape(B, L, \u001b[38;5;241m3\u001b[39m)\n",
      "Cell \u001b[0;32mIn[43], line 154\u001b[0m, in \u001b[0;36mGraphUNet.forward\u001b[0;34m(self, node_feats_in, batched_graph)\u001b[0m\n\u001b[1;32m    149\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39ml_n):\n\u001b[1;32m    150\u001b[0m     \u001b[38;5;66;03m#define basis (spherical harmonics) from xyz_positions, pull edge connections connectivity\u001b[39;00m\n\u001b[1;32m    151\u001b[0m     edge_basis_pos_post\u001b[38;5;241m.\u001b[39mappend(prep_for_gcn(gu\u001b[38;5;241m.\u001b[39mgraph_list[i], pos[i], \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39medge_pre[i], gu\u001b[38;5;241m.\u001b[39mgraph_list[i]\u001b[38;5;241m.\u001b[39mnodes(),\n\u001b[1;32m    152\u001b[0m                                             comp_grad \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcomp_basis_grad))\n\u001b[0;32m--> 154\u001b[0m     down_gcn_out\u001b[38;5;241m.\u001b[39mappend(\u001b[43mgu\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdown_gcns\u001b[49m\u001b[43m[\u001b[49m\u001b[43mi\u001b[49m\u001b[43m]\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mforward\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdown_gcn_in\u001b[49m\u001b[43m[\u001b[49m\u001b[43mi\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43medge_basis_pos_post\u001b[49m\u001b[43m[\u001b[49m\u001b[43mi\u001b[49m\u001b[43m]\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    155\u001b[0m \u001b[43m                                                \u001b[49m\u001b[43mgraph\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgu\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgraph_list\u001b[49m\u001b[43m[\u001b[49m\u001b[43mi\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43mbasis\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43medge_basis_pos_post\u001b[49m\u001b[43m[\u001b[49m\u001b[43mi\u001b[49m\u001b[43m]\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m)\n\u001b[1;32m    156\u001b[0m     \u001b[38;5;66;03m#top k pool, save indices pooled for unpooling\u001b[39;00m\n\u001b[1;32m    157\u001b[0m     out_and_indx \u001b[38;5;241m=\u001b[39m gu\u001b[38;5;241m.\u001b[39mpools[i](down_gcn_out[i], gu\u001b[38;5;241m.\u001b[39mgraph_list[i])\n",
      "File \u001b[0;32m/mnt/c/Users/nwood/OneDrive/Desktop/gudiff/se3_transformer/model/layers/attentiontopK.py:158\u001b[0m, in \u001b[0;36mAttentionBlockSE3.forward\u001b[0;34m(self, node_features, edge_features, graph, basis, **kwargs)\u001b[0m\n\u001b[1;32m    156\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m nvtx_range(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mAttentionBlockSE3\u001b[39m\u001b[38;5;124m'\u001b[39m):\n\u001b[1;32m    157\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m nvtx_range(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mkeys / values\u001b[39m\u001b[38;5;124m'\u001b[39m):\n\u001b[0;32m--> 158\u001b[0m         fused_key_value \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mto_key_value\u001b[49m\u001b[43m(\u001b[49m\u001b[43mnode_features\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43medge_features\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgraph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbasis\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    159\u001b[0m         key, value \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_get_key_value_from_fused(fused_key_value)\n\u001b[1;32m    161\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m nvtx_range(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mqueries\u001b[39m\u001b[38;5;124m'\u001b[39m):\n",
      "File \u001b[0;32m~/miniconda3/envs/se33/lib/python3.9/site-packages/torch/nn/modules/module.py:1501\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1496\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1497\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1498\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1499\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1500\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1501\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1502\u001b[0m \u001b[38;5;66;03m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1503\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[38;5;241m=\u001b[39m [], []\n",
      "File \u001b[0;32m/mnt/c/Users/nwood/OneDrive/Desktop/gudiff/se3_transformer/model/layers/convolution.py:290\u001b[0m, in \u001b[0;36mConvSE3.forward\u001b[0;34m(self, node_feats, edge_feats, graph, basis)\u001b[0m\n\u001b[1;32m    288\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m nvtx_range(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mConvSE3\u001b[39m\u001b[38;5;124m'\u001b[39m):\n\u001b[1;32m    289\u001b[0m     invariant_edge_feats \u001b[38;5;241m=\u001b[39m edge_feats[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m0\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39msqueeze(\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m)\n\u001b[0;32m--> 290\u001b[0m     src, dst \u001b[38;5;241m=\u001b[39m \u001b[43mgraph\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43medges\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    291\u001b[0m     out \u001b[38;5;241m=\u001b[39m {}\n\u001b[1;32m    292\u001b[0m     in_features \u001b[38;5;241m=\u001b[39m []\n",
      "File \u001b[0;32m~/miniconda3/envs/se33/lib/python3.9/site-packages/dgl/view.py:179\u001b[0m, in \u001b[0;36mHeteroEdgeView.__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    177\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__call__\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[1;32m    178\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Return all the edges.\"\"\"\u001b[39;00m\n\u001b[0;32m--> 179\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_graph\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mall_edges\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23fc8341",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "id": "a54aaa09",
   "metadata": {},
   "outputs": [],
   "source": [
    "true_pos = batched_graph.ndata['pos'].clone()\n",
    "        \n",
    "B=8\n",
    "L=65\n",
    "#add vectors for \n",
    "CA_t  = true_pos.reshape(B, L, 3)\n",
    "NC_t = CA_t + node_feats['1'][:,0,:].reshape(B, L, 3)\n",
    "CC_t = CA_t + node_feats['1'][:,1,:].reshape(B, L, 3)\n",
    "true =  torch.cat((NC_t,CA_t,CC_t),dim=2).reshape(B,L,3,3)\n",
    "\n",
    "\n",
    "out_pos, noise = gn.forward(bg.ndata['pos'])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "id": "64de7fdf",
   "metadata": {},
   "outputs": [],
   "source": [
    "CA_o  = out_pos.reshape(B, L, 3)\n",
    "NC_o = CA_o + nf['1'][:,0,:].reshape(B, L, 3)\n",
    "CC_o = CA_o + nf['1'][:,1,:].reshape(B, L, 3)\n",
    "out_noise =  torch.cat((NC_o,CA_o,CC_o),dim=2).reshape(B,L,3,3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "63b8aa5b",
   "metadata": {},
   "outputs": [],
   "source": [
    "tp = true_pos.reshape(8,65,3).to('cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "b54e53ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "# true_pos = batched_graph.ndata['pos']\n",
    "\n",
    "# batched_graph.ndata['pos'], noise = gn.forward(true_pos)\n",
    "# shift=gu.forward(node_feats,  batched_graph)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "284a60de",
   "metadata": {},
   "outputs": [],
   "source": [
    "import util.npose_util as nu\n",
    "def build_npose_from_coords(coords_in):\n",
    "    \n",
    "    rot_mat_cat = np.ones(sum((coords_in.shape[:-1], (1,)), ()))\n",
    "    \n",
    "    coords = np.concatenate((coords_in,rot_mat_cat),axis=-1)\n",
    "    \n",
    "    npose = np.ones((coords_in.shape[0]*5,4)) #5 is atoms per res\n",
    "\n",
    "    by_res = npose.reshape(-1, 5, 4)\n",
    "    \n",
    "    if ( \"N\" in ATOM_NAMES ):\n",
    "        by_res[:,N,:3] = coords_in[:,0,:3]\n",
    "    if ( \"CA\" in ATOM_NAMES ):\n",
    "        by_res[:,CA,:3] = coords_in[:,1,:3]\n",
    "    if ( \"C\" in ATOM_NAMES ):\n",
    "        by_res[:,C,:3] = coords_in[:,2,:3]\n",
    "    if ( \"O\" in ATOM_NAMES ):\n",
    "        by_res[:,O,:3] = nu.build_O(npose)\n",
    "    if ( \"CB\" in ATOM_NAMES ):\n",
    "        tpose = nu.tpose_from_npose(npose)\n",
    "        by_res[:,CB,:] = nu.build_CB(tpose)\n",
    "\n",
    "    return npose"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "id": "99c7e7f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "npose = build_npose_from_coords(true.reshape(8,65,3,3)[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "id": "fc4ca8b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "npose = build_npose_from_coords(po.reshape(8,65,3,3)[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "id": "e42f4404",
   "metadata": {},
   "outputs": [],
   "source": [
    "npose = build_npose_from_coords(out_noise.reshape(8,65,3,3).to('cpu').numpy()[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "id": "bd2149f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "nu.dump_npdb(npose,'output/tester.pdb')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "id": "2cf03969",
   "metadata": {},
   "outputs": [],
   "source": [
    "nu.dump_npdb(out_noise,'output/tester2.pdb')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "id": "edd32b0b",
   "metadata": {},
   "outputs": [],
   "source": [
    "nu.dump_npdb(npose,'output/tester3.pdb')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "b427d330",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(40, 4)"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "npose.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "b56a01b7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(8, 65, 3, 3)"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "po.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "a171b01b",
   "metadata": {},
   "outputs": [],
   "source": [
    "predout = pred(bg, nf, gn, gu)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "c05f7910",
   "metadata": {},
   "outputs": [],
   "source": [
    "po = predout.to('cpu').numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "2c7da119",
   "metadata": {},
   "outputs": [],
   "source": [
    "npose = build_npose_from_coords(po[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 271,
   "id": "a265e40b",
   "metadata": {},
   "outputs": [],
   "source": [
    "true_pos = batched_graph.ndata['pos']\n",
    "\n",
    "batched_graph.ndata['pos'], noise = gn.forward(true_pos)\n",
    "shift=gu.forward(node_feats,  batched_graph)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54f11585",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 272,
   "id": "cd7a0921",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0.0065, grad_fn=<MseLossBackward0>)\n"
     ]
    }
   ],
   "source": [
    "output = loss(noise,shift['1'].squeeze(1))\n",
    "print(output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 273,
   "id": "a543dfec",
   "metadata": {},
   "outputs": [],
   "source": [
    "opti.zero_grad()\n",
    "output.backward()\n",
    "opti.step()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85b036fa",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16e54318",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "id": "d07b65da",
   "metadata": {},
   "outputs": [],
   "source": [
    "true_pos = batched_graph.ndata['pos']\n",
    "shift=gu.forward(node_feats,  batched_graph)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 191,
   "id": "433659c7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[ 2.6800,  4.0886, -0.8873]],\n",
       "\n",
       "        [[ 3.4822,  4.9773, -0.8749]],\n",
       "\n",
       "        [[ 3.9890,  4.0204, -1.2399]],\n",
       "\n",
       "        ...,\n",
       "\n",
       "        [[ 0.1211, -3.3383, -0.6193]],\n",
       "\n",
       "        [[-0.4978, -0.5428,  1.7745]],\n",
       "\n",
       "        [[ 4.5303, -1.8521,  0.1575]]], grad_fn=<TransposeBackward0>)"
      ]
     },
     "execution_count": 191,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "shift['1']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 193,
   "id": "d3d16cc2",
   "metadata": {},
   "outputs": [],
   "source": [
    "#torch.autograd.gradcheck(FAPE_loss_CA,(shift['1'].reshape(B, L, 3).unsqueeze(0),true_pos.reshape(B, L, 3)) , eps=1e-3, atol=1e-3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c25d75a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "pred = torch.add(Ts.reshape(B, L, 3), batched_graph.ndata['pos'].reshape(B, L, 3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3f8f599",
   "metadata": {},
   "outputs": [],
   "source": [
    "FAPE_loss_CA(pred.unsqueeze(0).repeat(2,1,1,1), true_pos.reshape(B, L, 3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb10153f",
   "metadata": {},
   "outputs": [],
   "source": [
    "FAPE_loss_CA()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "id": "9217d1b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_step(batched_graph, node_feats, gauss_noise, graph_unet):\n",
    "    \n",
    "    true_pos = batched_graph.ndata['pos'].clone()\n",
    "    batched_graph.ndata['pos'] = gauss_noise.forward(batched_graph.ndata['pos'])\n",
    "    \n",
    "    B=8\n",
    "    L=65\n",
    "\n",
    "    shift=gu.forward(node_feats,  batched_graph)\n",
    "    offset = shift['1'].reshape(B, L, , 3)\n",
    "    #pred = torch.add(Ts.reshape(B, L, 3), batched_graph.ndata['pos'].reshape(B, L, 3))\n",
    "    \n",
    "        \n",
    "    #tloss, loss = FAPE_loss_CA(pred.unsqueeze(0).repeat(2,1,1,1), true_pos.reshape(B, L, 3))\n",
    "    \n",
    "    opti.zero_grad()\n",
    "    tloss.backward()\n",
    "    opti.step()\n",
    "    \n",
    "    return offset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "id": "3bde4119",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_heads = 16\n",
    "gu = GraphUNet(pred_fiber = Fiber({0:32,1:32}),cdivpred=2).to('cuda')\n",
    "dm = H4_DataModule(ca_coords)\n",
    "gn = GaussianNoise(sigma=0.01)\n",
    "opti = torch.optim.Adam(gu.parameters(), lr=0.01,\n",
    "            weight_decay=0)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ce13bc8",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_heads = 16\n",
    "gu = GraphUNet(pred_fiber = Fiber({0:32,1:32}),cdivpred=2).to('cuda')\n",
    "dm = H4_DataModule(ca_coords)\n",
    "gn = GaussianNoise(sigma=0.01).to('cuda')\n",
    "opti = torch.optim.Adam(gu.parameters(), lr=0.001, weight_decay=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "id": "e46b8713",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i, inp in enumerate(dm.gds):\n",
    "    batched_graph, node_feats, edge_feats = inp\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80564a1b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "id": "652fc9dc",
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "Expected all tensors to be on the same device, but found at least two devices, cpu and cuda:0! (when checking argument for argument index in method wrapper_CUDA__index_select)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[124], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m true_pos \u001b[38;5;241m=\u001b[39m batched_graph\u001b[38;5;241m.\u001b[39mndata[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mpos\u001b[39m\u001b[38;5;124m'\u001b[39m]\n\u001b[0;32m----> 2\u001b[0m shift\u001b[38;5;241m=\u001b[39m\u001b[43mgu\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mforward\u001b[49m\u001b[43m(\u001b[49m\u001b[43mnode_feats\u001b[49m\u001b[43m,\u001b[49m\u001b[43m  \u001b[49m\u001b[43mbatched_graph\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[0;32mIn[111], line 150\u001b[0m, in \u001b[0;36mGraphUNet.forward\u001b[0;34m(self, node_feats_in, batched_graph)\u001b[0m\n\u001b[1;32m    147\u001b[0m \u001b[38;5;66;03m#gcn and down pooling\u001b[39;00m\n\u001b[1;32m    148\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39ml_n):\n\u001b[1;32m    149\u001b[0m     \u001b[38;5;66;03m#define basis (spherical harmonics) from xyz_positions, pull edge connections connectivity\u001b[39;00m\n\u001b[0;32m--> 150\u001b[0m     edge_basis_pos_post\u001b[38;5;241m.\u001b[39mappend(\u001b[43mprep_for_gcn\u001b[49m\u001b[43m(\u001b[49m\u001b[43mgu\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgraph_list\u001b[49m\u001b[43m[\u001b[49m\u001b[43mi\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpos\u001b[49m\u001b[43m[\u001b[49m\u001b[43mi\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43medge_pre\u001b[49m\u001b[43m[\u001b[49m\u001b[43mi\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgu\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgraph_list\u001b[49m\u001b[43m[\u001b[49m\u001b[43mi\u001b[49m\u001b[43m]\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mnodes\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m)\n\u001b[1;32m    152\u001b[0m     down_gcn_out\u001b[38;5;241m.\u001b[39mappend(gu\u001b[38;5;241m.\u001b[39mdown_gcns[i]\u001b[38;5;241m.\u001b[39mforward(down_gcn_in[i], edge_basis_pos_post[i][\u001b[38;5;241m0\u001b[39m],\n\u001b[1;32m    153\u001b[0m                                                 graph\u001b[38;5;241m=\u001b[39mgu\u001b[38;5;241m.\u001b[39mgraph_list[i],basis\u001b[38;5;241m=\u001b[39medge_basis_pos_post[i][\u001b[38;5;241m1\u001b[39m]))\n\u001b[1;32m    154\u001b[0m     \u001b[38;5;66;03m#top k pool, save indices pooled for unpooling\u001b[39;00m\n",
      "Cell \u001b[0;32mIn[111], line 8\u001b[0m, in \u001b[0;36mprep_for_gcn\u001b[0;34m(graph, xyz_pos, edge_feats_input, idx, max_degree)\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mprep_for_gcn\u001b[39m(graph, xyz_pos, edge_feats_input, idx, max_degree\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m3\u001b[39m):\n\u001b[1;32m      6\u001b[0m     src, dst \u001b[38;5;241m=\u001b[39m graph\u001b[38;5;241m.\u001b[39medges()\n\u001b[0;32m----> 8\u001b[0m     new_pos \u001b[38;5;241m=\u001b[39m \u001b[43mF\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgather_row\u001b[49m\u001b[43m(\u001b[49m\u001b[43mxyz_pos\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43midx\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      9\u001b[0m     rel_pos \u001b[38;5;241m=\u001b[39m F\u001b[38;5;241m.\u001b[39mgather_row(new_pos,dst) \u001b[38;5;241m-\u001b[39m F\u001b[38;5;241m.\u001b[39mgather_row(new_pos,src) \n\u001b[1;32m     11\u001b[0m     basis_out \u001b[38;5;241m=\u001b[39m get_basis(rel_pos, max_degree\u001b[38;5;241m=\u001b[39mmax_degree,\n\u001b[1;32m     12\u001b[0m                                    compute_gradients\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m,\n\u001b[1;32m     13\u001b[0m                                    use_pad_trick\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\n",
      "File \u001b[0;32m~/miniconda3/envs/se33/lib/python3.9/site-packages/dgl/backend/pytorch/tensor.py:238\u001b[0m, in \u001b[0;36mgather_row\u001b[0;34m(data, row_index)\u001b[0m\n\u001b[1;32m    237\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mgather_row\u001b[39m(data, row_index):\n\u001b[0;32m--> 238\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mth\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mindex_select\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrow_index\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlong\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: Expected all tensors to be on the same device, but found at least two devices, cpu and cuda:0! (when checking argument for argument index in method wrapper_CUDA__index_select)"
     ]
    }
   ],
   "source": [
    "true_pos = batched_graph.ndata['pos']\n",
    "shift=gu.forward(node_feats,  batched_graph)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47b7c9aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i, inp in enumerate(dm.gds):\n",
    "    batched_graph, node_feats, edge_feats = inp\n",
    "\n",
    "    bg = to_cuda(batched_graph)\n",
    "    bg.ndata['pos'].requires_grad = True\n",
    "    nf = to_cuda(node_feats)\n",
    "    nf['0'].requires_grad = True\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "id": "d0ed8dfd",
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "Expected all tensors to be on the same device, but found at least two devices, cpu and cuda:0! (when checking argument for argument index in method wrapper_CUDA__index_select)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[117], line 7\u001b[0m\n\u001b[1;32m      4\u001b[0m B\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m8\u001b[39m\n\u001b[1;32m      5\u001b[0m L\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m65\u001b[39m\n\u001b[0;32m----> 7\u001b[0m shift\u001b[38;5;241m=\u001b[39m\u001b[43mgu\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mforward\u001b[49m\u001b[43m(\u001b[49m\u001b[43mnode_feats\u001b[49m\u001b[43m,\u001b[49m\u001b[43m  \u001b[49m\u001b[43mbatched_graph\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      8\u001b[0m offset \u001b[38;5;241m=\u001b[39m shift[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m1\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39mreshape(B, L, \u001b[38;5;241m2\u001b[39m, \u001b[38;5;241m3\u001b[39m)\n\u001b[1;32m      9\u001b[0m Ts \u001b[38;5;241m=\u001b[39m offset[:,:,\u001b[38;5;241m0\u001b[39m,:]\u001b[38;5;66;03m# translationupdate['1'][0]\u001b[39;00m\n",
      "Cell \u001b[0;32mIn[111], line 150\u001b[0m, in \u001b[0;36mGraphUNet.forward\u001b[0;34m(self, node_feats_in, batched_graph)\u001b[0m\n\u001b[1;32m    147\u001b[0m \u001b[38;5;66;03m#gcn and down pooling\u001b[39;00m\n\u001b[1;32m    148\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39ml_n):\n\u001b[1;32m    149\u001b[0m     \u001b[38;5;66;03m#define basis (spherical harmonics) from xyz_positions, pull edge connections connectivity\u001b[39;00m\n\u001b[0;32m--> 150\u001b[0m     edge_basis_pos_post\u001b[38;5;241m.\u001b[39mappend(\u001b[43mprep_for_gcn\u001b[49m\u001b[43m(\u001b[49m\u001b[43mgu\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgraph_list\u001b[49m\u001b[43m[\u001b[49m\u001b[43mi\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpos\u001b[49m\u001b[43m[\u001b[49m\u001b[43mi\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43medge_pre\u001b[49m\u001b[43m[\u001b[49m\u001b[43mi\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgu\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgraph_list\u001b[49m\u001b[43m[\u001b[49m\u001b[43mi\u001b[49m\u001b[43m]\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mnodes\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m)\n\u001b[1;32m    152\u001b[0m     down_gcn_out\u001b[38;5;241m.\u001b[39mappend(gu\u001b[38;5;241m.\u001b[39mdown_gcns[i]\u001b[38;5;241m.\u001b[39mforward(down_gcn_in[i], edge_basis_pos_post[i][\u001b[38;5;241m0\u001b[39m],\n\u001b[1;32m    153\u001b[0m                                                 graph\u001b[38;5;241m=\u001b[39mgu\u001b[38;5;241m.\u001b[39mgraph_list[i],basis\u001b[38;5;241m=\u001b[39medge_basis_pos_post[i][\u001b[38;5;241m1\u001b[39m]))\n\u001b[1;32m    154\u001b[0m     \u001b[38;5;66;03m#top k pool, save indices pooled for unpooling\u001b[39;00m\n",
      "Cell \u001b[0;32mIn[111], line 8\u001b[0m, in \u001b[0;36mprep_for_gcn\u001b[0;34m(graph, xyz_pos, edge_feats_input, idx, max_degree)\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mprep_for_gcn\u001b[39m(graph, xyz_pos, edge_feats_input, idx, max_degree\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m3\u001b[39m):\n\u001b[1;32m      6\u001b[0m     src, dst \u001b[38;5;241m=\u001b[39m graph\u001b[38;5;241m.\u001b[39medges()\n\u001b[0;32m----> 8\u001b[0m     new_pos \u001b[38;5;241m=\u001b[39m \u001b[43mF\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgather_row\u001b[49m\u001b[43m(\u001b[49m\u001b[43mxyz_pos\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43midx\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      9\u001b[0m     rel_pos \u001b[38;5;241m=\u001b[39m F\u001b[38;5;241m.\u001b[39mgather_row(new_pos,dst) \u001b[38;5;241m-\u001b[39m F\u001b[38;5;241m.\u001b[39mgather_row(new_pos,src) \n\u001b[1;32m     11\u001b[0m     basis_out \u001b[38;5;241m=\u001b[39m get_basis(rel_pos, max_degree\u001b[38;5;241m=\u001b[39mmax_degree,\n\u001b[1;32m     12\u001b[0m                                    compute_gradients\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m,\n\u001b[1;32m     13\u001b[0m                                    use_pad_trick\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\n",
      "File \u001b[0;32m~/miniconda3/envs/se33/lib/python3.9/site-packages/dgl/backend/pytorch/tensor.py:238\u001b[0m, in \u001b[0;36mgather_row\u001b[0;34m(data, row_index)\u001b[0m\n\u001b[1;32m    237\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mgather_row\u001b[39m(data, row_index):\n\u001b[0;32m--> 238\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mth\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mindex_select\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrow_index\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlong\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: Expected all tensors to be on the same device, but found at least two devices, cpu and cuda:0! (when checking argument for argument index in method wrapper_CUDA__index_select)"
     ]
    }
   ],
   "source": [
    "true_pos = batched_graph.ndata['pos'].clone()\n",
    "batched_graph.ndata['pos'] = gn.forward(batched_graph.ndata['pos'])\n",
    "\n",
    "B=8\n",
    "L=65\n",
    "\n",
    "shift=gu.forward(node_feats,  batched_graph)\n",
    "offset = shift['1'].reshape(B, L, 2, 3)\n",
    "Ts = offset[:,:,0,:]# translationupdate['1'][0]\n",
    "pred = torch.add(Ts.reshape(B, L, 3), batched_graph.ndata['pos'].reshape(B, L, 3))\n",
    "\n",
    "\n",
    "tloss, loss = FAPE_loss_CA(pred.unsqueeze(0).repeat(2,1,1,1), true_pos.reshape(B, L, 3))\n",
    "\n",
    "opti.zero_grad()\n",
    "tloss.backward()\n",
    "opti.step()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "caac57eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_heads = 16\n",
    "gu = GraphUNet(pred_fiber = Fiber({0:32,1:32}),cdivpred=2).to('cuda')\n",
    "dm = H4_DataModule(ca_coords)\n",
    "gn = GaussianNoise(sigma=0.01).to('cuda')\n",
    "opti = torch.optim.Adam(gu.parameters(), lr=0.001, weight_decay=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c9f1671",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "93ba1123",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i, inp in enumerate(dm.gds):\n",
    "    batched_graph, node_feats, edge_feats = inp\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "ab0dcfab",
   "metadata": {},
   "outputs": [],
   "source": [
    "true_pos = batched_graph.ndata['pos'].clone()\n",
    "noise_pos = gn.forward(batched_graph.ndata['pos'])\n",
    "noise_pos2 = gn.forward(batched_graph.ndata['pos'],scale=10000)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "9ce41eaf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([520, 3])"
      ]
     },
     "execution_count": 99,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "noise_pos.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "a5a666f2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([ 0.1053, -0.3110, -0.2766])"
      ]
     },
     "execution_count": 100,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "true_pos[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "id": "1c9c8444",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([129.7982, -45.9416,  70.2688])"
      ]
     },
     "execution_count": 101,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "noise_pos2[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "id": "eca32e38",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor(0.0083), tensor([0.0083]))"
      ]
     },
     "execution_count": 102,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "B=8\n",
    "L=65\n",
    "FAPE_loss_CA(noise_pos.reshape(B, L, 3).unsqueeze(0), true_pos.reshape(B, L, 3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "id": "1b74fbeb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor(0.9841), tensor([0.9841]))"
      ]
     },
     "execution_count": 103,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "B=8\n",
    "L=65\n",
    "FAPE_loss_CA(noise_pos2.reshape(B, L, 3).unsqueeze(0), true_pos.reshape(B, L, 3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2bf5f55c",
   "metadata": {},
   "outputs": [],
   "source": [
    "    true_pos = batched_graph.ndata['pos'].clone()\n",
    "    batched_graph.ndata['pos'] = gauss_noise.forward(batched_graph.ndata['pos'])\n",
    "    \n",
    "    B=8\n",
    "    L=65\n",
    "\n",
    "    shift=gu.forward(node_feats,  batched_graph)\n",
    "    offset = shift['1'].reshape(B, L, 2, 3)\n",
    "    Ts = offset[:,:,0,:]# translationupdate['1'][0]\n",
    "    pred = torch.add(Ts.reshape(B, L, 3), batched_graph.ndata['pos'].reshape(B, L, 3))\n",
    "    \n",
    "        \n",
    "    tloss, loss = FAPE_loss_CA(pred.unsqueeze(0).repeat(2,1,1,1), true_pos.reshape(B, L, 3))\n",
    "    \n",
    "    opti.zero_grad()\n",
    "    tloss.backward()\n",
    "    opti.step()\n",
    "    \n",
    "    return offset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0502dc6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "id": "cb11c3bd",
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "shape '[8, 65, 2, 3]' is invalid for input of size 1560",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[114], line 11\u001b[0m\n\u001b[1;32m      8\u001b[0m     nf \u001b[38;5;241m=\u001b[39m to_cuda(node_feats)\n\u001b[1;32m      9\u001b[0m     nf[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m0\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39mrequires_grad \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[0;32m---> 11\u001b[0m     loss \u001b[38;5;241m=\u001b[39m \u001b[43mtrain_step\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbg\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnf\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgn\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgu\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     13\u001b[0m     lsum \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m loss\n\u001b[1;32m     15\u001b[0m \u001b[38;5;28mprint\u001b[39m(lsum\u001b[38;5;241m/\u001b[39mi)\n",
      "Cell \u001b[0;32mIn[112], line 10\u001b[0m, in \u001b[0;36mtrain_step\u001b[0;34m(batched_graph, node_feats, gauss_noise, graph_unet)\u001b[0m\n\u001b[1;32m      7\u001b[0m L\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m65\u001b[39m\n\u001b[1;32m      9\u001b[0m shift\u001b[38;5;241m=\u001b[39mgu\u001b[38;5;241m.\u001b[39mforward(node_feats,  batched_graph)\n\u001b[0;32m---> 10\u001b[0m offset \u001b[38;5;241m=\u001b[39m \u001b[43mshift\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43m1\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mreshape\u001b[49m\u001b[43m(\u001b[49m\u001b[43mB\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mL\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m2\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m3\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m     11\u001b[0m Ts \u001b[38;5;241m=\u001b[39m offset[:,:,\u001b[38;5;241m0\u001b[39m,:]\u001b[38;5;66;03m# translationupdate['1'][0]\u001b[39;00m\n\u001b[1;32m     12\u001b[0m pred \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39madd(Ts\u001b[38;5;241m.\u001b[39mreshape(B, L, \u001b[38;5;241m3\u001b[39m), batched_graph\u001b[38;5;241m.\u001b[39mndata[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mpos\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39mreshape(B, L, \u001b[38;5;241m3\u001b[39m))\n",
      "\u001b[0;31mRuntimeError\u001b[0m: shape '[8, 65, 2, 3]' is invalid for input of size 1560"
     ]
    }
   ],
   "source": [
    "\n",
    "for e in range(100):\n",
    "    lsum = 0\n",
    "    for i, inp in enumerate(dm.gds):\n",
    "        batched_graph, node_feats, edge_feats = inp\n",
    "\n",
    "        bg = to_cuda(batched_graph)\n",
    "        bg.ndata['pos'].requires_grad = True\n",
    "        nf = to_cuda(node_feats)\n",
    "        nf['0'].requires_grad = True\n",
    "\n",
    "        loss = train_step(bg, nf, gn, gu)\n",
    "        \n",
    "        lsum += loss\n",
    "        \n",
    "    print(lsum/i)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "id": "12de4c34",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/nwoodall/miniconda3/envs/se33/lib/python3.9/site-packages/torch/utils/checkpoint.py:31: UserWarning: None of the inputs have requires_grad=True. Gradients will be None\n",
      "  warnings.warn(\"None of the inputs have requires_grad=True. Gradients will be None\")\n"
     ]
    }
   ],
   "source": [
    "B=8\n",
    "L=65\n",
    "\n",
    "shift=gu.forward(node_feats,  batched_graph)\n",
    "\n",
    "offset = shift['1'].reshape(B, L, 2, 3)\n",
    "Ts = offset[:,:,0,:] * 31 # translationupdate['1'][0]\n",
    "pred1 = torch.add(Ts.reshape(B, L, 3),batched_graph.ndata['pos'].reshape(B, L, 3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "id": "3a242e3a",
   "metadata": {},
   "outputs": [],
   "source": [
    "tloss, loss = FAPE_loss_CA(  pred1.unsqueeze(0).repeat(2,1,1,1), true_pos.reshape(B, L, 3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "29ed5cfc",
   "metadata": {},
   "outputs": [],
   "source": [
    "bg =to_cuda(batched_graph)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "bd518b5d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([  0,   0,   0,  ..., 519, 519, 519], device='cuda:0'),\n",
       " tensor([  1,   2,   3,  ..., 516, 517, 518], device='cuda:0'))"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bg.edges()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "id": "e178ad10",
   "metadata": {},
   "outputs": [],
   "source": [
    "opti.zero_grad()\n",
    "tloss.backward()\n",
    "opti.step()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "id": "e82f573f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "id": "2e585045",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([2, 8, 63, 63])\n",
      "torch.Size([2])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(tensor(0.9841, grad_fn=<SumBackward0>), tensor([0.4921, 0.4921]))"
      ]
     },
     "execution_count": 123,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "FAPE_loss_CA(  pred1.unsqueeze(0).repeat(2,1,1,1), true_pos.reshape(B, L, 3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c398bed",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "c60e5727",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([520, 3])"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "true_pos.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6dc46e9b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "279b4bac",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([520, 2, 3])"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "offset['1'].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "cc975020",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[  256.8314, -1025.1440,  -437.2067],\n",
       "        [  -32.3810,   269.8080,  -132.2642]], grad_fn=<SelectBackward0>)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "offset = shift['1'].reshape(B, L, 2, 3)\n",
    "        Ts = offset[:,:,0,:] * 10.0 # translationupdate['1'][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5f1839e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9cafbbb5",
   "metadata": {},
   "outputs": [],
   "source": [
    "ppp['1'].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "id": "5c07202d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "16640.0"
      ]
     },
     "execution_count": 113,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "199680/12"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "eda17e81",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "12.0"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "399360/33280"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14266044",
   "metadata": {},
   "outputs": [],
   "source": [
    "channels_div = num_heads/channels\n",
    "\n",
    "fiber = max_degrees*channel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84c52b2a",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i, inp in enumerate(dm.gds):\n",
    "    batched_graph, node_feats, edge_feats = inp\n",
    "    break\n",
    "    \n",
    "bg = to_cuda(batched_graph)\n",
    "edge_feats = to_cuda(edge_feats)\n",
    "node_feats = to_cuda(node_feats)\n",
    "\n",
    "basis = get_basis(bg.edata['rel_pos'], max_degree=max_degree,\n",
    "                                   compute_gradients=True,\n",
    "                                   use_pad_trick=False)\n",
    "\n",
    "#need to add basis fused here?\n",
    "\n",
    "basis = update_basis_with_fused(basis, max_degree, use_pad_trick=False,\n",
    "                                        fully_fused=False)\n",
    "\n",
    "#concatenate on the distances of the edge based on 'rel pos'\n",
    "edge_feats_cat = get_populated_edge_features(bg.edata['rel_pos'], edge_feats)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b2c98c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "#sample denoted \n",
    "gu = GraphUNet()\n",
    "dm = H4_DataModule(ca_coords)\n",
    "for i, inp in enumerate(dm.gds):\n",
    "    batched_graph, node_feats, edge_feats = inp\n",
    "    break\n",
    "pos = batched_graph.ndata['pos']\n",
    "edge_feats_out,basis_out, pos = prep_for_gcn(gu.graph_list[0], pos, edge_feats, gu.graph_list[0].nodes())\n",
    "out = gu.down_gcns[0].forward(node_feats, edge_feats_out,graph=gu.graph_list[0],basis=basis_out)\n",
    "out2, indx = gu.pools[0](out,gu.graph_list[0])\n",
    "#figure out the basis prep here\n",
    "\n",
    "edge_feats_1, basis_1, pos2 = prep_for_gcn(gu.graph_list[1], pos, get_edge_features(gu.graph_list[1]), indx)\n",
    "out3 = gu.bottom_gcn.forward(out2, edge_feats_1, graph=gu.graph_list[1],basis=basis_1)\n",
    "latent = {'0':gu.global_pool(out3,graph=gu.graph_list[1]).unsqueeze(-1)}\n",
    "up1 = gu.latent_unpool(latent,graph=gu.graph_list[1],u_features=out3)\n",
    "up2 = gu.up_gcns[0].forward(up1,edge_feats_1,graph=gu.graph_list[1],basis=basis_1)\n",
    "up3 = gu.unpools[0](up2,graph=gu.graph_list[0], idx = indx,u_features=out)\n",
    "final = gu.top_gcn.forward(up3,edge_feats_out, graph=gu.graph_list[0], basis=basis_out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "a3ccf34a",
   "metadata": {},
   "outputs": [],
   "source": [
    "dm = H4_DataModule(ca_coords)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "d86c1e74",
   "metadata": {},
   "outputs": [],
   "source": [
    "n_nodes = 65\n",
    "NODE_FEATURE_DIM = 12\n",
    "EDGE_FEATURE_DIM = 1 # probably expand to [2] one hot primary connect \n",
    "num_degrees = 4 # how many levels of spherical harmonics to use\n",
    "num_channels = 8 # how many\n",
    "num_heads = 4\n",
    "channels_div = 2\n",
    "max_degree = 4\n",
    "\n",
    "use_layer_norm = True\n",
    "\n",
    "fuse_level = ConvSE3FuseLevel.NONE\n",
    "\n",
    "fiber_in=Fiber({0: NODE_FEATURE_DIM})\n",
    "fiber_hidden=Fiber({0: num_degrees * num_channels})\n",
    "fiber_edge=Fiber({0: EDGE_FEATURE_DIM})\n",
    "fiber_out = Fiber({0: num_degrees * num_channels}) # can this be arbitrary, or projected"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "982dfb24",
   "metadata": {},
   "outputs": [],
   "source": [
    "ablock = AttentionBlockSE3(fiber_in=fiber_in,\n",
    "               fiber_out=fiber_hidden,\n",
    "               fiber_edge=fiber_edge,\n",
    "               num_heads=num_heads,\n",
    "               channels_div=channels_div,\n",
    "               use_layer_norm=use_layer_norm,\n",
    "               max_degree=max_degree,\n",
    "               fuse_level=fuse_level,\n",
    "               low_memory='True')\n",
    "acuda = ablock.to('cuda')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "3dce2b66",
   "metadata": {},
   "outputs": [],
   "source": [
    "tk = TopK_Pool(fiber_hidden)\n",
    "tk_cuda = tk.to('cuda')\n",
    "# tblock = [ablock,tk]\n",
    "# model = Sequential(*tblock)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "055cf9c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i, inp in enumerate(dm.gds):\n",
    "    batched_graph, node_feats, edge_feats = inp\n",
    "    break\n",
    "    \n",
    "bg = to_cuda(batched_graph)\n",
    "edge_feats = to_cuda(edge_feats)\n",
    "node_feats = to_cuda(node_feats)\n",
    "\n",
    "basis = get_basis(bg.edata['rel_pos'], max_degree=max_degree,\n",
    "                                   compute_gradients=True,\n",
    "                                   use_pad_trick=False)\n",
    "\n",
    "#need to add basis fused here?\n",
    "\n",
    "basis = update_basis_with_fused(basis, max_degree, use_pad_trick=False,\n",
    "                                        fully_fused=False)\n",
    "\n",
    "#concatenate on the distances of the edge based on 'rel pos'\n",
    "edge_feats_cat = get_populated_edge_features(bg.edata['rel_pos'], edge_feats)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "7c373348",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/nwoodall/miniconda3/envs/se33/lib/python3.9/site-packages/torch/utils/checkpoint.py:31: UserWarning: None of the inputs have requires_grad=True. Gradients will be None\n",
      "  warnings.warn(\"None of the inputs have requires_grad=True. Gradients will be None\")\n",
      "/home/nwoodall/miniconda3/envs/se33/lib/python3.9/site-packages/dgl/backend/pytorch/tensor.py:449: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()\n",
      "  assert input.numel() == input.storage().size(), (\n"
     ]
    }
   ],
   "source": [
    "out = acuda.forward(node_feats, edge_feats_cat,graph=bg,basis=basis)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "9e1a32ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "node_feat_1, inde = tk.forward(out, bg)\n",
    "ndf1 = {}\n",
    "ndf1['0'] = node_feat_1.unsqueeze(-1)\n",
    "\n",
    "new_pos = F.gather_row(bg.ndata['pos'], inde)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9081390",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "0457cf75",
   "metadata": {},
   "outputs": [],
   "source": [
    "#define subgraph 1, and rel pos indices \n",
    "\n",
    "bg_pool1 = define_UGraph(tk.k,batch_size=8) \n",
    "src, dst = bg_pool1.edges()\n",
    "src_pool1 = to_cuda(src)\n",
    "dst_pool1 = to_cuda(dst)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "12da583e",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#\n",
    "edge_feats_1 = {'0': bg_pool1.edata['con'][:, :1, None]}\n",
    "\n",
    "edge_feats_1 = to_cuda(edge_feats_1)\n",
    "\n",
    "\n",
    "rel_pos_pool1 = F.gather_row(new_pos,dst_pool1) - F.gather_row(new_pos,src_pool1) \n",
    "#rel_pos_pool1 = \n",
    "\n",
    "edge_feats_1_cat = get_populated_edge_features(rel_pos_pool1, edge_feats_1)\n",
    "basis_1 = get_basis(rel_pos_pool1, max_degree=max_degree,\n",
    "                                   compute_gradients=True,\n",
    "                                   use_pad_trick=False)\n",
    "basis_1 = update_basis_with_fused(basis_1, max_degree, use_pad_trick=False,\n",
    "                                        fully_fused=False)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "53627267",
   "metadata": {},
   "outputs": [],
   "source": [
    "NODE_FEATURE_DIM = 32\n",
    "EDGE_FEATURE_DIM = 1 # \n",
    "num_degrees = 4 # how many levels of spherical harmonics to use\n",
    "num_channels = 16 # how many\n",
    "num_heads = 8\n",
    "channels_div = 2\n",
    "max_degree = 4\n",
    "\n",
    "use_layer_norm = True\n",
    "fuse_level = ConvSE3FuseLevel.NONE\n",
    "\n",
    "\n",
    "fiber_in2=Fiber({0: NODE_FEATURE_DIM})\n",
    "fiber_hidden2=Fiber({0: num_degrees * num_channels*4})\n",
    "fiber_edge2=Fiber({0: EDGE_FEATURE_DIM})\n",
    "#fiber_out2 = Fiber({0: num_degrees * num_channels * 4}) # can this be arbitrary, or projected\n",
    "ablock2 = AttentionBlockSE3(fiber_in=fiber_in2,\n",
    "               fiber_out=fiber_hidden2,\n",
    "               fiber_edge=fiber_edge2,\n",
    "               num_heads=num_heads,\n",
    "               channels_div=channels_div,\n",
    "               use_layer_norm=use_layer_norm,\n",
    "               max_degree=max_degree,\n",
    "               fuse_level=fuse_level,\n",
    "               low_memory='True')\n",
    "acuda2 = ablock2.to('cuda')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "58ca1735",
   "metadata": {},
   "outputs": [],
   "source": [
    "out2 = acuda2.forward(ndf1, edge_feats_1_cat, graph=to_cuda(bg_pool1), basis=basis_1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "d5cbf2d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "#i think i need to build a new graph after the pool, ugh, ugh ,ugh\n",
    "#unpooling should be easier just add onto old."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "aca7f740",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([40, 256, 1])"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "out2['0'].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "56efbd12",
   "metadata": {},
   "outputs": [],
   "source": [
    "global_pooling_module = GPooling(pool='max', feat_type=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "b2ee7c03",
   "metadata": {},
   "outputs": [],
   "source": [
    "latent_pool = global_pooling_module(out2, to_cuda(bg_pool1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "e5552624",
   "metadata": {},
   "outputs": [],
   "source": [
    "lp = Latent_Unpool()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "be0859a3",
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "forward() missing 1 required positional argument: 'u_features'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[56], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mlp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mforward\u001b[49m\u001b[43m(\u001b[49m\u001b[43mlatent_pool\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbg_pool1\u001b[49m\u001b[43m,\u001b[49m\u001b[43mout2\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[0;31mTypeError\u001b[0m: forward() missing 1 required positional argument: 'u_features'"
     ]
    }
   ],
   "source": [
    "lp.forward(latent_pool, bg_pool1,out2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9186d6ad",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "8506f0b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "global_pooling_module = GPooling(pool='max', feat_type=0)\n",
    "latent_pool = global_pooling_module(out2, to_cuda(bg_pool1))\n",
    "node_feat_up1 = latent_pool.repeat_interleave(5,0) #copy pool to all new nodes\n",
    "node_feat_up1  = torch.add(node_feat_up1.unsqueeze(-1),out2['0']) #unet add "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "53f4ba63",
   "metadata": {},
   "outputs": [],
   "source": [
    "node_feat_up1 = latent_pool.repeat_interleave(5,0) #copy pool to all new nodes\n",
    "node_feat_up1  = torch.add(node_feat_up1.unsqueeze(-1),out2['0']) #unet add \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "ad34c923",
   "metadata": {},
   "outputs": [],
   "source": [
    "NODE_FEATURE_DIM = 256\n",
    "EDGE_FEATURE_DIM = 1 # \n",
    "num_degrees = 4 # how many levels of spherical harmonics to use\n",
    "num_channels = 4 # how many\n",
    "num_heads = 4\n",
    "channels_div = 1\n",
    "max_degree = 4\n",
    "\n",
    "use_layer_norm = True\n",
    "fuse_level = ConvSE3FuseLevel.NONE\n",
    "\n",
    "\n",
    "fiber_in3=Fiber({0: NODE_FEATURE_DIM})\n",
    "fiber_hidden3=Fiber({0: num_degrees * num_channels*2})\n",
    "fiber_edge3=Fiber({0: EDGE_FEATURE_DIM})\n",
    "#fiber_out2 = Fiber({0: num_degrees * num_channels * 4}) # can this be arbitrary, or projected\n",
    "ablock3 = AttentionBlockSE3(fiber_in=fiber_in3,\n",
    "               fiber_out=fiber_hidden3,\n",
    "               fiber_edge=fiber_edge3,\n",
    "               num_heads=num_heads,\n",
    "               channels_div=channels_div,\n",
    "               use_layer_norm=use_layer_norm,\n",
    "               max_degree=max_degree,\n",
    "               fuse_level=fuse_level,\n",
    "               low_memory='True')\n",
    "acuda3 = ablock3.to('cuda')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "22c19a87",
   "metadata": {},
   "outputs": [],
   "source": [
    "out3 = acuda3.forward({'0':node_feat_up1}, edge_feats_1_cat, graph=to_cuda(bg_pool1), basis=basis_1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "id": "311ff1ad",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([40, 32, 1])"
      ]
     },
     "execution_count": 106,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "out3['0'].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "id": "e1ef0781",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([520, 32, 1])"
      ]
     },
     "execution_count": 107,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#unpool \n",
    "\n",
    "node_feat_up2 = torch.zeros((bg.num_nodes(), out3['0'].shape[1],1 )).to('cuda')\n",
    "dd=F.scatter_row(node_feat_up2,inde,out3['0'])\n",
    "\n",
    "#add U-net\n",
    "pad= dd.shape[1]-node_feats['0'].shape[1]\n",
    "unet_add = torch.cat((node_feats['0'], torch.zeros(node_feats['0'].shape[0],pad ,1).to('cuda')), 1)\n",
    "\n",
    "torch.add(unet_add,dd).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "id": "4bfa8ede",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([520, 32, 1])"
      ]
     },
     "execution_count": 121,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "upool = Unpool()\n",
    "inde_list = [inde]\n",
    "upool(out3,bg,inde_list,node_feats)['0'].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "id": "d20106b7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([520, 32, 1]) torch.Size([520, 20, 1])\n"
     ]
    }
   ],
   "source": [
    "indelist = [inde]\n",
    "idx_count = 0\n",
    "out_feats = {}\n",
    "for key,val in out3.items():\n",
    "    new_h = val.new_zeros([bg.num_nodes(), val.shape[1],1])\n",
    "    pad = val.new_zeros([bg.num_nodes(), new_h.shape[1]-node_feats[key].shape[1],1])\n",
    "    print(new_h.shape,pad.shape)\n",
    "    F.scatter_row(new_h,indelist[idx_count],val)\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "id": "d5fff63b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([40])"
      ]
     },
     "execution_count": 116,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "inde.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "id": "7be6edb0",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Unpool(torch.nn.Module):\n",
    "    \"\"\"\n",
    "    Place features into torch.zeros array\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "\n",
    "    def forward(self, features: Dict[str, Tensor], graph: DGLGraph, idx: Tensor, u_features: Dict[str, Tensor]):\n",
    "        idx_count = 0\n",
    "        out_feats = {}\n",
    "        for key,val in features.items():\n",
    "            new_h = val.new_zeros([graph.num_nodes(), val.shape[1], 1])\n",
    "            pad = val.new_zeros([graph.num_nodes(), new_h.shape[1]-u_features[key].shape[1],1])\n",
    "            out_feats[key] = torch.add(F.scatter_row(new_h,idx[idx_count],val),torch.cat((u_features[key],pad),1))\n",
    "            idx_count +=1\n",
    "        return out_feats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "24d75eda",
   "metadata": {},
   "outputs": [],
   "source": [
    "unet_add = torch.cat((node_feats['0'], torch.zeros(node_feats['0'].shape[0],dd.shape[1]-node_feats['0'].shape[1],1).to('cuda')), 1).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "1761af37",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([ 45,  46,  47,  48,  49, 110, 111, 112, 113, 114, 175, 176, 177, 178,\n",
       "        179, 240, 241, 242, 243, 244, 305, 306, 307, 308, 309, 370, 371, 372,\n",
       "        373, 374, 435, 436, 437, 438, 439, 500, 501, 502, 503, 504],\n",
       "       device='cuda:0')"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "inde"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "725d1b7d",
   "metadata": {},
   "outputs": [],
   "source": [
    "?torch.scatter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "526b4467",
   "metadata": {},
   "outputs": [],
   "source": [
    "F.scatter_row"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "31e61428",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([40, 32, 1])"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "out3['0'].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "3960a4d6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([40, 256, 1])"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "out2['0'].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "6681886e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([40, 256])"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "node_feat_up1.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "8db81890",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([40, 256])"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "latent_pool.repeat_interleave(5,0).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5bb29fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "#unpooling\n",
    "\n",
    "#need torch.zeros size of previous graph\n",
    "torch.zeros((bg_pool1.num_nodes,))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "2c19257d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Graph(num_nodes=40, num_edges=160,\n",
       "      ndata_schemes={'pe': Scheme(shape=(12,), dtype=torch.float32), 'pos': Scheme(shape=(3,), dtype=torch.float32)}\n",
       "      edata_schemes={'con': Scheme(shape=(1,), dtype=torch.float32)})"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bg_pool1.num_nodes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b7e53d7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f350f97",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b1432f1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79a1826a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22c26e88",
   "metadata": {},
   "outputs": [],
   "source": [
    "def forward(self, features: Dict[str, Tensor], graph: DGLGraph, **kwargs) -> Tensor:\n",
    "        pooled = self.pool(graph, features[str(self.feat_type)])\n",
    "        return pooled.squeeze(dim=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15c86773",
   "metadata": {},
   "outputs": [],
   "source": [
    "#remake without pulling from graph?\n",
    "\n",
    "READOUT_ON_ATTRS = {\n",
    "    \"nodes\": (\"ndata\", \"batch_num_nodes\", \"number_of_nodes\"),\n",
    "    \"edges\": (\"edata\", \"batch_num_edges\", \"number_of_edges\"),\n",
    "}\n",
    "\n",
    "def _topk_on(graph, typestr, feat, k, descending, sortby, ntype_or_etype):\n",
    "    \"\"\"Internal function to take graph-wise top-k node/edge features of\n",
    "    field :attr:`feat` in :attr:`graph` ranked by keys at given\n",
    "    index :attr:`sortby`. If :attr:`descending` is set to False, return the\n",
    "    k smallest elements instead.\n",
    "\n",
    "    Parameters\n",
    "    ---------\n",
    "    graph : DGLGraph\n",
    "        The graph\n",
    "    typestr : str\n",
    "        'nodes' or 'edges'\n",
    "    feat : str\n",
    "        The feature field name.\n",
    "    k : int\n",
    "        The :math:`k` in \"top-:math`k`\".\n",
    "    descending : bool\n",
    "        Controls whether to return the largest or smallest elements,\n",
    "         defaults to True.\n",
    "    sortby : int\n",
    "        The key index we sort :attr:`feat` on, if set to None, we sort\n",
    "        the whole :attr:`feat`.\n",
    "    ntype_or_etype : str, tuple of str\n",
    "        Node/edge type.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    sorted_feat : Tensor\n",
    "        A tensor with shape :math:`(B, K, D)`, where\n",
    "        :math:`B` is the batch size of the input graph.\n",
    "    sorted_idx : Tensor\n",
    "        A tensor with shape :math:`(B, K)`(:math:`(B, K, D)` if sortby\n",
    "        is set to None), where\n",
    "        :math:`B` is the batch size of the input graph, :math:`D`\n",
    "        is the feature size.\n",
    "\n",
    "\n",
    "    Notes\n",
    "    -----\n",
    "    If an example has :math:`n` nodes/edges and :math:`n<k`, in the first\n",
    "    returned tensor the :math:`n+1` to :math:`k`th rows would be padded\n",
    "    with all zero; in the second returned tensor, the behavior of :math:`n+1`\n",
    "    to :math:`k`th elements is not defined.\n",
    "    \"\"\"\n",
    "    _, batch_num_objs_attr, _ = READOUT_ON_ATTRS[typestr]\n",
    "    data = getattr(graph, typestr)[ntype_or_etype].data\n",
    "    if F.ndim(data[feat]) > 2:\n",
    "        raise DGLError(\n",
    "            \"Only support {} feature `{}` with dimension less than or\"\n",
    "            \" equal to 2\".format(typestr, feat)\n",
    "        )\n",
    "    feat = data[feat]\n",
    "    hidden_size = F.shape(feat)[-1]\n",
    "    batch_num_objs = getattr(graph, batch_num_objs_attr)(ntype_or_etype)\n",
    "    batch_size = len(batch_num_objs)\n",
    "    length = max(max(F.asnumpy(batch_num_objs)), k)\n",
    "    fill_val = -float(\"inf\") if descending else float(\"inf\")\n",
    "    feat_ = F.pad_packed_tensor(\n",
    "        feat, batch_num_objs, fill_val, l_min=k\n",
    "    )  # (batch_size, l, d)\n",
    "\n",
    "    if F.backend_name == \"pytorch\" and sortby is not None:\n",
    "        # PyTorch's implementation of top-K\n",
    "        keys = feat_[..., sortby]  # (batch_size, l)\n",
    "        return _topk_torch(keys, k, descending, feat_)\n",
    "    else:\n",
    "        # Fallback to framework-agnostic implementation of top-K\n",
    "        if sortby is not None:\n",
    "            keys = F.squeeze(F.slice_axis(feat_, -1, sortby, sortby + 1), -1)\n",
    "            order = F.argsort(keys, -1, descending=descending)\n",
    "        else:\n",
    "            order = F.argsort(feat_, 1, descending=descending)\n",
    "        topk_indices = F.slice_axis(order, 1, 0, k)\n",
    "\n",
    "        if sortby is not None:\n",
    "            feat_ = F.reshape(feat_, (batch_size * length, -1))\n",
    "            shift = F.repeat(F.arange(0, batch_size) * length, k, -1)\n",
    "            shift = F.copy_to(shift, F.context(feat))\n",
    "            topk_indices_ = F.reshape(topk_indices, (-1,)) + shift\n",
    "        else:\n",
    "            feat_ = F.reshape(feat_, (-1,))\n",
    "            shift = F.repeat(\n",
    "                F.arange(0, batch_size), k * hidden_size, -1\n",
    "            ) * length * hidden_size + F.cat(\n",
    "                [F.arange(0, hidden_size)] * batch_size * k, -1\n",
    "            )\n",
    "            shift = F.copy_to(shift, F.context(feat))\n",
    "            topk_indices_ = F.reshape(topk_indices, (-1,)) * hidden_size + shift\n",
    "        out = F.reshape(F.gather_row(feat_, topk_indices_), (batch_size, k, -1))\n",
    "        out = F.replace_inf_with_zero(out)\n",
    "        return out, topk_indices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "4d4b0195",
   "metadata": {},
   "outputs": [],
   "source": [
    "for x in range(8):\n",
    "    for y in range(30):\n",
    "        if len(np.unique(sort_ind[x][:,y].cpu().numpy())) != 30:\n",
    "            print(False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "0c27f477",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 1.2111, -0.0900,  0.7318,  0.2344, -0.0669,  0.0927,  0.5824,  0.4390,\n",
       "          0.0690,  0.5615,  0.7202,  0.1591,  0.5839,  0.1566,  0.3246,  0.1450,\n",
       "          0.8620,  0.5528,  1.3103,  0.5718,  0.4452, -0.5404,  0.4007,  0.3480,\n",
       "          0.4214,  0.7397,  0.1821,  0.0995,  0.1473,  0.8472,  0.4826,  0.7203],\n",
       "        [ 1.2044, -0.0912,  0.7244,  0.2296, -0.1206,  0.0902,  0.5798,  0.4309,\n",
       "          0.0607,  0.5256,  0.7131,  0.1099,  0.5822,  0.1490,  0.3212,  0.1406,\n",
       "          0.8589,  0.5515,  1.3042,  0.5710,  0.4410, -0.5436,  0.3697,  0.3449,\n",
       "          0.4145,  0.7275,  0.1739,  0.0936,  0.1362,  0.8349,  0.4770,  0.7097],\n",
       "        [ 1.2012, -0.0977,  0.7028,  0.2276, -0.1264,  0.0872,  0.5759,  0.4240,\n",
       "          0.0556,  0.5194,  0.6933,  0.0538,  0.5749,  0.1320,  0.3177,  0.1326,\n",
       "          0.8483,  0.5320,  1.2934,  0.5513,  0.4327, -0.5531,  0.3374,  0.3360,\n",
       "          0.4096,  0.7245,  0.1727,  0.0884,  0.1138,  0.8332,  0.4558,  0.6915],\n",
       "        [ 1.1841, -0.0988,  0.6926,  0.2158, -0.1276,  0.0816,  0.5654,  0.3994,\n",
       "          0.0481,  0.5165,  0.6760,  0.0088,  0.5497,  0.1087,  0.3112,  0.1164,\n",
       "          0.8411,  0.5276,  1.2759,  0.5454,  0.4011, -0.5657,  0.3129,  0.3291,\n",
       "          0.3883,  0.6883,  0.1496,  0.0744,  0.0823,  0.8324,  0.4443,  0.6572],\n",
       "        [ 1.1757, -0.1016,  0.6879,  0.2071, -0.1334,  0.0805,  0.5621,  0.3876,\n",
       "          0.0469,  0.5091,  0.6333,  0.0045,  0.5085,  0.0788,  0.3016,  0.1011,\n",
       "          0.8172,  0.4893,  1.2559,  0.5111,  0.3874, -0.5815,  0.3119,  0.3125,\n",
       "          0.3805,  0.6783,  0.1490,  0.0630,  0.0374,  0.8213,  0.4017,  0.6260],\n",
       "        [ 1.1486, -0.1158,  0.6847,  0.1954, -0.1402,  0.0755,  0.5435,  0.3458,\n",
       "          0.0375,  0.5007,  0.6153,  0.0024,  0.4568,  0.0390,  0.2957,  0.0708,\n",
       "          0.8081,  0.4856,  1.2293,  0.5049,  0.3873, -0.6020,  0.3097,  0.3002,\n",
       "          0.3460,  0.6287,  0.1163,  0.0441, -0.0096,  0.8178,  0.3889,  0.5733],\n",
       "        [ 1.1418, -0.1215,  0.6688,  0.1718, -0.1445,  0.0564,  0.5380,  0.3345,\n",
       "          0.0218,  0.4898,  0.5426, -0.0097,  0.3950,  0.0026,  0.2817,  0.0544,\n",
       "          0.7738,  0.4322,  1.1982,  0.4570,  0.3731, -0.6247,  0.3056,  0.2565,\n",
       "          0.3367,  0.6271,  0.1090,  0.0252, -0.0101,  0.8005,  0.3870,  0.5728],\n",
       "        [ 1.1029, -0.1348,  0.6647,  0.1699, -0.1461,  0.0438,  0.5243,  0.3101,\n",
       "          0.0105,  0.4730,  0.5368, -0.0129,  0.3247, -0.0544,  0.2721,  0.0111,\n",
       "          0.7617,  0.4246,  1.1697,  0.4510,  0.3713, -0.6546,  0.3013,  0.2014,\n",
       "          0.2917,  0.6245,  0.0769,  0.0045, -0.0181,  0.7973,  0.3867,  0.5237],\n",
       "        [ 1.0956, -0.1427,  0.6516,  0.1631, -0.1464,  0.0416,  0.5147,  0.2743,\n",
       "         -0.0015,  0.4607,  0.4500, -0.0222,  0.3233, -0.0891,  0.2573,  0.0025,\n",
       "          0.7225,  0.3721,  1.1239,  0.4018,  0.3559, -0.6753,  0.2907,  0.1418,\n",
       "          0.2816,  0.6060,  0.0537, -0.0245, -0.0453,  0.7853,  0.3616,  0.4700],\n",
       "        [ 1.0602, -0.1474,  0.6515,  0.1589, -0.1604,  0.0022,  0.5085,  0.2731,\n",
       "         -0.0040,  0.4451,  0.4283, -0.0398,  0.3149, -0.1644,  0.2437, -0.0210,\n",
       "          0.7080,  0.3432,  1.1016,  0.3705,  0.3456, -0.7164,  0.2882,  0.0796,\n",
       "          0.2292,  0.6032,  0.0485, -0.0408, -0.0644,  0.7827,  0.3539,  0.4538]],\n",
       "       device='cuda:0', grad_fn=<SelectBackward0>)"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sort_feat[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "a8a64ef7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([10, 32])"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sort_ind[0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d214fe8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a5efeed",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = SE3TransformerPooled(\n",
    "        fiber_in=Fiber({0: dm.NODE_FEATURE_DIM}),\n",
    "        fiber_out=Fiber({0: num_degrees * num_channels}),\n",
    "        fiber_edge=Fiber({0: dm.EDGE_FEATURE_DIM}),\n",
    "        output_dim=1,\n",
    "        tensor_cores=using_tensor_cores(False),\n",
    "        num_degrees=num_degrees,\n",
    "        num_channels=num_channels,\n",
    "        **kwargs\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "a22797c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "?dgl.nn.pytorch."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7e9e983",
   "metadata": {},
   "outputs": [],
   "source": [
    "# get dataset from pdb using npose utils\n",
    "# import util.npose_util as nu\n",
    "# import os\n",
    "# import numpy as np\n",
    "\n",
    "# model_direc = '/mnt/c/Users/nwood/OneDrive/Desktop/hTest/HelixGen_master/data/4H_dataset/models/'\n",
    "\n",
    "# fL = os.listdir(model_direc)\n",
    "# coords = np.zeros((len(fL),65*5,4)) #65 aa, 5 atoms per aa\n",
    "# for i,file in enumerate(fL):\n",
    "#     coords[i] = nu.npose_from_file(f'{model_direc}/{file}')\n",
    "\n",
    "# coords_out = coords.reshape((27894,65,5,4))[...,:3]\n",
    "# ca_coords = coords_out.reshape((27894,65,5,3))[:,:,1,:]\n",
    "\n",
    "# np.savez_compressed('../gudiff/data/h4_coords.npz',coords_out)\n",
    "# np.savez_compressed('../gudiff/data/h4_ca_coords.npz',ca_coords)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "cca76781",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'Dataset' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[10], line 47\u001b[0m\n\u001b[0;32m     42\u001b[0m     batched_graph \u001b[38;5;241m=\u001b[39m dgl\u001b[38;5;241m.\u001b[39mbatch(graphList)\n\u001b[0;32m     44\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m batched_graph\n\u001b[1;32m---> 47\u001b[0m \u001b[38;5;28;01mclass\u001b[39;00m \u001b[38;5;21;01mGraphDataset\u001b[39;00m(\u001b[43mDataset\u001b[49m):\n\u001b[0;32m     48\u001b[0m     \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__init__\u001b[39m(\u001b[38;5;28mself\u001b[39m, ep_file : pathlib\u001b[38;5;241m.\u001b[39mPath, limit\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1000\u001b[39m):\n\u001b[0;32m     49\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdata_path \u001b[38;5;241m=\u001b[39m ep_file\n",
      "\u001b[1;31mNameError\u001b[0m: name 'Dataset' is not defined"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "\n",
    "\n",
    "def normalize_pc(points):\n",
    "    \"\"\"Center at Zero Divide furtherst points\"\"\"\n",
    "    centroid = np.mean(points, axis=0)\n",
    "    points -= centroid\n",
    "    #since the points are centered zero, the furthest points is the abs value di\n",
    "    furthest_distance = np.max(np.sqrt(np.sum(abs(points)**2,axis=-1)))\n",
    "    points /= furthest_distance\n",
    "\n",
    "    return points, furthest_distance\n",
    "    \n",
    "def make_pe_encoding(i_pos=8, embed_dim = 8, scale = 10, cast_type=torch.float32):\n",
    "    #positional encoding of node\n",
    "    i_array = np.arange(1,(embed_dim/2)+1)\n",
    "    wk = (1/(scale**(i_array*2/embed_dim)))\n",
    "    t_array = np.arange(i_pos)\n",
    "    si = torch.tensor(np.sin(wk*t_array.reshape((-1,1))))\n",
    "    ci = torch.tensor(np.cos(wk*t_array.reshape((-1,1))))\n",
    "    pe = torch.stack((si,ci),axis=2).reshape(t_array.shape[0],embed_dim).type(cast_type)\n",
    "    return pe\n",
    "\n",
    "\n",
    "def make_graph_struct(batch_size=32, n_nodes = 8):\n",
    "    # make a fake graph to be filled with generator outputs\n",
    "    \n",
    "    v1 = np.arange(n_nodes-1) #vertex 1 of edges in chronological order\n",
    "    v2 = np.arange(1,n_nodes) #vertex 2 of edges in chronological order\n",
    "\n",
    "    ss = np.zeros(len(v1),dtype=np.int32)\n",
    "    ss[np.arange(ss.shape[0])%2==0]=1  #alternate 0,1 for helix, loop, helix, etc\n",
    "    ss = ss[:,None] #unsqueeze\n",
    "    \n",
    "    pe = make_pe_encoding(i_pos=8, embed_dim = 8, scale = 10, cast_type=torch.float32)\n",
    "\n",
    "    graphList = []\n",
    "    for i in range(batch_size):\n",
    "        g = dgl.graph((v1,v2))\n",
    "        g.edata['ss'] = torch.tensor(ss,dtype=torch.float32)\n",
    "        g.ndata['pe'] = pe\n",
    "\n",
    "        graphList.append(g)\n",
    "\n",
    "    batched_graph = dgl.batch(graphList)\n",
    "\n",
    "    return batched_graph\n",
    "\n",
    "\n",
    "class GraphDataset(Dataset):\n",
    "    def __init__(self, ep_file : pathlib.Path, limit=1000):\n",
    "        self.data_path = ep_file\n",
    "        rr = np.load(self.data_path)\n",
    "        ep = [rr[f] for f in rr.files][0][:1000]\n",
    "        \n",
    "        #need to save furthest distance to regen later\n",
    "        #maybe consider small change for next steps\n",
    "        ep, self.furthest_distance = normalize_pc(ep.reshape((-1,3)))\n",
    "        self.ep = ep.reshape((-1,8,3))\n",
    "        \n",
    "        \n",
    "        v1 = np.arange(self.ep.shape[1]-1) #vertex 1 of edges in chronological order\n",
    "        v2 = np.arange(1,self.ep.shape[1]) #vertex 2 of edges in chronological order\n",
    "\n",
    "        ss = np.zeros(len(v1))\n",
    "        ss[np.arange(ss.shape[0])%2==0]=1  #alternate 0,1 for helix, loop, helix, etc\n",
    "        ss = ss[:,None] #unsqueeze\n",
    "\n",
    "        #positional encoding of node\n",
    "        pe = make_pe_encoding(i_pos=8, embed_dim = 8, scale = 10, cast_type=torch.float32)\n",
    "\n",
    "        graphList = []\n",
    "\n",
    "        for i,c in enumerate(self.ep):\n",
    "\n",
    "            g = dgl.graph((v1,v2))\n",
    "            g.ndata['pos'] = torch.tensor(c,dtype=torch.float32)\n",
    "            g.edata['ss'] = torch.tensor(ss,dtype=torch.float32)\n",
    "            g.ndata['pe'] = pe\n",
    "\n",
    "            graphList.append(g)\n",
    "        \n",
    "        self.graphList = graphList\n",
    "\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.graphList)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        return self.graphList[idx]\n",
    "\n",
    "    \n",
    "class HGenDataModule():\n",
    "    \"\"\"\n",
    "    Datamodule wrapping hGen data set. 8 Helical endpoints defining a four helix protein.\n",
    "    \"\"\"\n",
    "    #8 long positional encoding\n",
    "    NODE_FEATURE_DIM = 8\n",
    "    EDGE_FEATURE_DIM = 1 # 0 or 1 helix or loop\n",
    "\n",
    "    def __init__(self,\n",
    "                 data_dir: pathlib.Path, batch_size=32):\n",
    "        \n",
    "        self.data_dir = data_dir \n",
    "        self.GraphDatasetObj = GraphDataset(self.data_dir)\n",
    "        self.gds = DataLoader(self.GraphDatasetObj,batch_size=batch_size, shuffle=True, drop_last=True,\n",
    "                              collate_fn=self._collate)\n",
    "        \n",
    "    \n",
    "        \n",
    "    def _collate(self, graphs):\n",
    "        batched_graph = dgl.batch(graphs)\n",
    "        #reshape that batched graph to redivide into the individual graphs\n",
    "        edge_feats = {'0': batched_graph.edata['ss'][:, :self.EDGE_FEATURE_DIM, None]}\n",
    "        batched_graph.edata['rel_pos'] = _get_relative_pos(batched_graph)\n",
    "        # get node features\n",
    "        node_feats = {'0': batched_graph.ndata['pe'][:, :self.NODE_FEATURE_DIM, None]}\n",
    "        \n",
    "        return (batched_graph, node_feats, edge_feats)\n",
    "    \n",
    "def eval_gen(batch_size=8,z=12):\n",
    "    \n",
    "    in_z = torch.randn((batch_size,z), device='cuda',dtype = torch.float32)\n",
    "    out = hg(in_z)*31\n",
    "    out = out.reshape((-1,8,3)).detach().cpu().numpy()\n",
    "    \n",
    "    return eval_endpoints(out)\n",
    "    \n",
    "    \n",
    "\n",
    "def eval_endpoints(ep_in): \n",
    "    \n",
    "    ep = ep_in.reshape((-1,8,3))\n",
    "\n",
    "    v1 = np.arange(ep.shape[1]-1) #vertex 1 of edges in chronological order\n",
    "    v2 = np.arange(1,ep.shape[1]) #vertex 2 of edges in chronological order\n",
    "\n",
    "    hLL = np.linalg.norm(ep[:,v1]-ep[:,v2],axis=2)\n",
    "\n",
    "    hLoc = np.array([0,2,4,6])\n",
    "    lLoc = np.array([1,3,5])\n",
    "\n",
    "    return np.mean(hLL[:,hLoc]), np.mean(hLL[:,lLoc])\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "id": "4079c5b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "class UnpoolDep(torch.nn.Module):\n",
    "    \"\"\"\n",
    "    Place features into torch.zeros array\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "\n",
    "    def forward(self, features: Dict[str, Tensor], graph: DGLGraph, idx: Tensor, u_features: Dict[str, Tensor]):\n",
    "        idx_count = 0\n",
    "        out_feats = {}\n",
    "        for key,val in features.items():\n",
    "            new_h = val.new_zeros([graph.num_nodes(), val.shape[1], 1])\n",
    "            pad = val.new_zeros([graph.num_nodes(), new_h.shape[1]-u_features[key].shape[1],1])\n",
    "            out_feats[key] = torch.add(F.scatter_row(new_h,idx[idx_count],val),torch.cat((u_features[key],pad),1))\n",
    "            idx_count +=1\n",
    "        return out_feats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "210427a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Graph_4H_Dataset(Dataset):\n",
    "    def __init__(self, ca_coordinates, limit=1000, cast_type=torch.float32):\n",
    "        \n",
    "        self.ca_coords = ca_coordinates\n",
    "        self.norm_ca = normalize_points(ca_coordinates)\n",
    "        \n",
    "        n_nodes = self.ca_coords.shape[1] \n",
    "        \n",
    "        v1,v2,edge_data, ind = define_graph_edges(n_nodes)\n",
    "        pe = make_pe_encoding(n_nodes=n_nodes)\n",
    "\n",
    "        graphList = []\n",
    "\n",
    "        for i,c in enumerate(self.norm_ca):\n",
    "\n",
    "            g = dgl.graph((v1,v2))\n",
    "            g.edata['con'] = edge_data.type(cast_type).reshape((-1,1))\n",
    "            g.ndata['pe'] = pe\n",
    "            g.ndata['pos'] = torch.tensor(c,dtype=torch.float32)\n",
    "\n",
    "            graphList.append(g)\n",
    "        \n",
    "        self.graphList = graphList\n",
    "\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.graphList)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        return self.graphList[idx]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "se33",
   "language": "python",
   "name": "se33"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
