{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a02a1c0f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "import pathlib\n",
    "import dgl\n",
    "from dgl import backend as F\n",
    "import torch_geometric\n",
    "from torch.utils.data import random_split, DataLoader, Dataset\n",
    "from typing import Dict\n",
    "from torch import Tensor\n",
    "from dgl import DGLGraph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0cd0b9f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "#?torch_geometric.nn.pool.ASAPooling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "bf443f63",
   "metadata": {},
   "outputs": [],
   "source": [
    "from se3_transformer.model.basis import get_basis, update_basis_with_fused\n",
    "from se3_transformer.model.transformer import Sequential\n",
    "from se3_transformer.model.layers.attentiontopK import AttentionBlockSE3\n",
    "from se3_transformer.model.layers.linear import LinearSE3\n",
    "from se3_transformer.model.layers.convolution import ConvSE3, ConvSE3FuseLevel\n",
    "from se3_transformer.model.layers.norm import NormSE3\n",
    "from se3_transformer.model.layers.pooling import GPooling\n",
    "from se3_transformer.runtime.utils import str2bool, to_cuda\n",
    "from se3_transformer.model.fiber import Fiber\n",
    "from se3_transformer.model.transformer import get_populated_edge_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a687357b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.cuda.is_available()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e213e885",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(128, 65, 3)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_path_str  = 'data/h4_ca_coords.npz'\n",
    "test_limit = 128\n",
    "rr = np.load(data_path_str)\n",
    "ca_coords = [rr[f] for f in rr.files][0][:test_limit,:,:3]\n",
    "ca_coords.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "508327fa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "largest distance 32.8\n",
      "tensor([0., 1., 0., 1., 0., 1., 0., 1., 0., 1., 0., 1.])\n",
      "tensor([0.6000, 0.8000, 0.4000, 0.9000, 0.3000, 1.0000, 0.2000, 1.0000, 0.1000,\n",
      "        1.0000, 0.1000, 1.0000])\n",
      "tensor([1.0000, 0.2000, 0.8000, 0.6000, 0.6000, 0.8000, 0.4000, 0.9000, 0.3000,\n",
      "        1.0000, 0.2000, 1.0000])\n",
      "tensor([ 0.9000, -0.5000,  1.0000,  0.2000,  0.8000,  0.6000,  0.6000,  0.8000,\n",
      "         0.4000,  0.9000,  0.3000,  1.0000])\n",
      "tensor([ 0.4000, -0.9000,  1.0000, -0.3000,  1.0000,  0.3000,  0.8000,  0.7000,\n",
      "         0.6000,  0.8000,  0.4000,  0.9000])\n"
     ]
    }
   ],
   "source": [
    "#goal define edges of\n",
    "#connected backbone 1, \n",
    "#unconnected atoms 0,\n",
    "\n",
    "\n",
    "def get_midpoint(ep_in):\n",
    "    \"\"\"Get midpoint, of each batched set of points\"\"\"\n",
    "    \n",
    "    #calculate midpoint\n",
    "    midpoint = ep_in.sum(axis=1)/np.repeat(ep_in.shape[1], ep_in.shape[2])\n",
    "    \n",
    "    return midpoint\n",
    "\n",
    "\n",
    "def normalize_points(input_xyz, print_dist=False):\n",
    "    \n",
    "    #broadcast to distance matrix [Batch, M, R3] to [Batch,M,1, R3] to [Batch,1,M, R3] to [Batch, M,M, R3] \n",
    "    vec_diff = input_xyz[...,None,:]-input_xyz[...,None,:,:]\n",
    "    dist = np.sqrt(np.sum(np.square(vec_diff),axis=len(input_xyz.shape)))\n",
    "    furthest_dist = np.max(dist)\n",
    "    centroid  = get_midpoint(input_xyz)\n",
    "    if print_dist:\n",
    "        print(f'largest distance {furthest_dist:0.1f}')\n",
    "    \n",
    "    xyz_mean_zero = input_xyz - centroid[:,None,:]\n",
    "    return xyz_mean_zero/furthest_dist\n",
    "\n",
    "\n",
    "\n",
    "def define_graph_edges(n_nodes):\n",
    "    #connected backbone\n",
    "\n",
    "    con_v1 = np.arange(n_nodes-1) #vertex 1 of edges in chronological order\n",
    "    con_v2 = np.arange(1,n_nodes) #vertex 2 of edges in chronological order\n",
    "\n",
    "    ind = con_v1*(n_nodes-1)+con_v2-1 #account for removed self connections (-1)\n",
    "\n",
    "\n",
    "    #unconnected backbone\n",
    "\n",
    "    nodes = np.arange(n_nodes)\n",
    "    v1 = np.repeat(nodes,n_nodes-1) #starting vertices, same number repeated for each edge\n",
    "\n",
    "    start_v2 = np.repeat(np.arange(n_nodes)[None,:],n_nodes,axis=0)\n",
    "    diag_ind = np.diag_indices(n_nodes)\n",
    "    start_v2[diag_ind] = -1 #diagonal of matrix is self connections which we remove (self connections are managed elsewhere)\n",
    "    v2 = start_v2[start_v2>-0.5] #remove diagonal and flatten\n",
    "\n",
    "    edge_data = torch.zeros(len(v2))\n",
    "    edge_data[ind] = 1\n",
    "    \n",
    "    return v1,v2,edge_data, ind\n",
    "\n",
    "def make_pe_encoding(n_nodes=65, embed_dim = 12, scale = 1000, cast_type=torch.float32, print_out=False):\n",
    "    #positional encoding of node\n",
    "    i_array = np.arange(1,(embed_dim/2)+1)\n",
    "    wk = (1/(scale**(i_array*2/embed_dim)))\n",
    "    t_array = np.arange(n_nodes)\n",
    "    si = torch.tensor(np.sin(wk*t_array.reshape((-1,1))))\n",
    "    ci = torch.tensor(np.cos(wk*t_array.reshape((-1,1))))\n",
    "    pe = torch.stack((si,ci),axis=2).reshape(t_array.shape[0],embed_dim).type(cast_type)\n",
    "    \n",
    "    if print_out == True:\n",
    "        for x in range(int(n_nodes/12)):\n",
    "            print(np.round(pe[x],1))\n",
    "    \n",
    "    return pe\n",
    "    \n",
    "    \n",
    "#v1,v2,edge_data, ind = define_graph_edges(n_nodes)\n",
    "norm_p = normalize_points(ca_coords,print_dist=True)\n",
    "pe = make_pe_encoding(n_nodes=65, embed_dim = 12, scale = 10, print_out=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "d9979efa",
   "metadata": {},
   "outputs": [],
   "source": [
    "#v1,v2,edge_data, ind = define_graph_edges(4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "321dc5e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "#?dgl.nn.pytorch.KNNGraph, nearest neighbor graph maker\n",
    "def define_graph(batch_size=8,n_nodes=65):\n",
    "    \n",
    "    v1,v2,edge_data, ind = define_graph_edges(n_nodes)\n",
    "    pe = make_pe_encoding(n_nodes=65)\n",
    "    \n",
    "    graphList = []\n",
    "    \n",
    "    for i in range(batch_size):\n",
    "        \n",
    "        g = dgl.graph((v1,v2))\n",
    "        g.edata['con'] = edge_data\n",
    "        g.ndata['pe'] = pe\n",
    "\n",
    "        graphList.append(g)\n",
    "        \n",
    "    batched_graph = dgl.batch(graphList)\n",
    "\n",
    "    return batched_graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "5cc4e2ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Graph_4H_Dataset(Dataset):\n",
    "    def __init__(self, ca_coordinates, limit=1000, cast_type=torch.float32):\n",
    "        \n",
    "        self.ca_coords = ca_coordinates\n",
    "        self.norm_ca = normalize_points(ca_coordinates)\n",
    "        \n",
    "        n_nodes = self.ca_coords.shape[1] \n",
    "        \n",
    "        v1,v2,edge_data, ind = define_graph_edges(n_nodes)\n",
    "        pe = make_pe_encoding(n_nodes=n_nodes)\n",
    "\n",
    "        graphList = []\n",
    "\n",
    "        for i,c in enumerate(self.norm_ca):\n",
    "\n",
    "            g = dgl.graph((v1,v2))\n",
    "            g.edata['con'] = edge_data.type(cast_type).reshape((-1,1))\n",
    "            g.ndata['pe'] = pe\n",
    "            g.ndata['pos'] = torch.tensor(c,dtype=torch.float32)\n",
    "\n",
    "            graphList.append(g)\n",
    "        \n",
    "        self.graphList = graphList\n",
    "\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.graphList)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        return self.graphList[idx]\n",
    "\n",
    "def _get_relative_pos(graph_in: dgl.DGLGraph) -> torch.Tensor:\n",
    "    x = graph_in.ndata['pos']\n",
    "    src, dst = graph_in.edges()\n",
    "    rel_pos = x[dst] - x[src]\n",
    "    return rel_pos\n",
    "    \n",
    "#needs to be done\n",
    "class H4_DataModule():\n",
    "    \"\"\"\n",
    "    Datamodule wrapping hGen data set. 8 Helical endpoints defining a four helix protein.\n",
    "    \"\"\"\n",
    "    #8 long positional encoding\n",
    "    NODE_FEATURE_DIM = 12\n",
    "    EDGE_FEATURE_DIM = 1 # 0 or 1 helix or loop\n",
    "\n",
    "    def __init__(self,\n",
    "                 ca_coords: np.array, batch_size=8):\n",
    "        \n",
    "        self.GraphDatasetObj = Graph_4H_Dataset(ca_coords)\n",
    "        self.gds = DataLoader(self.GraphDatasetObj, batch_size=batch_size, shuffle=True, drop_last=True,\n",
    "                              collate_fn=self._collate)\n",
    "        \n",
    "    \n",
    "        \n",
    "    def _collate(self, graphs):\n",
    "        batched_graph = dgl.batch(graphs)\n",
    "        #reshape that batched graph to redivide into the individual graphs\n",
    "        edge_feats = {'0': batched_graph.edata['con'][:, :self.EDGE_FEATURE_DIM, None]}\n",
    "        batched_graph.edata['rel_pos'] = _get_relative_pos(batched_graph)\n",
    "        # get node features\n",
    "        node_feats = {'0': batched_graph.ndata['pe'][:, :self.NODE_FEATURE_DIM, None]}\n",
    "        \n",
    "        return (batched_graph, node_feats, edge_feats)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "d1e5744a",
   "metadata": {},
   "outputs": [],
   "source": [
    "dm = H4_DataModule(ca_coords)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "d86c1e74",
   "metadata": {},
   "outputs": [],
   "source": [
    "n_nodes = 65\n",
    "NODE_FEATURE_DIM = 12\n",
    "EDGE_FEATURE_DIM = 1 # probably expand to [2] one hot primary connect \n",
    "num_degrees = 4 # how many levels of spherical harmonics to use\n",
    "num_channels = 8 # how many\n",
    "num_heads = 4\n",
    "channels_div = 2\n",
    "max_degree = 4\n",
    "\n",
    "use_layer_norm = False\n",
    "fuse_level = ConvSE3FuseLevel.NONE\n",
    "\n",
    "\n",
    "fiber_in=Fiber({0: NODE_FEATURE_DIM})\n",
    "fiber_hidden=Fiber({0: num_degrees * num_channels})\n",
    "fiber_edge=Fiber({0: EDGE_FEATURE_DIM})\n",
    "fiber_out = Fiber({0: num_degrees * num_channels}) # can this be arbitrary, or projected"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "982dfb24",
   "metadata": {},
   "outputs": [],
   "source": [
    "ablock = AttentionBlockSE3(fiber_in=fiber_in,\n",
    "               fiber_out=fiber_hidden,\n",
    "               fiber_edge=fiber_edge,\n",
    "               num_heads=num_heads,\n",
    "               channels_div=channels_div,\n",
    "               use_layer_norm=use_layer_norm,\n",
    "               max_degree=max_degree,\n",
    "               fuse_level=fuse_level,\n",
    "               low_memory='True')\n",
    "acuda = ablock.to('cuda')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "533778b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def topK_se3(graph, feat, xi, k):\n",
    "    #remove this read from graph code, since se3 transformer natively uses pulled out feats from graph\n",
    "    # READOUT_ON_ATTRS = {\n",
    "    #     \"nodes\": (\"ndata\", \"batch_num_nodes\", \"number_of_nodes\"),\n",
    "    #     \"edges\": (\"edata\", \"batch_num_edges\", \"number_of_edges\"),\n",
    "    # }\n",
    "    # _, batch_num_objs_attr, _ = READOUT_ON_ATTRS[\"nodes\"]\n",
    "\n",
    "    # #this is a fancy way of saying 'batch_num_nodes\n",
    "    # data = getattr(bg, \"nodes\")[None].data\n",
    "    # if F.ndim(data[feat]) > 2:\n",
    "    #     raise DGLError(\n",
    "    #         \"Only support {} feature `{}` with dimension less than or\"\n",
    "    #         \" equal to 2\".format(typestr, feat)\n",
    "    #     )\n",
    "    # feat = data[feat]\n",
    "\n",
    "\n",
    "    hidden_size = feat.shape[-1]\n",
    "    batch_num_objs = getattr(bg, 'batch_num_nodes')(None)\n",
    "    batch_size = len(batch_num_objs)\n",
    "    descending = True\n",
    "\n",
    "    length = max(max(F.asnumpy(batch_num_objs)), k) #max k or batch of nodes size\n",
    "    fill_val = -float(\"inf\") if descending else float(\"inf\")\n",
    "    \n",
    "    feat_y = F.pad_packed_tensor(\n",
    "        feat, batch_num_objs, fill_val, l_min=k\n",
    "    )  # (batch_size, l, d)\n",
    "\n",
    "    order = F.argsort(feat_y, 1, descending=descending)\n",
    "    topk_indices = F.slice_axis(order, 1, 0, k)\n",
    "\n",
    "    #get batch shifts\n",
    "    feat_ = F.reshape(feat_y, (-1,))\n",
    "    shift = F.repeat(\n",
    "        F.arange(0, batch_size), k * hidden_size, -1\n",
    "    ) * length * hidden_size + F.cat(\n",
    "        [F.arange(0, hidden_size)] * batch_size * k, -1\n",
    "    )\n",
    "    \n",
    "    shift = F.copy_to(shift, F.context(feat))\n",
    "    topk_indices_ = F.reshape(topk_indices, (-1,)) * hidden_size + shift\n",
    "    #trainable params gather\n",
    "    out_y = F.reshape(F.gather_row(feat_, topk_indices_), (batch_size*k, -1))\n",
    "    out_y = F.replace_inf_with_zero(out_y)\n",
    "    #nodes features gather\n",
    "    out_xi = F.reshape(F.gather_row(xi, topk_indices_), (batch_size*k, -1))\n",
    "    out_xi = F.replace_inf_with_zero(out_xi)\n",
    "    return out_y, out_xi, topk_indices_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "9b3dbf7d",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "class TopK_Pool(torch.nn.Module):\n",
    "    \"\"\"\n",
    "    https://arxiv.org/pdf/1905.05178.pdf\n",
    "    Project Node Features to 1D for topK pooling using trainable weights\n",
    "    Only type '0' features coded, would need to mix features between degrees, avoiding this for now\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, fiber_in: Fiber, k=5):\n",
    "        super().__init__()\n",
    "        self.k = k\n",
    "        fiber_out = Fiber({0: 1}) #convert to 1D of nodes\n",
    "        self.weights = torch.nn.ParameterDict({\n",
    "            str(degree_out): torch.nn.Parameter(\n",
    "                torch.randn(channels_out, fiber_in[degree_out]) / np.sqrt(fiber_in[degree_out]))\n",
    "            for degree_out, channels_out in fiber_out\n",
    "        })\n",
    "        \n",
    "\n",
    "\n",
    "    def forward(self, features: Dict[str, Tensor], graph: DGLGraph) -> Dict[str, Tensor]:\n",
    "        #add topK selection, sigmoid, return nodes\n",
    "        yi = {\n",
    "            degree: torch.div(self.weights[degree] @ features[degree], self.weights[degree].norm())\n",
    "            for degree, weight in self.weights.items()\n",
    "        }\n",
    "        \n",
    "        y_selected, feats_selected, topk_indices_batched = topK_se3(graph, yi['0'], features['0'], self.k)\n",
    "        return torch.sigmoid(y_selected)*feats_selected, topk_indices_batched\n",
    "        \n",
    "        \n",
    "        \n",
    "        \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "3dce2b66",
   "metadata": {},
   "outputs": [],
   "source": [
    "tk = TopK_Pool(fiber_hidden)\n",
    "tk_cuda = tk.to('cuda')\n",
    "# tblock = [ablock,tk]\n",
    "# model = Sequential(*tblock)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "055cf9c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i, inp in enumerate(dm.gds):\n",
    "    batched_graph, node_feats, edge_feats = inp\n",
    "    break\n",
    "    \n",
    "bg = to_cuda(batched_graph)\n",
    "edge_feats = to_cuda(edge_feats)\n",
    "node_feats = to_cuda(node_feats)\n",
    "\n",
    "basis = get_basis(bg.edata['rel_pos'], max_degree=max_degree,\n",
    "                                   compute_gradients=False,\n",
    "                                   use_pad_trick=False)\n",
    "#concatenate on the distances of the edge based on 'rel pos'\n",
    "edge_feats_cat = get_populated_edge_features(bg.edata['rel_pos'], edge_feats)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "7c373348",
   "metadata": {},
   "outputs": [],
   "source": [
    "out = acuda.forward(node_feats, edge_feats_cat,graph=bg,basis=basis)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "9e1a32ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "out, inde= tk.forward(out, bg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "1f97447d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([40, 32])"
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "out.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "87d584a7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([40, 32])"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "kc.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "d42092f6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([40, 32])"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(kc*torch.sigmoid(yi)).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "25bbbebf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([40])"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "m.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "6cb8b5f1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([40])"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "k.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "4edb55cd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([520, 32, 1])"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "out['0'].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "dff129c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "out_y, out_xi, topk_indices_ = topK_se3(bg, yi['0'], out['0'], k)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "8ef70c36",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([8, 65, 32, 1])"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "feat_xi.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "8e74cffa",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([ 54,  53,  11,  12,  55, 119, 118,  76,  77, 120, 184, 183, 141, 185,\n",
       "        142, 249, 248, 206, 250, 207, 314, 313, 271, 315, 272, 379, 378, 336,\n",
       "        337, 380, 444, 443, 401, 445, 402, 509, 508, 466, 467, 510],\n",
       "       device='cuda:0')"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "topk_indices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "2ff3abe8",
   "metadata": {},
   "outputs": [],
   "source": [
    "feat = yi['0']\n",
    "hidden_size = feat.shape[-1]\n",
    "xi = out['0']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "2db8ba75",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([65, 65, 65, 65, 65, 65, 65, 65], device='cuda:0')"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "batch_num_objs = getattr(bg, 'batch_num_nodes')(None)\n",
    "batch_num_objs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "3cb26026",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "8"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "batch_size = len(batch_num_objs)\n",
    "batch_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "5e8bdfd3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "65"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "max(max(F.asnumpy(batch_num_objs)),k)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "a46f2552",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "65"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "length = max(max(F.asnumpy(batch_num_objs)), k)\n",
    "length"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "b4c7b226",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-inf"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "descending = True\n",
    "fill_val = -float(\"inf\") if descending else float(\"inf\")\n",
    "fill_val"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "c997bc67",
   "metadata": {},
   "outputs": [],
   "source": [
    "feat_y = F.pad_packed_tensor(\n",
    "        feat, batch_num_objs, fill_val, l_min=k\n",
    "    )  # (batch_size, l, d)\n",
    "feat_xi = F.pad_packed_tensor(\n",
    "        xi, batch_num_objs, fill_val, l_min=k\n",
    "    )  # (batch_size, l, d)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "acff9d4b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([8, 65, 32, 1])"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "feat_xi.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "c7ed6fc3",
   "metadata": {},
   "outputs": [],
   "source": [
    "order = F.argsort(feat_y, 1, descending=descending)\n",
    "topk_indices = F.slice_axis(order, 1, 0, k)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "0f0a2bf5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[[12]],\n",
       "\n",
       "         [[11]],\n",
       "\n",
       "         [[13]],\n",
       "\n",
       "         [[10]],\n",
       "\n",
       "         [[14]]],\n",
       "\n",
       "\n",
       "        [[[12]],\n",
       "\n",
       "         [[11]],\n",
       "\n",
       "         [[13]],\n",
       "\n",
       "         [[10]],\n",
       "\n",
       "         [[14]]],\n",
       "\n",
       "\n",
       "        [[[12]],\n",
       "\n",
       "         [[11]],\n",
       "\n",
       "         [[13]],\n",
       "\n",
       "         [[10]],\n",
       "\n",
       "         [[14]]],\n",
       "\n",
       "\n",
       "        [[[12]],\n",
       "\n",
       "         [[11]],\n",
       "\n",
       "         [[13]],\n",
       "\n",
       "         [[10]],\n",
       "\n",
       "         [[14]]],\n",
       "\n",
       "\n",
       "        [[[12]],\n",
       "\n",
       "         [[11]],\n",
       "\n",
       "         [[13]],\n",
       "\n",
       "         [[10]],\n",
       "\n",
       "         [[14]]],\n",
       "\n",
       "\n",
       "        [[[12]],\n",
       "\n",
       "         [[11]],\n",
       "\n",
       "         [[13]],\n",
       "\n",
       "         [[10]],\n",
       "\n",
       "         [[14]]],\n",
       "\n",
       "\n",
       "        [[[12]],\n",
       "\n",
       "         [[11]],\n",
       "\n",
       "         [[13]],\n",
       "\n",
       "         [[10]],\n",
       "\n",
       "         [[14]]],\n",
       "\n",
       "\n",
       "        [[[12]],\n",
       "\n",
       "         [[11]],\n",
       "\n",
       "         [[13]],\n",
       "\n",
       "         [[10]],\n",
       "\n",
       "         [[14]]]], device='cuda:0')"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "topk_indices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "a807b641",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([520])"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "feat_ = F.reshape(feat_y, (-1,))\n",
    "feat_.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "id": "924502ef",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(32, device='cuda:0')"
      ]
     },
     "execution_count": 108,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    " hidden_size_xi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "id": "3c798790",
   "metadata": {},
   "outputs": [],
   "source": [
    "shift = F.repeat(\n",
    "        F.arange(0, batch_size), k * hidden_size, -1\n",
    "    ) * length * hidden_size + F.cat(\n",
    "        [F.arange(0, hidden_size)] * batch_size * k, -1\n",
    "    )\n",
    "shift = F.copy_to(shift, F.context(feat))\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "id": "f887396d",
   "metadata": {},
   "outputs": [],
   "source": [
    "topk_indices_ = F.reshape(topk_indices, (-1,)) * hidden_size + shift"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "id": "f687d419",
   "metadata": {},
   "outputs": [],
   "source": [
    "out2 = F.reshape(F.gather_row(feat_2, topk_indices_), (batch_size, k, -1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9bfd39b",
   "metadata": {},
   "outputs": [],
   "source": [
    "hidden_size = feat.shape[-1]\n",
    "    batch_num_objs = getattr(bg, 'batch_num_nodes')(None)\n",
    "    batch_size = len(batch_num_objs)\n",
    "    descending = True\n",
    "\n",
    "    length = max(max(F.asnumpy(batch_num_objs)), k) #get maximum nodes in batch, or k\n",
    "    fill_val = -float(\"inf\") if descending else float(\"inf\")\n",
    "    feat_ = F.pad_packed_tensor(\n",
    "        feat, batch_num_objs, fill_val, l_min=k\n",
    "    )  # (batch_size, l, d)\n",
    "    \n",
    "    #use argsort to grab top nodes based on feat_ for each batch\n",
    "    order = F.argsort(feat_, 1, descending=descending)\n",
    "    topk_indices = F.slice_axis(order, 1, 0, k)\n",
    "\n",
    "\n",
    "    feat_ = F.reshape(feat_, (-1,))\n",
    "    #create batch based shift for each indices\n",
    "    shift = F.repeat(\n",
    "        F.arange(0, batch_size), k * hidden_size, -1\n",
    "    ) * length * hidden_size + F.cat(\n",
    "        [F.arange(0, hidden_size)] * batch_size * k, -1\n",
    "    )\n",
    "    #take new indi\n",
    "    shift = F.copy_to(shift, F.context(feat))\n",
    "    #use batch shift and hidden size to get the approriate indices\n",
    "    topk_indices_ = F.reshape(topk_indices, (-1,)) * hidden_size + shift\n",
    "\n",
    "    out = F.reshape(F.gather_row(feat_, topk_indices_), (batch_size, k, -1))\n",
    "    out = F.replace_inf_with_zero(out)\n",
    "    return out, topk_indices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f1cfa0f",
   "metadata": {},
   "outputs": [],
   "source": [
    "out = F.reshape(F.gather_row(feat_, topk_indices_), (batch_size, k, -1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "id": "63b2a03e",
   "metadata": {},
   "outputs": [],
   "source": [
    "?F.gather_row"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "id": "86d29207",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([520, 32])"
      ]
     },
     "execution_count": 144,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "feat_2 = out['0'].squeeze()\n",
    "feat_2.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "id": "d1e72377",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([  0,   1,   2,   3,   4,  65,  66,  67,  68,  69, 130, 131, 132, 133,\n",
       "        134, 195, 196, 197, 198, 199, 260, 261, 262, 263, 264, 325, 326, 327,\n",
       "        328, 329, 390, 391, 392, 393, 394, 455, 456, 457, 458, 459],\n",
       "       device='cuda:0')"
      ]
     },
     "execution_count": 147,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "topk_indices_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "id": "90bef7b9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([40, 32])"
      ]
     },
     "execution_count": 149,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "F.gather_row(feat_2, topk_indices_).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "88c09a14",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[48, 49, 47, 50, 46],\n",
       "        [48, 49, 47, 50, 46],\n",
       "        [48, 49, 47, 50, 46],\n",
       "        [48, 49, 47, 50, 46],\n",
       "        [48, 49, 47, 50, 46],\n",
       "        [48, 49, 47, 50, 46],\n",
       "        [48, 49, 47, 50, 46],\n",
       "        [48, 49, 47, 50, 46]], device='cuda:0')"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "topkInd.squeeze()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "859a4cde",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "id": "840d0090",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = model.to('cuda')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "id": "dd845040",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "id": "9b649de7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "id": "cab2b17a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "id": "c024742c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "id": "553b6af2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([33280, 1, 1])"
      ]
     },
     "execution_count": 119,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "edge_feats['0'].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "id": "631e90ee",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1.0000],\n",
       "        [0.1159]], device='cuda:0')"
      ]
     },
     "execution_count": 120,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "edge_feats_cat['0'][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "id": "3f8bd386",
   "metadata": {},
   "outputs": [],
   "source": [
    "acuda.forward(node_feats, edge_feats_cat,graph=bg,basis=basis)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "id": "b0b884f2",
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "forward() got multiple values for argument 'graph'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[122], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m fib \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[43m(\u001b[49m\u001b[43mnode_feats\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43medge_feats_cat\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgraph\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbg\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbasis\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbasis\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mk\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m5\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/envs/se33/lib/python3.9/site-packages/torch/nn/modules/module.py:1501\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1496\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1497\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1498\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1499\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1500\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1501\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1502\u001b[0m \u001b[38;5;66;03m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1503\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[38;5;241m=\u001b[39m [], []\n",
      "File \u001b[0;32m/mnt/c/Users/nwood/OneDrive/Desktop/gudiff/se3_transformer/model/transformer.py:46\u001b[0m, in \u001b[0;36mSequential.forward\u001b[0;34m(self, input, *args, **kwargs)\u001b[0m\n\u001b[1;32m     44\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[1;32m     45\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m module \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m:\n\u001b[0;32m---> 46\u001b[0m         \u001b[38;5;28minput\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[43mmodule\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     47\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28minput\u001b[39m\n",
      "File \u001b[0;32m~/miniconda3/envs/se33/lib/python3.9/site-packages/torch/nn/modules/module.py:1501\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1496\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1497\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1498\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1499\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1500\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1501\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1502\u001b[0m \u001b[38;5;66;03m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1503\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[38;5;241m=\u001b[39m [], []\n",
      "\u001b[0;31mTypeError\u001b[0m: forward() got multiple values for argument 'graph'"
     ]
    }
   ],
   "source": [
    "fib = model(node_feats, edge_feats_cat, graph=bg, basis=basis)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "8fc3311b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([520, 1, 1])"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fib['0'].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "599c911d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "65.0"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "520/8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2db825c6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8dc80622",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "id": "691e04d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "proj_z, z_concat, z, edge_w = fib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "id": "a560713d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([33280, 4, 1, 1])"
      ]
     },
     "execution_count": 112,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "edge_w.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "id": "a7006539",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([520, 16, 1])"
      ]
     },
     "execution_count": 113,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "z['0'].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "id": "03a08241",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([520, 28, 1])"
      ]
     },
     "execution_count": 114,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "z_concat['0'].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "id": "fe367209",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([520, 32, 1])"
      ]
     },
     "execution_count": 115,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "proj_z['0'].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "id": "c288e68c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([520, 32])"
      ]
     },
     "execution_count": 116,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "proj_z['0'].squeeze(-1).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "id": "0a737da8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "65.0"
      ]
     },
     "execution_count": 117,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "520/8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "id": "c663091f",
   "metadata": {},
   "outputs": [],
   "source": [
    "bg.ndata['h'] = proj_z['0'].squeeze(-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "id": "13e78ca8",
   "metadata": {},
   "outputs": [],
   "source": [
    "?dgl.topk_nodes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "id": "fa4fa5b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "feat = proj_z['0'].squeeze(-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "id": "64c9cc9e",
   "metadata": {},
   "outputs": [],
   "source": [
    "feat[66][0] = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "id": "47104f8b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(10., device='cuda:0', grad_fn=<SelectBackward0>)"
      ]
     },
     "execution_count": 126,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "feat[66][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "id": "b7297935",
   "metadata": {},
   "outputs": [],
   "source": [
    "out, topk_indices = topK_se3(bg, feat, 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "id": "f71538ae",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[64, 12,  3,  ..., 47, 57, 39],\n",
       "         [63, 11,  4,  ..., 48, 56, 38],\n",
       "         [62, 13,  2,  ..., 46, 58, 40],\n",
       "         [61, 10,  5,  ..., 49, 55, 37],\n",
       "         [60, 14,  1,  ..., 45, 59, 41]],\n",
       "\n",
       "        [[ 1, 12,  3,  ..., 47, 57, 39],\n",
       "         [64, 11,  4,  ..., 48, 56, 38],\n",
       "         [63, 13,  2,  ..., 46, 58, 40],\n",
       "         [62, 10,  5,  ..., 49, 55, 37],\n",
       "         [61, 14,  1,  ..., 45, 59, 41]],\n",
       "\n",
       "        [[64, 12,  3,  ..., 47, 57, 39],\n",
       "         [63, 11,  4,  ..., 48, 56, 38],\n",
       "         [62, 13,  2,  ..., 46, 58, 40],\n",
       "         [61, 10,  5,  ..., 49, 55, 37],\n",
       "         [60, 14,  1,  ..., 45, 59, 41]],\n",
       "\n",
       "        ...,\n",
       "\n",
       "        [[64, 12,  3,  ..., 47, 57, 39],\n",
       "         [63, 11,  4,  ..., 48, 56, 38],\n",
       "         [62, 13,  2,  ..., 46, 58, 40],\n",
       "         [61, 10,  5,  ..., 49, 55, 37],\n",
       "         [60, 14,  1,  ..., 45, 59, 41]],\n",
       "\n",
       "        [[64, 12,  3,  ..., 47, 57, 39],\n",
       "         [63, 11,  4,  ..., 48, 56, 38],\n",
       "         [62, 13,  2,  ..., 46, 58, 40],\n",
       "         [61, 10,  5,  ..., 49, 55, 37],\n",
       "         [60, 14,  1,  ..., 45, 59, 41]],\n",
       "\n",
       "        [[64, 12,  3,  ..., 47, 57, 39],\n",
       "         [63, 11,  4,  ..., 48, 56, 38],\n",
       "         [62, 13,  2,  ..., 46, 58, 40],\n",
       "         [61, 10,  5,  ..., 49, 55, 37],\n",
       "         [60, 14,  1,  ..., 45, 59, 41]]], device='cuda:0')"
      ]
     },
     "execution_count": 128,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "topk_indices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "id": "cf967810",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([8, 5, 32])"
      ]
     },
     "execution_count": 105,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "topk_indices.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "b6a0d56c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#feat = proj_z['0'].squeeze(-1)\n",
    "def topK_se3(graph, feat, k):\n",
    "    #remove this read from graph code, since se3 transformer natively uses pulled out feats from graph\n",
    "    # READOUT_ON_ATTRS = {\n",
    "    #     \"nodes\": (\"ndata\", \"batch_num_nodes\", \"number_of_nodes\"),\n",
    "    #     \"edges\": (\"edata\", \"batch_num_edges\", \"number_of_edges\"),\n",
    "    # }\n",
    "    # _, batch_num_objs_attr, _ = READOUT_ON_ATTRS[\"nodes\"]\n",
    "\n",
    "    # #this is a fancy way of saying 'batch_num_nodes\n",
    "    # data = getattr(bg, \"nodes\")[None].data\n",
    "    # if F.ndim(data[feat]) > 2:\n",
    "    #     raise DGLError(\n",
    "    #         \"Only support {} feature `{}` with dimension less than or\"\n",
    "    #         \" equal to 2\".format(typestr, feat)\n",
    "    #     )\n",
    "    # feat = data[feat]\n",
    "\n",
    "\n",
    "    hidden_size = feat.shape[-1]\n",
    "    batch_num_objs = getattr(bg, 'batch_num_nodes')(None)\n",
    "    batch_size = len(batch_num_objs)\n",
    "    descending = True\n",
    "\n",
    "    length = max(max(F.asnumpy(batch_num_objs)), k)\n",
    "    fill_val = -float(\"inf\") if descending else float(\"inf\")\n",
    "    feat_ = F.pad_packed_tensor(\n",
    "        feat, batch_num_objs, fill_val, l_min=k\n",
    "    )  # (batch_size, l, d)\n",
    "    \n",
    "    order = F.argsort(feat_, 1, descending=descending)\n",
    "    topk_indices = F.slice_axis(order, 1, 0, k)\n",
    "\n",
    "\n",
    "    feat_ = F.reshape(feat_, (-1,))\n",
    "    shift = F.repeat(\n",
    "        F.arange(0, batch_size), k * hidden_size, -1\n",
    "    ) * length * hidden_size + F.cat(\n",
    "        [F.arange(0, hidden_size)] * batch_size * k, -1\n",
    "    )\n",
    "    shift = F.copy_to(shift, F.context(feat))\n",
    "    topk_indices_ = F.reshape(topk_indices, (-1,)) * hidden_size + shift\n",
    "    \n",
    "    out = F.reshape(F.gather_row(feat_, topk_indices_), (batch_size, k, -1))\n",
    "    out = F.replace_inf_with_zero(out)\n",
    "    return out, topk_indices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "1a961772",
   "metadata": {},
   "outputs": [],
   "source": [
    "?F.argsort"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "d4b46098",
   "metadata": {},
   "outputs": [],
   "source": [
    "order = F.argsort(feat_, 1, descending=descending)\n",
    "topk_indices = F.slice_axis(order, 1, 0, k)\n",
    "\n",
    "\n",
    "feat_ = F.reshape(feat_, (-1,))\n",
    "shift = F.repeat(\n",
    "    F.arange(0, batch_size), k * hidden_size, -1\n",
    ") * length * hidden_size + F.cat(\n",
    "    [F.arange(0, hidden_size)] * batch_size * k, -1\n",
    ")\n",
    "shift = F.copy_to(shift, F.context(feat))\n",
    "topk_indices_ = F.reshape(topk_indices, (-1,)) * hidden_size + shift"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "24ce7f74",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[64, 12,  3,  ..., 47, 57, 39],\n",
       "         [63, 11,  4,  ..., 48, 56, 38],\n",
       "         [62, 13,  2,  ..., 46, 58, 40],\n",
       "         ...,\n",
       "         [44,  8,  7,  ..., 51, 38,  1],\n",
       "         [59, 16,  8,  ..., 43, 39, 42],\n",
       "         [47, 17,  9,  ..., 52, 37, 35]],\n",
       "\n",
       "        [[64, 12,  3,  ..., 47, 57, 39],\n",
       "         [63, 11,  4,  ..., 48, 56, 38],\n",
       "         [62, 13,  2,  ..., 46, 58, 40],\n",
       "         ...,\n",
       "         [44,  8,  7,  ..., 51, 38,  1],\n",
       "         [59, 16,  8,  ..., 43, 53, 42],\n",
       "         [47, 17,  9,  ..., 52, 37, 35]],\n",
       "\n",
       "        [[64, 12,  3,  ..., 47, 57, 39],\n",
       "         [63, 11,  4,  ..., 48, 56, 38],\n",
       "         [62, 13,  2,  ..., 46, 58, 40],\n",
       "         ...,\n",
       "         [44,  8,  7,  ..., 51, 38,  1],\n",
       "         [59, 16,  8,  ..., 43, 37, 42],\n",
       "         [47, 17,  9,  ..., 52, 39, 35]],\n",
       "\n",
       "        ...,\n",
       "\n",
       "        [[64, 12,  3,  ..., 47, 57, 39],\n",
       "         [63, 11,  4,  ..., 48, 56, 38],\n",
       "         [62, 13,  2,  ..., 46, 58, 40],\n",
       "         ...,\n",
       "         [44,  8,  7,  ..., 51, 38,  1],\n",
       "         [59, 16,  8,  ..., 43, 37, 42],\n",
       "         [47, 17,  9,  ..., 52, 39, 35]],\n",
       "\n",
       "        [[64, 12,  3,  ..., 47, 57, 39],\n",
       "         [63, 11,  4,  ..., 48, 56, 38],\n",
       "         [62, 13,  2,  ..., 46, 58, 40],\n",
       "         ...,\n",
       "         [44,  8,  7,  ..., 51, 38,  1],\n",
       "         [59, 16,  8,  ..., 43, 39, 42],\n",
       "         [47, 17,  9,  ..., 52, 37, 35]],\n",
       "\n",
       "        [[64, 12,  3,  ..., 47, 57, 39],\n",
       "         [63, 11,  4,  ..., 48, 56, 38],\n",
       "         [62, 13,  2,  ..., 46, 58, 40],\n",
       "         ...,\n",
       "         [44,  8,  7,  ..., 51, 38,  1],\n",
       "         [59, 16,  8,  ..., 43, 37, 42],\n",
       "         [47, 17,  9,  ..., 52, 53, 35]]], device='cuda:0')"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "topk_indices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "460d730f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'pe': tensor([[ 0.0000e+00,  1.0000e+00,  0.0000e+00,  ...,  1.0000e+00,\n",
       "          0.0000e+00,  1.0000e+00],\n",
       "        [ 3.1098e-01,  9.5042e-01,  9.9833e-02,  ...,  9.9999e-01,\n",
       "          1.0000e-03,  1.0000e+00],\n",
       "        [ 5.9113e-01,  8.0658e-01,  1.9867e-01,  ...,  9.9998e-01,\n",
       "          2.0000e-03,  1.0000e+00],\n",
       "        ...,\n",
       "        [ 6.8643e-01,  7.2720e-01, -8.3089e-02,  ...,  9.8084e-01,\n",
       "          6.1960e-02,  9.9808e-01],\n",
       "        [ 8.7854e-01,  4.7767e-01,  1.6814e-02,  ...,  9.8022e-01,\n",
       "          6.2958e-02,  9.9802e-01],\n",
       "        [ 9.8352e-01,  1.8078e-01,  1.1655e-01,  ...,  9.7959e-01,\n",
       "          6.3956e-02,  9.9795e-01]], device='cuda:0'), 'pos': tensor([[-0.3364, -0.0208, -0.0076],\n",
       "        [-0.3327,  0.0943, -0.0212],\n",
       "        [-0.3273,  0.1009,  0.0944],\n",
       "        ...,\n",
       "        [-0.0216,  0.2502,  0.1192],\n",
       "        [-0.0466,  0.2097,  0.0135],\n",
       "        [-0.1549,  0.2505,  0.0062]], device='cuda:0'), 'h': tensor([[ 0.4256, -0.0988, -0.1517,  ...,  0.4718,  0.2854, -0.3482],\n",
       "        [ 0.4763, -0.1348, -0.1978,  ...,  0.5644,  0.1871, -0.2673],\n",
       "        [ 0.5266, -0.1723, -0.2136,  ...,  0.6521,  0.0878, -0.1612],\n",
       "        ...,\n",
       "        [ 0.6179, -0.2052,  0.1512,  ...,  0.5955, -0.3328,  0.3289],\n",
       "        [ 0.6469, -0.2336,  0.1692,  ...,  0.6434, -0.4108,  0.4553],\n",
       "        [ 0.6638, -0.2566,  0.2163,  ...,  0.6748, -0.4712,  0.5734]],\n",
       "       device='cuda:0', grad_fn=<SqueezeBackward1>)}"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15c86773",
   "metadata": {},
   "outputs": [],
   "source": [
    "#remake without pulling from graph?\n",
    "\n",
    "READOUT_ON_ATTRS = {\n",
    "    \"nodes\": (\"ndata\", \"batch_num_nodes\", \"number_of_nodes\"),\n",
    "    \"edges\": (\"edata\", \"batch_num_edges\", \"number_of_edges\"),\n",
    "}\n",
    "\n",
    "def _topk_on(graph, typestr, feat, k, descending, sortby, ntype_or_etype):\n",
    "    \"\"\"Internal function to take graph-wise top-k node/edge features of\n",
    "    field :attr:`feat` in :attr:`graph` ranked by keys at given\n",
    "    index :attr:`sortby`. If :attr:`descending` is set to False, return the\n",
    "    k smallest elements instead.\n",
    "\n",
    "    Parameters\n",
    "    ---------\n",
    "    graph : DGLGraph\n",
    "        The graph\n",
    "    typestr : str\n",
    "        'nodes' or 'edges'\n",
    "    feat : str\n",
    "        The feature field name.\n",
    "    k : int\n",
    "        The :math:`k` in \"top-:math`k`\".\n",
    "    descending : bool\n",
    "        Controls whether to return the largest or smallest elements,\n",
    "         defaults to True.\n",
    "    sortby : int\n",
    "        The key index we sort :attr:`feat` on, if set to None, we sort\n",
    "        the whole :attr:`feat`.\n",
    "    ntype_or_etype : str, tuple of str\n",
    "        Node/edge type.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    sorted_feat : Tensor\n",
    "        A tensor with shape :math:`(B, K, D)`, where\n",
    "        :math:`B` is the batch size of the input graph.\n",
    "    sorted_idx : Tensor\n",
    "        A tensor with shape :math:`(B, K)`(:math:`(B, K, D)` if sortby\n",
    "        is set to None), where\n",
    "        :math:`B` is the batch size of the input graph, :math:`D`\n",
    "        is the feature size.\n",
    "\n",
    "\n",
    "    Notes\n",
    "    -----\n",
    "    If an example has :math:`n` nodes/edges and :math:`n<k`, in the first\n",
    "    returned tensor the :math:`n+1` to :math:`k`th rows would be padded\n",
    "    with all zero; in the second returned tensor, the behavior of :math:`n+1`\n",
    "    to :math:`k`th elements is not defined.\n",
    "    \"\"\"\n",
    "    _, batch_num_objs_attr, _ = READOUT_ON_ATTRS[typestr]\n",
    "    data = getattr(graph, typestr)[ntype_or_etype].data\n",
    "    if F.ndim(data[feat]) > 2:\n",
    "        raise DGLError(\n",
    "            \"Only support {} feature `{}` with dimension less than or\"\n",
    "            \" equal to 2\".format(typestr, feat)\n",
    "        )\n",
    "    feat = data[feat]\n",
    "    hidden_size = F.shape(feat)[-1]\n",
    "    batch_num_objs = getattr(graph, batch_num_objs_attr)(ntype_or_etype)\n",
    "    batch_size = len(batch_num_objs)\n",
    "    length = max(max(F.asnumpy(batch_num_objs)), k)\n",
    "    fill_val = -float(\"inf\") if descending else float(\"inf\")\n",
    "    feat_ = F.pad_packed_tensor(\n",
    "        feat, batch_num_objs, fill_val, l_min=k\n",
    "    )  # (batch_size, l, d)\n",
    "\n",
    "    if F.backend_name == \"pytorch\" and sortby is not None:\n",
    "        # PyTorch's implementation of top-K\n",
    "        keys = feat_[..., sortby]  # (batch_size, l)\n",
    "        return _topk_torch(keys, k, descending, feat_)\n",
    "    else:\n",
    "        # Fallback to framework-agnostic implementation of top-K\n",
    "        if sortby is not None:\n",
    "            keys = F.squeeze(F.slice_axis(feat_, -1, sortby, sortby + 1), -1)\n",
    "            order = F.argsort(keys, -1, descending=descending)\n",
    "        else:\n",
    "            order = F.argsort(feat_, 1, descending=descending)\n",
    "        topk_indices = F.slice_axis(order, 1, 0, k)\n",
    "\n",
    "        if sortby is not None:\n",
    "            feat_ = F.reshape(feat_, (batch_size * length, -1))\n",
    "            shift = F.repeat(F.arange(0, batch_size) * length, k, -1)\n",
    "            shift = F.copy_to(shift, F.context(feat))\n",
    "            topk_indices_ = F.reshape(topk_indices, (-1,)) + shift\n",
    "        else:\n",
    "            feat_ = F.reshape(feat_, (-1,))\n",
    "            shift = F.repeat(\n",
    "                F.arange(0, batch_size), k * hidden_size, -1\n",
    "            ) * length * hidden_size + F.cat(\n",
    "                [F.arange(0, hidden_size)] * batch_size * k, -1\n",
    "            )\n",
    "            shift = F.copy_to(shift, F.context(feat))\n",
    "            topk_indices_ = F.reshape(topk_indices, (-1,)) * hidden_size + shift\n",
    "        out = F.reshape(F.gather_row(feat_, topk_indices_), (batch_size, k, -1))\n",
    "        out = F.replace_inf_with_zero(out)\n",
    "        return out, topk_indices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "4d4b0195",
   "metadata": {},
   "outputs": [],
   "source": [
    "for x in range(8):\n",
    "    for y in range(30):\n",
    "        if len(np.unique(sort_ind[x][:,y].cpu().numpy())) != 30:\n",
    "            print(False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "0c27f477",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 1.2111, -0.0900,  0.7318,  0.2344, -0.0669,  0.0927,  0.5824,  0.4390,\n",
       "          0.0690,  0.5615,  0.7202,  0.1591,  0.5839,  0.1566,  0.3246,  0.1450,\n",
       "          0.8620,  0.5528,  1.3103,  0.5718,  0.4452, -0.5404,  0.4007,  0.3480,\n",
       "          0.4214,  0.7397,  0.1821,  0.0995,  0.1473,  0.8472,  0.4826,  0.7203],\n",
       "        [ 1.2044, -0.0912,  0.7244,  0.2296, -0.1206,  0.0902,  0.5798,  0.4309,\n",
       "          0.0607,  0.5256,  0.7131,  0.1099,  0.5822,  0.1490,  0.3212,  0.1406,\n",
       "          0.8589,  0.5515,  1.3042,  0.5710,  0.4410, -0.5436,  0.3697,  0.3449,\n",
       "          0.4145,  0.7275,  0.1739,  0.0936,  0.1362,  0.8349,  0.4770,  0.7097],\n",
       "        [ 1.2012, -0.0977,  0.7028,  0.2276, -0.1264,  0.0872,  0.5759,  0.4240,\n",
       "          0.0556,  0.5194,  0.6933,  0.0538,  0.5749,  0.1320,  0.3177,  0.1326,\n",
       "          0.8483,  0.5320,  1.2934,  0.5513,  0.4327, -0.5531,  0.3374,  0.3360,\n",
       "          0.4096,  0.7245,  0.1727,  0.0884,  0.1138,  0.8332,  0.4558,  0.6915],\n",
       "        [ 1.1841, -0.0988,  0.6926,  0.2158, -0.1276,  0.0816,  0.5654,  0.3994,\n",
       "          0.0481,  0.5165,  0.6760,  0.0088,  0.5497,  0.1087,  0.3112,  0.1164,\n",
       "          0.8411,  0.5276,  1.2759,  0.5454,  0.4011, -0.5657,  0.3129,  0.3291,\n",
       "          0.3883,  0.6883,  0.1496,  0.0744,  0.0823,  0.8324,  0.4443,  0.6572],\n",
       "        [ 1.1757, -0.1016,  0.6879,  0.2071, -0.1334,  0.0805,  0.5621,  0.3876,\n",
       "          0.0469,  0.5091,  0.6333,  0.0045,  0.5085,  0.0788,  0.3016,  0.1011,\n",
       "          0.8172,  0.4893,  1.2559,  0.5111,  0.3874, -0.5815,  0.3119,  0.3125,\n",
       "          0.3805,  0.6783,  0.1490,  0.0630,  0.0374,  0.8213,  0.4017,  0.6260],\n",
       "        [ 1.1486, -0.1158,  0.6847,  0.1954, -0.1402,  0.0755,  0.5435,  0.3458,\n",
       "          0.0375,  0.5007,  0.6153,  0.0024,  0.4568,  0.0390,  0.2957,  0.0708,\n",
       "          0.8081,  0.4856,  1.2293,  0.5049,  0.3873, -0.6020,  0.3097,  0.3002,\n",
       "          0.3460,  0.6287,  0.1163,  0.0441, -0.0096,  0.8178,  0.3889,  0.5733],\n",
       "        [ 1.1418, -0.1215,  0.6688,  0.1718, -0.1445,  0.0564,  0.5380,  0.3345,\n",
       "          0.0218,  0.4898,  0.5426, -0.0097,  0.3950,  0.0026,  0.2817,  0.0544,\n",
       "          0.7738,  0.4322,  1.1982,  0.4570,  0.3731, -0.6247,  0.3056,  0.2565,\n",
       "          0.3367,  0.6271,  0.1090,  0.0252, -0.0101,  0.8005,  0.3870,  0.5728],\n",
       "        [ 1.1029, -0.1348,  0.6647,  0.1699, -0.1461,  0.0438,  0.5243,  0.3101,\n",
       "          0.0105,  0.4730,  0.5368, -0.0129,  0.3247, -0.0544,  0.2721,  0.0111,\n",
       "          0.7617,  0.4246,  1.1697,  0.4510,  0.3713, -0.6546,  0.3013,  0.2014,\n",
       "          0.2917,  0.6245,  0.0769,  0.0045, -0.0181,  0.7973,  0.3867,  0.5237],\n",
       "        [ 1.0956, -0.1427,  0.6516,  0.1631, -0.1464,  0.0416,  0.5147,  0.2743,\n",
       "         -0.0015,  0.4607,  0.4500, -0.0222,  0.3233, -0.0891,  0.2573,  0.0025,\n",
       "          0.7225,  0.3721,  1.1239,  0.4018,  0.3559, -0.6753,  0.2907,  0.1418,\n",
       "          0.2816,  0.6060,  0.0537, -0.0245, -0.0453,  0.7853,  0.3616,  0.4700],\n",
       "        [ 1.0602, -0.1474,  0.6515,  0.1589, -0.1604,  0.0022,  0.5085,  0.2731,\n",
       "         -0.0040,  0.4451,  0.4283, -0.0398,  0.3149, -0.1644,  0.2437, -0.0210,\n",
       "          0.7080,  0.3432,  1.1016,  0.3705,  0.3456, -0.7164,  0.2882,  0.0796,\n",
       "          0.2292,  0.6032,  0.0485, -0.0408, -0.0644,  0.7827,  0.3539,  0.4538]],\n",
       "       device='cuda:0', grad_fn=<SelectBackward0>)"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sort_feat[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "a8a64ef7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([10, 32])"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sort_ind[0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d214fe8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a5efeed",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = SE3TransformerPooled(\n",
    "        fiber_in=Fiber({0: dm.NODE_FEATURE_DIM}),\n",
    "        fiber_out=Fiber({0: num_degrees * num_channels}),\n",
    "        fiber_edge=Fiber({0: dm.EDGE_FEATURE_DIM}),\n",
    "        output_dim=1,\n",
    "        tensor_cores=using_tensor_cores(False),\n",
    "        num_degrees=num_degrees,\n",
    "        num_channels=num_channels,\n",
    "        **kwargs\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "a22797c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "?dgl.nn.pytorch."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7e9e983",
   "metadata": {},
   "outputs": [],
   "source": [
    "# get dataset from pdb using npose utils\n",
    "# import util.npose_util as nu\n",
    "# import os\n",
    "# import numpy as np\n",
    "\n",
    "# model_direc = '/mnt/c/Users/nwood/OneDrive/Desktop/hTest/HelixGen_master/data/4H_dataset/models/'\n",
    "\n",
    "# fL = os.listdir(model_direc)\n",
    "# coords = np.zeros((len(fL),65*5,4)) #65 aa, 5 atoms per aa\n",
    "# for i,file in enumerate(fL):\n",
    "#     coords[i] = nu.npose_from_file(f'{model_direc}/{file}')\n",
    "\n",
    "# coords_out = coords.reshape((27894,65,5,4))[...,:3]\n",
    "# ca_coords = coords_out.reshape((27894,65,5,3))[:,:,1,:]\n",
    "\n",
    "# np.savez_compressed('../gudiff/data/h4_coords.npz',coords_out)\n",
    "# np.savez_compressed('../gudiff/data/h4_ca_coords.npz',ca_coords)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "cca76781",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'Dataset' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[10], line 47\u001b[0m\n\u001b[0;32m     42\u001b[0m     batched_graph \u001b[38;5;241m=\u001b[39m dgl\u001b[38;5;241m.\u001b[39mbatch(graphList)\n\u001b[0;32m     44\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m batched_graph\n\u001b[1;32m---> 47\u001b[0m \u001b[38;5;28;01mclass\u001b[39;00m \u001b[38;5;21;01mGraphDataset\u001b[39;00m(\u001b[43mDataset\u001b[49m):\n\u001b[0;32m     48\u001b[0m     \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__init__\u001b[39m(\u001b[38;5;28mself\u001b[39m, ep_file : pathlib\u001b[38;5;241m.\u001b[39mPath, limit\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1000\u001b[39m):\n\u001b[0;32m     49\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdata_path \u001b[38;5;241m=\u001b[39m ep_file\n",
      "\u001b[1;31mNameError\u001b[0m: name 'Dataset' is not defined"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "\n",
    "\n",
    "def normalize_pc(points):\n",
    "    \"\"\"Center at Zero Divide furtherst points\"\"\"\n",
    "    centroid = np.mean(points, axis=0)\n",
    "    points -= centroid\n",
    "    #since the points are centered zero, the furthest points is the abs value di\n",
    "    furthest_distance = np.max(np.sqrt(np.sum(abs(points)**2,axis=-1)))\n",
    "    points /= furthest_distance\n",
    "\n",
    "    return points, furthest_distance\n",
    "    \n",
    "def make_pe_encoding(i_pos=8, embed_dim = 8, scale = 10, cast_type=torch.float32):\n",
    "    #positional encoding of node\n",
    "    i_array = np.arange(1,(embed_dim/2)+1)\n",
    "    wk = (1/(scale**(i_array*2/embed_dim)))\n",
    "    t_array = np.arange(i_pos)\n",
    "    si = torch.tensor(np.sin(wk*t_array.reshape((-1,1))))\n",
    "    ci = torch.tensor(np.cos(wk*t_array.reshape((-1,1))))\n",
    "    pe = torch.stack((si,ci),axis=2).reshape(t_array.shape[0],embed_dim).type(cast_type)\n",
    "    return pe\n",
    "\n",
    "\n",
    "def make_graph_struct(batch_size=32, n_nodes = 8):\n",
    "    # make a fake graph to be filled with generator outputs\n",
    "    \n",
    "    v1 = np.arange(n_nodes-1) #vertex 1 of edges in chronological order\n",
    "    v2 = np.arange(1,n_nodes) #vertex 2 of edges in chronological order\n",
    "\n",
    "    ss = np.zeros(len(v1),dtype=np.int32)\n",
    "    ss[np.arange(ss.shape[0])%2==0]=1  #alternate 0,1 for helix, loop, helix, etc\n",
    "    ss = ss[:,None] #unsqueeze\n",
    "    \n",
    "    pe = make_pe_encoding(i_pos=8, embed_dim = 8, scale = 10, cast_type=torch.float32)\n",
    "\n",
    "    graphList = []\n",
    "    for i in range(batch_size):\n",
    "        g = dgl.graph((v1,v2))\n",
    "        g.edata['ss'] = torch.tensor(ss,dtype=torch.float32)\n",
    "        g.ndata['pe'] = pe\n",
    "\n",
    "        graphList.append(g)\n",
    "\n",
    "    batched_graph = dgl.batch(graphList)\n",
    "\n",
    "    return batched_graph\n",
    "\n",
    "\n",
    "class GraphDataset(Dataset):\n",
    "    def __init__(self, ep_file : pathlib.Path, limit=1000):\n",
    "        self.data_path = ep_file\n",
    "        rr = np.load(self.data_path)\n",
    "        ep = [rr[f] for f in rr.files][0][:1000]\n",
    "        \n",
    "        #need to save furthest distance to regen later\n",
    "        #maybe consider small change for next steps\n",
    "        ep, self.furthest_distance = normalize_pc(ep.reshape((-1,3)))\n",
    "        self.ep = ep.reshape((-1,8,3))\n",
    "        \n",
    "        \n",
    "        v1 = np.arange(self.ep.shape[1]-1) #vertex 1 of edges in chronological order\n",
    "        v2 = np.arange(1,self.ep.shape[1]) #vertex 2 of edges in chronological order\n",
    "\n",
    "        ss = np.zeros(len(v1))\n",
    "        ss[np.arange(ss.shape[0])%2==0]=1  #alternate 0,1 for helix, loop, helix, etc\n",
    "        ss = ss[:,None] #unsqueeze\n",
    "\n",
    "        #positional encoding of node\n",
    "        pe = make_pe_encoding(i_pos=8, embed_dim = 8, scale = 10, cast_type=torch.float32)\n",
    "\n",
    "        graphList = []\n",
    "\n",
    "        for i,c in enumerate(self.ep):\n",
    "\n",
    "            g = dgl.graph((v1,v2))\n",
    "            g.ndata['pos'] = torch.tensor(c,dtype=torch.float32)\n",
    "            g.edata['ss'] = torch.tensor(ss,dtype=torch.float32)\n",
    "            g.ndata['pe'] = pe\n",
    "\n",
    "            graphList.append(g)\n",
    "        \n",
    "        self.graphList = graphList\n",
    "\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.graphList)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        return self.graphList[idx]\n",
    "\n",
    "    \n",
    "class HGenDataModule():\n",
    "    \"\"\"\n",
    "    Datamodule wrapping hGen data set. 8 Helical endpoints defining a four helix protein.\n",
    "    \"\"\"\n",
    "    #8 long positional encoding\n",
    "    NODE_FEATURE_DIM = 8\n",
    "    EDGE_FEATURE_DIM = 1 # 0 or 1 helix or loop\n",
    "\n",
    "    def __init__(self,\n",
    "                 data_dir: pathlib.Path, batch_size=32):\n",
    "        \n",
    "        self.data_dir = data_dir \n",
    "        self.GraphDatasetObj = GraphDataset(self.data_dir)\n",
    "        self.gds = DataLoader(self.GraphDatasetObj,batch_size=batch_size, shuffle=True, drop_last=True,\n",
    "                              collate_fn=self._collate)\n",
    "        \n",
    "    \n",
    "        \n",
    "    def _collate(self, graphs):\n",
    "        batched_graph = dgl.batch(graphs)\n",
    "        #reshape that batched graph to redivide into the individual graphs\n",
    "        edge_feats = {'0': batched_graph.edata['ss'][:, :self.EDGE_FEATURE_DIM, None]}\n",
    "        batched_graph.edata['rel_pos'] = _get_relative_pos(batched_graph)\n",
    "        # get node features\n",
    "        node_feats = {'0': batched_graph.ndata['pe'][:, :self.NODE_FEATURE_DIM, None]}\n",
    "        \n",
    "        return (batched_graph, node_feats, edge_feats)\n",
    "    \n",
    "def eval_gen(batch_size=8,z=12):\n",
    "    \n",
    "    in_z = torch.randn((batch_size,z), device='cuda',dtype = torch.float32)\n",
    "    out = hg(in_z)*31\n",
    "    out = out.reshape((-1,8,3)).detach().cpu().numpy()\n",
    "    \n",
    "    return eval_endpoints(out)\n",
    "    \n",
    "    \n",
    "\n",
    "def eval_endpoints(ep_in): \n",
    "    \n",
    "    ep = ep_in.reshape((-1,8,3))\n",
    "\n",
    "    v1 = np.arange(ep.shape[1]-1) #vertex 1 of edges in chronological order\n",
    "    v2 = np.arange(1,ep.shape[1]) #vertex 2 of edges in chronological order\n",
    "\n",
    "    hLL = np.linalg.norm(ep[:,v1]-ep[:,v2],axis=2)\n",
    "\n",
    "    hLoc = np.array([0,2,4,6])\n",
    "    lLoc = np.array([1,3,5])\n",
    "\n",
    "    return np.mean(hLL[:,hLoc]), np.mean(hLL[:,lLoc])\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4079c5b6",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "se33",
   "language": "python",
   "name": "se33"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
