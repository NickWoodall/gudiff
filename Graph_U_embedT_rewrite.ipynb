{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a02a1c0f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "#clear memory better\n",
    "with torch.no_grad():\n",
    "    torch.cuda.empty_cache()\n",
    "import numpy as np\n",
    "import util.npose_util as nu\n",
    "import os\n",
    "import pathlib\n",
    "import dgl\n",
    "from dgl import backend as F\n",
    "import torch_geometric\n",
    "from torch.utils.data import random_split, DataLoader, Dataset\n",
    "from typing import Dict\n",
    "from torch import Tensor\n",
    "from dgl import DGLGraph\n",
    "from torch import nn\n",
    "# from chemical import cos_ideal_NCAC #from RoseTTAFold2\n",
    "from torch import einsum\n",
    "import time\n",
    "torch.cuda.is_available()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "33e16cff",
   "metadata": {},
   "outputs": [],
   "source": [
    "import se3_diffuse.utils as du"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6a31f547",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from data_rigid_diffuser import so3_diffuser\n",
    "# from data_rigid_diffuser import r3_diffuser\n",
    "# from scipy.spatial.transform import Rotation\n",
    "# from data_rigid_diffuser import rigid_utils as ru\n",
    "# import yaml\n",
    "from data_rigid_diffuser.diffuser import FrameDiffNoise\n",
    "from gudiff_model import Data_Graph\n",
    "from gudiff_model.Data_Graph import build_npose_from_coords, dump_coord_pdb, define_graph_edges, make_pe_encoding\n",
    "from gudiff_model.Data_Graph import Helix4_Dataset, Make_KNN_MP_Graphs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "bf443f63",
   "metadata": {},
   "outputs": [],
   "source": [
    "from se3_transformer.model.basis import get_basis, update_basis_with_fused\n",
    "from se3_transformer.model.transformer import Sequential, SE3Transformer\n",
    "from se3_transformer.model.transformer_topk import SE3Transformer_topK\n",
    "from se3_transformer.model.FAPE_Loss import FAPE_loss, Qs2Rs, normQ\n",
    "from se3_transformer.model.layers.attentiontopK import AttentionBlockSE3\n",
    "from se3_transformer.model.layers.linear import LinearSE3\n",
    "from se3_transformer.model.layers.convolution import ConvSE3, ConvSE3FuseLevel\n",
    "from se3_transformer.model.layers.norm import NormSE3\n",
    "from se3_transformer.model.layers.pooling import GPooling, Latent_Unpool, Unpool_Layer\n",
    "from se3_transformer.runtime.utils import str2bool, to_cuda\n",
    "from se3_transformer.model.fiber import Fiber\n",
    "from se3_transformer.model.transformer import get_populated_edge_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c0babffd",
   "metadata": {},
   "outputs": [],
   "source": [
    "#indices for, unsure if needed\n",
    "CA = Data_Graph.CA\n",
    "N = Data_Graph.N\n",
    "C = Data_Graph.C\n",
    "\n",
    "#find better way to incorporate coord_scale\n",
    "\n",
    "#needed\n",
    "N_CA_dist = (Data_Graph.N_CA_dist/10.).to('cuda')\n",
    "C_CA_dist = (Data_Graph.C_CA_dist/10.).to('cuda')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e213e885",
   "metadata": {},
   "outputs": [],
   "source": [
    "# data_path_str  = 'data/h4_ca_coords.npz'\n",
    "# test_limit = 1028\n",
    "# rr = np.load(data_path_str)\n",
    "# ca_coords = [rr[f] for f in rr.files][0][:test_limit,:,:3]\n",
    "# ca_coords.shape\n",
    "\n",
    "# getting N-Ca, Ca-C vectors to add as typeI features\n",
    "#apa = apart helices for val/train split\n",
    "#tog = together helices for val/train split\n",
    "apa_path_str  = 'data_npose/h4_apa_coords.npz'\n",
    "tog_path_str  = 'data_npose/h4_tog_coords.npz'\n",
    "\n",
    "#grab the first 3 atoms which are N,CA,C\n",
    "test_limit = 5028\n",
    "rr = np.load(apa_path_str)\n",
    "coords_apa = [rr[f] for f in rr.files][0][:test_limit,:]\n",
    "\n",
    "rr = np.load(tog_path_str)\n",
    "coords_tog = [rr[f] for f in rr.files][0][:test_limit,:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "2b9195dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "from gudiff_model.Graph_UNet import GraphUNet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab4fd030",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a25c4e1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "a5a815da",
   "metadata": {},
   "outputs": [],
   "source": [
    "def model_step(backbone_dict, noised_dict, batched_t, scores_scales, graph_maker, graph_unet, train=True):\n",
    "    \n",
    "    \n",
    "    CA_t  = backbone_dict['CA'].reshape(B, L, 3).to('cuda')\n",
    "    NC_t = CA_t + backbone_dict['N_CA'].reshape(B, L, 3).to('cuda')#not mult earlier #th\n",
    "    CC_t = CA_t + backbone_dict['C_CA'].reshape(B, L, 3).to('cuda')#not mult earlier\n",
    "    true =  torch.cat((NC_t,CA_t,CC_t),dim=2).reshape(B,L,3,3)\n",
    "    \n",
    "    CA_n  = noised_dict['CA'].reshape(B, L, 3).to('cuda')\n",
    "    NC_n = CA_n + noised_dict['N_CA'].reshape(B, L, 3).to('cuda')\n",
    "    CC_n = CA_n + noised_dict['C_CA'].reshape(B, L, 3).to('cuda')\n",
    "    noise_xyz =  torch.cat((NC_n,CA_n,CC_n),dim=2).reshape(B,L,3,3)\n",
    "    \n",
    "#     #rot mask for high T\n",
    "#     rot_t_max = 0.2\n",
    "#     t_mask = (batched_t>rot_t_max).to('cpu')\n",
    "#     noised_dict['N_CA'][t_mask] = backbone_dict['N_CA'].reshape(B, L,1, 3)[t_mask]\n",
    "#     noised_dict['C_CA'][t_mask] = backbone_dict['C_CA'].reshape(B, L,1, 3)[t_mask]\n",
    "    \n",
    "    x = graph_maker.prep_for_network(noised_dict)\n",
    "    out = graph_unet(x, batched_t)\n",
    "    CA_p = out['1'][:,0,:].reshape(B, L, 3)+CA_n #translation of Calpha\n",
    "    Qs = out['1'][:,1,:] # rotation\n",
    "    Qs = Qs.unsqueeze(1).repeat((1,2,1))\n",
    "    Qs = torch.cat((torch.ones((B*L,2,1),device=Qs.device),Qs),dim=-1).reshape(B,L,2,4)\n",
    "    Qs = normQ(Qs)\n",
    "    Rs = Qs2Rs(Qs)\n",
    "    N_C_to_Rot = torch.cat((noised_dict['N_CA'].reshape(B, L, 3).to('cuda'),\n",
    "                            noised_dict['C_CA'].reshape(B, L, 3).to('cuda')),dim=2).reshape(B,L,2,1,3)\n",
    "\n",
    "    \n",
    "    \n",
    "    rot_vecs = einsum('bnkij,bnkhj->bnki',Rs, N_C_to_Rot)\n",
    "    \n",
    "\n",
    "    \n",
    "    NC_p = CA_p + rot_vecs[:,:,0,:]*N_CA_dist #remove bc who cares? me maybe\n",
    "    CC_p = CA_p + rot_vecs[:,:,1,:]*C_CA_dist #remove maybe\n",
    "\n",
    "    pred = torch.cat((NC_p,CA_p,CC_p),dim=2).reshape(B,L,3,3)\n",
    "    \n",
    "    tloss, loss = FAPE_loss(pred.unsqueeze(0), true, scores_scales)\n",
    "    #tloss, loss = FAPE_loss(pred.unsqueeze(0), true, scores_scales)\n",
    "    \n",
    "    return tloss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "02f23891",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_noise_pred_true(backbone_dict, noised_dict, batched_t, graph_maker, graph_unet):\n",
    "    \n",
    "    CA_t  = backbone_dict['CA'].reshape(B, L, 3).to('cuda')\n",
    "    NC_t = CA_t + backbone_dict['N_CA'].reshape(B, L, 3).to('cuda')*N_CA_dist\n",
    "    CC_t = CA_t + backbone_dict['C_CA'].reshape(B, L, 3).to('cuda')*C_CA_dist\n",
    "    true =  torch.cat((NC_t,CA_t,CC_t),dim=2).reshape(B,L,3,3)\n",
    "    \n",
    "    CA_n  = noised_dict['CA'].reshape(B, L, 3).to('cuda')\n",
    "    NC_n = CA_n + noised_dict['N_CA'].reshape(B, L, 3).to('cuda')*N_CA_dist\n",
    "    CC_n = CA_n + noised_dict['C_CA'].reshape(B, L, 3).to('cuda')*C_CA_dist\n",
    "    noise_xyz =  torch.cat((NC_n,CA_n,CC_n),dim=2).reshape(B,L,3,3)\n",
    "    \n",
    "    x = graph_maker.prep_for_network(noised_dict)\n",
    "    out = graph_unet(x, batched_t)\n",
    "    CA_p = out['1'][:,0,:].reshape(B, L, 3)+CA_n #translation of Calpha\n",
    "    Qs = out['1'][:,1,:] # rotation\n",
    "    Qs = Qs.unsqueeze(1).repeat((1,2,1))\n",
    "    Qs = torch.cat((torch.ones((B*L,2,1),device=Qs.device),Qs),dim=-1).reshape(B,L,2,4)\n",
    "    Qs = normQ(Qs)\n",
    "    Rs = Qs2Rs(Qs)\n",
    "    N_C_to_Rot = torch.cat((noised_dict['N_CA'].reshape(B, L, 3).to('cuda'),\n",
    "                            noised_dict['C_CA'].reshape(B, L, 3).to('cuda')),dim=2).reshape(B,L,2,1,3)\n",
    "\n",
    "    \n",
    "    rot_vecs = einsum('bnkij,bnkhj->bnki',Rs, N_C_to_Rot)\n",
    "    NC_p = CA_p + rot_vecs[:,:,0,:].to('cuda')*N_CA_dist\n",
    "    CC_p = CA_p + rot_vecs[:,:,1,:].reshape(B, L, 3).to('cuda')*C_CA_dist\n",
    "\n",
    "    pred = torch.cat((NC_p,CA_p,CC_p),dim=2).reshape(B,L,3,3)\n",
    "    \n",
    "    return true.to('cpu').numpy()*10, noise_xyz.to('cpu').numpy()*10, pred.detach().to('cpu').numpy()*10\n",
    "\n",
    "def dump_tnp(true, noise, pred, t_val, e=0, numOut=1,outdir='output/'):\n",
    "    \n",
    "    if numOut>true.shape[0]:\n",
    "        numOut = true.shape[0]\n",
    "    \n",
    "    for x in range(numOut):\n",
    "        dump_coord_pdb(true[x], fileOut=f'{outdir}/true_{t_val[x]*100:.0f}_e{e}_{x}.pdb')\n",
    "        dump_coord_pdb(noise[x], fileOut=f'{outdir}/noise_{t_val[x]*100:.0f}_e{e}_{x}.pdb')\n",
    "        dump_coord_pdb(pred[x], fileOut=f'{outdir}/pred_{t_val[x]*100:.0f}_e{e}_{x}.pdb')\n",
    "        \n",
    "def visualize_model(bb_dict, noised_bb, batched_t, epoch, numOut=1, outdir='output/'):\n",
    "    true, noise, pred = get_noise_pred_true(bb_dict, noised_bb, batched_t, gm, gu)\n",
    "    dump_tnp(true,noise,pred, batched_t, e=epoch, numOut=numOut, outdir=f'{outdir}/models/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "5d28184c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_save_folder(name=''):\n",
    "    base_folder = time.strftime(f'log/%y%b%d_%I%M%p_{name}/', time.localtime())\n",
    "    if not os.path.exists(base_folder):\n",
    "        os.makedirs(base_folder)\n",
    "    subfolders = ['models']\n",
    "    for subfolder in subfolders:\n",
    "        if not os.path.exists(base_folder + subfolder):\n",
    "            os.makedirs(base_folder + subfolder)\n",
    "            \n",
    "    return base_folder\n",
    "        \n",
    "def save_chkpt(model_path, model, optimizer, epoch, batch, val_losses, train_losses):\n",
    "    \"\"\"Save a training checkpoint\n",
    "    Args:\n",
    "        model_path (str): the path to save the model to\n",
    "        model (nn.Module): the model to save\n",
    "        optimizer (torch.optim.Optimizer): the optimizer to save\n",
    "        epoch (int): the current epoch\n",
    "        batch (int): the current batch in the epoch\n",
    "        loss_domain (list of int): a list of the shared domain for val and training \n",
    "            losses\n",
    "        val_losses (list of float): a list containing the validation losses\n",
    "        train_losses (list of float): a list containing the training losses\n",
    "    \"\"\"\n",
    "    os.makedirs(os.path.dirname(model_path), exist_ok=True)\n",
    "    state_dict = dict()\n",
    "    state_dict.update({'model':model.state_dict(),\n",
    "                       'optimizer':optimizer.state_dict(),\n",
    "                       'epoch':epoch,\n",
    "                       'batch':batch,\n",
    "                       'train_losses':train_losses,\n",
    "                       'val_losses':val_losses\n",
    "                       })\n",
    "    torch.save(state_dict, f'{model_path}model_e{epoch}')\n",
    "    \n",
    "def load_model(model_path, model_class):\n",
    "    \"\"\"Load a saved model\"\"\"\n",
    "    \n",
    "    device = 'cuda:0'\n",
    "    model = model_class()\n",
    "    model.load_state_dict(torch.load(model_path)['model'])\n",
    "    model.to(device)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "149c44dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "#B = 32\n",
    "B = 16\n",
    "L=65\n",
    "#limit = 5028\n",
    "limit = 1028\n",
    "h4_trainData = Helix4_Dataset(coords_tog[:limit])\n",
    "h4_valData = Helix4_Dataset(coords_apa[:limit])\n",
    "train_dL = DataLoader(h4_trainData, batch_size=B, shuffle=True, drop_last=True)\n",
    "val_dL   = DataLoader(h4_valData, batch_size=B, shuffle=True, drop_last=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "58ac8828",
   "metadata": {},
   "outputs": [],
   "source": [
    "gu = GraphUNet(batch_size = B, num_layers_ca = 2).to('cuda')\n",
    "opti = torch.optim.Adam(gu.parameters(), lr=0.0005, weight_decay=5e-6) #prev lr=0.0005\n",
    "gm = Make_KNN_MP_Graphs() #consider precalculating graphs for training\n",
    "fdn= FrameDiffNoise()\n",
    "useR3 = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "b5faf34a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#visualize_T\n",
    "vis_t = np.array([0.05]*8)\n",
    "\n",
    "#single_t = np.array([0.01,0.05,0.1,0.2,0.3,0.5,0.8,1.0])\n",
    "vis_t = vis_t[None,...].repeat(int(np.ceil(B/len(vis_t))),axis=0).flatten()[:B]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "abf907bb",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "748495b5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.05 0.05 0.05 0.05 0.05 0.05 0.05 0.05 0.05 0.05 0.05 0.05 0.05 0.05\n",
      " 0.05 0.05]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/nwoodall/miniconda3/envs/se33/lib/python3.9/site-packages/dgl/backend/pytorch/tensor.py:449: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()\n",
      "  assert input.numel() == input.storage().size(), (\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Train Loss Epoch 0: 0.21747204661369324;   Epoch time: 56\n",
      "Average Train Loss Epoch 1: 0.20509067177772522;   Epoch time: 50\n",
      "Average Train Loss Epoch 2: 0.2028973400592804;   Epoch time: 50\n",
      "Average Train Loss Epoch 3: 0.20257936418056488;   Epoch time: 50\n",
      "Average Train Loss Epoch 4: 0.20073851943016052;   Epoch time: 51\n",
      "Average Train Loss Epoch 5: 0.19879992306232452;   Epoch time: 51\n",
      "Average Train Loss Epoch 6: 0.19685176014900208;   Epoch time: 51\n",
      "Average Train Loss Epoch 7: 0.1953815519809723;   Epoch time: 51\n",
      "Average Train Loss Epoch 8: 0.19391292333602905;   Epoch time: 51\n",
      "Average Train Loss Epoch 9: 0.19118303060531616;   Epoch time: 51\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/nwoodall/miniconda3/envs/se33/lib/python3.9/site-packages/torch/utils/checkpoint.py:31: UserWarning: None of the inputs have requires_grad=True. Gradients will be None\n",
      "  warnings.warn(\"None of the inputs have requires_grad=True. Gradients will be None\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Valid Loss Epoch 9: 0.16735468804836273\n",
      "Average Train Loss Epoch 10: 0.1897183358669281;   Epoch time: 51\n",
      "Average Train Loss Epoch 11: 0.1880844384431839;   Epoch time: 51\n",
      "Average Train Loss Epoch 12: 0.18495255708694458;   Epoch time: 51\n",
      "Average Train Loss Epoch 13: 0.18406108021736145;   Epoch time: 51\n",
      "Average Train Loss Epoch 14: 0.18138019740581512;   Epoch time: 51\n",
      "Average Train Loss Epoch 15: 0.1810176968574524;   Epoch time: 51\n",
      "Average Train Loss Epoch 16: 0.18003498017787933;   Epoch time: 51\n",
      "Average Train Loss Epoch 17: 0.17721673846244812;   Epoch time: 51\n",
      "Average Train Loss Epoch 18: 0.17455412447452545;   Epoch time: 51\n",
      "Average Train Loss Epoch 19: 0.17205914855003357;   Epoch time: 51\n",
      "Average Valid Loss Epoch 19: 0.1616533398628235\n",
      "Average Train Loss Epoch 20: 0.168820321559906;   Epoch time: 51\n",
      "Average Train Loss Epoch 21: 0.16573405265808105;   Epoch time: 51\n",
      "Average Train Loss Epoch 22: 0.16298282146453857;   Epoch time: 51\n",
      "Average Train Loss Epoch 23: 0.16021333634853363;   Epoch time: 51\n",
      "Average Train Loss Epoch 24: 0.15787498652935028;   Epoch time: 50\n",
      "Average Train Loss Epoch 25: 0.15363506972789764;   Epoch time: 51\n",
      "Average Train Loss Epoch 26: 0.15020333230495453;   Epoch time: 51\n",
      "Average Train Loss Epoch 27: 0.1457575112581253;   Epoch time: 50\n",
      "Average Train Loss Epoch 28: 0.14374980330467224;   Epoch time: 51\n",
      "Average Train Loss Epoch 29: 0.14086246490478516;   Epoch time: 51\n",
      "Average Valid Loss Epoch 29: 0.15373365581035614\n",
      "Average Train Loss Epoch 30: 0.13828949630260468;   Epoch time: 51\n",
      "Average Train Loss Epoch 31: 0.13717548549175262;   Epoch time: 51\n",
      "Average Train Loss Epoch 32: 0.13426513969898224;   Epoch time: 51\n",
      "Average Train Loss Epoch 33: 0.1326029896736145;   Epoch time: 50\n",
      "Average Train Loss Epoch 34: 0.13112956285476685;   Epoch time: 51\n",
      "Average Train Loss Epoch 35: 0.1294262856245041;   Epoch time: 51\n",
      "Average Train Loss Epoch 36: 0.12816300988197327;   Epoch time: 51\n",
      "Average Train Loss Epoch 37: 0.12665118277072906;   Epoch time: 51\n",
      "Average Train Loss Epoch 38: 0.12508146464824677;   Epoch time: 52\n",
      "Average Train Loss Epoch 39: 0.12383823841810226;   Epoch time: 50\n",
      "Average Valid Loss Epoch 39: 0.15798495709896088\n",
      "Average Train Loss Epoch 40: 0.12282543629407883;   Epoch time: 51\n",
      "Average Train Loss Epoch 41: 0.1217089369893074;   Epoch time: 51\n",
      "Average Train Loss Epoch 42: 0.12094107270240784;   Epoch time: 51\n",
      "Average Train Loss Epoch 43: 0.11934937536716461;   Epoch time: 51\n",
      "Average Train Loss Epoch 44: 0.11911371350288391;   Epoch time: 51\n",
      "Average Train Loss Epoch 45: 0.11830608546733856;   Epoch time: 51\n",
      "Average Train Loss Epoch 46: 0.11722886562347412;   Epoch time: 51\n",
      "Average Train Loss Epoch 47: 0.11597345024347305;   Epoch time: 50\n",
      "Average Train Loss Epoch 48: 0.11573802679777145;   Epoch time: 52\n",
      "Average Train Loss Epoch 49: 0.1149199903011322;   Epoch time: 53\n",
      "Average Valid Loss Epoch 49: 0.16050027310848236\n"
     ]
    }
   ],
   "source": [
    "t=0.05\n",
    "t_vec = np.ones((B,))*t\n",
    "print(t_vec)\n",
    "model_path = make_save_folder(name=f'fdiff_modelStep_doublecheck')\n",
    "num_epochs = 50\n",
    "e_start= 0\n",
    "save_per=10\n",
    "avg_vloss=0\n",
    "\n",
    "for e in range(e_start, e_start+num_epochs):\n",
    "    \n",
    "    running_tloss = 0 \n",
    "    start = time.time()\n",
    "    for i, bb_dict in enumerate(train_dL):\n",
    "        noised_bb, tv, ss = fdn.forward_fixed_nodes(bb_dict,t_vec=t_vec, useR3=useR3)\n",
    "        tv = tv.to('cuda')\n",
    "        ss = ss.to('cuda')\n",
    "        train_loss = model_step(bb_dict, noised_bb, tv, ss, gm, gu)\n",
    "        opti.zero_grad()\n",
    "        train_loss.backward()\n",
    "        opti.step()\n",
    "\n",
    "        running_tloss += train_loss.detach().cpu()\n",
    "    \n",
    "    end = time.time()\n",
    "    avg_tloss = running_tloss/(i+1)\n",
    "    print(f'Average Train Loss Epoch {e}: {avg_tloss};   Epoch time: {end-start:.0f}')\n",
    "\n",
    "    if e %save_per==save_per-1:\n",
    "        with torch.no_grad():\n",
    "            running_vloss = 0\n",
    "            for i, bb_dictv in enumerate(val_dL):\n",
    "                noised_bb, tv, ss = fdn.forward_fixed_nodes(bb_dictv,t_vec=None, useR3=useR3) #this does the opposite of traditional, upweighting lower\n",
    "                tv = tv.to('cuda')\n",
    "                ss = ss.to('cuda')\n",
    "                valid_loss = model_step(bb_dictv, noised_bb, tv, ss, gm, gu)\n",
    "                running_vloss += valid_loss\n",
    "                \n",
    "        avg_vloss = running_vloss/(i+1)\n",
    "        print(f'Average Valid Loss Epoch {e}: {avg_vloss}')\n",
    "                \n",
    "        noised_bb, tv, ss = fdn.forward_fixed_nodes(bb_dict, t_vec=vis_t)\n",
    "        tv = tv.to('cuda')\n",
    "        visualize_model(bb_dict, noised_bb, tv, e, numOut=8,outdir=f'{model_path}')\n",
    "        save_chkpt(f'{model_path}', gu, opti, e, B, avg_vloss, avg_tloss)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "6d4cc89e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#calculate score from noise, pred\n",
    "import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "e673b171",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#load model\n",
    "model_path = '23Sep01_0242AM_full_diff_embed_T_btest'\n",
    "modelFile = 'model_e489'\n",
    "#opti = torch.optim.Adam(gu.parameters())\n",
    "device = 'cuda:0'\n",
    "gu.load_state_dict(torch.load(f'log/{model_path}/{modelFile}')['model'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "14d72aaa",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_iter = iter(train_dL)\n",
    "bb_dict = next(test_iter)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "df51d804",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/nwoodall/miniconda3/envs/se33/lib/python3.9/site-packages/dgl/backend/pytorch/tensor.py:449: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()\n",
      "  assert input.numel() == input.storage().size(), (\n"
     ]
    }
   ],
   "source": [
    "noised_bb, tv, ss = fdn(bb_dict, t_vec=vis_t)\n",
    "tv = tv.to('cuda')\n",
    "visualize_model(bb_dict, noised_bb, tv, 'test', numOut=8,outdir=f'output/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "1648a614",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_iter = iter(train_dL)\n",
    "bb_dict = next(test_iter)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f79a532",
   "metadata": {},
   "outputs": [],
   "source": [
    "f_t = fdn.r3d.drift_coef()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "82952387",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'test_batch' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[19], line 3\u001b[0m\n\u001b[1;32m      1\u001b[0m t \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[1;32m      2\u001b[0m t_vec \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mones((B,))\u001b[38;5;241m*\u001b[39mt\n\u001b[0;32m----> 3\u001b[0m nd, tv, ss \u001b[38;5;241m=\u001b[39m fdn(\u001b[43mtest_batch\u001b[49m, t_vec\u001b[38;5;241m=\u001b[39mt_vec, useR3\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\n\u001b[1;32m      4\u001b[0m tv \u001b[38;5;241m=\u001b[39m tv\u001b[38;5;241m.\u001b[39mto(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcuda\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m      6\u001b[0m CA_n  \u001b[38;5;241m=\u001b[39m nd[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mCA\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39mreshape(B, L, \u001b[38;5;241m3\u001b[39m)\u001b[38;5;241m.\u001b[39mto(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcuda\u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'test_batch' is not defined"
     ]
    }
   ],
   "source": [
    "t = 1\n",
    "t_vec = np.ones((B,))*t\n",
    "nd, tv, ss = fdn(test_batch, t_vec=t_vec, useR3=False)\n",
    "tv = tv.to('cuda')\n",
    "\n",
    "CA_n  = nd['CA'].reshape(B, L, 3).to('cuda')\n",
    "NC_n = CA_n + nd['N_CA'].reshape(B, L, 3).to('cuda')*N_CA_dist\n",
    "CC_n = CA_n + nd['C_CA'].reshape(B, L, 3).to('cuda')*C_CA_dist\n",
    "noise_xyz =  torch.cat((NC_n,CA_n,CC_n),dim=2).reshape(B,L,3,3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "f3ca3539",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e6629e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "        if not np.isscalar(t):\n",
    "            raise ValueError(f'{t} must be a scalar.')\n",
    "        #x_t = self._scale(x_t)\n",
    "        g_t = self.diffusion_coef(t)\n",
    "        f_t = self.drift_coef(x_t, t)\n",
    "        z = noise_scale * np.random.normal(size=score_t.shape)\n",
    "        perturb = (f_t - g_t**2 * score_t) * dt + g_t * np.sqrt(dt) * z\n",
    "\n",
    "        if mask is not None:\n",
    "            perturb *= mask[..., None]\n",
    "        else:\n",
    "            mask = np.ones(x_t.shape[:-1])\n",
    "        x_t_1 = x_t - perturb\n",
    "        if center:\n",
    "            com = np.sum(x_t_1, axis=-2) / np.sum(mask, axis=-1)[..., None]\n",
    "            x_t_1 -= com[..., None, :]\n",
    "        #x_t_1 = self._unscale(x_t_1)\n",
    "        return x_t_1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99d1b022",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "58f91b4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_batch, batched_t = fdn.sample_ref(B)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b031c08",
   "metadata": {},
   "outputs": [],
   "source": [
    "# start1 = 1.0\n",
    "# end1 = 0.2\n",
    "# dt1 = 0.01\n",
    "# num_out = 1\n",
    "\n",
    "# start2 = 0.2\n",
    "# end2 = 0.0\n",
    "# dt2 = 0.0025\n",
    "\n",
    "# t_list_start = np.arange(start1,end1,-dt1)\n",
    "# t_list_end = np.arange(start2,end2,-dt2).repeat(2)\n",
    "\n",
    "# t_list = np.concatenate([t_list_start,t_list_end])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "c4f3bc2e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████████████████| 275/275 [02:27<00:00,  1.87it/s]\n"
     ]
    }
   ],
   "source": [
    "start1 = 1.0\n",
    "end1 = 0.3\n",
    "dt1 = 0.02\n",
    "num_out = 1\n",
    "\n",
    "start2 = 0.3\n",
    "end2 = 0.0\n",
    "dt2 = 0.0025\n",
    "\n",
    "t_list_start = np.arange(start1,end1,-dt1)\n",
    "t_list_end = np.arange(start2,end2,-dt2).repeat(2)\n",
    "\n",
    "t_list = np.concatenate([t_list_start,t_list_end])\n",
    "\n",
    "#first_iter = True\n",
    "for t in tqdm.tqdm(t_list):\n",
    "    #initialize t and noise\n",
    "    t= np.round(t,decimals=6)\n",
    "    t_vec = np.ones((B,))*t\n",
    "    nd, tv, ss = fdn(test_batch, t_vec=t_vec, useR3=False)\n",
    "    tv = tv.to('cuda')\n",
    "    \n",
    "    CA_n  = nd['CA'].reshape(B, L, 3).to('cuda')\n",
    "    NC_n = CA_n + nd['N_CA'].reshape(B, L, 3).to('cuda')*N_CA_dist\n",
    "    CC_n = CA_n + nd['C_CA'].reshape(B, L, 3).to('cuda')*C_CA_dist\n",
    "    noise_xyz =  torch.cat((NC_n,CA_n,CC_n),dim=2).reshape(B,L,3,3)\n",
    "    \n",
    "#     if isclose(t_print[tc],t):\n",
    "#         for x in range(num_out):\n",
    "#             dump_coord_pdb(noise_xyz[x].cpu()*10, fileOut=f'output/noise_{t*100:.0f}t_n{x}.pdb')  \n",
    "    \n",
    "    #predict X0 from Xt\n",
    "    x = gm.prep_for_network(nd)\n",
    "    with torch.no_grad():\n",
    "        out = gu(x, tv.to('cuda'))\n",
    "        \n",
    "    CA_p = out['1'][:,0,:].reshape(B, L, 3)+CA_n #translation of Calpha\n",
    "    Qs = out['1'][:,1,:] # rotation\n",
    "    Qs = Qs.unsqueeze(1).repeat((1,2,1))\n",
    "    Qs = torch.cat((torch.ones((B*L,2,1),device=Qs.device),Qs),dim=-1).reshape(B,L,2,4)\n",
    "    Qs = normQ(Qs)\n",
    "    Rs = Qs2Rs(Qs)\n",
    "    N_C_to_Rot = torch.cat((nd['N_CA'].reshape(B, L, 3).to('cuda'),\n",
    "                            nd['C_CA'].reshape(B, L, 3).to('cuda')),dim=2).reshape(B,L,2,1,3)\n",
    "    rot_vecs = einsum('bnkij,bnkhj->bnki',Rs, N_C_to_Rot)\n",
    "    NC_p = CA_p + rot_vecs[:,:,0,:].to('cuda')*N_CA_dist\n",
    "    CC_p = CA_p + rot_vecs[:,:,1,:].reshape(B, L, 3).to('cuda')*C_CA_dist\n",
    "\n",
    "\n",
    "    pred = torch.cat((NC_p,CA_p,CC_p),dim=2).reshape(B,L,3,3)\n",
    "#     if isclose(t_print[tc],t):\n",
    "#         tc+=1\n",
    "#         for x in range(num_out):\n",
    "#             dump_coord_pdb(pred[x].cpu()*10, fileOut=f'output/test_{t*100:.0f}t_n{x}.pdb')  \n",
    "        \n",
    "    #reset noise dict\n",
    "    test_batch['CA'] = CA_p.cpu().reshape(B, L, 3)\n",
    "    test_batch['N_CA'] = Data_Graph.torch_normalize(NC_p.cpu()-CA_p.cpu()).reshape(B,L, 1,3)\n",
    "    test_batch['C_CA'] = Data_Graph.torch_normalize(CC_p.cpu()-CA_p.cpu()).reshape(B,L, 1,3)\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "bb6ce035",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "counter+=1\n",
    "for x in range(B):\n",
    "    dump_coord_pdb(pred[x].cpu()*10, fileOut=f'output/testFINAL_{counter}_n{x}.pdb')  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "8f0fe2b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "counter=0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d07bf0ce",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "a4329845",
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.spatial.transform import Rotation\n",
    "from se3_diffuse import rigid_utils as ru\n",
    "#stubs for starting relative NC_CC vecs\n",
    "stub = np.array([[-1.45837285,  0 , 0],         #N\n",
    "         [0., 0., 0.],                 #CA\n",
    "        [0.55221403, 1.41890368, 0. ]] ) #C\n",
    "nca_stub = Data_Graph.torch_normalize(torch.tensor(stub[0]-stub[1]))\n",
    "cca_stub = Data_Graph.torch_normalize(torch.tensor(stub[2]-stub[1]))\n",
    "\n",
    "\n",
    "def rotvec_2_ncVec(rot_vec, cast = torch.float32):\n",
    "    \n",
    "#     rotmat = Rotation.from_rotvec(rot_ref).as_matrix()\n",
    "#     nc_vec = ru.rot_vec_mul(torch.tensor(rotmat,dtype=cast),ncs.reshape((-1,3))).reshape(batch_shape)\n",
    "#     cc_vec = ru.rot_vec_mul(torch.tensor(rotmat,dtype=cast),ccs.reshape((-1,3))).reshape(batch_shape)\n",
    "    ncs = nca_stub[None,None,None,:].repeat(B,L,1,1)\n",
    "    ccs = cca_stub[None,None,None,:].repeat(B,L,1,1)\n",
    "    batch_shape =  ncs.shape\n",
    "    \n",
    "    rotmat=du.rotvec_to_matrix(rot_vec.reshape((-1,3)))\n",
    "    nc_vec = ru.rot_vec_mul(torch.tensor(rotmat,dtype=cast),ncs.reshape((-1,3))).reshape(batch_shape)\n",
    "    cc_vec = ru.rot_vec_mul(torch.tensor(rotmat,dtype=cast),ccs.reshape((-1,3))).reshape(batch_shape)\n",
    "    \n",
    "    return nc_vec, cc_vec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "e17c2b18",
   "metadata": {},
   "outputs": [],
   "source": [
    "def sample_ref(self,batch_size,prot_length=65):\n",
    "    \n",
    "    B = batch_size\n",
    "    L = prot_length\n",
    "    \n",
    "    batched_t = torch.tensor(np.ones((B,)),dtype=cast,device='cuda')\n",
    "    rot_ref = self.so3d.sample_ref(n_samples=B*L)\n",
    "    trans_ref = self.r3d.sample_ref(n_samples=B*L)\n",
    "\n",
    "    nc_vec,cc_vec = rotvec_2_ncVec(rot_ref)\n",
    "\n",
    "    noised_dict = {'CA':torch.tensor(trans_ref,dtype=cast).reshape(B,L,-1), \n",
    "                   'N_CA':nc_vec.type(cast),\n",
    "                   'C_CA':cc_vec.type(cast)}\n",
    "    \n",
    "    CA_n  = noised_dict['CA'].reshape(B, L, 3).to('cuda')\n",
    "    NC_n = CA_n + noised_dict['N_CA'].reshape(B, L, 3).to('cuda')*N_CA_dist\n",
    "    CC_n = CA_n + noised_dict['C_CA'].reshape(B, L, 3).to('cuda')*C_CA_dist\n",
    "    \n",
    "    \n",
    "    return noised_dict\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "e763fdce",
   "metadata": {},
   "outputs": [],
   "source": [
    "#get rots from sample ref\n",
    "def _extract_trans_rots(rigid: ru.Rigid):\n",
    "    rot = rigid.get_rots().get_rot_mats().cpu().numpy()\n",
    "    rot_shape = rot.shape\n",
    "    num_rots = np.cumprod(rot_shape[:-2])[-1]\n",
    "    rot = rot.reshape((num_rots, 3, 3))\n",
    "    rot = Rotation.from_matrix(rot).as_rotvec().reshape(rot_shape[:-2] +(3,))\n",
    "    tran = rigid.get_trans().cpu().numpy()\n",
    "    return tran, rot\n",
    "\n",
    "def reverse_step(noise_dict, graph_unet, batched_t, \n",
    "                 graph_maker,dt=0.01, frame_diff=None, denoise=False, cast = torch.float32):\n",
    "    \n",
    "    CA_n = noised_dict['CA'].to('cuda')\n",
    "    NC_n = CA_n + noised_dict['N_CA'].reshape(B, L, 3).to('cuda')*N_CA_dist\n",
    "    CC_n = CA_n + noised_dict['C_CA'].reshape(B, L, 3).to('cuda')*C_CA_dist\n",
    "    rigids_init =  ru.Rigid.from_3_points(NC_n,CA_n,CC_n)\n",
    "\n",
    "\n",
    "    x = graph_maker.prep_for_network(noised_dict)\n",
    "\n",
    "\n",
    "    out = gu(x, batched_t)\n",
    "    CA_p = out['1'][:,0,:].reshape(B, L, 3)+CA_n #translation of Calpha\n",
    "    Qs = out['1'][:,1,:] # rotation\n",
    "    Qs = Qs.unsqueeze(1).repeat((1,2,1))\n",
    "    Qs = torch.cat((torch.ones((B*L,2,1),device=Qs.device),Qs),dim=-1).reshape(B,L,2,4)\n",
    "    Qs = normQ(Qs)\n",
    "    Rs = Qs2Rs(Qs)\n",
    "    N_C_to_Rot = torch.cat((noised_dict['N_CA'].reshape(B, L, 3).to('cuda'),\n",
    "                            noised_dict['C_CA'].reshape(B, L, 3).to('cuda')),dim=2).reshape(B,L,2,1,3)\n",
    "\n",
    "    rot_vecs = einsum('bnkij,bnkhj->bnki',Rs, N_C_to_Rot)\n",
    "    NC_p = CA_p + rot_vecs[:,:,0,:].to('cuda')*N_CA_dist\n",
    "    CC_p = CA_p + rot_vecs[:,:,1,:].reshape(B, L, 3).to('cuda')*C_CA_dist\n",
    "    if denoise:\n",
    "        pred = torch.cat((NC_p,CA_p,CC_p),dim=2).reshape(B,L,3,3)\n",
    "        return pred, pred.detach().to('cpu').numpy()*10\n",
    "    \n",
    "    else:\n",
    "        rigids_cur = ru.Rigid.from_3_points(NC_p,CA_p,CC_p)\n",
    "        trans_t, rot_t = _extract_trans_rots(rigids_init)\n",
    "        trans_score, rot_score = frame_diff.score(rigids_cur, rigids_init, batched_t)\n",
    "        \n",
    "        t = batched_t.cpu().numpy()[0]\n",
    "        \n",
    "        trans_t_1 = frame_diff.r3d.reverse_old(x_t=trans_t,\n",
    "                    score_t=trans_score.detach().numpy(),\n",
    "                    t=batched_t.cpu().numpy()[0],\n",
    "                    dt=dt,\n",
    "                    center=True,\n",
    "                    noise_scale=0)\n",
    "\n",
    "        rot_t_1 = frame_diff.so3d.reverse_old(rot_t=rot_t,\n",
    "                                       score_t=rot_score.cpu().detach().numpy(),\n",
    "                                       t=batched_t.cpu().numpy()[0], dt=dt,noise_scale=0)\n",
    "\n",
    "        nc_vec_t1, cc_vec_t1 = rotvec_2_ncVec(rot_t_1)\n",
    "        \n",
    "        noised_dict_step = {'CA':torch.tensor(trans_t_1,dtype=cast).reshape(B,L,-1), \n",
    "                       'N_CA':nc_vec_t1.type(cast),\n",
    "                       'C_CA':cc_vec_t1.type(cast)}\n",
    "        return noised_dict_step\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "d4eb98e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "noised_dict, batched_t = fdn.sample_ref(B)\n",
    "\n",
    "nd_rev = reverse_step(noised_dict, gu, batched_t, \n",
    "                      gm, frame_diff=fdn, dt=0.1, denoise=False, cast = torch.float32)\n",
    "\n",
    "\n",
    "# CA_n  = noised_dict['CA'].reshape(B, L, 3).to('cuda')\n",
    "# NC_n = CA_n + noised_dict['N_CA'].reshape(B, L, 3).to('cuda')*N_CA_dist\n",
    "# CC_n = CA_n + noised_dict['C_CA'].reshape(B, L, 3).to('cuda')*C_CA_dist\n",
    "# rigids_init =  ru.Rigid.from_3_points(NC_n,CA_n,CC_n)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d8cd041",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "8be872a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_iter = iter(train_dL)\n",
    "bb_dict = next(test_iter)\n",
    "\n",
    "t=0.3\n",
    "t_vec = np.ones(B,)*t\n",
    "batched_t = torch.tensor(t_vec,dtype=torch.float32).to('cuda')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "8f7ab832",
   "metadata": {},
   "outputs": [],
   "source": [
    "noised_bb, tv, ss = fdn(bb_dict,t_vec=t_vec, useR3=useR3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "c67e17dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "nd_2 = reverse_step(noised_bb, gu, batched_t, \n",
    "             gm, frame_diff=fdn, dt=0.01, denoise=False, cast = torch.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "c251b3c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "ndbb = noised_bb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "4c803260",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "30\n",
      "29\n",
      "28\n",
      "27\n",
      "26\n",
      "25\n",
      "24\n",
      "23\n",
      "22\n",
      "21\n",
      "20\n",
      "19\n",
      "18\n",
      "17\n",
      "16\n",
      "15\n",
      "14\n",
      "13\n",
      "12\n",
      "11\n",
      "10\n",
      "9\n",
      "8\n",
      "7\n",
      "6\n",
      "5\n",
      "4\n",
      "3\n",
      "2\n"
     ]
    }
   ],
   "source": [
    "while t>0.01:\n",
    "    \n",
    "    t_vec = np.ones(B,)*t\n",
    "    batched_t = torch.tensor(t_vec,dtype=torch.float32).to('cuda')\n",
    "    ndbb = reverse_step(ndbb, gu, batched_t, \n",
    "                        gm, frame_diff=fdn, dt=0.01, denoise=False, cast = torch.float32)\n",
    "    print(f'{t*100:.0f}')\n",
    "    t = t-.01\n",
    "    xyz = bbdict_to_coords(ndbb)\n",
    "    write_coord_pdb(xyz,name=f'out_{t*100:.0f}',limit=1)\n",
    "   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "f454b502",
   "metadata": {},
   "outputs": [],
   "source": [
    "def bbdict_to_coords(bb_dict_in):\n",
    "    \n",
    "    CA_  = bb_dict_in['CA'].reshape(B, L, 3).to('cuda')\n",
    "    NC_ = CA_ + bb_dict_in['N_CA'].reshape(B, L, 3).to('cuda')*N_CA_dist\n",
    "    CC_ = CA_ + bb_dict_in['C_CA'].reshape(B, L, 3).to('cuda')*C_CA_dist\n",
    "    xyz_cat =  torch.cat((NC_,CA_,CC_),dim=2).reshape(B,L,3,3)\n",
    "    \n",
    "    xyz_cat = xyz_cat.to('cpu').numpy()*10\n",
    "    \n",
    "    return xyz_cat\n",
    "\n",
    "def write_coord_pdb(xyz_in,name='coords',direc='output/',limit=2):\n",
    "    \n",
    "    for i,coords in enumerate(xyz_in):\n",
    "        if i>limit-1:\n",
    "            break\n",
    "        dump_coord_pdb(coords, fileOut=f'{direc}/{name}_{i}.pdb')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "c4b27b0d",
   "metadata": {},
   "outputs": [],
   "source": [
    "xyz1 = bbdict_to_coords(noised_bb)\n",
    "xyz2 = bbdict_to_coords(nd_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "0c15bd78",
   "metadata": {},
   "outputs": [],
   "source": [
    "write_coord_pdb(xyz1,name='start_0p3_')\n",
    "write_coord_pdb(xyz2,name='end_0p2_')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "717f703e",
   "metadata": {},
   "outputs": [],
   "source": [
    "    CA_n  = noised_dict['CA'].reshape(B, L, 3).to('cuda')\n",
    "    NC_n = CA_n + noised_dict['N_CA'].reshape(B, L, 3).to('cuda')*N_CA_dist\n",
    "    CC_n = CA_n + noised_dict['C_CA'].reshape(B, L, 3).to('cuda')*C_CA_dist\n",
    "    noise_xyz =  torch.cat((NC_n,CA_n,CC_n),dim=2).reshape(B,L,3,3)\n",
    "    \n",
    "    x = graph_maker.prep_for_network(noised_dict)\n",
    "    out = graph_unet(x, batched_t)\n",
    "    CA_p = out['1'][:,0,:].reshape(B, L, 3)+CA_n #translation of Calpha\n",
    "    Qs = out['1'][:,1,:] # rotation\n",
    "    Qs = Qs.unsqueeze(1).repeat((1,2,1))\n",
    "    Qs = torch.cat((torch.ones((B*L,2,1),device=Qs.device),Qs),dim=-1).reshape(B,L,2,4)\n",
    "    Qs = normQ(Qs)\n",
    "    Rs = Qs2Rs(Qs)\n",
    "    N_C_to_Rot = torch.cat((noised_dict['N_CA'].reshape(B, L, 3).to('cuda'),\n",
    "                            noised_dict['C_CA'].reshape(B, L, 3).to('cuda')),dim=2).reshape(B,L,2,1,3)\n",
    "\n",
    "    \n",
    "    rot_vecs = einsum('bnkij,bnkhj->bnki',Rs, N_C_to_Rot)\n",
    "    NC_p = CA_p + rot_vecs[:,:,0,:].to('cuda')*N_CA_dist\n",
    "    CC_p = CA_p + rot_vecs[:,:,1,:].reshape(B, L, 3).to('cuda')*C_CA_dist\n",
    "\n",
    "    pred = torch.cat((NC_p,CA_p,CC_p),dim=2).reshape(B,L,3,3)\n",
    "    \n",
    "    return true.to('cpu').numpy()*10, noise_xyz.to('cpu').numpy()*10, pred.detach().to('cpu').numpy()*10\n",
    "\n",
    "def dump_tnp(true, noise, pred, t_val, e=0, numOut=1,outdir='output/'):\n",
    "    \n",
    "    if numOut>true.shape[0]:\n",
    "        numOut = true.shape[0]\n",
    "    \n",
    "    for x in range(numOut):\n",
    "        dump_coord_pdb(true[x], fileOut=f'{outdir}/true_{t_val[x]*100:.0f}_e{e}_{x}.pdb')\n",
    "        dump_coord_pdb(noise[x], fileOut=f'{outdir}/noise_{t_val[x]*100:.0f}_e{e}_{x}.pdb')\n",
    "        dump_coord_pdb(pred[x], fileOut=f'{outdir}/pred_{t_val[x]*100:.0f}_e{e}_{x}.pdb')\n",
    "        \n",
    "def visualize_model(bb_dict, noised_bb, batched_t, epoch, numOut=1, outdir='output/'):\n",
    "    true, noise, pred = get_noise_pred_true(bb_dict, noised_bb, batched_t, gm, gu)\n",
    "    dump_tnp(true,noise,pred, batched_t, e=epoch, numOut=numOut, outdir=f'{outdir}/models/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3810a0c2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "7e93927f",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Helix4_Dataset(Dataset):\n",
    "    def __init__(self, coordinates: np.array, cast_type=torch.float32):\n",
    "        #prots,#length_prot in aa, #residues/aa, #xyz per atom\n",
    "           \n",
    "        #alphaFold reduce by 10\n",
    "        coord_div = 10\n",
    "        \n",
    "        coordinates = coordinates/coord_div\n",
    "        self.ca_coords = torch.tensor(coordinates[:,:,CA,:], dtype=cast_type)\n",
    "        #unsqueeze to stack together later\n",
    "        self.N_CA_vec = torch.tensor(coordinates[:,:,N,:] - coordinates[:,:,CA,:], dtype=cast_type)\n",
    "        self.C_CA_vec = torch.tensor(coordinates[:,:,C,:] - coordinates[:,:,CA,:], dtype=cast_type)\n",
    "        \n",
    "        self.N_CA_vec = torch_normalize(self.N_CA_vec).unsqueeze(2)\n",
    "        self.C_CA_vec = torch_normalize(self.C_CA_vec).unsqueeze(2)\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.ca_coords)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        return {'CA':self.ca_coords[idx], 'N_CA':self.N_CA_vec[idx], 'C_CA':self.C_CA_vec[idx]}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b50531e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Helix4_Dataset_Score(Dataset):\n",
    "    def __init__(self, coordinates: np.array, cast_type=torch.float32):\n",
    "        #prots,#length_prot in aa, #residues/aa, #xyz per atom\n",
    "           \n",
    "        #alphaFold style reduce by 10\n",
    "        coord_div = 10\n",
    "        \n",
    "        #center at zero\n",
    "        com  = (coordinates[:,:,CA,:].sum(axis=1)[:,None,:]/coordinates[:,:,CA,:].shape[1])[:,None,:]\n",
    "        coordinates = coordinates-com\n",
    "        \n",
    "        coordinates = coordinates/coord_div\n",
    "        self.ca_coords = torch.tensor(coordinates[:,:,CA,:], dtype=cast_type)\n",
    "        #unsqueeze to stack together later\n",
    "        self.N_CA_vec = torch.tensor(coordinates[:,:,N,:] - coordinates[:,:,CA,:], dtype=cast_type)\n",
    "        self.C_CA_vec = torch.tensor(coordinates[:,:,C,:] - coordinates[:,:,CA,:], dtype=cast_type)\n",
    "        \n",
    "        self.N_CA_vec = torch_normalize(self.N_CA_vec).unsqueeze(2)\n",
    "        self.C_CA_vec = torch_normalize(self.C_CA_vec).unsqueeze(2)\n",
    "        \n",
    "        self.rigids = torch.concatenate((torch.tensor(coordinates[:,:,N,:], dtype=cast_type).unsqueeze(2),\n",
    "                                         torch.tensor(coordinates[:,:,CA,:], dtype=cast_type).unsqueeze(2),\n",
    "                                         torch.tensor(coordinates[:,:,C,:], dtype=cast_type).unsqueeze(2)), dim=-2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc4f13fb",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e6e4ada",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b739ca65",
   "metadata": {},
   "outputs": [],
   "source": [
    "   def sample_ref(\n",
    "            self,\n",
    "            n_samples: int,\n",
    "            impute: ru.Rigid=None,\n",
    "            diffuse_mask: np.ndarray=None,\n",
    "            as_tensor_7: bool=False\n",
    "        ):\n",
    "        \"\"\"Samples rigids from reference distribution.\n",
    "\n",
    "        Args:\n",
    "            n_samples: Number of samples.\n",
    "            impute: Rigid objects to use as imputation values if either\n",
    "                translations or rotations are not diffused.\n",
    "        \"\"\"\n",
    "        if impute is not None:\n",
    "            assert impute.shape[0] == n_samples\n",
    "            trans_impute, rot_impute = _extract_trans_rots(impute)\n",
    "            trans_impute = trans_impute.reshape((n_samples, 3))\n",
    "            rot_impute = rot_impute.reshape((n_samples, 3))\n",
    "            trans_impute = self._r3_diffuser._scale(trans_impute)\n",
    "\n",
    "        if diffuse_mask is not None and impute is None:\n",
    "            raise ValueError('Must provide imputation values.')\n",
    "\n",
    "        if (not self._diffuse_rot) and impute is None:\n",
    "            raise ValueError('Must provide imputation values.')\n",
    "\n",
    "        if (not self._diffuse_trans) and impute is None:\n",
    "            raise ValueError('Must provide imputation values.')\n",
    "\n",
    "        if self._diffuse_rot:\n",
    "            rot_ref = self._so3_diffuser.sample_ref(\n",
    "                n_samples=n_samples)\n",
    "        else:\n",
    "            rot_ref = rot_impute\n",
    "\n",
    "        if self._diffuse_trans:\n",
    "            trans_ref = self._r3_diffuser.sample_ref(\n",
    "                n_samples=n_samples\n",
    "            )\n",
    "        else:\n",
    "            trans_ref = trans_impute\n",
    "\n",
    "        if diffuse_mask is not None:\n",
    "            rot_ref = self._apply_mask(\n",
    "                rot_ref, rot_impute, diffuse_mask[..., None])\n",
    "            trans_ref = self._apply_mask(\n",
    "                trans_ref, trans_impute, diffuse_mask[..., None])\n",
    "        trans_ref = self._r3_diffuser._unscale(trans_ref)\n",
    "        rigids_t = _assemble_rigid(rot_ref, trans_ref)\n",
    "        if as_tensor_7:\n",
    "            rigids_t = rigids_t.to_tensor_7()\n",
    "        return {'rigids_t': rigids_t}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "5bf81b42",
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'FrameDiffNoise' object has no attribute 'sample_ref'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[28], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mfdn\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msample_ref\u001b[49m(\u001b[38;5;241m32\u001b[39m)\n",
      "File \u001b[0;32m~/miniconda3/envs/se33/lib/python3.9/site-packages/torch/nn/modules/module.py:1614\u001b[0m, in \u001b[0;36mModule.__getattr__\u001b[0;34m(self, name)\u001b[0m\n\u001b[1;32m   1612\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m name \u001b[38;5;129;01min\u001b[39;00m modules:\n\u001b[1;32m   1613\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m modules[name]\n\u001b[0;32m-> 1614\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mAttributeError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m object has no attribute \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mformat(\n\u001b[1;32m   1615\u001b[0m     \u001b[38;5;28mtype\u001b[39m(\u001b[38;5;28mself\u001b[39m)\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m, name))\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'FrameDiffNoise' object has no attribute 'sample_ref'"
     ]
    }
   ],
   "source": [
    "fdn.sample_ref(32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fdeb8b5e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "539e748f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#visualize_T\n",
    "vis_t = np.array([0.01,0.05,0.1,0.2,0.3,0.5,0.8,1.0])\n",
    "vis_t = vis_t[None,...].repeat(int(np.ceil(B/len(vis_t))),axis=0).flatten()[:B]\n",
    "#vis_t =  torch.tensor(vis_t, dtype=torch.float32).to('cuda')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "67329384",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#load model\n",
    "model_path = '23Sep01_0242AM_full_diff_embed_T_btest'\n",
    "modelFile = 'model_e489'\n",
    "#opti = torch.optim.Adam(gu.parameters())\n",
    "device = 'cuda:0'\n",
    "gu.load_state_dict(torch.load(f'log/{model_path}/{modelFile}')['model'])\n",
    "#opti.load_state_dict(torch.load(f'log/{model_path}/{modelFile}')['optimizer'])\n",
    "#visualize_model(bb_dict, noised_bb, tv, 'test_start', numOut=8,outdir=f'output/')\n",
    "#visualize_model(bb_dict, noised_bb, tv, 'test_start', numOut=8,outdir=f'log/{model_path}')\n",
    "#save_chkpt(f'log/{model_path}/', gu, opti, 'test_start', B, avg_vloss, avg_tloss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "33c18fee",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_iter = iter(train_dL)\n",
    "test_batch = next(test_iter)\n",
    "\n",
    "t=0.05\n",
    "t_vec = np.ones((B,))*t\n",
    "nd, tv, ss = fdn(test_batch, t_vec=t_vec, useR3=False)\n",
    "\n",
    "tv = tv.to('cuda')\n",
    "# train_loss = model_step(bb_dict, noised_bb, tv, gm, gu)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "1df4be92",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/nwoodall/miniconda3/envs/se33/lib/python3.9/site-packages/dgl/backend/pytorch/tensor.py:449: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()\n",
      "  assert input.numel() == input.storage().size(), (\n"
     ]
    }
   ],
   "source": [
    "visualize_model(test_batch, nd, tv, 1000, numOut=1,outdir='output/')\n",
    "#save_chkpt(model_path, gu, opti, 1000, B, 0, 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "9f2adf25",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.05, 0.05, 0.05, 0.05, 0.05, 0.05, 0.05, 0.05, 0.05, 0.05, 0.05,\n",
       "       0.05, 0.05, 0.05, 0.05, 0.05, 0.05, 0.05, 0.05, 0.05, 0.05, 0.05,\n",
       "       0.05, 0.05, 0.05, 0.05, 0.05, 0.05, 0.05, 0.05, 0.05, 0.05])"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t_vec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "78b15462",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[25], line 20\u001b[0m\n\u001b[1;32m     18\u001b[0m train_loss \u001b[38;5;241m=\u001b[39m model_step(bb_dict, noised_bb, tv, ss, gm, gu)\n\u001b[1;32m     19\u001b[0m opti\u001b[38;5;241m.\u001b[39mzero_grad()\n\u001b[0;32m---> 20\u001b[0m \u001b[43mtrain_loss\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbackward\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     21\u001b[0m opti\u001b[38;5;241m.\u001b[39mstep()\n\u001b[1;32m     23\u001b[0m running_tloss \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m train_loss\u001b[38;5;241m.\u001b[39mdetach()\u001b[38;5;241m.\u001b[39mcpu()\n",
      "File \u001b[0;32m~/miniconda3/envs/se33/lib/python3.9/site-packages/torch/_tensor.py:487\u001b[0m, in \u001b[0;36mTensor.backward\u001b[0;34m(self, gradient, retain_graph, create_graph, inputs)\u001b[0m\n\u001b[1;32m    477\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m has_torch_function_unary(\u001b[38;5;28mself\u001b[39m):\n\u001b[1;32m    478\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m handle_torch_function(\n\u001b[1;32m    479\u001b[0m         Tensor\u001b[38;5;241m.\u001b[39mbackward,\n\u001b[1;32m    480\u001b[0m         (\u001b[38;5;28mself\u001b[39m,),\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    485\u001b[0m         inputs\u001b[38;5;241m=\u001b[39minputs,\n\u001b[1;32m    486\u001b[0m     )\n\u001b[0;32m--> 487\u001b[0m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mautograd\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbackward\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    488\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgradient\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mretain_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcreate_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minputs\u001b[49m\n\u001b[1;32m    489\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/envs/se33/lib/python3.9/site-packages/torch/autograd/__init__.py:200\u001b[0m, in \u001b[0;36mbackward\u001b[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001b[0m\n\u001b[1;32m    195\u001b[0m     retain_graph \u001b[38;5;241m=\u001b[39m create_graph\n\u001b[1;32m    197\u001b[0m \u001b[38;5;66;03m# The reason we repeat same the comment below is that\u001b[39;00m\n\u001b[1;32m    198\u001b[0m \u001b[38;5;66;03m# some Python versions print out the first line of a multi-line function\u001b[39;00m\n\u001b[1;32m    199\u001b[0m \u001b[38;5;66;03m# calls in the traceback and some print out the last line\u001b[39;00m\n\u001b[0;32m--> 200\u001b[0m \u001b[43mVariable\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_execution_engine\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun_backward\u001b[49m\u001b[43m(\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# Calls into the C++ engine to run the backward pass\u001b[39;49;00m\n\u001b[1;32m    201\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtensors\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgrad_tensors_\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mretain_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcreate_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    202\u001b[0m \u001b[43m    \u001b[49m\u001b[43mallow_unreachable\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maccumulate_grad\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "#t=0.1\n",
    "#t_vec = np.ones((B,))*t\n",
    "#print(t_vec)\n",
    "#model_path = make_save_folder(name=f'full_diff_embed_T_btest')\n",
    "num_epochs = 100\n",
    "e_start= 190\n",
    "save_per=10\n",
    "avg_vloss=0\n",
    "\n",
    "for e in range(e_start, e_start+num_epochs):\n",
    "    \n",
    "    running_tloss = 0 \n",
    "    start = time.time()\n",
    "    for i, bb_dict in enumerate(train_dL):\n",
    "        noised_bb, tv, ss = fdn(bb_dict,t_vec=None, useR3=useR3)\n",
    "        tv = tv.to('cuda')\n",
    "        ss = ss.to('cuda')\n",
    "        train_loss = model_step(bb_dict, noised_bb, tv, ss, gm, gu)\n",
    "        opti.zero_grad()\n",
    "        train_loss.backward()\n",
    "        opti.step()\n",
    "\n",
    "        running_tloss += train_loss.detach().cpu()\n",
    "    \n",
    "    end = time.time()\n",
    "    avg_tloss = running_tloss/(i+1)\n",
    "    print(f'Average Train Loss Epoch {e}: {avg_tloss};   Epoch time: {end-start:.0f}')\n",
    "\n",
    "    if e %save_per==save_per-1:\n",
    "        with torch.no_grad():\n",
    "            running_vloss = 0\n",
    "            for i, bb_dictv in enumerate(val_dL):\n",
    "                noised_bb, tv, ss = fdn(bb_dictv,t_vec=None, useR3=useR3)\n",
    "                tv = tv.to('cuda')\n",
    "                ss = ss.to('cuda')\n",
    "                valid_loss = model_step(bb_dictv, noised_bb, tv, ss, gm, gu)\n",
    "                running_vloss += valid_loss\n",
    "                \n",
    "        avg_vloss = running_vloss/(i+1)\n",
    "        print(f'Average Valid Loss Epoch {e}: {avg_vloss}')\n",
    "                \n",
    "        noised_bb, tv, ss = fdn(bb_dict, t_vec=vis_t)\n",
    "        tv = tv.to('cuda')\n",
    "        visualize_model(bb_dict, noised_bb, tv, e, numOut=8,outdir=f'log/{model_path}')\n",
    "        save_chkpt(f'log/{model_path}', gu, opti, e, B, avg_vloss, avg_tloss)\n",
    "#         visualize_model(bb_dict, noised_bb, tv, e, numOut=8,outdir=f'{model_path}')\n",
    "#         save_chkpt(f'{model_path}', gu, opti, e, B, avg_vloss, avg_tloss)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc618c49",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4cf435f6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2ce458c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e6ddcfc",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df7462d2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "cd433a11",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_iter = iter(train_dL)\n",
    "test_batch = next(test_iter)\n",
    "\n",
    "t=0.05\n",
    "t_vec = np.ones((B,))*t\n",
    "nd, tv, ss = fdn(test_batch, t_vec=t_vec, useR3=False)\n",
    "\n",
    "tv = tv.to('cuda')\n",
    "# train_loss = model_step(bb_dict, noised_bb, tv, gm, gu)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "4c7bbc63",
   "metadata": {},
   "outputs": [],
   "source": [
    "visualize_model(test_batch, nd, tv, 1000, numOut=8,outdir='output/')\n",
    "#save_chkpt('output/', gu, opti, 1000, B, 0, 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f356ac2a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21564364",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "4e13aa5f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#From\n",
    "#https://math.stackexchange.com/questions/939229/unit-quaternion-to-a-scalar-power\n",
    "\n",
    "#test code\n",
    "# Q = torch.tensor([0,0,1,0],dtype=torch.float)[None,None,None,...].repeat(2,3,2,1) #180 rotation about Y axis\n",
    "# rv = torch.tensor([[0,0,1]],dtype=torch.float)[None,None,...].repeat(2,3,2,1) #unit Z\n",
    "# Q = normQ(Q)\n",
    "#qp = powerQ(Q,0.5) rotate halfway (aka x-axis)\n",
    "#rv = rv.reshape((2,3,2,1,3))\n",
    "#rot_vecs = einsum('bnkij,bnkhj->bnki',Rs, rv) #should be x-axis\n",
    "\n",
    "def powerQ(quat_in, power):\n",
    "    \"\"\"Quaternion to the power, represent number of times to rotate Q. Only works on unit Q\"\"\"\n",
    "    return expQ(scaleQ(lnQ(quat_in),power))\n",
    "\n",
    "\n",
    "def expQ(quat_in, eps=1e-9):\n",
    "    quat_out = torch.zeros_like(quat_in, device=quat_in.device)\n",
    "    r = torch.sqrt(torch.sum(torch.square(quat_in[...,1:]),axis=-1,keepdim=True)+eps)\n",
    "    et = torch.exp(quat_in[...,0][...,None])\n",
    "    s = et*torch.sin(r)/r\n",
    "    s[torch.where(r<eps)[0]] = 0\n",
    "    \n",
    "    quat_out[...,0][...,None] = et*torch.cos(r)\n",
    "    quat_out[...,1] = s[...,0]*quat_in[...,1]\n",
    "    quat_out[...,2] = s[...,0]*quat_in[...,2]\n",
    "    quat_out[...,3] = s[...,0]*quat_in[...,3]\n",
    "    \n",
    "    return quat_out\n",
    "\n",
    "#fix in other location w calc\n",
    "def lnQ(quat_in, eps=1e-9):\n",
    "    quat_out = torch.zeros_like(quat_in, device=quat_in.device)\n",
    "    r = torch.sqrt(torch.sum(torch.square(quat_in[...,1:]),axis=-1,keepdim=True)+eps)\n",
    "    t = torch.atan2(r,quat_in[...,0][...,None])/r\n",
    "    t[torch.where(r<eps)[0]] = 0\n",
    "        \n",
    "    quat_out[...,0][...,None] = 0.5*torch.log(torch.sum(torch.square(quat_in),axis=-1,keepdim=True)+eps)\n",
    "    quat_out[...,1] = t[...,0]*quat_in[...,1]\n",
    "    quat_out[...,2] = t[...,0]*quat_in[...,2]\n",
    "    quat_out[...,3] = t[...,0]*quat_in[...,3]\n",
    "    \n",
    "    return quat_out\n",
    "    \n",
    "\n",
    "def scaleQ(quat_in, scale):\n",
    "    return torch.multiply(quat_in,scale)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26b7b65e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1db68d9c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fbc0c239",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "652bd82b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def model_step(backbone_dict, noised_dict, batched_t, scores_scales, graph_maker, graph_unet, train=True):\n",
    "    \n",
    "    CA_t  = backbone_dict['CA'].reshape(B, L, 3).to('cuda')\n",
    "    NC_t = CA_t + backbone_dict['N_CA'].reshape(B, L, 3).to('cuda')\n",
    "    CC_t = CA_t + backbone_dict['C_CA'].reshape(B, L, 3).to('cuda')\n",
    "    true =  torch.cat((NC_t,CA_t,CC_t),dim=2).reshape(B,L,3,3)\n",
    "    \n",
    "    CA_n  = noised_dict['CA'].reshape(B, L, 3).to('cuda')\n",
    "    NC_n = CA_n + noised_dict['N_CA'].reshape(B, L, 3).to('cuda')\n",
    "    CC_n = CA_n + noised_dict['C_CA'].reshape(B, L, 3).to('cuda')\n",
    "    noise_xyz =  torch.cat((NC_n,CA_n,CC_n),dim=2).reshape(B,L,3,3)\n",
    "    \n",
    "    x = graph_maker.prep_for_network(noised_dict)\n",
    "    out = graph_unet(x, batched_t)\n",
    "    CA_p = out['1'][:,0,:].reshape(B, L, 3)+CA_n #translation of Calpha\n",
    "    Qs = out['1'][:,1,:] # rotation\n",
    "    Qs = Qs.unsqueeze(1).repeat((1,2,1))\n",
    "    Qs = torch.cat((torch.ones((B*L,2,1),device=Qs.device),Qs),dim=-1).reshape(B,L,2,4)\n",
    "    Qs = normQ(Qs)\n",
    "    Rs = Qs2Rs(Qs)\n",
    "    N_C_to_Rot = torch.cat((noised_dict['N_CA'].reshape(B, L, 3).to('cuda'),\n",
    "                            noised_dict['C_CA'].reshape(B, L, 3).to('cuda')),dim=2).reshape(B,L,2,1,3)\n",
    "\n",
    "    \n",
    "    \n",
    "    rot_vecs = einsum('bnkij,bnkhj->bnki',Rs, N_C_to_Rot)\n",
    "    NC_p = CA_p + rot_vecs[:,:,0,:].to('cuda')*N_CA_dist\n",
    "    CC_p = CA_p + rot_vecs[:,:,1,:].reshape(B, L, 3).to('cuda')*C_CA_dist\n",
    "\n",
    "    pred = torch.cat((NC_p,CA_p,CC_p),dim=2).reshape(B,L,3,3)\n",
    "    \n",
    "    tloss, loss = FAPE_loss(pred.unsqueeze(0), true, scores_scales)\n",
    "    \n",
    "    return tloss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "55e49b75",
   "metadata": {},
   "outputs": [],
   "source": [
    "def noise_test(backbone_dict, noised_dict):\n",
    "    CA_t  = bb_dict['CA'].reshape(B, L, 3).to('cuda')\n",
    "    NC_t = CA_t + bb_dict['N_CA'].reshape(B, L, 3).to('cuda')*N_CA_dist\n",
    "    CC_t = CA_t + bb_dict['C_CA'].reshape(B, L, 3).to('cuda')*C_CA_dist\n",
    "    true =  torch.cat((NC_t,CA_t,CC_t),dim=2).reshape(B,L,3,3)\n",
    "    \n",
    "    CA_n  = noised_dict['CA'].reshape(B, L, 3).to('cuda')\n",
    "    NC_n = CA_n + noised_dict['N_CA'].reshape(B, L, 3).to('cuda')*N_CA_dist\n",
    "    CC_n = CA_n + noised_dict['C_CA'].reshape(B, L, 3).to('cuda')*C_CA_dist\n",
    "    noise_xyz =  torch.cat((NC_n,CA_n,CC_n),dim=2).reshape(B,L,3,3)\n",
    "    return true.to('cpu').numpy()*10, noise_xyz.to('cpu').numpy()*10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "00d45bb6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from util.npose_util import makePointPDB\n",
    "#gds = Graph_RadiusMP_4H_Dataset(coords_tog[:100], 10, mp_stride = 3)\n",
    "def view_mp_graph(mps: DGLGraph, coords: np.array ):\n",
    "    p = mps.ndata['pos']*10\n",
    "    \n",
    "    to = np.concatenate((coords, np.ones_like(coords)[:,:,0][...,None]),axis=2)\n",
    "    \n",
    "    makePointPDB(p,'test.pdb',outDirec='output')\n",
    "    nu.dump_npdb(to,'output/test2.pdb')\n",
    "#view_mp_graph(gds.mpSelfGraphList[0], coords_tog[0])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "se33",
   "language": "python",
   "name": "se33"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
