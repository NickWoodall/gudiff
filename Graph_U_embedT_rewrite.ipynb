{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a02a1c0f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "#clear memory better\n",
    "with torch.no_grad():\n",
    "    torch.cuda.empty_cache()\n",
    "import numpy as np\n",
    "import util.npose_util as nu\n",
    "import os\n",
    "import pathlib\n",
    "import dgl\n",
    "from dgl import backend as F\n",
    "import torch_geometric\n",
    "from torch.utils.data import random_split, DataLoader, Dataset\n",
    "from typing import Dict\n",
    "from torch import Tensor\n",
    "from dgl import DGLGraph\n",
    "from torch import nn\n",
    "# from chemical import cos_ideal_NCAC #from RoseTTAFold2\n",
    "from torch import einsum\n",
    "import time\n",
    "torch.cuda.is_available()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "33e16cff",
   "metadata": {},
   "outputs": [],
   "source": [
    "import se3_diffuse.utils as du"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6a31f547",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from data_rigid_diffuser import so3_diffuser\n",
    "# from data_rigid_diffuser import r3_diffuser\n",
    "# from scipy.spatial.transform import Rotation\n",
    "# from data_rigid_diffuser import rigid_utils as ru\n",
    "# import yaml\n",
    "from data_rigid_diffuser.diffuser import FrameDiffNoise\n",
    "from gudiff_model import Data_Graph\n",
    "from gudiff_model.Data_Graph import build_npose_from_coords, dump_coord_pdb, define_graph_edges, make_pe_encoding\n",
    "from gudiff_model.Data_Graph import Helix4_Dataset, Make_KNN_MP_Graphs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "bf443f63",
   "metadata": {},
   "outputs": [],
   "source": [
    "from se3_transformer.model.basis import get_basis, update_basis_with_fused\n",
    "from se3_transformer.model.transformer import Sequential, SE3Transformer\n",
    "from se3_transformer.model.transformer_topk import SE3Transformer_topK\n",
    "from se3_transformer.model.FAPE_Loss import FAPE_loss, Qs2Rs, normQ\n",
    "from se3_transformer.model.layers.attentiontopK import AttentionBlockSE3\n",
    "from se3_transformer.model.layers.linear import LinearSE3\n",
    "from se3_transformer.model.layers.convolution import ConvSE3, ConvSE3FuseLevel\n",
    "from se3_transformer.model.layers.norm import NormSE3\n",
    "from se3_transformer.model.layers.pooling import GPooling, Latent_Unpool, Unpool_Layer\n",
    "from se3_transformer.runtime.utils import str2bool, to_cuda\n",
    "from se3_transformer.model.fiber import Fiber\n",
    "from se3_transformer.model.transformer import get_populated_edge_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c0babffd",
   "metadata": {},
   "outputs": [],
   "source": [
    "#indices for, unsure if needed\n",
    "CA = Data_Graph.CA\n",
    "N = Data_Graph.N\n",
    "C = Data_Graph.C\n",
    "\n",
    "#find better way to incorporate coord_scale\n",
    "\n",
    "#needed\n",
    "N_CA_dist = (Data_Graph.N_CA_dist/10.).to('cuda')\n",
    "C_CA_dist = (Data_Graph.C_CA_dist/10.).to('cuda')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e213e885",
   "metadata": {},
   "outputs": [],
   "source": [
    "# data_path_str  = 'data/h4_ca_coords.npz'\n",
    "# test_limit = 1028\n",
    "# rr = np.load(data_path_str)\n",
    "# ca_coords = [rr[f] for f in rr.files][0][:test_limit,:,:3]\n",
    "# ca_coords.shape\n",
    "\n",
    "# getting N-Ca, Ca-C vectors to add as typeI features\n",
    "#apa = apart helices for val/train split\n",
    "#tog = together helices for val/train split\n",
    "apa_path_str  = 'data_npose/h4_apa_coords.npz'\n",
    "tog_path_str  = 'data_npose/h4_tog_coords.npz'\n",
    "\n",
    "#grab the first 3 atoms which are N,CA,C\n",
    "test_limit = 5028\n",
    "rr = np.load(apa_path_str)\n",
    "coords_apa = [rr[f] for f in rr.files][0][:test_limit,:]\n",
    "\n",
    "rr = np.load(tog_path_str)\n",
    "coords_tog = [rr[f] for f in rr.files][0][:test_limit,:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "2b9195dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "from gudiff_model.Graph_UNet import GraphUNet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "a5a815da",
   "metadata": {},
   "outputs": [],
   "source": [
    "def model_step(backbone_dict, noised_dict, batched_t, scores_scales, graph_maker, graph_unet, train=True):\n",
    "    \n",
    "    \n",
    "    CA_t  = backbone_dict['CA'].reshape(B, L, 3).to('cuda')\n",
    "    NC_t = CA_t + backbone_dict['N_CA'].reshape(B, L, 3).to('cuda')#not mult earlier #th\n",
    "    CC_t = CA_t + backbone_dict['C_CA'].reshape(B, L, 3).to('cuda')#not mult earlier\n",
    "    true =  torch.cat((NC_t,CA_t,CC_t),dim=2).reshape(B,L,3,3)\n",
    "    \n",
    "    CA_n  = noised_dict['CA'].reshape(B, L, 3).to('cuda')\n",
    "    NC_n = CA_n + noised_dict['N_CA'].reshape(B, L, 3).to('cuda')\n",
    "    CC_n = CA_n + noised_dict['C_CA'].reshape(B, L, 3).to('cuda')\n",
    "    noise_xyz =  torch.cat((NC_n,CA_n,CC_n),dim=2).reshape(B,L,3,3)\n",
    "    \n",
    "#     #rot mask for high T\n",
    "#     rot_t_max = 0.2\n",
    "#     t_mask = (batched_t>rot_t_max).to('cpu')\n",
    "#     noised_dict['N_CA'][t_mask] = backbone_dict['N_CA'].reshape(B, L,1, 3)[t_mask]\n",
    "#     noised_dict['C_CA'][t_mask] = backbone_dict['C_CA'].reshape(B, L,1, 3)[t_mask]\n",
    "    \n",
    "    x = graph_maker.prep_for_network(noised_dict)\n",
    "    out = graph_unet(x, batched_t)\n",
    "    CA_p = out['1'][:,0,:].reshape(B, L, 3)+CA_n #translation of Calpha\n",
    "    Qs = out['1'][:,1,:] # rotation\n",
    "    Qs = Qs.unsqueeze(1).repeat((1,2,1))\n",
    "    Qs = torch.cat((torch.ones((B*L,2,1),device=Qs.device),Qs),dim=-1).reshape(B,L,2,4)\n",
    "    Qs = normQ(Qs)\n",
    "    Rs = Qs2Rs(Qs)\n",
    "    N_C_to_Rot = torch.cat((noised_dict['N_CA'].reshape(B, L, 3).to('cuda'),\n",
    "                            noised_dict['C_CA'].reshape(B, L, 3).to('cuda')),dim=2).reshape(B,L,2,1,3)\n",
    "\n",
    "    \n",
    "    \n",
    "    rot_vecs = einsum('bnkij,bnkhj->bnki',Rs, N_C_to_Rot)\n",
    "    \n",
    "\n",
    "    \n",
    "    NC_p = CA_p + rot_vecs[:,:,0,:]*N_CA_dist #remove bc who cares? me maybe\n",
    "    CC_p = CA_p + rot_vecs[:,:,1,:]*C_CA_dist #remove maybe\n",
    "\n",
    "    pred = torch.cat((NC_p,CA_p,CC_p),dim=2).reshape(B,L,3,3)\n",
    "    \n",
    "    tloss, loss = FAPE_loss(pred.unsqueeze(0), true, scores_scales)\n",
    "    #tloss, loss = FAPE_loss(pred.unsqueeze(0), true, scores_scales)\n",
    "    \n",
    "    return tloss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "02f23891",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_noise_pred_true(backbone_dict, noised_dict, batched_t, graph_maker, graph_unet):\n",
    "    \n",
    "    CA_t  = backbone_dict['CA'].reshape(B, L, 3).to('cuda')\n",
    "    NC_t = CA_t + backbone_dict['N_CA'].reshape(B, L, 3).to('cuda')*N_CA_dist\n",
    "    CC_t = CA_t + backbone_dict['C_CA'].reshape(B, L, 3).to('cuda')*C_CA_dist\n",
    "    true =  torch.cat((NC_t,CA_t,CC_t),dim=2).reshape(B,L,3,3)\n",
    "    \n",
    "    CA_n  = noised_dict['CA'].reshape(B, L, 3).to('cuda')\n",
    "    NC_n = CA_n + noised_dict['N_CA'].reshape(B, L, 3).to('cuda')*N_CA_dist\n",
    "    CC_n = CA_n + noised_dict['C_CA'].reshape(B, L, 3).to('cuda')*C_CA_dist\n",
    "    noise_xyz =  torch.cat((NC_n,CA_n,CC_n),dim=2).reshape(B,L,3,3)\n",
    "    \n",
    "    x = graph_maker.prep_for_network(noised_dict)\n",
    "    out = graph_unet(x, batched_t)\n",
    "    CA_p = out['1'][:,0,:].reshape(B, L, 3)+CA_n #translation of Calpha\n",
    "    Qs = out['1'][:,1,:] # rotation\n",
    "    Qs = Qs.unsqueeze(1).repeat((1,2,1))\n",
    "    Qs = torch.cat((torch.ones((B*L,2,1),device=Qs.device),Qs),dim=-1).reshape(B,L,2,4)\n",
    "    Qs = normQ(Qs)\n",
    "    Rs = Qs2Rs(Qs)\n",
    "    N_C_to_Rot = torch.cat((noised_dict['N_CA'].reshape(B, L, 3).to('cuda'),\n",
    "                            noised_dict['C_CA'].reshape(B, L, 3).to('cuda')),dim=2).reshape(B,L,2,1,3)\n",
    "\n",
    "    \n",
    "    rot_vecs = einsum('bnkij,bnkhj->bnki',Rs, N_C_to_Rot)\n",
    "    NC_p = CA_p + rot_vecs[:,:,0,:].to('cuda')*N_CA_dist\n",
    "    CC_p = CA_p + rot_vecs[:,:,1,:].reshape(B, L, 3).to('cuda')*C_CA_dist\n",
    "\n",
    "    pred = torch.cat((NC_p,CA_p,CC_p),dim=2).reshape(B,L,3,3)\n",
    "    \n",
    "    return true.to('cpu').numpy()*10, noise_xyz.to('cpu').numpy()*10, pred.detach().to('cpu').numpy()*10\n",
    "\n",
    "def dump_tnp(true, noise, pred, t_val, e=0, numOut=1,outdir='output/'):\n",
    "    \n",
    "    if numOut>true.shape[0]:\n",
    "        numOut = true.shape[0]\n",
    "    \n",
    "    for x in range(numOut):\n",
    "        dump_coord_pdb(true[x], fileOut=f'{outdir}/true_{t_val[x]*100:.0f}_e{e}_{x}.pdb')\n",
    "        dump_coord_pdb(noise[x], fileOut=f'{outdir}/noise_{t_val[x]*100:.0f}_e{e}_{x}.pdb')\n",
    "        dump_coord_pdb(pred[x], fileOut=f'{outdir}/pred_{t_val[x]*100:.0f}_e{e}_{x}.pdb')\n",
    "        \n",
    "def visualize_model(bb_dict, noised_bb, batched_t, epoch, numOut=1, outdir='output/'):\n",
    "    true, noise, pred = get_noise_pred_true(bb_dict, noised_bb, batched_t, gm, gu)\n",
    "    dump_tnp(true,noise,pred, batched_t, e=epoch, numOut=numOut, outdir=f'{outdir}/models/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "5d28184c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_save_folder(name=''):\n",
    "    base_folder = time.strftime(f'log/%y%b%d_%I%M%p_{name}/', time.localtime())\n",
    "    if not os.path.exists(base_folder):\n",
    "        os.makedirs(base_folder)\n",
    "    subfolders = ['models']\n",
    "    for subfolder in subfolders:\n",
    "        if not os.path.exists(base_folder + subfolder):\n",
    "            os.makedirs(base_folder + subfolder)\n",
    "            \n",
    "    return base_folder\n",
    "        \n",
    "def save_chkpt(model_path, model, optimizer, epoch, batch, val_losses, train_losses):\n",
    "    \"\"\"Save a training checkpoint\n",
    "    Args:\n",
    "        model_path (str): the path to save the model to\n",
    "        model (nn.Module): the model to save\n",
    "        optimizer (torch.optim.Optimizer): the optimizer to save\n",
    "        epoch (int): the current epoch\n",
    "        batch (int): the current batch in the epoch\n",
    "        loss_domain (list of int): a list of the shared domain for val and training \n",
    "            losses\n",
    "        val_losses (list of float): a list containing the validation losses\n",
    "        train_losses (list of float): a list containing the training losses\n",
    "    \"\"\"\n",
    "    os.makedirs(os.path.dirname(model_path), exist_ok=True)\n",
    "    state_dict = dict()\n",
    "    state_dict.update({'model':model.state_dict(),\n",
    "                       'optimizer':optimizer.state_dict(),\n",
    "                       'epoch':epoch,\n",
    "                       'batch':batch,\n",
    "                       'train_losses':train_losses,\n",
    "                       'val_losses':val_losses\n",
    "                       })\n",
    "    torch.save(state_dict, f'{model_path}model_e{epoch}')\n",
    "    \n",
    "def load_model(model_path, model_class):\n",
    "    \"\"\"Load a saved model\"\"\"\n",
    "    \n",
    "    device = 'cuda:0'\n",
    "    model = model_class()\n",
    "    model.load_state_dict(torch.load(model_path)['model'])\n",
    "    model.to(device)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "149c44dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "B = 32\n",
    "L=65\n",
    "limit = 5028\n",
    "h4_trainData = Helix4_Dataset(coords_tog[:limit])\n",
    "h4_valData = Helix4_Dataset(coords_apa[:limit])\n",
    "train_dL = DataLoader(h4_trainData, batch_size=B, shuffle=True, drop_last=True)\n",
    "val_dL   = DataLoader(h4_valData, batch_size=B, shuffle=True, drop_last=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "58ac8828",
   "metadata": {},
   "outputs": [],
   "source": [
    "gu = GraphUNet(batch_size = B, num_layers_ca = 2).to('cuda')\n",
    "opti = torch.optim.Adam(gu.parameters(), lr=0.0005, weight_decay=5e-6) #prev lr=0.0005\n",
    "gm = Make_KNN_MP_Graphs() #consider precalculating graphs for training\n",
    "fdn= FrameDiffNoise()\n",
    "useR3 = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "b5faf34a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#visualize_T\n",
    "vis_t = np.array([0.01,0.05,0.1,0.2,0.3,0.5,0.8,1.0])\n",
    "vis_t = vis_t[None,...].repeat(int(np.ceil(B/len(vis_t))),axis=0).flatten()[:B]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "748495b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "#t=0.1\n",
    "#t_vec = np.ones((B,))*t\n",
    "#print(t_vec)\n",
    "#model_path = make_save_folder(name=f'fdiff_modelStep_rot_remove')\n",
    "# num_epochs = 200\n",
    "# e_start= 209\n",
    "# save_per=10\n",
    "# avg_vloss=0\n",
    "\n",
    "# for e in range(e_start, e_start+num_epochs):\n",
    "    \n",
    "#     running_tloss = 0 \n",
    "#     start = time.time()\n",
    "#     for i, bb_dict in enumerate(train_dL):\n",
    "#         noised_bb, tv, ss = fdn(bb_dict,t_vec=None, useR3=useR3)\n",
    "#         tv = tv.to('cuda')\n",
    "#         ss = ss.to('cuda')\n",
    "#         train_loss = model_step(bb_dict, noised_bb, tv, ss, gm, gu)\n",
    "#         opti.zero_grad()\n",
    "#         train_loss.backward()\n",
    "#         opti.step()\n",
    "\n",
    "#         running_tloss += train_loss.detach().cpu()\n",
    "    \n",
    "#     end = time.time()\n",
    "#     avg_tloss = running_tloss/(i+1)\n",
    "#     print(f'Average Train Loss Epoch {e}: {avg_tloss};   Epoch time: {end-start:.0f}')\n",
    "\n",
    "#     if e %save_per==save_per-1:\n",
    "#         with torch.no_grad():\n",
    "#             running_vloss = 0\n",
    "#             for i, bb_dictv in enumerate(val_dL):\n",
    "#                 noised_bb, tv, ss = fdn(bb_dictv,t_vec=None, useR3=useR3) #this does the opposite of traditional, upweighting lower\n",
    "#                 tv = tv.to('cuda')\n",
    "#                 ss = ss.to('cuda')\n",
    "#                 valid_loss = model_step(bb_dictv, noised_bb, tv, ss, gm, gu)\n",
    "#                 running_vloss += valid_loss\n",
    "                \n",
    "#         avg_vloss = running_vloss/(i+1)\n",
    "#         print(f'Average Valid Loss Epoch {e}: {avg_vloss}')\n",
    "                \n",
    "#         noised_bb, tv, ss = fdn(bb_dict, t_vec=vis_t)\n",
    "#         tv = tv.to('cuda')\n",
    "#         visualize_model(bb_dict, noised_bb, tv, e, numOut=8,outdir=f'{model_path}')\n",
    "#         save_chkpt(f'{model_path}', gu, opti, e, B, avg_vloss, avg_tloss)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "6d4cc89e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#calculate score from noise, pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "e673b171",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#load model\n",
    "model_path = '23Sep01_0242AM_full_diff_embed_T_btest'\n",
    "modelFile = 'model_e489'\n",
    "#opti = torch.optim.Adam(gu.parameters())\n",
    "device = 'cuda:0'\n",
    "gu.load_state_dict(torch.load(f'log/{model_path}/{modelFile}')['model'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "a4329845",
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.spatial.transform import Rotation\n",
    "from se3_diffuse import rigid_utils as ru\n",
    "#stubs for starting relative NC_CC vecs\n",
    "stub = np.array([[-1.45837285,  0 , 0],         #N\n",
    "         [0., 0., 0.],                 #CA\n",
    "        [0.55221403, 1.41890368, 0. ]] ) #C\n",
    "nca_stub = Data_Graph.torch_normalize(torch.tensor(stub[0]-stub[1]))\n",
    "cca_stub = Data_Graph.torch_normalize(torch.tensor(stub[2]-stub[1]))\n",
    "\n",
    "ncs = nca_stub[None,None,None,:].repeat(B,L,1,1)\n",
    "ccs = cca_stub[None,None,None,:].repeat(B,L,1,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "4799e54b",
   "metadata": {},
   "outputs": [],
   "source": [
    "cast = torch.float32\n",
    "bb_dict = {'CA': np.zeros((B,L,3)), 'N_CA': ncs.clone() , 'C_CA': ccs.clone()}\n",
    "\n",
    "batched_t = torch.tensor(np.ones((B,)),dtype=cast,device='cuda')\n",
    "rot_ref = fdn.so3d.sample_ref(n_samples=B*L)\n",
    "trans_ref = fdn.r3d.sample_ref(n_samples=B*L)\n",
    "\n",
    "batch_shape =  ncs.shape\n",
    "rotmat = Rotation.from_rotvec(rot_ref).as_matrix()\n",
    "nc_vec = ru.rot_vec_mul(torch.tensor(rotmat,dtype=cast),ncs.reshape((-1,3))).reshape(batch_shape)\n",
    "cc_vec = ru.rot_vec_mul(torch.tensor(rotmat,dtype=cast),ccs.reshape((-1,3))).reshape(batch_shape)\n",
    "\n",
    "noised_dict = {'CA':torch.tensor(trans_ref,dtype=cast).reshape(B,L,-1), \n",
    "               'N_CA':nc_vec.type(cast),\n",
    "               'C_CA':cc_vec.type(cast)}\n",
    "\n",
    "\n",
    "CA_n  = noised_dict['CA'].reshape(B, L, 3).to('cuda')\n",
    "NC_n = CA_n + noised_dict['N_CA'].reshape(B, L, 3).to('cuda')*N_CA_dist\n",
    "CC_n = CA_n + noised_dict['C_CA'].reshape(B, L, 3).to('cuda')*C_CA_dist\n",
    "rigids_init =  ru.Rigid.from_3_points(NC_n,CA_n,CC_n)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "335e4a01",
   "metadata": {},
   "outputs": [],
   "source": [
    "#get rots from sample ref\n",
    "def _extract_trans_rots(rigid: ru.Rigid):\n",
    "    rot = rigid.get_rots().get_rot_mats().cpu().numpy()\n",
    "    rot_shape = rot.shape\n",
    "    num_rots = np.cumprod(rot_shape[:-2])[-1]\n",
    "    rot = rot.reshape((num_rots, 3, 3))\n",
    "    rot = Rotation.from_matrix(rot).as_rotvec().reshape(rot_shape[:-2] +(3,))\n",
    "    tran = rigid.get_trans().cpu().numpy()\n",
    "    return tran, rot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "3b18ad0d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/nwoodall/miniconda3/envs/se33/lib/python3.9/site-packages/dgl/backend/pytorch/tensor.py:449: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()\n",
      "  assert input.numel() == input.storage().size(), (\n"
     ]
    }
   ],
   "source": [
    "#model_step = \n",
    "\n",
    "cast = torch.float32\n",
    "\n",
    "CA_n = noised_dict['CA'].to('cuda')\n",
    "\n",
    "\n",
    "x = gm.prep_for_network(noised_dict)\n",
    "\n",
    "\n",
    "out = gu(x, batched_t)\n",
    "CA_p = out['1'][:,0,:].reshape(B, L, 3)+CA_n #translation of Calpha\n",
    "Qs = out['1'][:,1,:] # rotation\n",
    "Qs = Qs.unsqueeze(1).repeat((1,2,1))\n",
    "Qs = torch.cat((torch.ones((B*L,2,1),device=Qs.device),Qs),dim=-1).reshape(B,L,2,4)\n",
    "Qs = normQ(Qs)\n",
    "Rs = Qs2Rs(Qs)\n",
    "N_C_to_Rot = torch.cat((noised_dict['N_CA'].reshape(B, L, 3).to('cuda'),\n",
    "                        noised_dict['C_CA'].reshape(B, L, 3).to('cuda')),dim=2).reshape(B,L,2,1,3)\n",
    "\n",
    "\n",
    "\n",
    "rot_vecs = einsum('bnkij,bnkhj->bnki',Rs, N_C_to_Rot)\n",
    "NC_p = CA_p + rot_vecs[:,:,0,:].to('cuda')*N_CA_dist\n",
    "CC_p = CA_p + rot_vecs[:,:,1,:].reshape(B, L, 3).to('cuda')*C_CA_dist\n",
    "\n",
    "pred = torch.cat((NC_p,CA_p,CC_p),dim=2).reshape(B,L,3,3)\n",
    "rigids_cur = ru.Rigid.from_3_points(NC_p,CA_p,CC_p)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "dbc564a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "trans_score, rot_score = fdn.score(rigids_cur, rigids_init,batched_t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "82c50cc8",
   "metadata": {},
   "outputs": [],
   "source": [
    "trans_t, rot_t = _extract_trans_rots(rigids_init)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "d75c2321",
   "metadata": {},
   "outputs": [],
   "source": [
    "rots_t = rigids_init.get_rots()\n",
    "rots_0 = rigids_cur.get_rots()\n",
    "\n",
    "rots_0_inv = rots_0.invert()\n",
    "quats_0_inv = rots_0_inv.get_quats()\n",
    "quats_t = rots_t.get_quats()\n",
    "quats_0t = ru.quat_multiply(quats_0_inv, quats_t)\n",
    "rotvec_0t = du.quat_to_rotvec(quats_0t)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "a0273691",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([32, 65, 3])"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rotvec_0t.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "98f4fb25",
   "metadata": {},
   "outputs": [],
   "source": [
    "rot_score = fdn.so3d.torch_score(rotvec_0t, batched_t)\n",
    "        \n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "b92c8dbe",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([32, 65, 3])"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rot_score.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ad626f0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b57790f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "f87859ab",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([32, 65, 3])"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rot_score.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "d0688b4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "trans_t_1 = fdn.r3d.reverse_old(x_t=trans_t,\n",
    "                    score_t=trans_score.detach().numpy(),\n",
    "                    t=1,\n",
    "                    dt=0.01,\n",
    "                    center=True,\n",
    "                    noise_scale=0)\n",
    "\n",
    "rot_t_1 = fdn.so3d.reverse_old(rot_t=rot_t,\n",
    "                               score_t=rot_score.cpu().detach().numpy(),\n",
    "                               t=1, dt=0.01,noise_scale=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "368621d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def reverse(\n",
    "            self,\n",
    "            rigid_t: ru.Rigid,\n",
    "            rot_score: np.ndarray,\n",
    "            trans_score: np.ndarray,\n",
    "            t: float,\n",
    "            dt: float,\n",
    "            diffuse_mask: np.ndarray = None,\n",
    "            center: bool=True,\n",
    "            noise_scale: float=1.0,\n",
    "        ):\n",
    "        \"\"\"Reverse sampling function from (t) to (t-1).\n",
    "\n",
    "        Args:\n",
    "            rigid_t: [..., N] protein rigid objects at time t.\n",
    "            rot_score: [..., N, 3] rotation score.\n",
    "            trans_score: [..., N, 3] translation score.\n",
    "            t: continuous time in [0, 1].\n",
    "            dt: continuous step size in [0, 1].\n",
    "            mask: [..., N] which residues to update.\n",
    "            center: true to set center of mass to zero after step\n",
    "\n",
    "        Returns:\n",
    "            rigid_t_1: [..., N] protein rigid objects at time t-1.\n",
    "        \"\"\"\n",
    "        trans_t, rot_t = _extract_trans_rots(rigid_t)\n",
    "        if not self._diffuse_rot:\n",
    "            rot_t_1 = rot_t\n",
    "        else:\n",
    "            rot_t_1 = self._so3_diffuser.reverse(\n",
    "                rot_t=rot_t,\n",
    "                score_t=rot_score,\n",
    "                t=t,\n",
    "                dt=dt,\n",
    "                noise_scale=noise_scale,\n",
    "                )\n",
    "        if not self._diffuse_trans:\n",
    "            trans_t_1 = trans_t\n",
    "        else:\n",
    "            trans_t_1 = self._r3_diffuser.reverse(\n",
    "                x_t=trans_t,\n",
    "                score_t=trans_score,\n",
    "                t=t,\n",
    "                dt=dt,\n",
    "                center=center,\n",
    "                noise_scale=noise_scale\n",
    "                )\n",
    "\n",
    "        if diffuse_mask is not None:\n",
    "            trans_t_1 = self._apply_mask(\n",
    "                trans_t_1, trans_t, diffuse_mask[..., None])\n",
    "            rot_t_1 = self._apply_mask(\n",
    "                rot_t_1, rot_t, diffuse_mask[..., None])\n",
    "\n",
    "        return _assemble_rigid(rot_t_1, trans_t_1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "a75c130c",
   "metadata": {},
   "outputs": [],
   "source": [
    "trans_score = fdn.r3d.score(rigids_cur.get_trans().cpu(), rigids_init.get_trans().cpu(), \n",
    "                            batched_t[:,None,None].repeat((1,L,3)).cpu())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "0340a2a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "rots_t = rigids_init.get_rots()\n",
    "rots_0 = rigids_cur.get_rots()\n",
    "\n",
    "rots_0_inv = rots_0.invert()\n",
    "quats_0_inv = rots_0_inv.get_quats()\n",
    "quats_t = rots_t.get_quats()\n",
    "quats_0t = ru.quat_multiply(quats_0_inv, quats_t)\n",
    "rotvec_0t = du.quat_to_rotvec(quats_0t)\n",
    "rot_score = fdn.so3d.torch_score(rotvec_0t, batched_t[:,None].repeat((1,L)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60eaf412",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8c58ad6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29ab31b0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d916ddc",
   "metadata": {},
   "outputs": [],
   "source": [
    "    def calc_rot_score(self, rots_t, rots_0, t):\n",
    "        rots_0_inv = rots_0.invert()\n",
    "        quats_0_inv = rots_0_inv.get_quats()\n",
    "        quats_t = rots_t.get_quats()\n",
    "        quats_0t = ru.quat_multiply(quats_0_inv, quats_t)\n",
    "        rotvec_0t = du.quat_to_rotvec(quats_0t)\n",
    "        return self._so3_diffuser.torch_score(rotvec_0t, t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2cacd617",
   "metadata": {},
   "outputs": [],
   "source": [
    "rot_score = self.diffuser.calc_rot_score(\n",
    "            init_rigids.get_rots(),\n",
    "            curr_rigids.get_rots(),\n",
    "            input_feats['t']\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86389392",
   "metadata": {},
   "outputs": [],
   "source": [
    "calc_trans_score(self, trans_t, trans_0, t, use_torch=False, scale=True):\n",
    "        return self._r3_diffuser.score(\n",
    "            trans_t, trans_0, t, use_torch=use_torch, scale=scale)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f7ab832",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80edcd3f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "8fb42eb6",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_iter = iter(train_dL)\n",
    "test_batch = next(test_iter)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "310e5ef6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([32, 65, 3])"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_batch['CA'].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "65955e3f",
   "metadata": {},
   "outputs": [],
   "source": [
    "nc_vec = test_batch['N_CA'].reshape((-1,3))\n",
    "cc_vec = test_batch['C_CA'].reshape((-1,3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f7b5a6f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce4445e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "        rot_score = self.diffuser.calc_rot_score(\n",
    "            init_rigids.get_rots(),\n",
    "            curr_rigids.get_rots(),\n",
    "            input_feats['t']\n",
    "        )\n",
    "        rot_score = rot_score * node_mask[..., None]\n",
    "\n",
    "        curr_rigids = self.unscale_rigids(curr_rigids)\n",
    "        trans_score = self.diffuser.calc_trans_score(\n",
    "            init_rigids.get_trans(),\n",
    "            curr_rigids.get_trans(),\n",
    "            input_feats['t'][:, None, None],\n",
    "            use_torch=True,\n",
    "        )\n",
    "        trans_score = trans_score * node_mask[..., None]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45a86d13",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "c7a454c2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([2080, 3])"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nc_vec.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2b17b3d",
   "metadata": {},
   "outputs": [],
   "source": [
    "        self.N_CA_vec = torch.tensor(coordinates[:,:,N,:] - coordinates[:,:,CA,:], dtype=cast_type)\n",
    "        self.C_CA_vec = torch.tensor(coordinates[:,:,C,:] - coordinates[:,:,CA,:], dtype=cast_type)\n",
    "        \n",
    "        self.N_CA_vec = torch_normalize(self.N_CA_vec).unsqueeze(2)\n",
    "        self.C_CA_vec = torch_normalize(self.C_CA_vec).unsqueeze(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af7733bf",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4833c99",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "7e93927f",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Helix4_Dataset(Dataset):\n",
    "    def __init__(self, coordinates: np.array, cast_type=torch.float32):\n",
    "        #prots,#length_prot in aa, #residues/aa, #xyz per atom\n",
    "           \n",
    "        #alphaFold reduce by 10\n",
    "        coord_div = 10\n",
    "        \n",
    "        coordinates = coordinates/coord_div\n",
    "        self.ca_coords = torch.tensor(coordinates[:,:,CA,:], dtype=cast_type)\n",
    "        #unsqueeze to stack together later\n",
    "        self.N_CA_vec = torch.tensor(coordinates[:,:,N,:] - coordinates[:,:,CA,:], dtype=cast_type)\n",
    "        self.C_CA_vec = torch.tensor(coordinates[:,:,C,:] - coordinates[:,:,CA,:], dtype=cast_type)\n",
    "        \n",
    "        self.N_CA_vec = torch_normalize(self.N_CA_vec).unsqueeze(2)\n",
    "        self.C_CA_vec = torch_normalize(self.C_CA_vec).unsqueeze(2)\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.ca_coords)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        return {'CA':self.ca_coords[idx], 'N_CA':self.N_CA_vec[idx], 'C_CA':self.C_CA_vec[idx]}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b50531e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Helix4_Dataset_Score(Dataset):\n",
    "    def __init__(self, coordinates: np.array, cast_type=torch.float32):\n",
    "        #prots,#length_prot in aa, #residues/aa, #xyz per atom\n",
    "           \n",
    "        #alphaFold style reduce by 10\n",
    "        coord_div = 10\n",
    "        \n",
    "        #center at zero\n",
    "        com  = (coordinates[:,:,CA,:].sum(axis=1)[:,None,:]/coordinates[:,:,CA,:].shape[1])[:,None,:]\n",
    "        coordinates = coordinates-com\n",
    "        \n",
    "        coordinates = coordinates/coord_div\n",
    "        self.ca_coords = torch.tensor(coordinates[:,:,CA,:], dtype=cast_type)\n",
    "        #unsqueeze to stack together later\n",
    "        self.N_CA_vec = torch.tensor(coordinates[:,:,N,:] - coordinates[:,:,CA,:], dtype=cast_type)\n",
    "        self.C_CA_vec = torch.tensor(coordinates[:,:,C,:] - coordinates[:,:,CA,:], dtype=cast_type)\n",
    "        \n",
    "        self.N_CA_vec = torch_normalize(self.N_CA_vec).unsqueeze(2)\n",
    "        self.C_CA_vec = torch_normalize(self.C_CA_vec).unsqueeze(2)\n",
    "        \n",
    "        self.rigids = torch.concatenate((torch.tensor(coordinates[:,:,N,:], dtype=cast_type).unsqueeze(2),\n",
    "                                         torch.tensor(coordinates[:,:,CA,:], dtype=cast_type).unsqueeze(2),\n",
    "                                         torch.tensor(coordinates[:,:,C,:], dtype=cast_type).unsqueeze(2)), dim=-2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc4f13fb",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e6e4ada",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b739ca65",
   "metadata": {},
   "outputs": [],
   "source": [
    "   def sample_ref(\n",
    "            self,\n",
    "            n_samples: int,\n",
    "            impute: ru.Rigid=None,\n",
    "            diffuse_mask: np.ndarray=None,\n",
    "            as_tensor_7: bool=False\n",
    "        ):\n",
    "        \"\"\"Samples rigids from reference distribution.\n",
    "\n",
    "        Args:\n",
    "            n_samples: Number of samples.\n",
    "            impute: Rigid objects to use as imputation values if either\n",
    "                translations or rotations are not diffused.\n",
    "        \"\"\"\n",
    "        if impute is not None:\n",
    "            assert impute.shape[0] == n_samples\n",
    "            trans_impute, rot_impute = _extract_trans_rots(impute)\n",
    "            trans_impute = trans_impute.reshape((n_samples, 3))\n",
    "            rot_impute = rot_impute.reshape((n_samples, 3))\n",
    "            trans_impute = self._r3_diffuser._scale(trans_impute)\n",
    "\n",
    "        if diffuse_mask is not None and impute is None:\n",
    "            raise ValueError('Must provide imputation values.')\n",
    "\n",
    "        if (not self._diffuse_rot) and impute is None:\n",
    "            raise ValueError('Must provide imputation values.')\n",
    "\n",
    "        if (not self._diffuse_trans) and impute is None:\n",
    "            raise ValueError('Must provide imputation values.')\n",
    "\n",
    "        if self._diffuse_rot:\n",
    "            rot_ref = self._so3_diffuser.sample_ref(\n",
    "                n_samples=n_samples)\n",
    "        else:\n",
    "            rot_ref = rot_impute\n",
    "\n",
    "        if self._diffuse_trans:\n",
    "            trans_ref = self._r3_diffuser.sample_ref(\n",
    "                n_samples=n_samples\n",
    "            )\n",
    "        else:\n",
    "            trans_ref = trans_impute\n",
    "\n",
    "        if diffuse_mask is not None:\n",
    "            rot_ref = self._apply_mask(\n",
    "                rot_ref, rot_impute, diffuse_mask[..., None])\n",
    "            trans_ref = self._apply_mask(\n",
    "                trans_ref, trans_impute, diffuse_mask[..., None])\n",
    "        trans_ref = self._r3_diffuser._unscale(trans_ref)\n",
    "        rigids_t = _assemble_rigid(rot_ref, trans_ref)\n",
    "        if as_tensor_7:\n",
    "            rigids_t = rigids_t.to_tensor_7()\n",
    "        return {'rigids_t': rigids_t}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "5bf81b42",
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'FrameDiffNoise' object has no attribute 'sample_ref'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[28], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mfdn\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msample_ref\u001b[49m(\u001b[38;5;241m32\u001b[39m)\n",
      "File \u001b[0;32m~/miniconda3/envs/se33/lib/python3.9/site-packages/torch/nn/modules/module.py:1614\u001b[0m, in \u001b[0;36mModule.__getattr__\u001b[0;34m(self, name)\u001b[0m\n\u001b[1;32m   1612\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m name \u001b[38;5;129;01min\u001b[39;00m modules:\n\u001b[1;32m   1613\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m modules[name]\n\u001b[0;32m-> 1614\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mAttributeError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m object has no attribute \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mformat(\n\u001b[1;32m   1615\u001b[0m     \u001b[38;5;28mtype\u001b[39m(\u001b[38;5;28mself\u001b[39m)\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m, name))\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'FrameDiffNoise' object has no attribute 'sample_ref'"
     ]
    }
   ],
   "source": [
    "fdn.sample_ref(32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fdeb8b5e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "539e748f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#visualize_T\n",
    "vis_t = np.array([0.01,0.05,0.1,0.2,0.3,0.5,0.8,1.0])\n",
    "vis_t = vis_t[None,...].repeat(int(np.ceil(B/len(vis_t))),axis=0).flatten()[:B]\n",
    "#vis_t =  torch.tensor(vis_t, dtype=torch.float32).to('cuda')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "67329384",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#load model\n",
    "model_path = '23Sep01_0242AM_full_diff_embed_T_btest'\n",
    "modelFile = 'model_e489'\n",
    "#opti = torch.optim.Adam(gu.parameters())\n",
    "device = 'cuda:0'\n",
    "gu.load_state_dict(torch.load(f'log/{model_path}/{modelFile}')['model'])\n",
    "#opti.load_state_dict(torch.load(f'log/{model_path}/{modelFile}')['optimizer'])\n",
    "#visualize_model(bb_dict, noised_bb, tv, 'test_start', numOut=8,outdir=f'output/')\n",
    "#visualize_model(bb_dict, noised_bb, tv, 'test_start', numOut=8,outdir=f'log/{model_path}')\n",
    "#save_chkpt(f'log/{model_path}/', gu, opti, 'test_start', B, avg_vloss, avg_tloss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "33c18fee",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_iter = iter(train_dL)\n",
    "test_batch = next(test_iter)\n",
    "\n",
    "t=0.05\n",
    "t_vec = np.ones((B,))*t\n",
    "nd, tv, ss = fdn(test_batch, t_vec=t_vec, useR3=False)\n",
    "\n",
    "tv = tv.to('cuda')\n",
    "# train_loss = model_step(bb_dict, noised_bb, tv, gm, gu)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "1df4be92",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/nwoodall/miniconda3/envs/se33/lib/python3.9/site-packages/dgl/backend/pytorch/tensor.py:449: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()\n",
      "  assert input.numel() == input.storage().size(), (\n"
     ]
    }
   ],
   "source": [
    "visualize_model(test_batch, nd, tv, 1000, numOut=1,outdir='output/')\n",
    "#save_chkpt(model_path, gu, opti, 1000, B, 0, 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "9f2adf25",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.05, 0.05, 0.05, 0.05, 0.05, 0.05, 0.05, 0.05, 0.05, 0.05, 0.05,\n",
       "       0.05, 0.05, 0.05, 0.05, 0.05, 0.05, 0.05, 0.05, 0.05, 0.05, 0.05,\n",
       "       0.05, 0.05, 0.05, 0.05, 0.05, 0.05, 0.05, 0.05, 0.05, 0.05])"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t_vec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "78b15462",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[25], line 20\u001b[0m\n\u001b[1;32m     18\u001b[0m train_loss \u001b[38;5;241m=\u001b[39m model_step(bb_dict, noised_bb, tv, ss, gm, gu)\n\u001b[1;32m     19\u001b[0m opti\u001b[38;5;241m.\u001b[39mzero_grad()\n\u001b[0;32m---> 20\u001b[0m \u001b[43mtrain_loss\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbackward\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     21\u001b[0m opti\u001b[38;5;241m.\u001b[39mstep()\n\u001b[1;32m     23\u001b[0m running_tloss \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m train_loss\u001b[38;5;241m.\u001b[39mdetach()\u001b[38;5;241m.\u001b[39mcpu()\n",
      "File \u001b[0;32m~/miniconda3/envs/se33/lib/python3.9/site-packages/torch/_tensor.py:487\u001b[0m, in \u001b[0;36mTensor.backward\u001b[0;34m(self, gradient, retain_graph, create_graph, inputs)\u001b[0m\n\u001b[1;32m    477\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m has_torch_function_unary(\u001b[38;5;28mself\u001b[39m):\n\u001b[1;32m    478\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m handle_torch_function(\n\u001b[1;32m    479\u001b[0m         Tensor\u001b[38;5;241m.\u001b[39mbackward,\n\u001b[1;32m    480\u001b[0m         (\u001b[38;5;28mself\u001b[39m,),\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    485\u001b[0m         inputs\u001b[38;5;241m=\u001b[39minputs,\n\u001b[1;32m    486\u001b[0m     )\n\u001b[0;32m--> 487\u001b[0m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mautograd\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbackward\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    488\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgradient\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mretain_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcreate_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minputs\u001b[49m\n\u001b[1;32m    489\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/envs/se33/lib/python3.9/site-packages/torch/autograd/__init__.py:200\u001b[0m, in \u001b[0;36mbackward\u001b[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001b[0m\n\u001b[1;32m    195\u001b[0m     retain_graph \u001b[38;5;241m=\u001b[39m create_graph\n\u001b[1;32m    197\u001b[0m \u001b[38;5;66;03m# The reason we repeat same the comment below is that\u001b[39;00m\n\u001b[1;32m    198\u001b[0m \u001b[38;5;66;03m# some Python versions print out the first line of a multi-line function\u001b[39;00m\n\u001b[1;32m    199\u001b[0m \u001b[38;5;66;03m# calls in the traceback and some print out the last line\u001b[39;00m\n\u001b[0;32m--> 200\u001b[0m \u001b[43mVariable\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_execution_engine\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun_backward\u001b[49m\u001b[43m(\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# Calls into the C++ engine to run the backward pass\u001b[39;49;00m\n\u001b[1;32m    201\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtensors\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgrad_tensors_\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mretain_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcreate_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    202\u001b[0m \u001b[43m    \u001b[49m\u001b[43mallow_unreachable\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maccumulate_grad\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "#t=0.1\n",
    "#t_vec = np.ones((B,))*t\n",
    "#print(t_vec)\n",
    "#model_path = make_save_folder(name=f'full_diff_embed_T_btest')\n",
    "num_epochs = 100\n",
    "e_start= 190\n",
    "save_per=10\n",
    "avg_vloss=0\n",
    "\n",
    "for e in range(e_start, e_start+num_epochs):\n",
    "    \n",
    "    running_tloss = 0 \n",
    "    start = time.time()\n",
    "    for i, bb_dict in enumerate(train_dL):\n",
    "        noised_bb, tv, ss = fdn(bb_dict,t_vec=None, useR3=useR3)\n",
    "        tv = tv.to('cuda')\n",
    "        ss = ss.to('cuda')\n",
    "        train_loss = model_step(bb_dict, noised_bb, tv, ss, gm, gu)\n",
    "        opti.zero_grad()\n",
    "        train_loss.backward()\n",
    "        opti.step()\n",
    "\n",
    "        running_tloss += train_loss.detach().cpu()\n",
    "    \n",
    "    end = time.time()\n",
    "    avg_tloss = running_tloss/(i+1)\n",
    "    print(f'Average Train Loss Epoch {e}: {avg_tloss};   Epoch time: {end-start:.0f}')\n",
    "\n",
    "    if e %save_per==save_per-1:\n",
    "        with torch.no_grad():\n",
    "            running_vloss = 0\n",
    "            for i, bb_dictv in enumerate(val_dL):\n",
    "                noised_bb, tv, ss = fdn(bb_dictv,t_vec=None, useR3=useR3)\n",
    "                tv = tv.to('cuda')\n",
    "                ss = ss.to('cuda')\n",
    "                valid_loss = model_step(bb_dictv, noised_bb, tv, ss, gm, gu)\n",
    "                running_vloss += valid_loss\n",
    "                \n",
    "        avg_vloss = running_vloss/(i+1)\n",
    "        print(f'Average Valid Loss Epoch {e}: {avg_vloss}')\n",
    "                \n",
    "        noised_bb, tv, ss = fdn(bb_dict, t_vec=vis_t)\n",
    "        tv = tv.to('cuda')\n",
    "        visualize_model(bb_dict, noised_bb, tv, e, numOut=8,outdir=f'log/{model_path}')\n",
    "        save_chkpt(f'log/{model_path}', gu, opti, e, B, avg_vloss, avg_tloss)\n",
    "#         visualize_model(bb_dict, noised_bb, tv, e, numOut=8,outdir=f'{model_path}')\n",
    "#         save_chkpt(f'{model_path}', gu, opti, e, B, avg_vloss, avg_tloss)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc618c49",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4cf435f6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2ce458c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e6ddcfc",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df7462d2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "cd433a11",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_iter = iter(train_dL)\n",
    "test_batch = next(test_iter)\n",
    "\n",
    "t=0.05\n",
    "t_vec = np.ones((B,))*t\n",
    "nd, tv, ss = fdn(test_batch, t_vec=t_vec, useR3=False)\n",
    "\n",
    "tv = tv.to('cuda')\n",
    "# train_loss = model_step(bb_dict, noised_bb, tv, gm, gu)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "4c7bbc63",
   "metadata": {},
   "outputs": [],
   "source": [
    "visualize_model(test_batch, nd, tv, 1000, numOut=8,outdir='output/')\n",
    "#save_chkpt('output/', gu, opti, 1000, B, 0, 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f356ac2a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21564364",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "4e13aa5f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#From\n",
    "#https://math.stackexchange.com/questions/939229/unit-quaternion-to-a-scalar-power\n",
    "\n",
    "#test code\n",
    "# Q = torch.tensor([0,0,1,0],dtype=torch.float)[None,None,None,...].repeat(2,3,2,1) #180 rotation about Y axis\n",
    "# rv = torch.tensor([[0,0,1]],dtype=torch.float)[None,None,...].repeat(2,3,2,1) #unit Z\n",
    "# Q = normQ(Q)\n",
    "#qp = powerQ(Q,0.5) rotate halfway (aka x-axis)\n",
    "#rv = rv.reshape((2,3,2,1,3))\n",
    "#rot_vecs = einsum('bnkij,bnkhj->bnki',Rs, rv) #should be x-axis\n",
    "\n",
    "def powerQ(quat_in, power):\n",
    "    \"\"\"Quaternion to the power, represent number of times to rotate Q. Only works on unit Q\"\"\"\n",
    "    return expQ(scaleQ(lnQ(quat_in),power))\n",
    "\n",
    "\n",
    "def expQ(quat_in, eps=1e-9):\n",
    "    quat_out = torch.zeros_like(quat_in, device=quat_in.device)\n",
    "    r = torch.sqrt(torch.sum(torch.square(quat_in[...,1:]),axis=-1,keepdim=True)+eps)\n",
    "    et = torch.exp(quat_in[...,0][...,None])\n",
    "    s = et*torch.sin(r)/r\n",
    "    s[torch.where(r<eps)[0]] = 0\n",
    "    \n",
    "    quat_out[...,0][...,None] = et*torch.cos(r)\n",
    "    quat_out[...,1] = s[...,0]*quat_in[...,1]\n",
    "    quat_out[...,2] = s[...,0]*quat_in[...,2]\n",
    "    quat_out[...,3] = s[...,0]*quat_in[...,3]\n",
    "    \n",
    "    return quat_out\n",
    "\n",
    "#fix in other location w calc\n",
    "def lnQ(quat_in, eps=1e-9):\n",
    "    quat_out = torch.zeros_like(quat_in, device=quat_in.device)\n",
    "    r = torch.sqrt(torch.sum(torch.square(quat_in[...,1:]),axis=-1,keepdim=True)+eps)\n",
    "    t = torch.atan2(r,quat_in[...,0][...,None])/r\n",
    "    t[torch.where(r<eps)[0]] = 0\n",
    "        \n",
    "    quat_out[...,0][...,None] = 0.5*torch.log(torch.sum(torch.square(quat_in),axis=-1,keepdim=True)+eps)\n",
    "    quat_out[...,1] = t[...,0]*quat_in[...,1]\n",
    "    quat_out[...,2] = t[...,0]*quat_in[...,2]\n",
    "    quat_out[...,3] = t[...,0]*quat_in[...,3]\n",
    "    \n",
    "    return quat_out\n",
    "    \n",
    "\n",
    "def scaleQ(quat_in, scale):\n",
    "    return torch.multiply(quat_in,scale)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26b7b65e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1db68d9c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fbc0c239",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "652bd82b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def model_step(backbone_dict, noised_dict, batched_t, scores_scales, graph_maker, graph_unet, train=True):\n",
    "    \n",
    "    CA_t  = backbone_dict['CA'].reshape(B, L, 3).to('cuda')\n",
    "    NC_t = CA_t + backbone_dict['N_CA'].reshape(B, L, 3).to('cuda')\n",
    "    CC_t = CA_t + backbone_dict['C_CA'].reshape(B, L, 3).to('cuda')\n",
    "    true =  torch.cat((NC_t,CA_t,CC_t),dim=2).reshape(B,L,3,3)\n",
    "    \n",
    "    CA_n  = noised_dict['CA'].reshape(B, L, 3).to('cuda')\n",
    "    NC_n = CA_n + noised_dict['N_CA'].reshape(B, L, 3).to('cuda')\n",
    "    CC_n = CA_n + noised_dict['C_CA'].reshape(B, L, 3).to('cuda')\n",
    "    noise_xyz =  torch.cat((NC_n,CA_n,CC_n),dim=2).reshape(B,L,3,3)\n",
    "    \n",
    "    x = graph_maker.prep_for_network(noised_dict)\n",
    "    out = graph_unet(x, batched_t)\n",
    "    CA_p = out['1'][:,0,:].reshape(B, L, 3)+CA_n #translation of Calpha\n",
    "    Qs = out['1'][:,1,:] # rotation\n",
    "    Qs = Qs.unsqueeze(1).repeat((1,2,1))\n",
    "    Qs = torch.cat((torch.ones((B*L,2,1),device=Qs.device),Qs),dim=-1).reshape(B,L,2,4)\n",
    "    Qs = normQ(Qs)\n",
    "    Rs = Qs2Rs(Qs)\n",
    "    N_C_to_Rot = torch.cat((noised_dict['N_CA'].reshape(B, L, 3).to('cuda'),\n",
    "                            noised_dict['C_CA'].reshape(B, L, 3).to('cuda')),dim=2).reshape(B,L,2,1,3)\n",
    "\n",
    "    \n",
    "    \n",
    "    rot_vecs = einsum('bnkij,bnkhj->bnki',Rs, N_C_to_Rot)\n",
    "    NC_p = CA_p + rot_vecs[:,:,0,:].to('cuda')*N_CA_dist\n",
    "    CC_p = CA_p + rot_vecs[:,:,1,:].reshape(B, L, 3).to('cuda')*C_CA_dist\n",
    "\n",
    "    pred = torch.cat((NC_p,CA_p,CC_p),dim=2).reshape(B,L,3,3)\n",
    "    \n",
    "    tloss, loss = FAPE_loss(pred.unsqueeze(0), true, scores_scales)\n",
    "    \n",
    "    return tloss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "55e49b75",
   "metadata": {},
   "outputs": [],
   "source": [
    "def noise_test(backbone_dict, noised_dict):\n",
    "    CA_t  = bb_dict['CA'].reshape(B, L, 3).to('cuda')\n",
    "    NC_t = CA_t + bb_dict['N_CA'].reshape(B, L, 3).to('cuda')*N_CA_dist\n",
    "    CC_t = CA_t + bb_dict['C_CA'].reshape(B, L, 3).to('cuda')*C_CA_dist\n",
    "    true =  torch.cat((NC_t,CA_t,CC_t),dim=2).reshape(B,L,3,3)\n",
    "    \n",
    "    CA_n  = noised_dict['CA'].reshape(B, L, 3).to('cuda')\n",
    "    NC_n = CA_n + noised_dict['N_CA'].reshape(B, L, 3).to('cuda')*N_CA_dist\n",
    "    CC_n = CA_n + noised_dict['C_CA'].reshape(B, L, 3).to('cuda')*C_CA_dist\n",
    "    noise_xyz =  torch.cat((NC_n,CA_n,CC_n),dim=2).reshape(B,L,3,3)\n",
    "    return true.to('cpu').numpy()*10, noise_xyz.to('cpu').numpy()*10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "00d45bb6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from util.npose_util import makePointPDB\n",
    "#gds = Graph_RadiusMP_4H_Dataset(coords_tog[:100], 10, mp_stride = 3)\n",
    "def view_mp_graph(mps: DGLGraph, coords: np.array ):\n",
    "    p = mps.ndata['pos']*10\n",
    "    \n",
    "    to = np.concatenate((coords, np.ones_like(coords)[:,:,0][...,None]),axis=2)\n",
    "    \n",
    "    makePointPDB(p,'test.pdb',outDirec='output')\n",
    "    nu.dump_npdb(to,'output/test2.pdb')\n",
    "#view_mp_graph(gds.mpSelfGraphList[0], coords_tog[0])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "se33",
   "language": "python",
   "name": "se33"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
