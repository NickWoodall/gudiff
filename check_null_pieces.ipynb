{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a02a1c0f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "#clear memory better\n",
    "with torch.no_grad():\n",
    "    torch.cuda.empty_cache()\n",
    "import numpy as np\n",
    "import util.npose_util as nu\n",
    "import os\n",
    "import pathlib\n",
    "import dgl\n",
    "from dgl import backend as F\n",
    "import torch_geometric\n",
    "from torch.utils.data import random_split, DataLoader, Dataset\n",
    "from typing import Dict\n",
    "from torch import Tensor\n",
    "from dgl import DGLGraph\n",
    "from torch import nn\n",
    "from chemical import cos_ideal_NCAC #from RoseTTAFold2\n",
    "from torch import einsum\n",
    "import time\n",
    "torch.cuda.is_available()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "33e16cff",
   "metadata": {},
   "outputs": [],
   "source": [
    "import se3_diffuse.utils as du"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6a31f547",
   "metadata": {},
   "outputs": [],
   "source": [
    "from data_rigid_diffuser import so3_diffuser\n",
    "from data_rigid_diffuser import r3_diffuser\n",
    "from data_rigid_diffuser import oneHot_diffuser\n",
    "from scipy.spatial.transform import Rotation\n",
    "from data_rigid_diffuser import rigid_utils as ru\n",
    "import yaml\n",
    "from data_rigid_diffuser.diffuser import FrameDiffNoise\n",
    "from gudiff_model import Data_Graph\n",
    "from gudiff_model.Data_Graph import build_npose_from_coords, dump_coord_pdb, define_graph_edges, make_pe_encoding\n",
    "from gudiff_model.Data_Graph import Helix4_Dataset, Make_KNN_MP_Graphs\n",
    "from gudiff_model.Data_Graph_Null import  Make_nullKNN_MP_Graphs\n",
    "import gudiff_model.Data_Graph_Null"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "bf443f63",
   "metadata": {},
   "outputs": [],
   "source": [
    "from se3_transformer.model.basis import get_basis, update_basis_with_fused\n",
    "from se3_transformer.model.transformer import Sequential, SE3Transformer\n",
    "from se3_transformer.model.transformer_topk import SE3Transformer_topK\n",
    "from se3_transformer.model.FAPE_Loss import FAPE_loss, Qs2Rs, normQ\n",
    "from se3_transformer.model.layers.attentiontopK import AttentionBlockSE3\n",
    "from se3_transformer.model.layers.linear import LinearSE3\n",
    "from se3_transformer.model.layers.convolution import ConvSE3, ConvSE3FuseLevel\n",
    "from se3_transformer.model.layers.norm import NormSE3\n",
    "from se3_transformer.model.layers.pooling import GPooling, Latent_Unpool, Unpool_Layer\n",
    "from se3_transformer.runtime.utils import str2bool, to_cuda\n",
    "from se3_transformer.model.fiber import Fiber\n",
    "from se3_transformer.model.transformer import get_populated_edge_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "48bf9476",
   "metadata": {},
   "outputs": [],
   "source": [
    "from se3_transformer.model.FAPE_Loss import FAPE_loss_null, FAPE_loss_real, FAPE_loss\n",
    "from se3_transformer.model.FAPE_Loss import get_t"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c0babffd",
   "metadata": {},
   "outputs": [],
   "source": [
    "#indices for, unsure if needed\n",
    "CA = Data_Graph.CA\n",
    "N = Data_Graph.N\n",
    "C = Data_Graph.C\n",
    "\n",
    "# #find better way to incorporate coord_scale\n",
    "\n",
    "#needed\n",
    "N_CA_dist = (Data_Graph.N_CA_dist/10.).to('cuda')\n",
    "C_CA_dist = (Data_Graph.C_CA_dist/10.).to('cuda')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e213e885",
   "metadata": {},
   "outputs": [],
   "source": [
    "# data_path_str  = 'data/h4_ca_coords.npz'\n",
    "# test_limit = 1028\n",
    "# rr = np.load(data_path_str)\n",
    "# ca_coords = [rr[f] for f in rr.files][0][:test_limit,:,:3]\n",
    "# ca_coords.shape\n",
    "\n",
    "# getting N-Ca, Ca-C vectors to add as typeI features\n",
    "#apa = apart helices for val/train split\n",
    "#tog = together helices for val/train split\n",
    "\n",
    "#mode for tablet\n",
    "apa_path_str  = 'data_npose/h4_apa_coords.npz'\n",
    "tog_path_str  = 'data_npose/h4_tog_coords.npz'\n",
    "\n",
    "#grab the first 3 atoms which are N,CA,C\n",
    "test_limit = 2048\n",
    "rr = np.load(apa_path_str)\n",
    "coords_apa = [rr[f] for f in rr.files][0][:test_limit,:]\n",
    "\n",
    "rr = np.load(tog_path_str)\n",
    "coords_tog = [rr[f] for f in rr.files][0][:test_limit,:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "98745b1e",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'train_dL' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[11], line 6\u001b[0m\n\u001b[1;32m      4\u001b[0m config_path\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdata_rigid_diffuser/base.yaml\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[1;32m      5\u001b[0m fnd \u001b[38;5;241m=\u001b[39m FrameDiffNoise(config_path)\n\u001b[0;32m----> 6\u001b[0m testiter \u001b[38;5;241m=\u001b[39m \u001b[38;5;28miter\u001b[39m(\u001b[43mtrain_dL\u001b[49m)\n\u001b[1;32m      7\u001b[0m bb_dict \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mnext\u001b[39m(testiter)\n\u001b[1;32m      8\u001b[0m t\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0.0000001\u001b[39m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'train_dL' is not defined"
     ]
    }
   ],
   "source": [
    "stride=4\n",
    "L=128\n",
    "mkg = Make_nullKNN_MP_Graphs(KNN=30, mp_stride=stride, n_nodes=L)\n",
    "config_path='data_rigid_diffuser/base.yaml'\n",
    "fnd = FrameDiffNoise(config_path)\n",
    "testiter = iter(train_dL)\n",
    "bb_dict = next(testiter)\n",
    "t=0.0000001\n",
    "t_cpu = np.ones((B,))*t\n",
    "noised_dict = fnd(bb_dict, t_vec=t_cpu)\n",
    "\n",
    "feat_dict = mkg.prep_for_network(noised_dict, cuda=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9741478d",
   "metadata": {},
   "outputs": [],
   "source": [
    "feat_dict['node_feats']['0'][:128][~noised_dict['real_nodes_mask'][0],12:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "a961d127",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'noised_dict' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[9], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mnoised_dict\u001b[49m[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mreal_nodes_mask\u001b[39m\u001b[38;5;124m'\u001b[39m]\n",
      "\u001b[0;31mNameError\u001b[0m: name 'noised_dict' is not defined"
     ]
    }
   ],
   "source": [
    "noised_dict['real_nodes_mask']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "8108f3eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "    \n",
    "def circular_pe_encoding(n_nodes=128,embed_dim=12, cast_type=torch.float32):\n",
    "    #positional encoding of node, all repeat every n_nodes\n",
    "    i_array = np.arange(1,(embed_dim/2)+1)\n",
    "    period = 2*np.pi\n",
    "    wk = period/(n_nodes)*i_array**2\n",
    "    t_array = np.arange(n_nodes)\n",
    "    si = torch.tensor(np.sin(wk*t_array.reshape((-1,1))))\n",
    "    ci = torch.tensor(np.cos(wk*t_array.reshape((-1,1))))\n",
    "    pe = torch.stack((si,ci),axis=2).reshape(t_array.shape[0],embed_dim).type(cast_type)\n",
    "    \n",
    "    return pe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "c685e750",
   "metadata": {},
   "outputs": [],
   "source": [
    "device='cuda'\n",
    "\n",
    "B = 2\n",
    "L=128\n",
    "limit = 1028\n",
    "prot_trainData = Data_Graph.ProteinBB_Dataset(coords_tog[:limit], n_nodes=L,\n",
    "              n_atoms=5, coord_div=10, cast_type=torch.float32)\n",
    "train_dL = DataLoader(prot_trainData, batch_size=B, shuffle=True, drop_last=True)\n",
    "stride=4\n",
    "mkg = Make_nullKNN_MP_Graphs(KNN=30, mp_stride=stride, n_nodes=L)\n",
    "\n",
    "score_weights = {}\n",
    "score_weights['nf_real'] = torch.tensor(0,device=device)\n",
    "score_weights['3D_real'] = torch.tensor(1.0,device=device)\n",
    "score_weights['3D_null'] = torch.tensor(1.0,device=device)\n",
    "\n",
    "config_path='data_rigid_diffuser/base.yaml'\n",
    "fnd = FrameDiffNoise(config_path)\n",
    "bb_dict = next(iter(train_dL))\n",
    "t=0.1\n",
    "t_cpu = np.ones((B,))*t\n",
    "noised_dict = fnd(bb_dict, t_vec=t_cpu)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "b7d0f7dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "#lets figure out how to fix the ndf1, ndf0\n",
    "#decide if edge dimensions need directionality\n",
    "\n",
    "KNN=30\n",
    "mp_stride=4\n",
    "n_nodes=128\n",
    "coord_div=10 \n",
    "cast_type=torch.float32\n",
    "channels_start=32\n",
    "ndf1=6\n",
    "ndf0=32\n",
    "embed_dim_pe=12\n",
    "nr_node_feats=5\n",
    "cuda=True\n",
    "real_threshold=1.99\n",
    "\n",
    "        \n",
    "pe = circular_pe_encoding(n_nodes=n_nodes,embed_dim=embed_dim_pe, cast_type=torch.float32)\n",
    "null_stride = mp_stride*2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "1e363aee",
   "metadata": {},
   "outputs": [],
   "source": [
    "graphList = []\n",
    "mpGraphList = []\n",
    "mpRevGraphList = []\n",
    "mpSelfGraphList = []\n",
    "\n",
    "j=0\n",
    "caXYZ = noised_dict['bb_noised']['CA'][j]\n",
    "\n",
    "#round nodes to be real (1) or (null 0)\n",
    "#get null node indices from mask\n",
    "\n",
    "real_nodes_feats =  noised_dict['real_nodes_noise'][j].clamp(0,1)\n",
    "\n",
    "real_nodes_fround = torch.round( noised_dict['real_nodes_noise'][j]).clamp(0,1)\n",
    "real_nodes_mask = real_nodes_fround.sum(-1) > real_threshold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "beeb5dc7",
   "metadata": {},
   "outputs": [],
   "source": [
    "#make a knn graph form the real nodes only\n",
    "graph = gudiff_model.Data_Graph_Null.monomer_null_knngraph(caXYZ, real_nodes_mask, k=KNN)\n",
    "graph.ndata['pe_nf'] = torch.cat((pe,real_nodes_feats),dim=-1).type(cast_type)\n",
    "graph.ndata['pos'] = caXYZ\n",
    "graph.ndata['bb_ori'] = torch.cat((noised_dict['bb_noised']['N_CA'][j], noised_dict['bb_noised']['C_CA'][j]),axis=1)\n",
    "graph.ndata['real_nodes_mask']=real_nodes_mask\n",
    "\n",
    "#gather edge data from all possible noised edges produced\n",
    "gsrc, gdst = graph.edges()\n",
    "num_edges = len(gsrc)\n",
    "\n",
    "#adjacent AA are one apart, or the loop connection from zero node to the last node\n",
    "adj_nodes_mask = ((torch.abs(gsrc-gdst)==1) | (torch.abs(gsrc-gdst)==len(gsrc)-1)) \n",
    "\n",
    "#actually we need to determine\n",
    "null_nodes = torch.arange(n_nodes,dtype=torch.int)[~real_nodes_mask]\n",
    "real_nodes = torch.arange(n_nodes,dtype=torch.int)[real_nodes_mask]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "9d5b217f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#broadcast each src/dst node against all null nodes, if any match along node dimension is a null edge\n",
    "gsrc_compare = (gsrc[:,None] - null_nodes[None,:])\n",
    "gdst_compare = (gdst[:,None] - null_nodes[None,:])\n",
    "null_edges_src_ind = torch.where(gsrc_compare==0,True,False).any(dim=1)\n",
    "null_edges_dst_ind = torch.where(gdst_compare==0,True,False).any(dim=1)\n",
    "\n",
    "#broadcast each src/dst node against all real or null nodes, if any match along node dimension is a null edge\n",
    "gsrc_compare = (gsrc[:,None] - real_nodes[None,:])\n",
    "gdst_compare = (gdst[:,None] - real_nodes[None,:])\n",
    "real_edges_src_ind = torch.where(gsrc_compare==0,True,False).any(dim=1)\n",
    "real_edges_dst_ind = torch.where(gdst_compare==0,True,False).any(dim=1)\n",
    "#null edges connect to any null nodes (|), real edges must both be real (&)\n",
    "null_edges = null_edges_src_ind | null_edges_dst_ind\n",
    "real_edges = real_edges_src_ind & real_edges_dst_ind\n",
    "adj_real = adj_nodes_mask&real_edges"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "a4597f8e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#edge features likely not needed, taken care of in node features\n",
    "\n",
    "EDGE_DIM=1\n",
    "\n",
    "###\n",
    "#             enoised = noised_dict['edge_cons'][j]\n",
    "#             enoised = enoised.reshape((-1,EDGE_DIM,2))[:num_edges]\n",
    "edata = torch.ones(gsrc.shape+(EDGE_DIM,))\n",
    "# oh1_mask = torch.tensor([1,0,0]).unsqueeze(-1)\n",
    "# oh2_mask = torch.tensor([0,1,0]).unsqueeze(-1)\n",
    "# oh3_mask = torch.tensor([0,0,1]).unsqueeze(-1)\n",
    "\n",
    "\n",
    "# #needs to add - /+ N/C directon for this data????, or is this covered by pe encoding\n",
    "# edata[real_edges] = torch.gather(enoised[real_edges],2,oh2_mask.repeat(real_edges.sum(),1,1))[:,:,0]\n",
    "# edata[adj_real] = torch.gather(enoised[adj_real],2,oh1_mask.repeat(adj_real.sum(),1,1))[:,:,0]\n",
    "# edata[null_edges] = torch.gather(enoised[null_edges],2,oh3_mask.repeat(null_edges.sum(),1,1))[:,:,0]\n",
    "\n",
    "# edge_dir = torch.ones_like(gsrc,dtype=torch.long) #NotC direction off AA sequence\n",
    "# edge_dir[gdst<gsrc]=-1 # #NotC; reverse direction \n",
    "# edata[adj_nodes_mask]=edata[adj_nodes_mask]*edge_dir\n",
    "\n",
    "graph.edata['con'] = edata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "d5769e02",
   "metadata": {},
   "outputs": [],
   "source": [
    "#max possible mp feats, is +1 for range(start,end,stride) combines with real+null=total + stride rounding \n",
    "mp_list = torch.zeros((len(list(range(0,n_nodes, mp_stride)))+1),caXYZ.shape[1])\n",
    "\n",
    "new_src = torch.tensor([],dtype=torch.int)\n",
    "new_dst = torch.tensor([],dtype=torch.int)\n",
    "\n",
    "new_src_rev = torch.tensor([], dtype=torch.int)\n",
    "new_dst_rev = torch.tensor([], dtype=torch.int)\n",
    "\n",
    "#create midpoints for real nodes\n",
    "i=0#mp list counter\n",
    "mp_real_node_counter = 0\n",
    "for real_index in range(0,len(real_nodes), mp_stride):\n",
    "    x = real_nodes[real_index] #convert to match torch.int from\n",
    "    src, dst = graph.in_edges(x) #dst repeats x, this grab null nodes too\n",
    "\n",
    "    n_tot = torch.cat((x.unsqueeze(0),src)) #add x to node list\n",
    "    mp_list[i] = caXYZ[n_tot].sum(axis=0)/n_tot.shape[0]\n",
    "    mp_node = i + graph.num_nodes() #add midpoints nodes at end of graph\n",
    "    mp_real_node_counter += 1\n",
    "    #define edges between midpoint nodes and nodes defining midpoint for midpointGraph\n",
    "\n",
    "    new_src = torch.cat((new_src,n_tot))\n",
    "    new_dst = torch.cat((new_dst,\n",
    "                         (torch.tensor(mp_node,dtype=torch.int).unsqueeze(0).repeat(n_tot.shape[0]))))\n",
    "\n",
    "    i+=1\n",
    "\n",
    "#remove extra null nodes from .in_edges call\n",
    "\n",
    "#remove edges that are null node connections,\n",
    "#dst are the midpoint nodes for mpGraph, src are mp nodes for mpGraphRev\n",
    "#only remove non-mp nodes\n",
    "\n",
    "real_mask_rem1 = torch.isin(new_src,real_nodes)\n",
    "#             real_mask_rem2 = torch.isin(new_dst_rev,real_nodes) \n",
    "new_src = new_src[real_mask_rem1]\n",
    "new_dst = new_dst[real_mask_rem1]\n",
    "#             new_src_rev = new_src_rev[real_mask_rem2]\n",
    "#             new_dst_rev = new_dst_rev[real_mask_rem2]\n",
    "\n",
    "\n",
    "#collapse collected null nodes onto null mp of contingous sections \n",
    "end_p = ((null_nodes.roll(1)-null_nodes)==-1) #consecutive are equal to negative one (look right)\n",
    "start_p = ((null_nodes.roll(-1)-null_nodes)==1) #consecutive are equal to one (look left)\n",
    "startend = (start_p != end_p) #remove overlap of interior consecutive nodes\n",
    "start = start_p == startend #just get the starts\n",
    "end  = end_p == startend #just get the ends\n",
    "si = torch.arange(len(start),dtype=torch.int)[start]# indices of start of consecutive nodes\n",
    "ei = torch.arange((len(end)),dtype=torch.int)[end] # indices of end of cone\n",
    "\n",
    "#connect first and last groups if approriate\n",
    "if null_nodes[0]==0 and null_nodes[-1]==self.n_nodes-1:\n",
    "    #roll last group across barrier\n",
    "    roll_con = len(start)-si[-1]\n",
    "    null_nodes = null_nodes.roll(int(roll_con))\n",
    "    #update end index and start index by roll and remove groups (one from end)\n",
    "    #add zero to start and remove last start (rolled)\n",
    "    ei = (ei+roll_con)[:-1]\n",
    "    sic=torch.zeros_like(si[1:])\n",
    "    sic[1:] = si[1:-1]+roll_con\n",
    "    si = sic\n",
    "\n",
    "#mp_list_null  = torch.ones((si.shape[0],caXYZ.shape[1]))*-1e9\n",
    "#add null nodes to the end of mp_list\n",
    "counter_mp_index = 0 #mp list counter, start/end  \n",
    "tot_indices = si.shape[0]\n",
    "while counter_mp_index < tot_indices:\n",
    "\n",
    "    n_tot = null_nodes[si[counter_mp_index]:ei[counter_mp_index]+1]\n",
    "    while len(n_tot) <  mp_stride and counter_mp_index+1<tot_indices:\n",
    "        #merge non-continuous null nodes smaller than stride\n",
    "        counter_mp_index=counter_mp_index+1\n",
    "        n_tot = torch.cat([n_tot,null_nodes[si[counter_mp_index]:ei[counter_mp_index]+1]],axis=0)\n",
    "\n",
    "    mp_list[i] = caXYZ[n_tot].sum(axis=0)/n_tot.shape[0]\n",
    "    mp_node = i + graph.num_nodes() #add midpoints nodes at end of graph\n",
    "\n",
    "    #from null nodes to new mp_node\n",
    "    new_src = torch.cat((new_src,n_tot))\n",
    "    new_dst = torch.cat((new_dst,\n",
    "                         (torch.tensor(mp_node,dtype=torch.int).unsqueeze(0).repeat(n_tot.shape[0]))))\n",
    "    #and reverse graph for coming off\n",
    "    new_src_rev = torch.cat((new_src_rev,\n",
    "                             (torch.tensor(mp_node,dtype=torch.int).unsqueeze(0).repeat(n_tot.shape[0]))))\n",
    "    new_dst_rev = torch.cat((new_dst_rev,n_tot))\n",
    "\n",
    "    i=i+1\n",
    "    counter_mp_index += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "73227d1b",
   "metadata": {},
   "outputs": [],
   "source": [
    "mp_node_indx = torch.arange(0,len(mp_list)).type(torch.int)    \n",
    "\n",
    "mpGraph = dgl.graph((new_src,new_dst))\n",
    "to_Add = len(mp_list)+graph.num_nodes()-mpGraph.num_nodes()\n",
    "mpGraph.add_nodes(to_Add) #nodes without any use for padding\n",
    "mp_pos = torch.cat((caXYZ,mp_list),axis=0).type(cast_type)\n",
    "mpGraph.ndata['pos'] = mp_pos\n",
    "\n",
    "mp_real_node_counter\n",
    "mp_real_node_counter = counter_mp_index\n",
    "\n",
    "#mp real/ null nodes\n",
    "mp_node_real_mask = torch.zeros(mp_list.shape[0],dtype=torch.bool)\n",
    "mp_node_real_mask[:mp_real_node_counter] = True\n",
    "mpGraph.ndata['mp_node_real_mask'] = torch.cat([real_nodes_mask,mp_node_real_mask])\n",
    "\n",
    "#match output shape of first transformer\n",
    "pe_mp = torch.cat((pe,torch.zeros((pe.shape[0], channels_start-pe.shape[1]))),axis=1)\n",
    "mpGraph.ndata['pe'] = torch.cat((pe_mp,pe_mp[mp_node_indx]))\n",
    "mpGraph.edata['con'] = torch.ones((mpGraph.num_edges(),1))\n",
    "mpGraph_rev = dgl.graph((new_dst,new_src))\n",
    "mpGraph_rev.add_nodes(to_Add)\n",
    "mpGraph_rev.ndata['pos'] = torch.cat((caXYZ,mp_list),axis=0).type(cast_type)\n",
    "mpGraph_rev.ndata['pe'] = torch.cat((pe_mp,pe_mp[mp_node_indx]))\n",
    "mpGraph_rev.edata['con'] = torch.ones((mpGraph_rev.num_edges(),1))\n",
    "mpGraph_rev.ndata['mp_node_real_mask'] = torch.cat([real_nodes_mask,mp_node_real_mask])\n",
    "#make graph for self interaction of midpoints\n",
    "v1,v2,edge_data, ind = define_graph_edges(len(mp_list))\n",
    "mpSelfGraph = dgl.graph((v1,v2))\n",
    "mpSelfGraph.edata['con'] = edge_data.reshape((-1,1))\n",
    "mpSelfGraph.ndata['pe'] = pe[mp_node_indx] #not really needed\n",
    "mpSelfGraph.ndata['pos'] = mp_list.type(cast_type)\n",
    "\n",
    "\n",
    "mpSelfGraphList.append(mpSelfGraph)\n",
    "mpGraphList.append(mpGraph)\n",
    "mpRevGraphList.append(mpGraph_rev)\n",
    "graphList.append(graph)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4c13c78",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2fa5b8fe",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "6d044f40",
   "metadata": {},
   "outputs": [],
   "source": [
    "#this should probably be already transferred to GPU for speed... at some point\n",
    "#this should probably be already transferred to GPU for speed... at some point\n",
    "class Make_nullKNN_MP_Graphs():\n",
    "    \n",
    "    #8 long positional encoding\n",
    "    NODE_FEATURE_DIM_0 = 17 #circular pe encoding dim\n",
    "    EDGE_FEATURE_DIM = 1 # 0 or 1 primary seq connection or not\n",
    "    NODE_FEATURE_DIM_1 = 2\n",
    "    \n",
    "    def __init__(self, KNN=30, mp_stride=4, n_nodes=128, coord_div=10, \n",
    "                       cast_type=torch.float32, channels_start=32,\n",
    "                       ndf1=6, ndf0=32,embed_dim_pe=12, nr_node_feats=5,cuda=True, real_threshold=1.99):\n",
    "        \n",
    "        self.KNN = KNN\n",
    "        self.n_nodes = n_nodes\n",
    "        self.pe = circular_pe_encoding(n_nodes=n_nodes,embed_dim=embed_dim_pe, cast_type=torch.float32)\n",
    "        self.mp_stride = mp_stride\n",
    "        self.null_stride = mp_stride*2\n",
    "        self.cast_type = cast_type\n",
    "        self.channels_start = channels_start\n",
    "        self.real_threshold = real_threshold\n",
    "        \n",
    "        \n",
    "        \n",
    "        self.cuda = cuda\n",
    "        self.ndf1 = ndf1 #awkard adding of nodes features to mpGraph\n",
    "        self.ndf0 = ndf0\n",
    "        self.NODE_FEATURE_DIM_0 = embed_dim_pe + nr_node_feats\n",
    "        \n",
    "        \n",
    "    def create_and_batch(self, bb_dict, print_out=False,cast_type=torch.float):\n",
    "\n",
    "        graphList = []\n",
    "        mpGraphList = []\n",
    "        mpRevGraphList = []\n",
    "        mpSelfGraphList = []\n",
    "        \n",
    "        for j, caXYZ in enumerate(bb_dict['bb_noised']['CA']):\n",
    "            #round nodes to be real (1) or (null 0)\n",
    "            #get null node indices from mask\n",
    "            \n",
    "            real_nodes_feats = bb_dict['real_nodes_noise'][j].clamp(0,1)\n",
    "            \n",
    "            real_nodes_fround = torch.round(bb_dict['real_nodes_noise'][j]).clamp(0,1)\n",
    "            real_nodes_mask = real_nodes_fround.sum(-1) > self.real_threshold\n",
    "\n",
    "            #make a knn graph form the real nodes only\n",
    "            graph = gudiff_model.Data_Graph_Null.monomer_null_knngraph(caXYZ, real_nodes_mask, k=self.KNN)\n",
    "            graph.ndata['pe_nf'] = torch.cat((self.pe,real_nodes_feats),dim=-1).type(cast_type)\n",
    "            graph.ndata['pos'] = caXYZ\n",
    "            graph.ndata['bb_ori'] = torch.cat((bb_dict['bb_noised']['N_CA'][j], bb_dict['bb_noised']['C_CA'][j]),axis=1)\n",
    "            graph.ndata['real_nodes_mask']=real_nodes_mask\n",
    "\n",
    "            #gather edge data from all possible noised edges produced\n",
    "            gsrc, gdst = graph.edges()\n",
    "            num_edges = len(gsrc)\n",
    "\n",
    "            #adjacent AA are one apart, or the loop connection from zero node to the last node\n",
    "            adj_nodes_mask = ((torch.abs(gsrc-gdst)==1) | (torch.abs(gsrc-gdst)==len(gsrc)-1)) \n",
    "\n",
    "            #actually we need to determine\n",
    "            null_nodes = torch.arange(self.n_nodes,dtype=torch.int)[~real_nodes_mask]\n",
    "            real_nodes = torch.arange(self.n_nodes,dtype=torch.int)[real_nodes_mask]\n",
    "            \n",
    "                        #broadcast each src/dst node against all null nodes, if any match along node dimension is a null edge\n",
    "            gsrc_compare = (gsrc[:,None] - null_nodes[None,:])\n",
    "            gdst_compare = (gdst[:,None] - null_nodes[None,:])\n",
    "            null_edges_src_ind = torch.where(gsrc_compare==0,True,False).any(dim=1)\n",
    "            null_edges_dst_ind = torch.where(gdst_compare==0,True,False).any(dim=1)\n",
    "\n",
    "            #broadcast each src/dst node against all real or null nodes, if any match along node dimension is a null edge\n",
    "            gsrc_compare = (gsrc[:,None] - real_nodes[None,:])\n",
    "            gdst_compare = (gdst[:,None] - real_nodes[None,:])\n",
    "            real_edges_src_ind = torch.where(gsrc_compare==0,True,False).any(dim=1)\n",
    "            real_edges_dst_ind = torch.where(gdst_compare==0,True,False).any(dim=1)\n",
    "            #null edges connect to any null nodes (|), real edges must both be real (&)\n",
    "            null_edges = null_edges_src_ind | null_edges_dst_ind\n",
    "            real_edges = real_edges_src_ind & real_edges_dst_ind\n",
    "            adj_real = adj_nodes_mask&real_edges\n",
    "\n",
    "            #edge features likely not needed, taken care of in node features\n",
    "\n",
    "            EDGE_DIM=self.EDGE_FEATURE_DIM\n",
    "\n",
    "            ###\n",
    "#             enoised = noised_dict['edge_cons'][j]\n",
    "#             enoised = enoised.reshape((-1,EDGE_DIM,2))[:num_edges]\n",
    "            edata = torch.ones(gsrc.shape+(EDGE_DIM,))\n",
    "            # oh1_mask = torch.tensor([1,0,0]).unsqueeze(-1)\n",
    "            # oh2_mask = torch.tensor([0,1,0]).unsqueeze(-1)\n",
    "            # oh3_mask = torch.tensor([0,0,1]).unsqueeze(-1)\n",
    "\n",
    "\n",
    "            # #needs to add - /+ N/C directon for this data????, or is this covered by pe encoding\n",
    "            # edata[real_edges] = torch.gather(enoised[real_edges],2,oh2_mask.repeat(real_edges.sum(),1,1))[:,:,0]\n",
    "            # edata[adj_real] = torch.gather(enoised[adj_real],2,oh1_mask.repeat(adj_real.sum(),1,1))[:,:,0]\n",
    "            # edata[null_edges] = torch.gather(enoised[null_edges],2,oh3_mask.repeat(null_edges.sum(),1,1))[:,:,0]\n",
    "\n",
    "            # edge_dir = torch.ones_like(gsrc,dtype=torch.long) #NotC direction off AA sequence\n",
    "            # edge_dir[gdst<gsrc]=-1 # #NotC; reverse direction \n",
    "            # edata[adj_nodes_mask]=edata[adj_nodes_mask]*edge_dir\n",
    "\n",
    "            graph.edata['con'] = edata\n",
    "\n",
    "            #way to get real_edges and null edges in loop code\n",
    "            # null_edges = torch.zeros_like(gsrc)\n",
    "            # for i,x in enumerate(gsrc):\n",
    "            #     if gsrc[i] in null_nodes or gdst[i] in null_nodes:\n",
    "            #         null_edges[i] = 1\n",
    "\n",
    "            # real_edges = torch.zeros_like(gsrc)\n",
    "            # for i,x in enumerate(gsrc):\n",
    "            #     if gsrc[i] in real_nodes and gdst[i] in real_nodes:\n",
    "            #         real_edges[i] = 1\n",
    "\n",
    "            #max possible mp feats, is +1 for range(start,end,stride) combines with real+null=total + stride rounding \n",
    "            mp_list = torch.zeros((len(list(range(0,self.n_nodes, self.mp_stride)))+1),caXYZ.shape[1])\n",
    "\n",
    "            new_src = torch.tensor([],dtype=torch.int)\n",
    "            new_dst = torch.tensor([],dtype=torch.int)\n",
    "\n",
    "            new_src_rev = torch.tensor([], dtype=torch.int)\n",
    "            new_dst_rev = torch.tensor([], dtype=torch.int)\n",
    "\n",
    "            #create midpoints for real nodes\n",
    "            i=0#mp list counter\n",
    "            mp_real_node_counter = 0\n",
    "            for real_index in range(0,len(real_nodes), self.mp_stride):\n",
    "                x = real_nodes[real_index] #convert to match torch.int from\n",
    "                src, dst = graph.in_edges(x) #dst repeats x, this grab null nodes too\n",
    "\n",
    "                n_tot = torch.cat((x.unsqueeze(0),src)) #add x to node list\n",
    "                mp_list[i] = caXYZ[n_tot].sum(axis=0)/n_tot.shape[0]\n",
    "                mp_node = i + graph.num_nodes() #add midpoints nodes at end of graph\n",
    "                mp_real_node_counter += 1\n",
    "                #define edges between midpoint nodes and nodes defining midpoint for midpointGraph\n",
    "\n",
    "                new_src = torch.cat((new_src,n_tot))\n",
    "                new_dst = torch.cat((new_dst,\n",
    "                                     (torch.tensor(mp_node,dtype=torch.int).unsqueeze(0).repeat(n_tot.shape[0]))))\n",
    "\n",
    "                i+=1\n",
    "\n",
    "            #remove extra null nodes from .in_edges call\n",
    "\n",
    "            #remove edges that are null node connections,\n",
    "            #dst are the midpoint nodes for mpGraph, src are mp nodes for mpGraphRev\n",
    "            #only remove non-mp nodes\n",
    "\n",
    "            real_mask_rem1 = torch.isin(new_src,real_nodes)\n",
    "            #             real_mask_rem2 = torch.isin(new_dst_rev,real_nodes) \n",
    "            new_src = new_src[real_mask_rem1]\n",
    "            new_dst = new_dst[real_mask_rem1]\n",
    "            #             new_src_rev = new_src_rev[real_mask_rem2]\n",
    "            #             new_dst_rev = new_dst_rev[real_mask_rem2]\n",
    "\n",
    "\n",
    "            #collapse collected null nodes onto null mp of contingous sections \n",
    "            end_p = ((null_nodes.roll(1)-null_nodes)==-1) #consecutive are equal to negative one (look right)\n",
    "            start_p = ((null_nodes.roll(-1)-null_nodes)==1) #consecutive are equal to one (look left)\n",
    "            startend = (start_p != end_p) #remove overlap of interior consecutive nodes\n",
    "            start = start_p == startend #just get the starts\n",
    "            end  = end_p == startend #just get the ends\n",
    "            si = torch.arange(len(start),dtype=torch.int)[start]# indices of start of consecutive nodes\n",
    "            ei = torch.arange((len(end)),dtype=torch.int)[end] # indices of end of cone\n",
    "\n",
    "            #connect first and last groups if approriate\n",
    "            if null_nodes[0]==0 and null_nodes[-1]==self.n_nodes-1:\n",
    "                #roll last group across barrier\n",
    "                roll_con = len(start)-si[-1]\n",
    "                null_nodes = null_nodes.roll(int(roll_con))\n",
    "                #update end index and start index by roll and remove groups (one from end)\n",
    "                #add zero to start and remove last start (rolled)\n",
    "                ei = (ei+roll_con)[:-1]\n",
    "                sic=torch.zeros_like(si[1:])\n",
    "                sic[1:] = si[1:-1]+roll_con\n",
    "                si = sic\n",
    "\n",
    "            #mp_list_null  = torch.ones((si.shape[0],caXYZ.shape[1]))*-1e9\n",
    "            #add null nodes to the end of mp_list\n",
    "            counter_mp_index = 0 #mp list counter, start/end  \n",
    "            tot_indices = si.shape[0]\n",
    "            while counter_mp_index < tot_indices:\n",
    "\n",
    "                n_tot = null_nodes[si[counter_mp_index]:ei[counter_mp_index]+1]\n",
    "                while len(n_tot) <  self.mp_stride and counter_mp_index+1<tot_indices:\n",
    "                    #merge non-continuous null nodes smaller than stride\n",
    "                    counter_mp_index=counter_mp_index+1\n",
    "                    n_tot = torch.cat([n_tot,null_nodes[si[counter_mp_index]:ei[counter_mp_index]+1]],axis=0)\n",
    "\n",
    "                mp_list[i] = caXYZ[n_tot].sum(axis=0)/n_tot.shape[0]\n",
    "                mp_node = i + graph.num_nodes() #add midpoints nodes at end of graph\n",
    "\n",
    "                #from null nodes to new mp_node\n",
    "                new_src = torch.cat((new_src,n_tot))\n",
    "                new_dst = torch.cat((new_dst,\n",
    "                                     (torch.tensor(mp_node,dtype=torch.int).unsqueeze(0).repeat(n_tot.shape[0]))))\n",
    "                #and reverse graph for coming off\n",
    "                new_src_rev = torch.cat((new_src_rev,\n",
    "                                         (torch.tensor(mp_node,dtype=torch.int).unsqueeze(0).repeat(n_tot.shape[0]))))\n",
    "                new_dst_rev = torch.cat((new_dst_rev,n_tot))\n",
    "\n",
    "                i=i+1\n",
    "                counter_mp_index += 1\n",
    "\n",
    "            mp_node_indx = torch.arange(0,len(mp_list)).type(torch.int)    \n",
    "\n",
    "            mpGraph = dgl.graph((new_src,new_dst))\n",
    "            to_Add = len(mp_list)+graph.num_nodes()-mpGraph.num_nodes()\n",
    "            mpGraph.add_nodes(to_Add) #nodes without any use for padding\n",
    "            mp_pos = torch.cat((caXYZ,mp_list),axis=0).type(self.cast_type)\n",
    "            mpGraph.ndata['pos'] = mp_pos\n",
    "\n",
    "            mp_real_node_counter\n",
    "            mp_real_node_counter = counter_mp_index\n",
    "\n",
    "            #mp real/ null nodes\n",
    "            mp_node_real_mask = torch.zeros(mp_list.shape[0],dtype=torch.bool)\n",
    "            mp_node_real_mask[:mp_real_node_counter] = True\n",
    "            mpGraph.ndata['mp_node_real_mask'] = torch.cat([real_nodes_mask,mp_node_real_mask])\n",
    "\n",
    "            #match output shape of first transformer\n",
    "            pe_mp = torch.cat((self.pe,torch.zeros((self.pe.shape[0], self.channels_start-self.pe.shape[1]))),axis=1)\n",
    "            mpGraph.ndata['pe'] = torch.cat((pe_mp,pe_mp[mp_node_indx]))\n",
    "            mpGraph.edata['con'] = torch.ones((mpGraph.num_edges(),1))\n",
    "            mpGraph_rev = dgl.graph((new_dst,new_src))\n",
    "            mpGraph_rev.add_nodes(to_Add)\n",
    "            mpGraph_rev.ndata['pos'] = torch.cat((caXYZ,mp_list),axis=0).type(self.cast_type)\n",
    "            mpGraph_rev.ndata['pe'] = torch.cat((pe_mp,pe_mp[mp_node_indx]))\n",
    "            mpGraph_rev.edata['con'] = torch.ones((mpGraph_rev.num_edges(),1))\n",
    "            mpGraph_rev.ndata['mp_node_real_mask'] = torch.cat([real_nodes_mask,mp_node_real_mask])\n",
    "            #make graph for self interaction of midpoints\n",
    "            v1,v2,edge_data, ind = define_graph_edges(len(mp_list))\n",
    "            mpSelfGraph = dgl.graph((v1,v2))\n",
    "            mpSelfGraph.edata['con'] = edge_data.reshape((-1,1))\n",
    "            mpSelfGraph.ndata['pe'] = self.pe[mp_node_indx] #not really needed\n",
    "            mpSelfGraph.ndata['pos'] = mp_list.type(self.cast_type)\n",
    "\n",
    "            \n",
    "            mpSelfGraphList.append(mpSelfGraph)\n",
    "            mpGraphList.append(mpGraph)\n",
    "            mpRevGraphList.append(mpGraph_rev)\n",
    "            graphList.append(graph)\n",
    "       \n",
    "        return dgl.batch(graphList), dgl.batch(mpGraphList), dgl.batch(mpSelfGraphList), dgl.batch(mpRevGraphList)\n",
    "    \n",
    "    def prep_for_network(self, bb_dict, cuda=True):\n",
    "    \n",
    "        batched_graph, batched_mpgraph, batched_mpself_graph, batched_mpRevgraph =  self.create_and_batch(bb_dict)\n",
    "        \n",
    "        edge_feats        =    {'0':   batched_graph.edata['con'][:, :self.EDGE_FEATURE_DIM, None]}\n",
    "        edge_feats_mp     = {'0': batched_mpgraph.edata['con'][:, :self.EDGE_FEATURE_DIM, None]} #def all one now\n",
    "        edge_feats_mpself = {'0': batched_mpself_graph.edata['con'][:, :self.EDGE_FEATURE_DIM, None]}\n",
    "#         edge_feats_mp     = {'0': batched_mpRevgraph.edata['con'][:, :self.EDGE_FEATURE_DIM, None]}\n",
    "        batched_graph.edata['rel_pos']   = gudiff_model.Data_Graph_Null._get_relative_pos(batched_graph)\n",
    "        batched_mpgraph.edata['rel_pos'] = gudiff_model.Data_Graph_Null._get_relative_pos(batched_mpgraph)\n",
    "        batched_mpself_graph.edata['rel_pos'] = gudiff_model.Data_Graph_Null._get_relative_pos(batched_mpself_graph)\n",
    "        batched_mpRevgraph.edata['rel_pos'] = gudiff_model.Data_Graph_Null._get_relative_pos(batched_mpRevgraph)\n",
    "        # get node features\n",
    "        node_feats =         {'0': batched_graph.ndata['pe_nf'][:, :self.NODE_FEATURE_DIM_0, None],\n",
    "                              '1': batched_graph.ndata['bb_ori'][:,:self.NODE_FEATURE_DIM_1, :3]}\n",
    "        node_feats_mp =      {'0': batched_mpgraph.ndata['pe'][:, :self.ndf0, None],\n",
    "                              '1': torch.ones((batched_mpgraph.num_nodes(),self.ndf1,3))}\n",
    "        #unused\n",
    "        node_feats_mpself =  {'0': batched_mpself_graph.ndata['pe'][:, :self.NODE_FEATURE_DIM_0, None]}\n",
    "        \n",
    "        out_dict = {}\n",
    "        \n",
    "        if cuda:\n",
    "            bg,nf,ef = to_cuda(batched_graph), to_cuda(node_feats), to_cuda(edge_feats)\n",
    "            bg_mp, nf_mp, ef_mp = to_cuda(batched_mpgraph), to_cuda(node_feats_mp), to_cuda(edge_feats_mp)\n",
    "            bg_mps, nf_mps, ef_mps = to_cuda(batched_mpself_graph), to_cuda(node_feats_mpself), to_cuda(edge_feats_mpself)\n",
    "            bg_mpRev = to_cuda(batched_mpRevgraph)\n",
    "\n",
    "            \n",
    "            #return bg,nf,ef, bg_mp, nf_mp, ef_mp, bg_mps, nf_mps, ef_mps, bg_mpRev\n",
    "        \n",
    "        else:\n",
    "            bg,nf,ef = batched_graph, node_feats, edge_feats\n",
    "            bg_mp, nf_mp, ef_mp = batched_mpgraph, node_feats_mp, edge_feats_mp\n",
    "            bg_mps, nf_mps, ef_mps = batched_mpself_graph, node_feats_mpself, edge_feats_mpself\n",
    "            bg_mpRev = batched_mpRevgraph\n",
    "            \n",
    "            #return bg,nf,ef, bg_mp, nf_mp, ef_mp, bg_mps, nf_mps, ef_mps, bg_mpRev\n",
    "        \n",
    "                    \n",
    "        out_dict['batched_graph'] = bg\n",
    "        out_dict['node_feats'] = nf\n",
    "        out_dict['edge_feats'] = ef\n",
    "        out_dict['batched_graph_mp'] = bg_mp\n",
    "        out_dict['node_feats_mp'] = nf_mp\n",
    "        out_dict['edge_feats_mp'] = ef_mp\n",
    "        out_dict['batched_graph_mpself'] = bg_mps\n",
    "        out_dict['node_feats_mpself'] = nf_mps\n",
    "        out_dict['edge_feats_mpself'] = ef_mps\n",
    "        out_dict['batched_graph_mprev'] = bg_mpRev\n",
    "        \n",
    "        return out_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8aba9c9f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "165dc297",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0baab26e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "f3eae2f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# B = 16\n",
    "# L=65\n",
    "# limit = 1028\n",
    "# h4_trainData = Helix4_Dataset(coords_tog[:limit])\n",
    "# h4_valData = Helix4_Dataset(coords_apa[:limit])\n",
    "# train_dL = DataLoader(h4_trainData, batch_size=B, shuffle=True, drop_last=True)\n",
    "# val_dL   = DataLoader(h4_valData, batch_size=B, shuffle=True, drop_last=True)\n",
    "# testiter = iter(train_dL)\n",
    "# bb_dict = next(testiter)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "87f67d73",
   "metadata": {},
   "outputs": [],
   "source": [
    "from data_rigid_diffuser import diffuser"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "581b3006",
   "metadata": {},
   "outputs": [],
   "source": [
    "#I think I adjusted inputs and outputs,\n",
    "#sigmoid for nodes features for real/null pred?\n",
    "#need loss function for real/null nodes\n",
    "#need to get function to just pull real nodes for viewing?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "d79401b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "#helper functions for Diffusion_Graphical_UNet_Model\n",
    "\n",
    "def define_poolGraph(n_nodes, batch_size, cast_type=torch.float32, cuda_out=True ):\n",
    "    \n",
    "    v1,v2,edge_data, ind = define_graph_edges(n_nodes)\n",
    "    #pe = make_pe_encoding(n_nodes=n_nodes)#pe e\n",
    "    \n",
    "    graphList = []\n",
    "    \n",
    "    for i in range(batch_size):\n",
    "        \n",
    "        g = dgl.graph((v1,v2))\n",
    "        g.edata['con'] = edge_data.type(cast_type).reshape((-1,1))\n",
    "        g.ndata['pos'] = torch.zeros((n_nodes,3),dtype=torch.float32)\n",
    "\n",
    "        graphList.append(g)\n",
    "        \n",
    "    batched_graph = dgl.batch(graphList)\n",
    "    \n",
    "    if cuda_out:\n",
    "        return to_cuda(batched_graph)\n",
    "    else:\n",
    "        return batched_graph            \n",
    "        \n",
    "def pull_edge_features(graph, edge_feat_dim=1):\n",
    "    return {'0': graph.edata['con'][:, :edge_feat_dim, None]}\n",
    "\n",
    "def prep_for_gcn(graph, xyz_pos, edge_feats_input, idx, max_degree=3, comp_grad=True):\n",
    "    \n",
    "    src, dst = graph.edges()\n",
    "    \n",
    "    new_pos = F.gather_row(xyz_pos, idx)\n",
    "    rel_pos = F.gather_row(new_pos,dst) - F.gather_row(new_pos,src) \n",
    "    \n",
    "    basis_out = get_basis(rel_pos, max_degree=max_degree,\n",
    "                                   compute_gradients=comp_grad,\n",
    "                                   use_pad_trick=False)\n",
    "    basis_out = update_basis_with_fused(basis_out, max_degree, use_pad_trick=False,\n",
    "                                            fully_fused=False)\n",
    "    edge_feats_out = get_populated_edge_features(rel_pos, edge_feats_input)\n",
    "    return edge_feats_out, basis_out, new_pos    \n",
    "\n",
    "#--- layer for converting t[0,1] to be more expressive\n",
    "class GaussianFourierProjection(nn.Module):\n",
    "    \"\"\"Gaussian random features for encoding time steps.\"\"\"  \n",
    "    #From Yang Song, Tutorial on Score based diffusion models\n",
    "    def __init__(self, embed_dim, scale=30.):\n",
    "        super().__init__()\n",
    "        # Randomly sample weights during initialization. These weights are fixed \n",
    "        # during optimization and are not trainable.\n",
    "        self.W = nn.Parameter(torch.randn(embed_dim // 2) * scale, requires_grad=False)\n",
    "    def forward(self, x):\n",
    "        x_proj = x[:, None] * self.W[None, :] * 2 * np.pi\n",
    "        return torch.cat([torch.sin(x_proj), torch.cos(x_proj)], dim=-1)\n",
    "    \n",
    "class GaussianFourierProjection_Linear(nn.Module):\n",
    "    \"\"\"Gaussian random features for encoding time steps.\"\"\"  \n",
    "    #From Yang Song, Tutorial on Score based diffusion models\n",
    "    def __init__(self, embed_dim, scale=30., use_deg1 = True):\n",
    "        super().__init__()\n",
    "        self.GFP = GaussianFourierProjection(embed_dim, scale=scale)\n",
    "        self.linear0 = nn.Linear(embed_dim,embed_dim)\n",
    "        self.use_deg1 = use_deg1\n",
    "        self.act = nn.SiLU()\n",
    "        if use_deg1:\n",
    "            self.linear1 = nn.Linear(embed_dim,1) #create a scalar for multiplication to vector '1'\n",
    "            #according to to some toronto math notes I believe this retains invariance\n",
    "\n",
    "    def forward(self, t):\n",
    "        if self.use_deg1:\n",
    "            return {'0': self.act(self.linear0(self.GFP(t))), '1':self.act(self.linear1(self.GFP(t)))}\n",
    "        else:\n",
    "            return {'0' : self.act(self.linear0(self.GFP(t)))}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "6b515101",
   "metadata": {},
   "outputs": [],
   "source": [
    "##-- Graphical U-net for Denoising\n",
    "class GraphUNet_Null(torch.nn.Module):\n",
    "    def __init__(self, \n",
    "                 fiber_start = Fiber({0:12, 1:2}),\n",
    "                 fiber_out = Fiber({0:5,1:2}),\n",
    "                 k=4,\n",
    "                 batch_size = 8,\n",
    "                 stride=4,\n",
    "                 max_degree=3,\n",
    "                 channels=32,\n",
    "                 num_heads = 8,\n",
    "                 channels_div=4,\n",
    "                 num_layers = 1,\n",
    "                 num_layers_ca = 1,\n",
    "                 edge_feature_dim=1,\n",
    "                 latent_pool_type = 'avg',\n",
    "                 t_size = 12,\n",
    "                 zero_lin=True,\n",
    "                 use_tdeg1 = True,\n",
    "                 cuda=True):\n",
    "        super(GraphUNet_Null, self).__init__()\n",
    "        \n",
    "        #fiber_out is 5 for the null nodes, 1deg (2 (3D vector) to update translation/ rotation)\n",
    "        \n",
    "        #self.comp_basis_grad = True\n",
    "        self.cuda = cuda\n",
    "        \n",
    "        if cuda:\n",
    "            self.device='cuda:0'\n",
    "        else:\n",
    "            self.device='cpu'\n",
    "        \n",
    "        self.max_degree=max_degree #number of 'orbital types' to use for representing the sphere\n",
    "        self.B = batch_size\n",
    "        self.k = k #number of midpoints to be chosen to reduce graph size (topK pooling layer)\n",
    "        self.ts = t_size #number of features to represent t-value\n",
    "        \n",
    "        self.use_tdeg1 = use_tdeg1 #apply a t-value to degree (vector) one in the se3transformer\n",
    "                                    #scalar t put in one dimension , pad zero for other. Perhaps Bad to do.\n",
    "        self.zero_lin = zero_lin #apply a zero weight value to the linear \n",
    "        \n",
    "        self.embed_t = GaussianFourierProjection_Linear(self.ts, use_deg1=self.use_tdeg1)\n",
    "        self.t_fiber = Fiber({0:self.ts}) #add for change in fiber with self.concat_t\n",
    "        \n",
    "        self.num_layers = 1 #se3 transformers layers for all except the CA graph layer\n",
    "        self.num_layers_ca = num_layers_ca #layers to use on the CA-alpha graph layer\n",
    "        self.channels = 32\n",
    "        self.feat0 = 32 #deg0 number of features\n",
    "        self.feat1 = 6  #deg1 number of features\n",
    "        self.channels_div = 4\n",
    "        self.num_heads = 8 #se3 attention heads\n",
    "        self.mult = int(stride/2) #multiplier to increase channels as the graph reduces nodes\n",
    "        self.fiber_edge=Fiber({0:edge_feature_dim})\n",
    "        self.edge_feat_dim = edge_feature_dim\n",
    "        \n",
    "        self.pool_type = latent_pool_type \n",
    "        \n",
    "        self.channels_down_ca = channels #c_alpha interactions by nearest  neighbors onto midpoints \n",
    "        #(on the down side of U-Net)\n",
    "        self.fiber_start =  fiber_start\n",
    "        self.fiber_hidden_down_ca = Fiber.create(self.max_degree, self.channels_down_ca)\n",
    "        self.fiber_out_down_ca =Fiber({0: self.feat0, 1: self.feat1})\n",
    "        \n",
    "        #concat fiber+t_value, plus one on input fiber, use concat_t method during forward call\n",
    "        self.down_ca = SE3Transformer(num_layers = self.num_layers_ca,\n",
    "                        fiber_in=self.fiber_start+self.t_fiber,\n",
    "                        fiber_hidden= self.fiber_hidden_down_ca, \n",
    "                        fiber_out=self.fiber_out_down_ca,\n",
    "                        num_heads = self.num_heads,\n",
    "                        channels_div = self.channels_div,\n",
    "                        fiber_edge=self.fiber_edge,\n",
    "                        low_memory=True,\n",
    "                        tensor_cores=False)\n",
    "        \n",
    "        self.channels_down_ca2mp = self.channels_down_ca*self.mult\n",
    "        \n",
    "        #pool from c_alpha onto midpoints\n",
    "        self.fiber_in_down_ca2mp     = self.fiber_out_down_ca\n",
    "        self.fiber_hidden_down_ca2mp = Fiber.create(max_degree, self.channels_down_ca2mp)\n",
    "        self.fiber_out_down_ca2mp    = Fiber({0: self.feat0*self.mult, 1: self.feat1*self.mult})\n",
    "        \n",
    "        #concat_t, plus one on input fiber, run concat_t method on forward call\n",
    "        self.down_ca2mp = SE3Transformer(num_layers = self.num_layers,\n",
    "                            fiber_in     = self.fiber_in_down_ca2mp+self.t_fiber,\n",
    "                            fiber_hidden = self.fiber_hidden_down_ca2mp, \n",
    "                            fiber_out    = self.fiber_out_down_ca2mp,\n",
    "                            num_heads =    self.num_heads,\n",
    "                            channels_div = self.channels_div,\n",
    "                            fiber_edge=self. fiber_edge,\n",
    "                            low_memory=True,\n",
    "                            tensor_cores=False)\n",
    "        \n",
    "        #topK selection of midpoint node graph\n",
    "        self.fiber_in_mptopk =  self.fiber_out_down_ca2mp\n",
    "        self.fiber_hidden_down_mp  =self.fiber_hidden_down_ca2mp\n",
    "        self.fiber_out_down_mp_out =self.fiber_out_down_ca2mp\n",
    "        self.fiber_out_topkpool=Fiber({0: self.feat0*self.mult*self.mult})\n",
    "        \n",
    "        #concat_t, plus one on input fiber, run concat_t method on forward\n",
    "        self.mp_topk = SE3Transformer_topK(num_layers = self.num_layers,\n",
    "                                        fiber_in      = self.fiber_in_mptopk+self.t_fiber,\n",
    "                                        fiber_hidden  = self.fiber_hidden_down_mp, \n",
    "                                        fiber_out     = self.fiber_out_down_mp_out ,\n",
    "                                        fiber_out_topk= self.fiber_out_topkpool,\n",
    "                                        k             = self.k,\n",
    "                                        num_heads     = self.num_heads,\n",
    "                                        channels_div  = self.channels_div,\n",
    "                                        fiber_edge    =  self.fiber_edge,\n",
    "                                        low_memory=True,\n",
    "                                        tensor_cores=False)\n",
    "        \n",
    "        self.gsmall = define_poolGraph(self.k, self.B, cast_type=torch.float32, cuda_out=self.cuda)\n",
    "        self.ef_small = pull_edge_features(self.gsmall, edge_feat_dim=self.edge_feat_dim)\n",
    "        \n",
    "        #change to doing convolutions instead of transformer\n",
    "        self.fiber_in_down_gcn   =  self.fiber_out_topkpool\n",
    "        self.fiber_out_down_gcn  = Fiber({0: self.feat0*self.mult*self.mult, 1: self.feat1*self.mult})\n",
    "\n",
    "        self.down_gcn = ConvSE3(fiber_in  = self.fiber_in_down_gcn,\n",
    "                           fiber_out = self.fiber_out_down_gcn,\n",
    "                           fiber_edge= self.fiber_edge,\n",
    "                             self_interaction=True,\n",
    "                             use_layer_norm=True,\n",
    "                             max_degree=self.max_degree,\n",
    "                             fuse_level= ConvSE3FuseLevel.NONE,\n",
    "                             low_memory= True)\n",
    "        \n",
    "        \n",
    "        self.fiber_in_down_gcnp = self.fiber_out_down_gcn\n",
    "        #probably rename latent to something more approriate \n",
    "        self.latent_size = self.feat0*self.mult*self.mult\n",
    "        self.fiber_latent = Fiber({0: self.latent_size})\n",
    "\n",
    "        self.down_gcn2pool = ConvSE3(fiber_in=self.fiber_in_down_gcnp,\n",
    "                                     fiber_out=self.fiber_latent,\n",
    "                                     fiber_edge=self.fiber_edge,\n",
    "                                     self_interaction=True,\n",
    "                                     use_layer_norm=True,\n",
    "                                     max_degree=self.max_degree,\n",
    "                                     fuse_level= ConvSE3FuseLevel.NONE,\n",
    "                                     low_memory= True)\n",
    "        \n",
    "        self.global_pool = GPooling(pool=self.pool_type, feat_type=0)\n",
    "\n",
    "        self.latent_unpool_layer = Latent_Unpool(fiber_in = self.fiber_latent, fiber_add = self.fiber_out_down_gcn, \n",
    "                                            knodes = self.k)\n",
    "\n",
    "        self.up_gcn = ConvSE3(fiber_in=self.fiber_out_down_gcn,\n",
    "                             fiber_out=self.fiber_out_down_gcn,\n",
    "                             fiber_edge=self.fiber_edge,\n",
    "                             self_interaction=True,\n",
    "                             use_layer_norm=True,\n",
    "                             max_degree=self.max_degree,\n",
    "                             fuse_level= ConvSE3FuseLevel.NONE,\n",
    "                             low_memory= True)\n",
    "        \n",
    "        self.unpool_layer = Unpool_Layer(fiber_in=self.fiber_out_down_gcn, fiber_add=self.fiber_out_down_ca)\n",
    "        \n",
    "        self.fiber_in_up_gcn_mp = self.unpool_layer.fiber_out\n",
    "        self.fiber_hidden_up_mp= self.fiber_hidden_down_ca2mp\n",
    "        self.fiber_out_up_gcn_mp = self.fiber_out_down_mp_out\n",
    "\n",
    "        self.up_gcn_mp = SE3Transformer(num_layers = num_layers,\n",
    "                        fiber_in=self.fiber_in_up_gcn_mp,\n",
    "                        fiber_hidden= self.fiber_hidden_up_mp, \n",
    "                        fiber_out=self.fiber_out_up_gcn_mp,\n",
    "                        num_heads = self.num_heads,\n",
    "                        channels_div = self.channels_div,\n",
    "                        fiber_edge=self.fiber_edge,\n",
    "                        low_memory=True,\n",
    "                        tensor_cores=False)\n",
    "        \n",
    "        self.unpool_layer_off_mp = Unpool_Layer(fiber_in=self.fiber_out_down_mp_out, fiber_add=self.fiber_out_down_mp_out)\n",
    "\n",
    "        self.fiber_in_up_off_mp = self.fiber_out_up_gcn_mp\n",
    "        self.fiber_hidden_up_off_mp = self.fiber_hidden_up_mp\n",
    "        self.fiber_out_up_off_mp = self.fiber_out_down_ca \n",
    "        \n",
    "        #uses reverse graph to move mp off \n",
    "        \n",
    "        self.up_off_mp = SE3Transformer(num_layers = self.num_layers,\n",
    "                        fiber_in=self.fiber_in_up_off_mp,\n",
    "                        fiber_hidden= self.fiber_hidden_up_off_mp, \n",
    "                        fiber_out=self.fiber_out_up_off_mp,\n",
    "                        num_heads = self.num_heads,\n",
    "                        channels_div = self.channels_div,\n",
    "                        fiber_edge=self.fiber_edge,\n",
    "                        low_memory=True,\n",
    "                        tensor_cores=False)\n",
    "        \n",
    "        self.pre_linear = Fiber({0:16,1:36}) \n",
    "        #add for 0 for node prediction (real, null), \n",
    "        #1 for prediction of \n",
    "        \n",
    "        #concat_t, plus one on input fiber, run concat_t method on forward\n",
    "        \n",
    "        self.up_ca = SE3Transformer(num_layers = self.num_layers_ca,\n",
    "                                    fiber_in=self.fiber_out_down_ca+self.t_fiber,\n",
    "                                    fiber_hidden= self.fiber_hidden_down_ca, \n",
    "                                    fiber_out=self.pre_linear,\n",
    "                                    num_heads = self.num_heads,\n",
    "                                    channels_div = self.channels_div,\n",
    "                                    fiber_edge= self.fiber_edge,\n",
    "                                    low_memory=True,\n",
    "                                    tensor_cores=False)\n",
    "        \n",
    "        self.fiber_out = fiber_out\n",
    "        \n",
    "        self.linear = LinearSE3(fiber_in=self.pre_linear,\n",
    "                                fiber_out=fiber_out)\n",
    "        \n",
    "        #do i need to add activation to zero(linera)\n",
    "        \n",
    "        if self.zero_lin:\n",
    "            self.zero_linear()\n",
    "        self.act = nn.SiLU()\n",
    "        self.sig = nn.Sigmoid()\n",
    "        \n",
    "    def zero_linear(self):\n",
    "        \"\"\"Zero linear weights of degree one only.\"\"\"\n",
    "        nn.init.zeros_(self.linear.weights['1'])\n",
    "        \n",
    "    def concat_mp_feats(self, ca_feats_in, mp_feats):\n",
    "        \"\"\"Concatenate the mp and calpha feats, by debatching batched graph\"\"\"\n",
    "        nf0_c = ca_feats_in['0'].shape[-2]\n",
    "        nf1_c = ca_feats_in['1'].shape[-2]\n",
    "\n",
    "        out0_cat_shape = (self.B,self.ca_nodes,-1,1)\n",
    "        mp0_cat_shape  = (self.B,self.mp_nodes,-1,1)\n",
    "        out1_cat_shape = (self.B,self.ca_nodes,-1,3)\n",
    "        mp1_cat_shape  = (self.B,self.mp_nodes,-1,3)\n",
    "\n",
    "        nf_c = {} #nf_cat\n",
    "        nf_c['0'] = torch.cat((ca_feats_in['0'].reshape(out0_cat_shape), \n",
    "                                 mp_feats['0'].reshape(mp0_cat_shape)[:,-(self.mp_nodes-self.ca_nodes):,:,:]),\n",
    "                              axis=1).reshape((-1,nf0_c,1))\n",
    "\n",
    "        nf_c['1'] = torch.cat((ca_feats_in['1'].reshape(out1_cat_shape), \n",
    "                                 mp_feats['1'].reshape(mp1_cat_shape)[:,-(self.mp_nodes-self.ca_nodes):,:,:]),\n",
    "                              axis=1).reshape((-1,nf1_c,3))\n",
    "\n",
    "        return nf_c\n",
    "        \n",
    "    def pull_out_mp_feats(self, ca_mp_feats):\n",
    "        \"\"\"Select mp feats selected as the topK nodes\"\"\"\n",
    "\n",
    "        nf0_c = ca_mp_feats['0'].shape[1]\n",
    "        nf1_c = ca_mp_feats['1'].shape[1]\n",
    "\n",
    "        nf_mp_ = {}\n",
    "        #select just mp nodes to move on, the other nodes don't connect but mainting self connections\n",
    "        nf_mp_['0'] = ca_mp_feats['0'].reshape(self.B,self.mp_nodes,\n",
    "                                               nf0_c,1)[:,-(self.mp_nodes-self.ca_nodes):,...].reshape((-1,nf0_c,1))\n",
    "        nf_mp_['1'] = ca_mp_feats['1'].reshape(self.B,self.mp_nodes,\n",
    "                                               nf1_c,3)[:,-(self.mp_nodes-self.ca_nodes):,...].reshape((-1,nf1_c,3))\n",
    "\n",
    "        return nf_mp_\n",
    "    \n",
    "    def concat_t(self, feats_in, embedded_t, use_deg1=True, cast_type=torch.float):\n",
    "        \"\"\"Concatenate T to first position of each tensor. Pad Zeros left for degree 1.\"\"\"\n",
    "        feats_out = {}\n",
    "        key = next(iter(feats_in.keys()))\n",
    "        shape_tuple = (self.B,-1)+feats_in[key].shape[1:]\n",
    "        batch_shape = feats_in[key].reshape(shape_tuple).shape\n",
    "        L = batch_shape[1] #can be ca, ca+mp, mp, k nodes long\n",
    "\n",
    "        if '0' in feats_in.keys():\n",
    "            feats_out['0'] = torch.concat((embedded_t['0'][:,None,:,None].repeat(1,L,1,1), \n",
    "                                           feats_in['0'].reshape((self.B,L,-1,1))),\n",
    "                                          axis=2).reshape((self.B*L,-1,1))\n",
    "        if '1' in feats_in.keys():\n",
    "            \n",
    "            if use_deg1:\n",
    "                feats_out['1'] = torch.multiply(feats_in['1'],\n",
    "                                                embedded_t['1'][:,None,:,None].repeat(1,L,1,1).reshape((self.B*L,-1,1)))\n",
    "            else:\n",
    "                feats_out['1'] = feats_in['1']\n",
    "\n",
    "        return feats_out\n",
    "    \n",
    "    \n",
    "    def forward(self, feat_dict, batched_t):\n",
    "        \n",
    "        \n",
    "        b_graph, nf, ef = feat_dict['batched_graph'], feat_dict['node_feats'], feat_dict['edge_feats'] \n",
    "        b_graph_mp, nf_mp, ef_mp = feat_dict['batched_graph_mp'], feat_dict['node_feats_mp'], feat_dict['edge_feats_mp']\n",
    "        b_graph_mps, nf_mps, ef_mps =  feat_dict['batched_graph_mpself'], feat_dict['node_feats_mpself'], feat_dict['edge_feats_mpself']\n",
    "        b_graph_mpRev = feat_dict['batched_graph_mprev'] \n",
    "\n",
    "        #assumes equal node numbers in g raphs\n",
    "        self.ca_nodes = int(b_graph.batch_num_nodes()[0])\n",
    "        self.mp_nodes = int(b_graph_mp.batch_num_nodes()[0]) #ca+mp nodes number\n",
    "\n",
    "        #SE3 Attention Transformer, c_alpha\n",
    "        embed_t = self.embed_t(batched_t)\n",
    "        t_nf = self.concat_t(nf, embed_t, use_deg1=self.use_tdeg1) #concat_t on\n",
    "        nf_ca_down_out = self.down_ca(b_graph, t_nf, ef)\n",
    "\n",
    "        #concatenate on midpoints feats\n",
    "        \n",
    "        nf_down_cat_mp = self.concat_mp_feats(nf_ca_down_out, nf_mp)\n",
    "\n",
    "        #pool from ca onto selected midpoints via SE3 Attention transformer\n",
    "        #edges from ca to mp only (ca nodes zero after this)\n",
    "        t_nf_down_cat_mp = self.concat_t(nf_down_cat_mp, embed_t,use_deg1=self.use_tdeg1) #concat_t on\n",
    "        nf_down_ca2mp_out = self.down_ca2mp(b_graph_mp, t_nf_down_cat_mp, ef_mp)\n",
    "\n",
    "        #remove ca node feats from tensor \n",
    "        nf_mp_out = self.pull_out_mp_feats(nf_down_ca2mp_out)\n",
    "\n",
    "        t_nf_mp_out = self.concat_t(nf_mp_out, embed_t, use_deg1=self.use_tdeg1) #concat_t on\n",
    "        node_feats_tk, topk_feats, topk_indx = self.mp_topk(b_graph_mps, t_nf_mp_out, ef_mps)\n",
    "\n",
    "        #make new basis for small graph of k selected midpoints\n",
    "        edge_feats_out, basis_out, new_pos = prep_for_gcn(self.gsmall, b_graph_mps.ndata['pos'], self.ef_small,\n",
    "                                                          topk_indx,\n",
    "                                                          max_degree=self.max_degree, comp_grad=True)\n",
    "\n",
    "        down_gcn_out = self.down_gcn(topk_feats, edge_feats_out, self.gsmall,  basis_out)\n",
    "\n",
    "        down_gcnpool_out = self.down_gcn2pool(down_gcn_out, edge_feats_out, self.gsmall,  basis_out)\n",
    "\n",
    "        pooled_tensor = self.global_pool(down_gcnpool_out,self.gsmall)\n",
    "        pooled = {'0':pooled_tensor}\n",
    "        #----------------------------------------- end of down section\n",
    "        lat_unp = self.latent_unpool_layer(pooled,down_gcn_out)\n",
    "\n",
    "        up_gcn_out = self.up_gcn(lat_unp, edge_feats_out, self.gsmall,  basis_out)\n",
    "\n",
    "        k_to_mp  = self.unpool_layer(up_gcn_out,node_feats_tk,topk_indx)\n",
    "\n",
    "        up_mp_gcn_out = self.up_gcn_mp(b_graph_mps, k_to_mp, ef_mps)\n",
    "        \n",
    "        off_mp_add = {}\n",
    "        for k,v in up_mp_gcn_out.items():\n",
    "            off_mp_add[k] = torch.add(up_mp_gcn_out[k],nf_mp_out[k])\n",
    "\n",
    "\n",
    "        #####triple check from here\n",
    "        #midpoints node indices for unpool layer\n",
    "        mp_node_indx = torch.arange(self.ca_nodes,self.mp_nodes, device=self.device)\n",
    "        mp_idx = mp_node_indx[None,...].repeat_interleave(self.B,0)\n",
    "        mp_idx =((torch.arange(self.B,device=self.device)*(self.mp_nodes)).reshape((-1,1))+mp_idx).reshape((-1))\n",
    "        \n",
    "        #during unpool, keep mp=values and ca=zeros\n",
    "        zeros_mp_ca = {}\n",
    "        for k,v in nf_down_cat_mp.items():\n",
    "            zeros_mp_ca[k] = torch.zeros_like(v, device=self.device)\n",
    "\n",
    "\n",
    "        unpoff_out = self.unpool_layer_off_mp(off_mp_add, zeros_mp_ca, mp_idx)\n",
    "        \n",
    "        out_up_off_mp = self.up_off_mp(b_graph_mpRev, unpoff_out, ef_mp)\n",
    "        \n",
    "        #select just ca nodes, mp = zeros from last convolution\n",
    "        inv_mp_idx= torch.arange(0,self.ca_nodes, device=self.device)\n",
    "        inv_mp_idx = inv_mp_idx[None,...].repeat_interleave(self.B,0)\n",
    "        inv_mp_idx =((torch.arange(self.B,device=self.device)*(self.mp_nodes)).reshape((-1,1))\n",
    "                     +inv_mp_idx).reshape((-1))\n",
    "\n",
    "        node_final_ca = {}\n",
    "        for key in out_up_off_mp.keys():\n",
    "            node_final_ca[key] = torch.add(out_up_off_mp[key][inv_mp_idx,...],nf_ca_down_out[key])\n",
    "\n",
    "        #return updates \n",
    "        t_node_final_ca = self.concat_t(node_final_ca, embed_t, use_deg1=self.use_tdeg1) #concat_t on\n",
    "        \n",
    "        output = self.linear(self.up_ca(b_graph, t_node_final_ca, ef))\n",
    "        output['0'] = self.sig(output['0']) #normalize to zero to one for node calculation\n",
    "        \n",
    "        return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "02ba860f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_pV_to_points(dict_in):\n",
    "    \n",
    "    CA_fp  = dict_in['bb_firstp']['CA'].reshape(B, L, 3).to(device)\n",
    "    NC_fp = CA_fp + dict_in['bb_firstp']['N_CA'].reshape(B, L, 3).to(device)\n",
    "    CC_fp = CA_fp + dict_in['bb_firstp']['C_CA'].reshape(B, L, 3).to(device)\n",
    "    fp =  torch.cat((NC_fp,CA_fp,CC_fp),dim=2).reshape(B,L,3,3)\n",
    "    \n",
    "    CA_lp  = dict_in['bb_firstp']['CA'].reshape(B, L, 3).to(device)\n",
    "    NC_lp = CA_fp + dict_in['bb_firstp']['N_CA'].reshape(B, L, 3).to(device)\n",
    "    CC_lp = CA_fp + dict_in['bb_firstp']['C_CA'].reshape(B, L, 3).to(device)\n",
    "    lp =  torch.cat((NC_lp,CA_lp,CC_lp),dim=2).reshape(B,L,3,3)\n",
    "    \n",
    "    return fp, lp\n",
    "def get_noise_pred_true_null(noised_dict, batched_t, graph_maker, graph_unet):\n",
    "    \n",
    "    CA_t  = noised_dict['bb_shifted']['CA'].reshape(B, L, 3).to('cuda')\n",
    "    NC_t = CA_t + noised_dict['bb_shifted']['N_CA'].reshape(B, L, 3).to('cuda')*N_CA_dist\n",
    "    CC_t = CA_t + noised_dict['bb_shifted']['C_CA'].reshape(B, L, 3).to('cuda')*C_CA_dist\n",
    "    true =  torch.cat((NC_t,CA_t,CC_t),dim=2).reshape(B,L,3,3)\n",
    "    \n",
    "    CA_n  = noised_dict['bb_noised']['CA'].reshape(B, L, 3).to('cuda')\n",
    "    NC_n = CA_n + noised_dict['bb_noised']['N_CA'].reshape(B, L, 3).to('cuda')*N_CA_dist\n",
    "    CC_n = CA_n + noised_dict['bb_noised']['C_CA'].reshape(B, L, 3).to('cuda')*C_CA_dist\n",
    "    noise_xyz =  torch.cat((NC_n,CA_n,CC_n),dim=2).reshape(B,L,3,3)\n",
    "    \n",
    "    feat_dict = graph_maker.prep_for_network(noised_dict)\n",
    "    out = graph_unet(feat_dict, batched_t)\n",
    "    CA_p = out['1'][:,0,:].reshape(B, L, 3)+CA_n #translation of Calpha\n",
    "    Qs = out['1'][:,1,:] # rotation\n",
    "    Qs = Qs.unsqueeze(1).repeat((1,2,1))\n",
    "    Qs = torch.cat((torch.ones((B*L,2,1),device=Qs.device),Qs),dim=-1).reshape(B,L,2,4)\n",
    "    Qs = normQ(Qs)\n",
    "    Rs = Qs2Rs(Qs)\n",
    "    N_C_to_Rot = torch.cat((noised_dict['bb_noised']['N_CA'].reshape(B, L, 3).to('cuda'),\n",
    "                            noised_dict['bb_noised']['C_CA'].reshape(B, L, 3).to('cuda')),dim=2).reshape(B,L,2,1,3)\n",
    "\n",
    "    \n",
    "    rot_vecs = einsum('bnkij,bnkhj->bnki',Rs, N_C_to_Rot)\n",
    "    NC_p = CA_p + rot_vecs[:,:,0,:].to('cuda')*N_CA_dist\n",
    "    CC_p = CA_p + rot_vecs[:,:,1,:].reshape(B, L, 3).to('cuda')*C_CA_dist\n",
    "\n",
    "    pred = torch.cat((NC_p,CA_p,CC_p),dim=2).reshape(B,L,3,3)\n",
    "    \n",
    "    nf_pred = out['0']\n",
    "    \n",
    "    nf_pred = out['0']\n",
    "    real_nodes_pred = torch.round(nf_pred ).clamp(0,1)\n",
    "    real_nodes_pred_mask = (real_nodes_pred.squeeze().sum(-1)>1.99).reshape(B,L)\n",
    "    \n",
    "    real_nodes_true_mask = noised_dict['real_nodes_mask']\n",
    "    #place roll here later\n",
    "#     true = true.to('cpu').numpy()*10\n",
    "#     noise_xyz = noise_xyz.to('cpu').numpy()*10\n",
    "#     pred = pred.detach().to('cpu').numpy()*10\n",
    "    \n",
    "    \n",
    "    return true, noise_xyz, pred , real_nodes_pred_mask, real_nodes_true_mask\n",
    "        \n",
    "def roll2_continous_true(real_mask_in):\n",
    "    \"\"\"Return roll amount to set zero on Nterminal residue for pdb file view\"\"\"\n",
    "\n",
    "    roll_con_out = []\n",
    "    for i,rmr in enumerate(real_mask_in):\n",
    "        ep_bool = (rmr^rmr.roll(-1) | rmr^rmr.roll(1)) & rmr\n",
    "        si = torch.arange(ep_bool.shape[0])[ep_bool]\n",
    "        #circular if start/end real nodes and we need to roll\n",
    "        if rmr[0] and rmr[-1]:\n",
    "            #roll last group across barrier\n",
    "            roll_con = -si[-1]\n",
    "        elif not rmr[0]: #move first group to front\n",
    "            roll_con = -si[0]\n",
    "        else:\n",
    "            roll_con=0\n",
    "\n",
    "        roll_con_out.append(roll_con)\n",
    "\n",
    "    return roll_con_out\n",
    "      \n",
    "def dump_tnp_null(true, noise, pred, t_val, e=0, numOut=1, real_mask=None, pred_mask=None, outdir='output/'):\n",
    "    \n",
    "    if numOut>true.shape[0]:\n",
    "        numOut = true.shape[0]\n",
    "    \n",
    "    tnk_dir = f'{outdir}/true_node_mask/'\n",
    "    pnk_dir = f'{outdir}/pred_node_mask/'\n",
    "    f_dir = f'{outdir}/full/'\n",
    "    \n",
    "    if not os.path.isdir(tnk_dir) and real_mask is not None:\n",
    "        os.makedirs(tnk_dir)\n",
    "    if not os.path.isdir(pnk_dir) and pred_mask is not None:\n",
    "        os.makedirs(pnk_dir)\n",
    "    if not os.path.isdir(f_dir) and real_mask is not None:\n",
    "        os.makedirs(f_dir)\n",
    "    \n",
    "    if real_mask is not None:\n",
    "        rc = roll2_continous_true(real_mask)\n",
    "        for x in range(numOut):\n",
    "            t_o = true[x].roll(int(rc[x]),dims=0).detach().to('cpu').numpy()*10\n",
    "            n_o = noise[x].roll(int(rc[x]),dims=0).detach().to('cpu').numpy()*10\n",
    "            p_o = pred[x].roll(int(rc[x]),dims=0).detach().to('cpu').numpy()*10\n",
    "            dump_coord_pdb(t_o, fileOut=f'{f_dir}/true_{t_val[x]*100:.0f}_e{e}_{x}.pdb')\n",
    "            dump_coord_pdb(n_o, fileOut=f'{f_dir}/noise_{t_val[x]*100:.0f}_e{e}_{x}.pdb')\n",
    "            dump_coord_pdb(p_o, fileOut=f'{f_dir}/pred_{t_val[x]*100:.0f}_e{e}_{x}.pdb')\n",
    "        \n",
    "    if pred_mask is not None:\n",
    "        rc = roll2_continous_true(pred_mask)\n",
    "        for x,c in enumerate(np.arange(numOut)):\n",
    "            t_o = true[x].roll(int(rc[x]),dims=0).detach().to('cpu').numpy()*10\n",
    "            n_o = noise[x].roll(int(rc[x]),dims=0).detach().to('cpu').numpy()*10\n",
    "            p_o = pred[x].roll(int(rc[x]),dims=0).detach().to('cpu').numpy()*10\n",
    "            pm = pred_mask[x].roll(int(rc[x]),dims=0)\n",
    "            dump_coord_pdb(t_o[pm], fileOut=f'{pnk_dir}/true_{t_val[x]*100:.0f}_e{e}_{x}.pdb')\n",
    "            dump_coord_pdb(n_o[pm], fileOut=f'{pnk_dir}/noise_{t_val[x]*100:.0f}_e{e}_{x}.pdb')\n",
    "            dump_coord_pdb(p_o[pm], fileOut=f'{pnk_dir}/pred_{t_val[x]*100:.0f}_e{e}_{x}.pdb')\n",
    "            \n",
    "    if real_mask is not None:\n",
    "        rc = roll2_continous_true(real_mask)\n",
    "        for x,c in enumerate(np.arange(numOut)):\n",
    "            t_o = true[x].roll(int(rc[x]),dims=0).detach().to('cpu').numpy()*10\n",
    "            n_o = noise[x].roll(int(rc[x]),dims=0).detach().to('cpu').numpy()*10\n",
    "            p_o = pred[x].roll(int(rc[x]),dims=0).detach().to('cpu').numpy()*10\n",
    "            rm = real_mask[x].roll(int(rc[x]),dims=0)\n",
    "            dump_coord_pdb(t_o[rm], fileOut=f'{pnk_dir}/true_{t_val[x]*100:.0f}_e{e}_{x}.pdb')\n",
    "            dump_coord_pdb(n_o[rm], fileOut=f'{pnk_dir}/noise_{t_val[x]*100:.0f}_e{e}_{x}.pdb')\n",
    "            dump_coord_pdb(p_o[rm], fileOut=f'{pnk_dir}/pred_{t_val[x]*100:.0f}_e{e}_{x}.pdb')\n",
    "            \n",
    "#     if real_mask is not None:\n",
    "#         rc = roll2_continous_true(real_mask)\n",
    "#         for x in range(numOut):\n",
    "#             dump_coord_pdb(true[x][real_mask[x]], fileOut=f'{tnk_dir}/true_{t_val[x]*100:.0f}_e{e}_{x}.pdb')\n",
    "#             dump_coord_pdb(noise[x][real_mask[x]], fileOut=f'{tnk_dir}/noise_{t_val[x]*100:.0f}_e{e}_{x}.pdb')\n",
    "#             dump_coord_pdb(pred[x][real_mask[x]], fileOut=f'{tnk_dir}/pred_{t_val[x]*100:.0f}_e{e}_{x}.pdb')\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "d7e3e99d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_pV_to_points(dict_in,device='cuda'):\n",
    "    \n",
    "    CA_fp  = dict_in['bb_firstp']['CA'].to(device)\n",
    "    NC_fp = CA_fp + dict_in['bb_firstp']['N_CA'].to(device)\n",
    "    CC_fp = CA_fp +dict_in['bb_firstp']['C_CA'].to(device)\n",
    "    fp =  torch.cat((NC_fp,CA_fp,CC_fp),dim=2).reshape(B,1,3,3)\n",
    "    \n",
    "    CA_lp  = dict_in['bb_lastp']['CA'].to(device)\n",
    "    NC_lp = CA_lp + dict_in['bb_lastp']['N_CA'].to(device)\n",
    "    CC_lp = CA_lp + dict_in['bb_lastp']['C_CA'].to(device)\n",
    "    lp =  torch.cat((NC_lp,CA_lp,CC_lp),dim=2).reshape(B,1,3,3)\n",
    "    \n",
    "    return fp, lp\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "7eeb65f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "def model_step_null(noised_dict, batched_t, graph_maker, graph_unet, train=True):\n",
    "    #prep coordinates for output display from and comparison via FAPE\n",
    "    \n",
    "    CA_t  = noised_dict['bb_shifted']['CA'].reshape(B, L, 3).to(device)\n",
    "    NC_t = CA_t + noised_dict['bb_shifted']['N_CA'].reshape(B, L, 3).to(device)#not mult by bond distance, seems to help?\n",
    "    CC_t = CA_t + noised_dict['bb_shifted']['C_CA'].reshape(B, L, 3).to(device)#not mult \n",
    "    true =  torch.cat((NC_t,CA_t,CC_t),dim=2).reshape(B,L,3,3)\n",
    "\n",
    "    CA_n  = noised_dict['bb_noised']['CA'].reshape(B, L, 3).to(device)\n",
    "    NC_n = CA_n + noised_dict['bb_noised']['N_CA'].reshape(B, L, 3).to(device)\n",
    "    CC_n = CA_n + noised_dict['bb_noised']['C_CA'].reshape(B, L, 3).to(device)\n",
    "    noise_xyz =  torch.cat((NC_n,CA_n,CC_n),dim=2).reshape(B,L,3,3)\n",
    "\n",
    "    #prepare graphs\n",
    "    feat_dict = graph_maker.prep_for_network(noised_dict, cuda=True)\n",
    "    out =graph_unet(feat_dict,batched_t)\n",
    "    \n",
    "    \n",
    "    #FAPE Loss for the prediction\n",
    "    CA_p = out['1'][:,0,:].reshape(B, L, 3)+CA_n #translation of Calpha\n",
    "    Qs = out['1'][:,1,:] # rotation , convert from x,y,z (Quat) to rotate input vectors\n",
    "    Qs = Qs.unsqueeze(1).repeat((1,2,1))\n",
    "    Qs = torch.cat((torch.ones((B*L,2,1),device=Qs.device),Qs),dim=-1).reshape(B,L,2,4)\n",
    "    Qs = normQ(Qs)\n",
    "    Rs = Qs2Rs(Qs)\n",
    "    N_C_to_Rot = torch.cat((noised_dict['bb_noised']['N_CA'].reshape(B, L, 3).to(device),\n",
    "                            noised_dict['bb_noised']['C_CA'].reshape(B, L, 3).to(device)),dim=2).reshape(B,L,2,1,3)\n",
    "    rot_vecs = einsum('bnkij,bnkhj->bnki',Rs, N_C_to_Rot)\n",
    "    NC_p = CA_p + rot_vecs[:,:,0,:]*N_CA_dist #comparable but seems better not have it for true, but have it for pred\n",
    "    CC_p = CA_p + rot_vecs[:,:,1,:]*C_CA_dist #maybe this helep prevent \n",
    "\n",
    "    pred = torch.cat((NC_p,CA_p,CC_p),dim=2).reshape(B,L,3,3)\n",
    "    \n",
    "    #divide loss by real and null nodes\n",
    "    \n",
    "    fp, lp  = convert_pV_to_points(noised_dict)\n",
    "\n",
    "    real_mask = noised_dict['real_nodes_mask'].to('cuda')\n",
    "    score_scales = noised_dict['score_scales'].to('cuda')\n",
    "\n",
    "    lr, lr_d = FAPE_loss_real(pred, true, score_scales, real_mask,  d_clamp=10.0, d_clamp_inter=30.0,\n",
    "                   A=10.0, gamma=score_weights['3D_real'], eps=1e-6)\n",
    "    ln, ln_d = FAPE_loss_null(pred, fp, lp, real_mask, true, score_scales,  d_clamp=10.0,\n",
    "                       d_clamp_inter=30.0, A=10.0, gamma=score_weights['3D_null'], eps=1e-6)\n",
    "    \n",
    "    structure_loss = lr*score_weights['3D_real']+ln*score_weights['3D_null']\n",
    "    \n",
    "    #score for node feats determining whether node is real or fake\n",
    "    nf_pred = out['0']\n",
    "\n",
    "    nf_feat_dim = noised_dict['real_nodes_noise'].shape[-1]\n",
    "    nf_true = torch.ones(noised_dict['real_nodes_mask'].shape+(nf_feat_dim,) + (1,),\n",
    "                         dtype=torch.float,device=device)\n",
    "\n",
    "    nf_real_mask_mult = real_mask.unsqueeze(-1).unsqueeze(-1).to(device)\n",
    "    nf_true = nf_true*nf_real_mask_mult\n",
    "\n",
    "    nf_pred = nf_pred.reshape(B,-1,nf_feat_dim)\n",
    "    pred_nf_loss = torch.sum(torch.abs(nf_true.squeeze()-nf_pred),dim=-1) #absolute value loss\n",
    "    pred_nf_loss = pred_nf_loss.to(device)\n",
    "    \n",
    "    ss_scales = to_cuda(noised_dict['score_scales'])[:,None,None]\n",
    "    pnfloss = (torch.sum((pred_nf_loss*ss_scales/L)))*score_weights['nf_real']\n",
    "    \n",
    "    final_loss = structure_loss + pnfloss\n",
    "    \n",
    "    \n",
    "    return final_loss, pnfloss.detach().cpu(), structure_loss.detach().cpu()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c9e308d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "97322803",
   "metadata": {},
   "outputs": [],
   "source": [
    "device='cuda'\n",
    "\n",
    "B = 2\n",
    "L=128\n",
    "limit = 1028\n",
    "prot_trainData = Data_Graph.ProteinBB_Dataset(coords_tog[:limit], n_nodes=L,\n",
    "              n_atoms=5, coord_div=10, cast_type=torch.float32)\n",
    "train_dL = DataLoader(prot_trainData, batch_size=B, shuffle=True, drop_last=True)\n",
    "stride=4\n",
    "mkg = Make_nullKNN_MP_Graphs(KNN=30, mp_stride=stride, n_nodes=L)\n",
    "\n",
    "score_weights = {}\n",
    "score_weights['nf_real'] = torch.tensor(0,device=device)\n",
    "score_weights['3D_real'] = torch.tensor(1.0,device=device)\n",
    "score_weights['3D_null'] = torch.tensor(1.0,device=device)\n",
    "\n",
    "config_path='data_rigid_diffuser/base.yaml'\n",
    "fnd = FrameDiffNoise(config_path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "77cce375",
   "metadata": {},
   "outputs": [],
   "source": [
    "gunn= GraphUNet_Null(fiber_start = Fiber({0:17, 1:2}),\n",
    "                     fiber_out = Fiber({0:5,1:2}),\n",
    "                      k=8,\n",
    "                      batch_size = B,\n",
    "                      stride=stride,\n",
    "                       max_degree=3,\n",
    "                       channels=32,\n",
    "                      num_heads = 8,\n",
    "                      channels_div=4,\n",
    "                      num_layers = 1,\n",
    "                     num_layers_ca = 2,\n",
    "                     edge_feature_dim=1,\n",
    "                     latent_pool_type = 'avg',\n",
    "                     t_size = 12,\n",
    "                    zero_lin=True,\n",
    "                   use_tdeg1 = False,\n",
    "                 cuda=True).to('cuda')\n",
    "\n",
    "opti = torch.optim.Adam(gunn.parameters(), lr=0.001, weight_decay=5e-7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "df44e18d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def FAPE_loss(pred, true, score_scales,  d_clamp=10.0, d_clamp_inter=30.0, A=10.0, gamma=1.0, eps=1e-6):\n",
    "    '''\n",
    "    Calculate Backbone FAPE loss from RosettaTTAFold\n",
    "    https://github.com/uw-ipd/RoseTTAFold2/blob/main/network/loss.py\n",
    "    Input:\n",
    "        - pred: predicted coordinates (I, B, L, n_atom, 3)\n",
    "        - true: true coordinates (B, L, n_atom, 3)\n",
    "    Output: str loss\n",
    "    '''\n",
    "    I = pred.shape[0]\n",
    "    true = true.unsqueeze(0)\n",
    "    t_tilde_ij = get_t(true[:,:,:,0], true[:,:,:,1], true[:,:,:,2])\n",
    "    t_ij = get_t(pred[:,:,:,0], pred[:,:,:,1], pred[:,:,:,2])\n",
    "\n",
    "    difference = torch.sqrt(torch.square(t_tilde_ij-t_ij).sum(dim=-1) + eps)\n",
    "    eij_label = difference[-1].clone().detach()\n",
    "\n",
    "    clamp = torch.zeros_like(difference)\n",
    "\n",
    "    # intra vs inter#me coded\n",
    "    clamp[:,True] = d_clamp\n",
    "\n",
    "    difference = torch.clamp(difference, max=clamp)\n",
    "    loss = difference / A # (I, B, L, L)\n",
    "    # calculate masked loss (ignore missing regions when calculate loss)\n",
    "    loss = (loss[:,True]).sum(dim=-1) / (torch.ones_like(loss).sum()+eps) # (I)\n",
    "    \n",
    "    # weighting loss\n",
    "#     w_loss = torch.pow(torch.full((I,), gamma, device=pred.device), torch.arange(I, device=pred.device))\n",
    "#     w_loss = torch.flip(w_loss, (0,))\n",
    "#     w_loss = w_loss / w_loss.sum()\n",
    "    w_loss = score_scales[None,None,:,None]\n",
    "\n",
    "    tot_loss = (w_loss * loss).sum()\n",
    "    \n",
    "    return tot_loss, loss.detach()\n",
    "def FAPE_loss_real(pred, true, score_scales, real_mask, \n",
    "                   d_clamp=10.0, d_clamp_inter=30.0, A=10.0, gamma=1.0, eps=1e-6):\n",
    "    '''\n",
    "    Calculate Backbone FAPE loss from RosettaTTAFold\n",
    "    https://github.com/uw-ipd/RoseTTAFold2/blob/main/network/loss.py\n",
    "    Input:\n",
    "        - pred: predicted coordinates (I, B, L, n_atom, 3)\n",
    "        - true: true coordinates (B, L, n_atom, 3)\n",
    "    Output: str loss\n",
    "    '''\n",
    "    batch = true.shape[0]\n",
    "    length = true.shape[1]\n",
    "    pred = pred.unsqueeze(0) #maybe swap back for consistenccy\n",
    "    true = true.unsqueeze(0)\n",
    "    \n",
    "    t_tilde_ij = get_t(true[:,:,:,0], true[:,:,:,1], true[:,:,:,2])\n",
    "    t_ij = get_t(pred[:,:,:,0], pred[:,:,:,1], pred[:,:,:,2])\n",
    "    \n",
    "    difference = torch.sqrt(torch.square(t_tilde_ij-t_ij).sum(dim=-1) + eps)\n",
    "    clamp = torch.zeros_like(difference)\n",
    "    # intra vs inter#me coded\n",
    "    clamp[:,True] = torch.tensor(d_clamp)\n",
    "    difference = torch.clamp(difference, max=clamp)\n",
    "    loss = difference / A # (I, B, L, L)\n",
    "\n",
    "    # n points, becomes nxn comparisons for FAPE LOSS, need to mask both dimensions\n",
    "    rm_e = real_mask.repeat((1,length)).reshape(1,batch,length,length)\n",
    "    rm_et =  torch.transpose(rm_e,2,3)\n",
    "\n",
    "    loss_norm_masked = (rm_e*loss*rm_et).sum(dim=(2,3))/((rm_e*rm_et).sum(dim=(2,3)))\n",
    "    w_loss = score_scales[None,:]\n",
    "\n",
    "    tot_loss = (w_loss * loss_norm_masked).sum()\n",
    "    \n",
    "    return tot_loss, loss.detach()\n",
    "\n",
    "def FAPE_loss_null(pred, first_point, last_point, real_mask, score_scales,  d_clamp=10.0,\n",
    "                   d_clamp_inter=30.0, A=10.0, gamma=0.1, eps=1e-6):\n",
    "    '''\n",
    "    Calculate Backbone FAPE loss from RosettaTTAFold\n",
    "    https://github.com/uw-ipd/RoseTTAFold2/blob/main/network/loss.py\n",
    "    Input:\n",
    "        - pred: predicted coordinates (I, B, L, n_atom, 3)\n",
    "        - first_point: true coordinate (B, 1, n_atom, 3) N-terminal location\n",
    "        - last_point: true coordinates (B, 1, n_atom, 3) C-terminal location\n",
    "        chooses lowest loss of null to c-terminal/ n-terminal since its indeterminant\n",
    "        gamma set to overweight weight of null\n",
    "    Output: str loss\n",
    "    \n",
    "    \n",
    "    '''\n",
    "    first_point = first_point.unsqueeze(0)\n",
    "    last_point = last_point.unsqueeze(0)\n",
    "\n",
    "    pred = pred.unsqueeze(0) #maybe swap back for consistenccy\n",
    "    true = torch.ones_like(pred)\n",
    "    null_mask = (~real_mask).unsqueeze(0) \n",
    "\n",
    "    #add first and last point to characterize FAPE loss to the closest proper null node (endpoints)\n",
    "    flp_pred = torch.concat((first_point,last_point,pred),2)\n",
    "    flp_true = torch.concat((first_point,last_point,true),2)\n",
    "\n",
    "    t_tilde_ij = get_t(flp_true[:,:,:,0], flp_true[:,:,:,1], flp_true[:,:,:,2])\n",
    "    t_ij = get_t(flp_pred[:,:,:,0], flp_pred[:,:,:,1], flp_pred[:,:,:,2])\n",
    "\n",
    "    difference = torch.sqrt(torch.square(t_tilde_ij-t_ij).sum(dim=-1) + eps)\n",
    "    clamp = torch.zeros_like(difference)\n",
    "    \n",
    "    # intra vs inter #multimer monomer i think, #coding out\n",
    "    clamp[:,True] = torch.tensor(d_clamp)\n",
    "    difference = torch.clamp(difference, max=clamp)\n",
    "    \n",
    "    #null nodes, least difference to just two points\n",
    "    #reduces shape by last dimension\n",
    "    difference_fp = difference[:,:,2:,0]\n",
    "    difference_lp = difference[:,:,2:,1]\n",
    "    nearest_endpoint = difference_lp.clone()\n",
    "    nearest_endpoint[difference_fp<difference_lp] = difference_fp[difference_fp<difference_lp]\n",
    "    \n",
    "    loss = nearest_endpoint / A # (I, B, L)\n",
    "    (null_mask*loss).sum(dim=(2))/((null_mask).sum(dim=(2)))\n",
    "\n",
    "    loss_norm_masked= (null_mask*loss).sum(dim=(2))/((null_mask).sum(dim=(2)))\n",
    "    \n",
    "    w_loss = score_scales[None,:]\n",
    "    tot_loss = (w_loss * loss_norm_masked).sum()\n",
    "    \n",
    "    return tot_loss, loss.detach()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "id": "cfb4dca8",
   "metadata": {},
   "outputs": [],
   "source": [
    "B=2\n",
    "L=128\n",
    "t=0.0001\n",
    "t_cpu = np.ones((B,))*t\n",
    "noised_dict = fnd.forward(bb_dict,t_vec=t_cpu)\n",
    "batched_t = to_cuda(noised_dict['t_vec'])\n",
    "\n",
    "CA_t  = noised_dict['bb_shifted']['CA'].reshape(B, L, 3)\n",
    "NC_t = CA_t + noised_dict['bb_shifted']['N_CA'].reshape(B, L, 3)#not mult by bond distance, seems to help?\n",
    "CC_t = CA_t + noised_dict['bb_shifted']['C_CA'].reshape(B, L, 3)#not mult \n",
    "true_save =  torch.cat((NC_t,CA_t,CC_t),dim=2).reshape(B,L,3,3)\n",
    "\n",
    "CA_n  = noised_dict['bb_noised']['CA'].reshape(B, L, 3)\n",
    "NC_n = CA_n + noised_dict['bb_noised']['N_CA'].reshape(B, L, 3)\n",
    "CC_n = CA_n + noised_dict['bb_noised']['C_CA'].reshape(B, L, 3)\n",
    "noise_xyz_save =  torch.cat((NC_n,CA_n,CC_n),dim=2).reshape(B,L,3,3)\n",
    "\n",
    "score_scales = torch.ones_like(noised_dict['score_scales'])\n",
    "real_mask_save =  noised_dict['real_nodes_mask']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "0eb928a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "#prepare graphs\n",
    "feat_dict = mkg.prep_for_network(noised_dict, cuda=True)\n",
    "out =gunn(feat_dict,batched_t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "7e11d485",
   "metadata": {},
   "outputs": [],
   "source": [
    "nf_pred = out['0']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "846c3a09",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([2, 128, 5])"
      ]
     },
     "execution_count": 95,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nf_pred.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "1f6314d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "nf_feat_dim = noised_dict['real_nodes_noise'].shape[-1]\n",
    "nf_true = torch.ones(noised_dict['real_nodes_mask'].shape+(nf_feat_dim,) + (1,),\n",
    "                     dtype=torch.float,device=device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "92aa726d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([2, 128, 5, 1])"
      ]
     },
     "execution_count": 97,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nf_true.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "31929b3f",
   "metadata": {},
   "outputs": [],
   "source": [
    "real_mask = real_mask_save\n",
    "nf_real_mask_mult = real_mask.unsqueeze(-1).unsqueeze(-1).to(device)\n",
    "nf_true = nf_true*nf_real_mask_mult"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "id": "0679988e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([2, 128])"
      ]
     },
     "execution_count": 113,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "real_mask.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "38273dd1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([2, 128, 5, 1])"
      ]
     },
     "execution_count": 98,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nf_true.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "f4bbb90e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([2, 128, 5])"
      ]
     },
     "execution_count": 99,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nf_pred = nf_pred.reshape(B,-1,nf_feat_dim)\n",
    "nf_pred.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "id": "e938c1ee",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[1.0000e+00, 4.2584e-01, 0.0000e+00, 1.0000e+00, 0.0000e+00],\n",
       "         [1.0000e+00, 2.2184e-03, 0.0000e+00, 1.0000e+00, 0.0000e+00],\n",
       "         [1.0000e+00, 8.9352e-01, 0.0000e+00, 1.0000e+00, 0.0000e+00],\n",
       "         ...,\n",
       "         [1.0000e+00, 6.1556e-03, 0.0000e+00, 1.0000e+00, 0.0000e+00],\n",
       "         [1.0000e+00, 9.3650e-01, 0.0000e+00, 1.0000e+00, 0.0000e+00],\n",
       "         [1.0000e+00, 9.9924e-01, 0.0000e+00, 1.0000e+00, 0.0000e+00]],\n",
       "\n",
       "        [[1.0000e+00, 1.1921e-07, 0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
       "         [1.0000e+00, 1.3578e-04, 2.2053e-01, 0.0000e+00, 0.0000e+00],\n",
       "         [1.0000e+00, 3.7215e-02, 1.4837e-01, 1.1361e-04, 0.0000e+00],\n",
       "         ...,\n",
       "         [1.0000e+00, 2.6147e-03, 7.4917e-04, 0.0000e+00, 0.0000e+00],\n",
       "         [1.0000e+00, 5.4830e-04, 5.7740e-01, 0.0000e+00, 0.0000e+00],\n",
       "         [1.0000e+00, 4.8995e-05, 2.0310e-03, 0.0000e+00, 0.0000e+00]]],\n",
       "       device='cuda:0', grad_fn=<AbsBackward0>)"
      ]
     },
     "execution_count": 114,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.abs(nf_true.squeeze()-nf_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "id": "58a4a5bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "pred_nf_loss = torch.sum(torch.abs(nf_true.squeeze()-nf_pred),dim=-1) #absolute value loss\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "id": "8e29f1ab",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([2, 128, 5])"
      ]
     },
     "execution_count": 116,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nf_pred.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "id": "a5ce1992",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[0.],\n",
       "         [0.],\n",
       "         [0.],\n",
       "         [0.],\n",
       "         [0.]],\n",
       "\n",
       "        [[0.],\n",
       "         [0.],\n",
       "         [0.],\n",
       "         [0.],\n",
       "         [0.]],\n",
       "\n",
       "        [[0.],\n",
       "         [0.],\n",
       "         [0.],\n",
       "         [0.],\n",
       "         [0.]],\n",
       "\n",
       "        [[0.],\n",
       "         [0.],\n",
       "         [0.],\n",
       "         [0.],\n",
       "         [0.]],\n",
       "\n",
       "        [[0.],\n",
       "         [0.],\n",
       "         [0.],\n",
       "         [0.],\n",
       "         [0.]],\n",
       "\n",
       "        [[0.],\n",
       "         [0.],\n",
       "         [0.],\n",
       "         [0.],\n",
       "         [0.]],\n",
       "\n",
       "        [[0.],\n",
       "         [0.],\n",
       "         [0.],\n",
       "         [0.],\n",
       "         [0.]],\n",
       "\n",
       "        [[0.],\n",
       "         [0.],\n",
       "         [0.],\n",
       "         [0.],\n",
       "         [0.]],\n",
       "\n",
       "        [[0.],\n",
       "         [0.],\n",
       "         [0.],\n",
       "         [0.],\n",
       "         [0.]],\n",
       "\n",
       "        [[0.],\n",
       "         [0.],\n",
       "         [0.],\n",
       "         [0.],\n",
       "         [0.]],\n",
       "\n",
       "        [[0.],\n",
       "         [0.],\n",
       "         [0.],\n",
       "         [0.],\n",
       "         [0.]],\n",
       "\n",
       "        [[0.],\n",
       "         [0.],\n",
       "         [0.],\n",
       "         [0.],\n",
       "         [0.]],\n",
       "\n",
       "        [[0.],\n",
       "         [0.],\n",
       "         [0.],\n",
       "         [0.],\n",
       "         [0.]],\n",
       "\n",
       "        [[0.],\n",
       "         [0.],\n",
       "         [0.],\n",
       "         [0.],\n",
       "         [0.]],\n",
       "\n",
       "        [[0.],\n",
       "         [0.],\n",
       "         [0.],\n",
       "         [0.],\n",
       "         [0.]],\n",
       "\n",
       "        [[0.],\n",
       "         [0.],\n",
       "         [0.],\n",
       "         [0.],\n",
       "         [0.]],\n",
       "\n",
       "        [[0.],\n",
       "         [0.],\n",
       "         [0.],\n",
       "         [0.],\n",
       "         [0.]],\n",
       "\n",
       "        [[0.],\n",
       "         [0.],\n",
       "         [0.],\n",
       "         [0.],\n",
       "         [0.]],\n",
       "\n",
       "        [[0.],\n",
       "         [0.],\n",
       "         [0.],\n",
       "         [0.],\n",
       "         [0.]],\n",
       "\n",
       "        [[0.],\n",
       "         [0.],\n",
       "         [0.],\n",
       "         [0.],\n",
       "         [0.]],\n",
       "\n",
       "        [[0.],\n",
       "         [0.],\n",
       "         [0.],\n",
       "         [0.],\n",
       "         [0.]],\n",
       "\n",
       "        [[0.],\n",
       "         [0.],\n",
       "         [0.],\n",
       "         [0.],\n",
       "         [0.]],\n",
       "\n",
       "        [[0.],\n",
       "         [0.],\n",
       "         [0.],\n",
       "         [0.],\n",
       "         [0.]],\n",
       "\n",
       "        [[0.],\n",
       "         [0.],\n",
       "         [0.],\n",
       "         [0.],\n",
       "         [0.]],\n",
       "\n",
       "        [[0.],\n",
       "         [0.],\n",
       "         [0.],\n",
       "         [0.],\n",
       "         [0.]],\n",
       "\n",
       "        [[0.],\n",
       "         [0.],\n",
       "         [0.],\n",
       "         [0.],\n",
       "         [0.]],\n",
       "\n",
       "        [[0.],\n",
       "         [0.],\n",
       "         [0.],\n",
       "         [0.],\n",
       "         [0.]],\n",
       "\n",
       "        [[0.],\n",
       "         [0.],\n",
       "         [0.],\n",
       "         [0.],\n",
       "         [0.]],\n",
       "\n",
       "        [[0.],\n",
       "         [0.],\n",
       "         [0.],\n",
       "         [0.],\n",
       "         [0.]],\n",
       "\n",
       "        [[0.],\n",
       "         [0.],\n",
       "         [0.],\n",
       "         [0.],\n",
       "         [0.]],\n",
       "\n",
       "        [[0.],\n",
       "         [0.],\n",
       "         [0.],\n",
       "         [0.],\n",
       "         [0.]],\n",
       "\n",
       "        [[0.],\n",
       "         [0.],\n",
       "         [0.],\n",
       "         [0.],\n",
       "         [0.]],\n",
       "\n",
       "        [[0.],\n",
       "         [0.],\n",
       "         [0.],\n",
       "         [0.],\n",
       "         [0.]],\n",
       "\n",
       "        [[0.],\n",
       "         [0.],\n",
       "         [0.],\n",
       "         [0.],\n",
       "         [0.]],\n",
       "\n",
       "        [[0.],\n",
       "         [0.],\n",
       "         [0.],\n",
       "         [0.],\n",
       "         [0.]],\n",
       "\n",
       "        [[0.],\n",
       "         [0.],\n",
       "         [0.],\n",
       "         [0.],\n",
       "         [0.]],\n",
       "\n",
       "        [[0.],\n",
       "         [0.],\n",
       "         [0.],\n",
       "         [0.],\n",
       "         [0.]],\n",
       "\n",
       "        [[0.],\n",
       "         [0.],\n",
       "         [0.],\n",
       "         [0.],\n",
       "         [0.]],\n",
       "\n",
       "        [[0.],\n",
       "         [0.],\n",
       "         [0.],\n",
       "         [0.],\n",
       "         [0.]],\n",
       "\n",
       "        [[0.],\n",
       "         [0.],\n",
       "         [0.],\n",
       "         [0.],\n",
       "         [0.]],\n",
       "\n",
       "        [[0.],\n",
       "         [0.],\n",
       "         [0.],\n",
       "         [0.],\n",
       "         [0.]],\n",
       "\n",
       "        [[0.],\n",
       "         [0.],\n",
       "         [0.],\n",
       "         [0.],\n",
       "         [0.]],\n",
       "\n",
       "        [[0.],\n",
       "         [0.],\n",
       "         [0.],\n",
       "         [0.],\n",
       "         [0.]],\n",
       "\n",
       "        [[0.],\n",
       "         [0.],\n",
       "         [0.],\n",
       "         [0.],\n",
       "         [0.]],\n",
       "\n",
       "        [[0.],\n",
       "         [0.],\n",
       "         [0.],\n",
       "         [0.],\n",
       "         [0.]],\n",
       "\n",
       "        [[0.],\n",
       "         [0.],\n",
       "         [0.],\n",
       "         [0.],\n",
       "         [0.]],\n",
       "\n",
       "        [[0.],\n",
       "         [0.],\n",
       "         [0.],\n",
       "         [0.],\n",
       "         [0.]],\n",
       "\n",
       "        [[0.],\n",
       "         [0.],\n",
       "         [0.],\n",
       "         [0.],\n",
       "         [0.]],\n",
       "\n",
       "        [[0.],\n",
       "         [0.],\n",
       "         [0.],\n",
       "         [0.],\n",
       "         [0.]],\n",
       "\n",
       "        [[0.],\n",
       "         [0.],\n",
       "         [0.],\n",
       "         [0.],\n",
       "         [0.]],\n",
       "\n",
       "        [[0.],\n",
       "         [0.],\n",
       "         [0.],\n",
       "         [0.],\n",
       "         [0.]],\n",
       "\n",
       "        [[0.],\n",
       "         [0.],\n",
       "         [0.],\n",
       "         [0.],\n",
       "         [0.]],\n",
       "\n",
       "        [[0.],\n",
       "         [0.],\n",
       "         [0.],\n",
       "         [0.],\n",
       "         [0.]],\n",
       "\n",
       "        [[0.],\n",
       "         [0.],\n",
       "         [0.],\n",
       "         [0.],\n",
       "         [0.]],\n",
       "\n",
       "        [[0.],\n",
       "         [0.],\n",
       "         [0.],\n",
       "         [0.],\n",
       "         [0.]],\n",
       "\n",
       "        [[0.],\n",
       "         [0.],\n",
       "         [0.],\n",
       "         [0.],\n",
       "         [0.]],\n",
       "\n",
       "        [[0.],\n",
       "         [0.],\n",
       "         [0.],\n",
       "         [0.],\n",
       "         [0.]],\n",
       "\n",
       "        [[0.],\n",
       "         [0.],\n",
       "         [0.],\n",
       "         [0.],\n",
       "         [0.]],\n",
       "\n",
       "        [[0.],\n",
       "         [0.],\n",
       "         [0.],\n",
       "         [0.],\n",
       "         [0.]],\n",
       "\n",
       "        [[0.],\n",
       "         [0.],\n",
       "         [0.],\n",
       "         [0.],\n",
       "         [0.]],\n",
       "\n",
       "        [[0.],\n",
       "         [0.],\n",
       "         [0.],\n",
       "         [0.],\n",
       "         [0.]],\n",
       "\n",
       "        [[0.],\n",
       "         [0.],\n",
       "         [0.],\n",
       "         [0.],\n",
       "         [0.]],\n",
       "\n",
       "        [[0.],\n",
       "         [0.],\n",
       "         [0.],\n",
       "         [0.],\n",
       "         [0.]],\n",
       "\n",
       "        [[0.],\n",
       "         [0.],\n",
       "         [0.],\n",
       "         [0.],\n",
       "         [0.]],\n",
       "\n",
       "        [[0.],\n",
       "         [0.],\n",
       "         [0.],\n",
       "         [0.],\n",
       "         [0.]],\n",
       "\n",
       "        [[0.],\n",
       "         [0.],\n",
       "         [0.],\n",
       "         [0.],\n",
       "         [0.]],\n",
       "\n",
       "        [[0.],\n",
       "         [0.],\n",
       "         [0.],\n",
       "         [0.],\n",
       "         [0.]],\n",
       "\n",
       "        [[0.],\n",
       "         [0.],\n",
       "         [0.],\n",
       "         [0.],\n",
       "         [0.]],\n",
       "\n",
       "        [[0.],\n",
       "         [0.],\n",
       "         [0.],\n",
       "         [0.],\n",
       "         [0.]],\n",
       "\n",
       "        [[0.],\n",
       "         [0.],\n",
       "         [0.],\n",
       "         [0.],\n",
       "         [0.]],\n",
       "\n",
       "        [[0.],\n",
       "         [0.],\n",
       "         [0.],\n",
       "         [0.],\n",
       "         [0.]],\n",
       "\n",
       "        [[0.],\n",
       "         [0.],\n",
       "         [0.],\n",
       "         [0.],\n",
       "         [0.]],\n",
       "\n",
       "        [[0.],\n",
       "         [0.],\n",
       "         [0.],\n",
       "         [0.],\n",
       "         [0.]],\n",
       "\n",
       "        [[0.],\n",
       "         [0.],\n",
       "         [0.],\n",
       "         [0.],\n",
       "         [0.]],\n",
       "\n",
       "        [[0.],\n",
       "         [0.],\n",
       "         [0.],\n",
       "         [0.],\n",
       "         [0.]],\n",
       "\n",
       "        [[0.],\n",
       "         [0.],\n",
       "         [0.],\n",
       "         [0.],\n",
       "         [0.]],\n",
       "\n",
       "        [[0.],\n",
       "         [0.],\n",
       "         [0.],\n",
       "         [0.],\n",
       "         [0.]],\n",
       "\n",
       "        [[0.],\n",
       "         [0.],\n",
       "         [0.],\n",
       "         [0.],\n",
       "         [0.]],\n",
       "\n",
       "        [[0.],\n",
       "         [0.],\n",
       "         [0.],\n",
       "         [0.],\n",
       "         [0.]],\n",
       "\n",
       "        [[0.],\n",
       "         [0.],\n",
       "         [0.],\n",
       "         [0.],\n",
       "         [0.]],\n",
       "\n",
       "        [[0.],\n",
       "         [0.],\n",
       "         [0.],\n",
       "         [0.],\n",
       "         [0.]],\n",
       "\n",
       "        [[0.],\n",
       "         [0.],\n",
       "         [0.],\n",
       "         [0.],\n",
       "         [0.]],\n",
       "\n",
       "        [[0.],\n",
       "         [0.],\n",
       "         [0.],\n",
       "         [0.],\n",
       "         [0.]],\n",
       "\n",
       "        [[0.],\n",
       "         [0.],\n",
       "         [0.],\n",
       "         [0.],\n",
       "         [0.]],\n",
       "\n",
       "        [[0.],\n",
       "         [0.],\n",
       "         [0.],\n",
       "         [0.],\n",
       "         [0.]],\n",
       "\n",
       "        [[0.],\n",
       "         [0.],\n",
       "         [0.],\n",
       "         [0.],\n",
       "         [0.]],\n",
       "\n",
       "        [[0.],\n",
       "         [0.],\n",
       "         [0.],\n",
       "         [0.],\n",
       "         [0.]],\n",
       "\n",
       "        [[0.],\n",
       "         [0.],\n",
       "         [0.],\n",
       "         [0.],\n",
       "         [0.]],\n",
       "\n",
       "        [[0.],\n",
       "         [0.],\n",
       "         [0.],\n",
       "         [0.],\n",
       "         [0.]],\n",
       "\n",
       "        [[0.],\n",
       "         [0.],\n",
       "         [0.],\n",
       "         [0.],\n",
       "         [0.]],\n",
       "\n",
       "        [[0.],\n",
       "         [0.],\n",
       "         [0.],\n",
       "         [0.],\n",
       "         [0.]],\n",
       "\n",
       "        [[0.],\n",
       "         [0.],\n",
       "         [0.],\n",
       "         [0.],\n",
       "         [0.]],\n",
       "\n",
       "        [[0.],\n",
       "         [0.],\n",
       "         [0.],\n",
       "         [0.],\n",
       "         [0.]],\n",
       "\n",
       "        [[0.],\n",
       "         [0.],\n",
       "         [0.],\n",
       "         [0.],\n",
       "         [0.]],\n",
       "\n",
       "        [[0.],\n",
       "         [0.],\n",
       "         [0.],\n",
       "         [0.],\n",
       "         [0.]],\n",
       "\n",
       "        [[0.],\n",
       "         [0.],\n",
       "         [0.],\n",
       "         [0.],\n",
       "         [0.]],\n",
       "\n",
       "        [[0.],\n",
       "         [0.],\n",
       "         [0.],\n",
       "         [0.],\n",
       "         [0.]],\n",
       "\n",
       "        [[0.],\n",
       "         [0.],\n",
       "         [0.],\n",
       "         [0.],\n",
       "         [0.]],\n",
       "\n",
       "        [[0.],\n",
       "         [0.],\n",
       "         [0.],\n",
       "         [0.],\n",
       "         [0.]],\n",
       "\n",
       "        [[0.],\n",
       "         [0.],\n",
       "         [0.],\n",
       "         [0.],\n",
       "         [0.]],\n",
       "\n",
       "        [[0.],\n",
       "         [0.],\n",
       "         [0.],\n",
       "         [0.],\n",
       "         [0.]],\n",
       "\n",
       "        [[0.],\n",
       "         [0.],\n",
       "         [0.],\n",
       "         [0.],\n",
       "         [0.]],\n",
       "\n",
       "        [[0.],\n",
       "         [0.],\n",
       "         [0.],\n",
       "         [0.],\n",
       "         [0.]],\n",
       "\n",
       "        [[0.],\n",
       "         [0.],\n",
       "         [0.],\n",
       "         [0.],\n",
       "         [0.]],\n",
       "\n",
       "        [[0.],\n",
       "         [0.],\n",
       "         [0.],\n",
       "         [0.],\n",
       "         [0.]],\n",
       "\n",
       "        [[0.],\n",
       "         [0.],\n",
       "         [0.],\n",
       "         [0.],\n",
       "         [0.]],\n",
       "\n",
       "        [[0.],\n",
       "         [0.],\n",
       "         [0.],\n",
       "         [0.],\n",
       "         [0.]],\n",
       "\n",
       "        [[0.],\n",
       "         [0.],\n",
       "         [0.],\n",
       "         [0.],\n",
       "         [0.]],\n",
       "\n",
       "        [[0.],\n",
       "         [0.],\n",
       "         [0.],\n",
       "         [0.],\n",
       "         [0.]],\n",
       "\n",
       "        [[0.],\n",
       "         [0.],\n",
       "         [0.],\n",
       "         [0.],\n",
       "         [0.]],\n",
       "\n",
       "        [[0.],\n",
       "         [0.],\n",
       "         [0.],\n",
       "         [0.],\n",
       "         [0.]],\n",
       "\n",
       "        [[0.],\n",
       "         [0.],\n",
       "         [0.],\n",
       "         [0.],\n",
       "         [0.]],\n",
       "\n",
       "        [[0.],\n",
       "         [0.],\n",
       "         [0.],\n",
       "         [0.],\n",
       "         [0.]],\n",
       "\n",
       "        [[0.],\n",
       "         [0.],\n",
       "         [0.],\n",
       "         [0.],\n",
       "         [0.]],\n",
       "\n",
       "        [[0.],\n",
       "         [0.],\n",
       "         [0.],\n",
       "         [0.],\n",
       "         [0.]],\n",
       "\n",
       "        [[0.],\n",
       "         [0.],\n",
       "         [0.],\n",
       "         [0.],\n",
       "         [0.]],\n",
       "\n",
       "        [[0.],\n",
       "         [0.],\n",
       "         [0.],\n",
       "         [0.],\n",
       "         [0.]],\n",
       "\n",
       "        [[0.],\n",
       "         [0.],\n",
       "         [0.],\n",
       "         [0.],\n",
       "         [0.]],\n",
       "\n",
       "        [[0.],\n",
       "         [0.],\n",
       "         [0.],\n",
       "         [0.],\n",
       "         [0.]],\n",
       "\n",
       "        [[0.],\n",
       "         [0.],\n",
       "         [0.],\n",
       "         [0.],\n",
       "         [0.]],\n",
       "\n",
       "        [[0.],\n",
       "         [0.],\n",
       "         [0.],\n",
       "         [0.],\n",
       "         [0.]],\n",
       "\n",
       "        [[0.],\n",
       "         [0.],\n",
       "         [0.],\n",
       "         [0.],\n",
       "         [0.]],\n",
       "\n",
       "        [[0.],\n",
       "         [0.],\n",
       "         [0.],\n",
       "         [0.],\n",
       "         [0.]],\n",
       "\n",
       "        [[0.],\n",
       "         [0.],\n",
       "         [0.],\n",
       "         [0.],\n",
       "         [0.]],\n",
       "\n",
       "        [[0.],\n",
       "         [0.],\n",
       "         [0.],\n",
       "         [0.],\n",
       "         [0.]],\n",
       "\n",
       "        [[0.],\n",
       "         [0.],\n",
       "         [0.],\n",
       "         [0.],\n",
       "         [0.]]], device='cuda:0')"
      ]
     },
     "execution_count": 123,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nf_true[~real_mask]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "id": "894f4a3c",
   "metadata": {},
   "outputs": [],
   "source": [
    "ss_scales = to_cuda(noised_dict['score_scales'])[:,None,None]\n",
    "pnfloss = (torch.sum((pred_nf_loss*ss_scales/L)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "id": "e7d34d3b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[314.6670]],\n",
       "\n",
       "        [[314.6670]]], device='cuda:0')"
      ]
     },
     "execution_count": 133,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ss_scales"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "id": "5312f7ff",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(27.7679, device='cuda:0', grad_fn=<SumBackward0>)"
      ]
     },
     "execution_count": 128,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pnfloss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "id": "cd562e61",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(0, device='cuda:0')"
      ]
     },
     "execution_count": 126,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "score_weights['nf_real']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "844d70b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "#score for node feats determining whether node is real or fake\n",
    "    nf_pred = out['0']\n",
    "\n",
    "    nf_feat_dim = noised_dict['real_nodes_noise'].shape[-1]\n",
    "    nf_true = torch.ones(noised_dict['real_nodes_mask'].shape+(nf_feat_dim,) + (1,),\n",
    "                         dtype=torch.float,device=device)\n",
    "\n",
    "    nf_real_mask_mult = real_mask.unsqueeze(-1).unsqueeze(-1).to(device)\n",
    "    nf_true = nf_true*nf_real_mask_mult\n",
    "\n",
    "    nf_pred = nf_pred.reshape(B,-1,nf_feat_dim)\n",
    "    pred_nf_loss = torch.sum(torch.abs(nf_true.squeeze()-nf_pred),dim=-1) #absolute value loss\n",
    "    pred_nf_loss = pred_nf_loss.to(device)\n",
    "    \n",
    "    ss_scales = to_cuda(noised_dict['score_scales'])[:,None,None]\n",
    "    pnfloss = (torch.sum((pred_nf_loss*ss_scales/L)))*score_weights['nf_real']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "173362c4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "f940b71e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#FAPE LOSS EXAMPLES"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c09f42b8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef0976d3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d4f9da0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62808446",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d361aec",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "7f850dea",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0.0164)\n",
      "tensor(18.0122)\n"
     ]
    }
   ],
   "source": [
    "B=2\n",
    "L=128\n",
    "t=0.0000001\n",
    "t_cpu = np.ones((B,))*t\n",
    "noised_dict = fnd.forward(bb_dict,t_vec=t_cpu)\n",
    "batched_t = to_cuda(noised_dict['t_vec'])\n",
    "\n",
    "CA_t  = noised_dict['bb_shifted']['CA'].reshape(B, L, 3)\n",
    "NC_t = CA_t + noised_dict['bb_shifted']['N_CA'].reshape(B, L, 3)#not mult by bond distance, seems to help?\n",
    "CC_t = CA_t + noised_dict['bb_shifted']['C_CA'].reshape(B, L, 3)#not mult \n",
    "true_save =  torch.cat((NC_t,CA_t,CC_t),dim=2).reshape(B,L,3,3)\n",
    "\n",
    "CA_n  = noised_dict['bb_noised']['CA'].reshape(B, L, 3)\n",
    "NC_n = CA_n + noised_dict['bb_noised']['N_CA'].reshape(B, L, 3)\n",
    "CC_n = CA_n + noised_dict['bb_noised']['C_CA'].reshape(B, L, 3)\n",
    "noise_xyz_save =  torch.cat((NC_n,CA_n,CC_n),dim=2).reshape(B,L,3,3)\n",
    "\n",
    "score_scales = torch.ones_like(noised_dict['score_scales'])\n",
    "real_mask_save =  noised_dict['real_nodes_mask']\n",
    "\n",
    "fp_save, lp_save  = convert_pV_to_points(noised_dict,device='cpu')\n",
    "\n",
    "n=0\n",
    "ld, ln_d = FAPE_loss(noise_xyz_save[n][real_mask_save[n]].unsqueeze(0).unsqueeze(0),\n",
    "                     true_save[n][real_mask_save[n]].unsqueeze(0),\n",
    "                     score_scales[0].unsqueeze(0),  d_clamp=10.0, d_clamp_inter=30.0, A=10.0, gamma=1.0, eps=1e-6)\n",
    "print(ld)\n",
    "\n",
    "ld, ln_d = FAPE_loss_null(noise_xyz_save, fp_save, lp_save, real_mask_save,score_scales,  d_clamp=10.0,\n",
    "                   d_clamp_inter=30.0, A=10.0, gamma=0.1, eps=1e-6)\n",
    "\n",
    "print(ln_d.sum())\n",
    "# ld, ln_d = FAPE_loss(noise_xyz_save.unsqueeze(0), true_save, score_scales,  d_clamp=10.0, \n",
    "#                      d_clamp_inter=30.0, A=10.0, gamma=1.0, eps=1e-6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "43b754cf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 1, 128, 128])\n",
      "tensor([[78.0410]])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor([[0.0185]])"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "d_clamp=10.0,\n",
    "d_clamp_inter=30.0\n",
    "A=10.0\n",
    "gamma=0.1\n",
    "eps=1e-6\n",
    "\n",
    "pred = noise_xyz_save.unsqueeze(0) #maybe swap back for consistenccy\n",
    "true = true_save.unsqueeze(0)\n",
    "real_mask = real_mask_save[0].unsqueeze(0)\n",
    "    \n",
    "t_tilde_ij = get_t(true[:,:,:,0], true[:,:,:,1], true[:,:,:,2])\n",
    "t_ij = get_t(pred[:,:,:,0], pred[:,:,:,1], pred[:,:,:,2])\n",
    "    \n",
    "difference = torch.sqrt(torch.square(t_tilde_ij-t_ij).sum(dim=-1) + eps)\n",
    "clamp = torch.zeros_like(difference)\n",
    "# intra vs inter#me coded\n",
    "clamp[:,True] = torch.tensor(d_clamp)\n",
    "difference = torch.clamp(difference, max=clamp)\n",
    "loss = difference / A # (I, B, L, L)\n",
    "\n",
    "loss = loss[:,0,...].unsqueeze(0)\n",
    "\n",
    "rm_e = real_mask.repeat((1,L)).reshape(1,1,L,L)\n",
    "rm_et =  torch.transpose(rm_e,2,3)\n",
    "print(rm_et.shape)\n",
    "print((rm_e*loss*rm_et).sum(dim=(2,3)))\n",
    "(rm_e*loss*rm_et).sum(dim=(2,3))/((rm_e*rm_et).sum(dim=(2,3)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "fe525aef",
   "metadata": {},
   "outputs": [],
   "source": [
    "n=0\n",
    "ld, ln_d =  FAPE_loss_real(noise_xyz_save[n].unsqueeze(0),\n",
    "                     true_save[n].unsqueeze(0),\n",
    "                     score_scales[0].unsqueeze(0), \n",
    "                            real_mask[0].unsqueeze(0),\n",
    "                           d_clamp=10.0, d_clamp_inter=30.0, A=10.0, gamma=1.0, eps=1e-6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "40bdb673",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 2, 1, 3, 3])\n",
      "torch.Size([1, 2, 128, 3, 3])\n",
      "diff torch.Size([1, 2, 130, 130])\n",
      "torch.Size([1, 2, 130, 130])\n",
      "torch.Size([1, 2, 128])\n",
      "torch.Size([1, 2, 128])\n",
      "tensor(1.8570)\n",
      "torch.Size([1, 2, 128])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor([[0.0001, 0.0001]])"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "d_clamp=10.0,\n",
    "d_clamp_inter=30.0\n",
    "A=10.0\n",
    "gamma=0.1\n",
    "eps=1e-6\n",
    "\n",
    "first_point = fp_save.clone().unsqueeze(0)\n",
    "last_point = lp_save.clone().unsqueeze(0)\n",
    "#first_point = lp_save.clone().unsqueeze(0)\n",
    "\n",
    "pred = noise_xyz_save.unsqueeze(0) #maybe swap back for consistenccy\n",
    "true = true_save.unsqueeze(0)\n",
    "null_mask = ~real_mask_save.unsqueeze(0) \n",
    "\n",
    "#fp = lp_save.repeat((1,L,1,1)).unsqueeze(0)\n",
    "print(first_point.shape)\n",
    "print(pred.shape)\n",
    "\n",
    "#add first and last point to characterize FAPE loss to the closest proper null node (endpoints)\n",
    "flp_pred = torch.concat((first_point,last_point,pred),2)\n",
    "flp_true = torch.concat((first_point,last_point,true),2)\n",
    "\n",
    "\n",
    "#this doesn't work since all points are the same\n",
    "t_tilde_ij = get_t(flp_true[:,:,:,0], flp_true[:,:,:,1], flp_true[:,:,:,2])\n",
    "t_ij = get_t(flp_pred[:,:,:,0], flp_pred[:,:,:,1], flp_pred[:,:,:,2])\n",
    "\n",
    "difference = torch.sqrt(torch.square(t_tilde_ij-t_ij).sum(dim=-1) + eps)\n",
    "\n",
    "print('diff',difference.shape)\n",
    "clamp = torch.zeros_like(difference)\n",
    "# intra vs inter#me coded\n",
    "clamp[:,True] = torch.tensor(d_clamp)\n",
    "difference = torch.clamp(difference, max=clamp)\n",
    "print(difference.shape)\n",
    "#null nodes\n",
    "difference_fp = difference[:,:,2:,0]\n",
    "difference_lp = difference[:,:,2:,1]\n",
    "\n",
    "difference_fp\n",
    "print(difference_lp.shape)\n",
    "nearest_endpoint = difference_lp.clone()\n",
    "nearest_endpoint[difference_fp<difference_lp] = difference_fp[difference_fp<difference_lp]\n",
    "print(nearest_endpoint.shape)\n",
    "loss = nearest_endpoint / A # (I, B, L, L)\n",
    "print(loss.sum())\n",
    "print(loss.shape)\n",
    "#nm_et =  torch.transpose(nm_e,1,2)\n",
    "(null_mask*loss).sum(dim=(2))/((null_mask).sum(dim=(2)))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "6f483789",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0.0150) FAPE_Regular_ALL\n",
      "tensor(0.0356) FAPE_REAL\n",
      "tensor(0.0002) FAPE_null\n"
     ]
    }
   ],
   "source": [
    "check(bb_dict,t=0.0000001, jp_fape=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "08c498b9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0.0221) FAPE_Regular_ALL\n",
      "tensor(0.0497) FAPE_REAL\n",
      "tensor(0.0142) FAPE_null\n"
     ]
    }
   ],
   "source": [
    "check(bb_dict,t=0.01, jp_fape=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "638b98f6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0.0543) FAPE_Regular_ALL\n",
      "tensor(0.1162) FAPE_REAL\n",
      "tensor(0.0540) FAPE_null\n"
     ]
    }
   ],
   "source": [
    "check(bb_dict,t=0.05, jp_fape=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "056e5f38",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0.0939) FAPE_Regular_ALL\n",
      "tensor(0.1901) FAPE_REAL\n",
      "tensor(0.1047) FAPE_null\n"
     ]
    }
   ],
   "source": [
    "check(bb_dict,t=0.1, jp_fape=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "33ece146",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0.2576) FAPE_Regular_ALL\n",
      "tensor(0.5220) FAPE_REAL\n",
      "tensor(0.3238) FAPE_null\n"
     ]
    }
   ],
   "source": [
    "check(bb_dict,t=0.5, jp_fape=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "9e879adc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0.2573) FAPE_Regular_ALL\n",
      "tensor(0.5200) FAPE_REAL\n",
      "tensor(0.3442) FAPE_null\n"
     ]
    }
   ],
   "source": [
    "check(bb_dict,t=1.0, jp_fape=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "06fde4fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def check(bb_dict, t=0.1,n=0, jp_fape=True):\n",
    "    \n",
    "    t_cpu = np.ones((B,))*t\n",
    "    noised_dict = fnd.forward(bb_dict,t_vec=t_cpu)\n",
    "    batched_t = to_cuda(noised_dict['t_vec'])\n",
    "\n",
    "    if not jp_fape:\n",
    "        rnm = noised_dict['real_nodes_mask'][n]\n",
    "        rr = roll2_continous_true(noised_dict['real_nodes_mask'])\n",
    "        real_indices = torch.arange(128).roll(int(rr[n]))\n",
    "        rnm = rnm.roll((int(rr[n])))\n",
    "        first_real_index = real_indices[rnm][0]\n",
    "        last_real_index = real_indices[rnm][-1]\n",
    "\n",
    "        print('first real index',first_real_index)\n",
    "        print('last_real_index',last_real_index)\n",
    "        print('real_indices',real_indices)\n",
    "\n",
    "        fpc1 = noised_dict['bb_firstp']['CA'][n]\n",
    "        fpc1t = noised_dict['bb_shifted']['CA'][n][first_real_index ]\n",
    "        print('fp_ca_recorded:   ',fpc1)\n",
    "        print('fp_cafpc1t_found: ',fpc1t )\n",
    "        print()\n",
    "        lpc1 = noised_dict['bb_lastp']['CA'][n]\n",
    "        lpc1t = noised_dict['bb_shifted']['CA'][n][last_real_index ]\n",
    "        print('lp_ca_recorded:   ',lpc1)\n",
    "        print('lp_cafpc1t_found: ',lpc1t )\n",
    "        print()\n",
    "        fpc1 = noised_dict['bb_firstp']['N_CA'][n]\n",
    "        fpc1t = noised_dict['bb_shifted']['N_CA'][first_real_index ]\n",
    "        print('fp_nca_recorded:   ',fpc1)\n",
    "        print('fpc1t_nca_found: ',fpc1t )\n",
    "\n",
    "        print()\n",
    "        lpc1 = noised_dict['bb_lastp']['N_CA'][n]\n",
    "        lpc1t = noised_dict['bb_shifted']['N_CA'][last_real_index ]\n",
    "        print('lp_nca_recorded:   ',lpc1)\n",
    "        print('lpc1t_nca_found: ',lpc1t )\n",
    "\n",
    "        fpc1 = noised_dict['bb_firstp']['C_CA'][n]\n",
    "        fpc1t = noised_dict['bb_shifted']['C_CA'][first_real_index ]\n",
    "        print('fp_nca_recorded:   ',fpc1)\n",
    "        print('fpc1t_nca_found: ',fpc1t )\n",
    "\n",
    "        print()\n",
    "        lpc1 = noised_dict['bb_lastp']['C_CA'][n]\n",
    "        lpc1t = noised_dict['bb_shifted']['C_CA'][last_real_index ]\n",
    "        print('lp_nca_recorded:   ',lpc1)\n",
    "        print('lpc1t_nca_found: ',lpc1t )\n",
    "    \n",
    "    CA_t  = noised_dict['bb_shifted']['CA'].reshape(B, L, 3)\n",
    "    NC_t = CA_t + noised_dict['bb_shifted']['N_CA'].reshape(B, L, 3)#not mult by bond distance, seems to help?\n",
    "    CC_t = CA_t + noised_dict['bb_shifted']['C_CA'].reshape(B, L, 3)#not mult \n",
    "    true =  torch.cat((NC_t,CA_t,CC_t),dim=2).reshape(B,L,3,3)\n",
    "\n",
    "    CA_n  = noised_dict['bb_noised']['CA'].reshape(B, L, 3)\n",
    "    NC_n = CA_n + noised_dict['bb_noised']['N_CA'].reshape(B, L, 3)\n",
    "    CC_n = CA_n + noised_dict['bb_noised']['C_CA'].reshape(B, L, 3)\n",
    "    noise_xyz =  torch.cat((NC_n,CA_n,CC_n),dim=2).reshape(B,L,3,3)\n",
    "    \n",
    "    fp_save, lp_save  = convert_pV_to_points(noised_dict,device='cpu')\n",
    "\n",
    "    score_scales = torch.ones_like(noised_dict['score_scales'])\n",
    "    real_mask =  noised_dict['real_nodes_mask']\n",
    "    ld, ln_d = FAPE_loss(noise_xyz.unsqueeze(0), true,score_scales,  d_clamp=10.0,\n",
    "                       d_clamp_inter=30.0, A=10.0, gamma=1.0, eps=1e-6)\n",
    "    print(ld,\"FAPE_Regular_ALL\")\n",
    "    \n",
    "    lr, ln_dr = FAPE_loss_real(noise_xyz, true, score_scales, real_mask, d_clamp=10.0,\n",
    "                   d_clamp_inter=30.0, A=10.0, gamma=1.0, eps=1e-6)\n",
    "    print(lr,\"FAPE_REAL\")\n",
    "    \n",
    "    pred, first_point, last_point, real_mask, score_scales\n",
    "    \n",
    "    ln, ln_dr = FAPE_loss_null(noise_xyz, fp_save, lp_save, real_mask, score_scales, d_clamp=10.0,\n",
    "                   d_clamp_inter=30.0, A=10.0, gamma=1.0, eps=1e-6)\n",
    "    print(ln,\"FAPE_null\")\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cbd494d3",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "se33",
   "language": "python",
   "name": "se33"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
