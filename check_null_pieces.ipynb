{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 264,
   "id": "a02a1c0f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 264,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "#clear memory better\n",
    "with torch.no_grad():\n",
    "    torch.cuda.empty_cache()\n",
    "import numpy as np\n",
    "import util.npose_util as nu\n",
    "import os\n",
    "import pathlib\n",
    "import dgl\n",
    "from dgl import backend as F\n",
    "import torch_geometric\n",
    "from torch.utils.data import random_split, DataLoader, Dataset\n",
    "from typing import Dict\n",
    "from torch import Tensor\n",
    "from dgl import DGLGraph\n",
    "from torch import nn\n",
    "from chemical import cos_ideal_NCAC #from RoseTTAFold2\n",
    "from torch import einsum\n",
    "import time\n",
    "torch.cuda.is_available()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 265,
   "id": "33e16cff",
   "metadata": {},
   "outputs": [],
   "source": [
    "import se3_diffuse.utils as du"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 266,
   "id": "6a31f547",
   "metadata": {},
   "outputs": [],
   "source": [
    "from data_rigid_diffuser import so3_diffuser\n",
    "from data_rigid_diffuser import r3_diffuser\n",
    "from data_rigid_diffuser import oneHot_diffuser\n",
    "from scipy.spatial.transform import Rotation\n",
    "from data_rigid_diffuser import rigid_utils as ru\n",
    "import yaml\n",
    "from data_rigid_diffuser.diffuser import FrameDiffNoise\n",
    "from gudiff_model import Data_Graph\n",
    "from gudiff_model.Data_Graph import build_npose_from_coords, dump_coord_pdb, define_graph_edges, make_pe_encoding\n",
    "from gudiff_model.Data_Graph import Helix4_Dataset, Make_KNN_MP_Graphs\n",
    "from gudiff_model.Data_Graph_Null import  Make_nullKNN_MP_Graphs\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 267,
   "id": "bf443f63",
   "metadata": {},
   "outputs": [],
   "source": [
    "from se3_transformer.model.basis import get_basis, update_basis_with_fused\n",
    "from se3_transformer.model.transformer import Sequential, SE3Transformer\n",
    "from se3_transformer.model.transformer_topk import SE3Transformer_topK\n",
    "from se3_transformer.model.FAPE_Loss import FAPE_loss, Qs2Rs, normQ\n",
    "from se3_transformer.model.layers.attentiontopK import AttentionBlockSE3\n",
    "from se3_transformer.model.layers.linear import LinearSE3\n",
    "from se3_transformer.model.layers.convolution import ConvSE3, ConvSE3FuseLevel\n",
    "from se3_transformer.model.layers.norm import NormSE3\n",
    "from se3_transformer.model.layers.pooling import GPooling, Latent_Unpool, Unpool_Layer\n",
    "from se3_transformer.runtime.utils import str2bool, to_cuda\n",
    "from se3_transformer.model.fiber import Fiber\n",
    "from se3_transformer.model.transformer import get_populated_edge_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 268,
   "id": "48bf9476",
   "metadata": {},
   "outputs": [],
   "source": [
    "from se3_transformer.model.FAPE_Loss import FAPE_loss_null, FAPE_loss_real, FAPE_loss\n",
    "from se3_transformer.model.FAPE_Loss import get_t"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 269,
   "id": "c0babffd",
   "metadata": {},
   "outputs": [],
   "source": [
    "#indices for, unsure if needed\n",
    "CA = Data_Graph.CA\n",
    "N = Data_Graph.N\n",
    "C = Data_Graph.C\n",
    "\n",
    "# #find better way to incorporate coord_scale\n",
    "\n",
    "#needed\n",
    "N_CA_dist = (Data_Graph.N_CA_dist/10.).to('cuda')\n",
    "C_CA_dist = (Data_Graph.C_CA_dist/10.).to('cuda')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 270,
   "id": "e213e885",
   "metadata": {},
   "outputs": [],
   "source": [
    "# data_path_str  = 'data/h4_ca_coords.npz'\n",
    "# test_limit = 1028\n",
    "# rr = np.load(data_path_str)\n",
    "# ca_coords = [rr[f] for f in rr.files][0][:test_limit,:,:3]\n",
    "# ca_coords.shape\n",
    "\n",
    "# getting N-Ca, Ca-C vectors to add as typeI features\n",
    "#apa = apart helices for val/train split\n",
    "#tog = together helices for val/train split\n",
    "\n",
    "#mode for tablet\n",
    "apa_path_str  = 'data_npose/h4_apa_coords.npz'\n",
    "tog_path_str  = 'data_npose/h4_tog_coords.npz'\n",
    "\n",
    "#grab the first 3 atoms which are N,CA,C\n",
    "test_limit = 2048\n",
    "rr = np.load(apa_path_str)\n",
    "coords_apa = [rr[f] for f in rr.files][0][:test_limit,:]\n",
    "\n",
    "rr = np.load(tog_path_str)\n",
    "coords_tog = [rr[f] for f in rr.files][0][:test_limit,:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 271,
   "id": "f3eae2f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# B = 16\n",
    "# L=65\n",
    "# limit = 1028\n",
    "# h4_trainData = Helix4_Dataset(coords_tog[:limit])\n",
    "# h4_valData = Helix4_Dataset(coords_apa[:limit])\n",
    "# train_dL = DataLoader(h4_trainData, batch_size=B, shuffle=True, drop_last=True)\n",
    "# val_dL   = DataLoader(h4_valData, batch_size=B, shuffle=True, drop_last=True)\n",
    "# testiter = iter(train_dL)\n",
    "# bb_dict = next(testiter)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 272,
   "id": "87f67d73",
   "metadata": {},
   "outputs": [],
   "source": [
    "from data_rigid_diffuser import diffuser"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 273,
   "id": "581b3006",
   "metadata": {},
   "outputs": [],
   "source": [
    "#I think I adjusted inputs and outputs,\n",
    "#sigmoid for nodes features for real/null pred?\n",
    "#need loss function for real/null nodes\n",
    "#need to get function to just pull real nodes for viewing?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 274,
   "id": "d79401b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "#helper functions for Diffusion_Graphical_UNet_Model\n",
    "\n",
    "def define_poolGraph(n_nodes, batch_size, cast_type=torch.float32, cuda_out=True ):\n",
    "    \n",
    "    v1,v2,edge_data, ind = define_graph_edges(n_nodes)\n",
    "    #pe = make_pe_encoding(n_nodes=n_nodes)#pe e\n",
    "    \n",
    "    graphList = []\n",
    "    \n",
    "    for i in range(batch_size):\n",
    "        \n",
    "        g = dgl.graph((v1,v2))\n",
    "        g.edata['con'] = edge_data.type(cast_type).reshape((-1,1))\n",
    "        g.ndata['pos'] = torch.zeros((n_nodes,3),dtype=torch.float32)\n",
    "\n",
    "        graphList.append(g)\n",
    "        \n",
    "    batched_graph = dgl.batch(graphList)\n",
    "    \n",
    "    if cuda_out:\n",
    "        return to_cuda(batched_graph)\n",
    "    else:\n",
    "        return batched_graph            \n",
    "        \n",
    "def pull_edge_features(graph, edge_feat_dim=1):\n",
    "    return {'0': graph.edata['con'][:, :edge_feat_dim, None]}\n",
    "\n",
    "def prep_for_gcn(graph, xyz_pos, edge_feats_input, idx, max_degree=3, comp_grad=True):\n",
    "    \n",
    "    src, dst = graph.edges()\n",
    "    \n",
    "    new_pos = F.gather_row(xyz_pos, idx)\n",
    "    rel_pos = F.gather_row(new_pos,dst) - F.gather_row(new_pos,src) \n",
    "    \n",
    "    basis_out = get_basis(rel_pos, max_degree=max_degree,\n",
    "                                   compute_gradients=comp_grad,\n",
    "                                   use_pad_trick=False)\n",
    "    basis_out = update_basis_with_fused(basis_out, max_degree, use_pad_trick=False,\n",
    "                                            fully_fused=False)\n",
    "    edge_feats_out = get_populated_edge_features(rel_pos, edge_feats_input)\n",
    "    return edge_feats_out, basis_out, new_pos    \n",
    "\n",
    "#--- layer for converting t[0,1] to be more expressive\n",
    "class GaussianFourierProjection(nn.Module):\n",
    "    \"\"\"Gaussian random features for encoding time steps.\"\"\"  \n",
    "    #From Yang Song, Tutorial on Score based diffusion models\n",
    "    def __init__(self, embed_dim, scale=30.):\n",
    "        super().__init__()\n",
    "        # Randomly sample weights during initialization. These weights are fixed \n",
    "        # during optimization and are not trainable.\n",
    "        self.W = nn.Parameter(torch.randn(embed_dim // 2) * scale, requires_grad=False)\n",
    "    def forward(self, x):\n",
    "        x_proj = x[:, None] * self.W[None, :] * 2 * np.pi\n",
    "        return torch.cat([torch.sin(x_proj), torch.cos(x_proj)], dim=-1)\n",
    "    \n",
    "class GaussianFourierProjection_Linear(nn.Module):\n",
    "    \"\"\"Gaussian random features for encoding time steps.\"\"\"  \n",
    "    #From Yang Song, Tutorial on Score based diffusion models\n",
    "    def __init__(self, embed_dim, scale=30., use_deg1 = True):\n",
    "        super().__init__()\n",
    "        self.GFP = GaussianFourierProjection(embed_dim, scale=scale)\n",
    "        self.linear0 = nn.Linear(embed_dim,embed_dim)\n",
    "        self.use_deg1 = use_deg1\n",
    "        self.act = nn.SiLU()\n",
    "        if use_deg1:\n",
    "            self.linear1 = nn.Linear(embed_dim,1) #create a scalar for multiplication to vector '1'\n",
    "            #according to to some toronto math notes I believe this retains invariance\n",
    "\n",
    "    def forward(self, t):\n",
    "        if self.use_deg1:\n",
    "            return {'0': self.act(self.linear0(self.GFP(t))), '1':self.act(self.linear1(self.GFP(t)))}\n",
    "        else:\n",
    "            return {'0' : self.act(self.linear0(self.GFP(t)))}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 275,
   "id": "6b515101",
   "metadata": {},
   "outputs": [],
   "source": [
    "##-- Graphical U-net for Denoising\n",
    "class GraphUNet_Null(torch.nn.Module):\n",
    "    def __init__(self, \n",
    "                 fiber_start = Fiber({0:12, 1:2}),\n",
    "                 fiber_out = Fiber({0:5,1:2}),\n",
    "                 k=4,\n",
    "                 batch_size = 8,\n",
    "                 stride=4,\n",
    "                 max_degree=3,\n",
    "                 channels=32,\n",
    "                 num_heads = 8,\n",
    "                 channels_div=4,\n",
    "                 num_layers = 1,\n",
    "                 num_layers_ca = 1,\n",
    "                 edge_feature_dim=1,\n",
    "                 latent_pool_type = 'avg',\n",
    "                 t_size = 12,\n",
    "                 zero_lin=True,\n",
    "                 use_tdeg1 = True,\n",
    "                 cuda=True):\n",
    "        super(GraphUNet_Null, self).__init__()\n",
    "        \n",
    "        #fiber_out is 5 for the null nodes, 1deg (2 (3D vector) to update translation/ rotation)\n",
    "        \n",
    "        #self.comp_basis_grad = True\n",
    "        self.cuda = cuda\n",
    "        \n",
    "        if cuda:\n",
    "            self.device='cuda:0'\n",
    "        else:\n",
    "            self.device='cpu'\n",
    "        \n",
    "        self.max_degree=max_degree #number of 'orbital types' to use for representing the sphere\n",
    "        self.B = batch_size\n",
    "        self.k = k #number of midpoints to be chosen to reduce graph size (topK pooling layer)\n",
    "        self.ts = t_size #number of features to represent t-value\n",
    "        \n",
    "        self.use_tdeg1 = use_tdeg1 #apply a t-value to degree (vector) one in the se3transformer\n",
    "                                    #scalar t put in one dimension , pad zero for other. Perhaps Bad to do.\n",
    "        self.zero_lin = zero_lin #apply a zero weight value to the linear \n",
    "        \n",
    "        self.embed_t = GaussianFourierProjection_Linear(self.ts, use_deg1=self.use_tdeg1)\n",
    "        self.t_fiber = Fiber({0:self.ts}) #add for change in fiber with self.concat_t\n",
    "        \n",
    "        self.num_layers = 1 #se3 transformers layers for all except the CA graph layer\n",
    "        self.num_layers_ca = num_layers_ca #layers to use on the CA-alpha graph layer\n",
    "        self.channels = 32\n",
    "        self.feat0 = 32 #deg0 number of features\n",
    "        self.feat1 = 6  #deg1 number of features\n",
    "        self.channels_div = 4\n",
    "        self.num_heads = 8 #se3 attention heads\n",
    "        self.mult = int(stride/2) #multiplier to increase channels as the graph reduces nodes\n",
    "        self.fiber_edge=Fiber({0:edge_feature_dim})\n",
    "        self.edge_feat_dim = edge_feature_dim\n",
    "        \n",
    "        self.pool_type = latent_pool_type \n",
    "        \n",
    "        self.channels_down_ca = channels #c_alpha interactions by nearest  neighbors onto midpoints \n",
    "        #(on the down side of U-Net)\n",
    "        self.fiber_start =  fiber_start\n",
    "        self.fiber_hidden_down_ca = Fiber.create(self.max_degree, self.channels_down_ca)\n",
    "        self.fiber_out_down_ca =Fiber({0: self.feat0, 1: self.feat1})\n",
    "        \n",
    "        #concat fiber+t_value, plus one on input fiber, use concat_t method during forward call\n",
    "        self.down_ca = SE3Transformer(num_layers = self.num_layers_ca,\n",
    "                        fiber_in=self.fiber_start+self.t_fiber,\n",
    "                        fiber_hidden= self.fiber_hidden_down_ca, \n",
    "                        fiber_out=self.fiber_out_down_ca,\n",
    "                        num_heads = self.num_heads,\n",
    "                        channels_div = self.channels_div,\n",
    "                        fiber_edge=self.fiber_edge,\n",
    "                        low_memory=True,\n",
    "                        tensor_cores=False)\n",
    "        \n",
    "        self.channels_down_ca2mp = self.channels_down_ca*self.mult\n",
    "        \n",
    "        #pool from c_alpha onto midpoints\n",
    "        self.fiber_in_down_ca2mp     = self.fiber_out_down_ca\n",
    "        self.fiber_hidden_down_ca2mp = Fiber.create(max_degree, self.channels_down_ca2mp)\n",
    "        self.fiber_out_down_ca2mp    = Fiber({0: self.feat0*self.mult, 1: self.feat1*self.mult})\n",
    "        \n",
    "        #concat_t, plus one on input fiber, run concat_t method on forward call\n",
    "        self.down_ca2mp = SE3Transformer(num_layers = self.num_layers,\n",
    "                            fiber_in     = self.fiber_in_down_ca2mp+self.t_fiber,\n",
    "                            fiber_hidden = self.fiber_hidden_down_ca2mp, \n",
    "                            fiber_out    = self.fiber_out_down_ca2mp,\n",
    "                            num_heads =    self.num_heads,\n",
    "                            channels_div = self.channels_div,\n",
    "                            fiber_edge=self. fiber_edge,\n",
    "                            low_memory=True,\n",
    "                            tensor_cores=False)\n",
    "        \n",
    "        #topK selection of midpoint node graph\n",
    "        self.fiber_in_mptopk =  self.fiber_out_down_ca2mp\n",
    "        self.fiber_hidden_down_mp  =self.fiber_hidden_down_ca2mp\n",
    "        self.fiber_out_down_mp_out =self.fiber_out_down_ca2mp\n",
    "        self.fiber_out_topkpool=Fiber({0: self.feat0*self.mult*self.mult})\n",
    "        \n",
    "        #concat_t, plus one on input fiber, run concat_t method on forward\n",
    "        self.mp_topk = SE3Transformer_topK(num_layers = self.num_layers,\n",
    "                                        fiber_in      = self.fiber_in_mptopk+self.t_fiber,\n",
    "                                        fiber_hidden  = self.fiber_hidden_down_mp, \n",
    "                                        fiber_out     = self.fiber_out_down_mp_out ,\n",
    "                                        fiber_out_topk= self.fiber_out_topkpool,\n",
    "                                        k             = self.k,\n",
    "                                        num_heads     = self.num_heads,\n",
    "                                        channels_div  = self.channels_div,\n",
    "                                        fiber_edge    =  self.fiber_edge,\n",
    "                                        low_memory=True,\n",
    "                                        tensor_cores=False)\n",
    "        \n",
    "        self.gsmall = define_poolGraph(self.k, self.B, cast_type=torch.float32, cuda_out=self.cuda)\n",
    "        self.ef_small = pull_edge_features(self.gsmall, edge_feat_dim=self.edge_feat_dim)\n",
    "        \n",
    "        #change to doing convolutions instead of transformer\n",
    "        self.fiber_in_down_gcn   =  self.fiber_out_topkpool\n",
    "        self.fiber_out_down_gcn  = Fiber({0: self.feat0*self.mult*self.mult, 1: self.feat1*self.mult})\n",
    "\n",
    "        self.down_gcn = ConvSE3(fiber_in  = self.fiber_in_down_gcn,\n",
    "                           fiber_out = self.fiber_out_down_gcn,\n",
    "                           fiber_edge= self.fiber_edge,\n",
    "                             self_interaction=True,\n",
    "                             use_layer_norm=True,\n",
    "                             max_degree=self.max_degree,\n",
    "                             fuse_level= ConvSE3FuseLevel.NONE,\n",
    "                             low_memory= True)\n",
    "        \n",
    "        \n",
    "        self.fiber_in_down_gcnp = self.fiber_out_down_gcn\n",
    "        #probably rename latent to something more approriate \n",
    "        self.latent_size = self.feat0*self.mult*self.mult\n",
    "        self.fiber_latent = Fiber({0: self.latent_size})\n",
    "\n",
    "        self.down_gcn2pool = ConvSE3(fiber_in=self.fiber_in_down_gcnp,\n",
    "                                     fiber_out=self.fiber_latent,\n",
    "                                     fiber_edge=self.fiber_edge,\n",
    "                                     self_interaction=True,\n",
    "                                     use_layer_norm=True,\n",
    "                                     max_degree=self.max_degree,\n",
    "                                     fuse_level= ConvSE3FuseLevel.NONE,\n",
    "                                     low_memory= True)\n",
    "        \n",
    "        self.global_pool = GPooling(pool=self.pool_type, feat_type=0)\n",
    "\n",
    "        self.latent_unpool_layer = Latent_Unpool(fiber_in = self.fiber_latent, fiber_add = self.fiber_out_down_gcn, \n",
    "                                            knodes = self.k)\n",
    "\n",
    "        self.up_gcn = ConvSE3(fiber_in=self.fiber_out_down_gcn,\n",
    "                             fiber_out=self.fiber_out_down_gcn,\n",
    "                             fiber_edge=self.fiber_edge,\n",
    "                             self_interaction=True,\n",
    "                             use_layer_norm=True,\n",
    "                             max_degree=self.max_degree,\n",
    "                             fuse_level= ConvSE3FuseLevel.NONE,\n",
    "                             low_memory= True)\n",
    "        \n",
    "        self.unpool_layer = Unpool_Layer(fiber_in=self.fiber_out_down_gcn, fiber_add=self.fiber_out_down_ca)\n",
    "        \n",
    "        self.fiber_in_up_gcn_mp = self.unpool_layer.fiber_out\n",
    "        self.fiber_hidden_up_mp= self.fiber_hidden_down_ca2mp\n",
    "        self.fiber_out_up_gcn_mp = self.fiber_out_down_mp_out\n",
    "\n",
    "        self.up_gcn_mp = SE3Transformer(num_layers = num_layers,\n",
    "                        fiber_in=self.fiber_in_up_gcn_mp,\n",
    "                        fiber_hidden= self.fiber_hidden_up_mp, \n",
    "                        fiber_out=self.fiber_out_up_gcn_mp,\n",
    "                        num_heads = self.num_heads,\n",
    "                        channels_div = self.channels_div,\n",
    "                        fiber_edge=self.fiber_edge,\n",
    "                        low_memory=True,\n",
    "                        tensor_cores=False)\n",
    "        \n",
    "        self.unpool_layer_off_mp = Unpool_Layer(fiber_in=self.fiber_out_down_mp_out, fiber_add=self.fiber_out_down_mp_out)\n",
    "\n",
    "        self.fiber_in_up_off_mp = self.fiber_out_up_gcn_mp\n",
    "        self.fiber_hidden_up_off_mp = self.fiber_hidden_up_mp\n",
    "        self.fiber_out_up_off_mp = self.fiber_out_down_ca \n",
    "        \n",
    "        #uses reverse graph to move mp off \n",
    "        \n",
    "        self.up_off_mp = SE3Transformer(num_layers = self.num_layers,\n",
    "                        fiber_in=self.fiber_in_up_off_mp,\n",
    "                        fiber_hidden= self.fiber_hidden_up_off_mp, \n",
    "                        fiber_out=self.fiber_out_up_off_mp,\n",
    "                        num_heads = self.num_heads,\n",
    "                        channels_div = self.channels_div,\n",
    "                        fiber_edge=self.fiber_edge,\n",
    "                        low_memory=True,\n",
    "                        tensor_cores=False)\n",
    "        \n",
    "        self.pre_linear = Fiber({0:16,1:36}) \n",
    "        #add for 0 for node prediction (real, null), \n",
    "        #1 for prediction of \n",
    "        \n",
    "        #concat_t, plus one on input fiber, run concat_t method on forward\n",
    "        \n",
    "        self.up_ca = SE3Transformer(num_layers = self.num_layers_ca,\n",
    "                                    fiber_in=self.fiber_out_down_ca+self.t_fiber,\n",
    "                                    fiber_hidden= self.fiber_hidden_down_ca, \n",
    "                                    fiber_out=self.pre_linear,\n",
    "                                    num_heads = self.num_heads,\n",
    "                                    channels_div = self.channels_div,\n",
    "                                    fiber_edge= self.fiber_edge,\n",
    "                                    low_memory=True,\n",
    "                                    tensor_cores=False)\n",
    "        \n",
    "        self.fiber_out = fiber_out\n",
    "        \n",
    "        self.linear = LinearSE3(fiber_in=self.pre_linear,\n",
    "                                fiber_out=fiber_out)\n",
    "        \n",
    "        #do i need to add activation to zero(linera)\n",
    "        \n",
    "        if self.zero_lin:\n",
    "            self.zero_linear()\n",
    "        self.act = nn.SiLU()\n",
    "        self.sig = nn.Sigmoid()\n",
    "        \n",
    "    def zero_linear(self):\n",
    "        \"\"\"Zero linear weights of degree one only.\"\"\"\n",
    "        nn.init.zeros_(self.linear.weights['1'])\n",
    "        \n",
    "    def concat_mp_feats(self, ca_feats_in, mp_feats):\n",
    "        \"\"\"Concatenate the mp and calpha feats, by debatching batched graph\"\"\"\n",
    "        nf0_c = ca_feats_in['0'].shape[-2]\n",
    "        nf1_c = ca_feats_in['1'].shape[-2]\n",
    "\n",
    "        out0_cat_shape = (self.B,self.ca_nodes,-1,1)\n",
    "        mp0_cat_shape  = (self.B,self.mp_nodes,-1,1)\n",
    "        out1_cat_shape = (self.B,self.ca_nodes,-1,3)\n",
    "        mp1_cat_shape  = (self.B,self.mp_nodes,-1,3)\n",
    "\n",
    "        nf_c = {} #nf_cat\n",
    "        nf_c['0'] = torch.cat((ca_feats_in['0'].reshape(out0_cat_shape), \n",
    "                                 mp_feats['0'].reshape(mp0_cat_shape)[:,-(self.mp_nodes-self.ca_nodes):,:,:]),\n",
    "                              axis=1).reshape((-1,nf0_c,1))\n",
    "\n",
    "        nf_c['1'] = torch.cat((ca_feats_in['1'].reshape(out1_cat_shape), \n",
    "                                 mp_feats['1'].reshape(mp1_cat_shape)[:,-(self.mp_nodes-self.ca_nodes):,:,:]),\n",
    "                              axis=1).reshape((-1,nf1_c,3))\n",
    "\n",
    "        return nf_c\n",
    "        \n",
    "    def pull_out_mp_feats(self, ca_mp_feats):\n",
    "        \"\"\"Select mp feats selected as the topK nodes\"\"\"\n",
    "\n",
    "        nf0_c = ca_mp_feats['0'].shape[1]\n",
    "        nf1_c = ca_mp_feats['1'].shape[1]\n",
    "\n",
    "        nf_mp_ = {}\n",
    "        #select just mp nodes to move on, the other nodes don't connect but mainting self connections\n",
    "        nf_mp_['0'] = ca_mp_feats['0'].reshape(self.B,self.mp_nodes,\n",
    "                                               nf0_c,1)[:,-(self.mp_nodes-self.ca_nodes):,...].reshape((-1,nf0_c,1))\n",
    "        nf_mp_['1'] = ca_mp_feats['1'].reshape(self.B,self.mp_nodes,\n",
    "                                               nf1_c,3)[:,-(self.mp_nodes-self.ca_nodes):,...].reshape((-1,nf1_c,3))\n",
    "\n",
    "        return nf_mp_\n",
    "    \n",
    "    def concat_t(self, feats_in, embedded_t, use_deg1=True, cast_type=torch.float):\n",
    "        \"\"\"Concatenate T to first position of each tensor. Pad Zeros left for degree 1.\"\"\"\n",
    "        feats_out = {}\n",
    "        key = next(iter(feats_in.keys()))\n",
    "        shape_tuple = (self.B,-1)+feats_in[key].shape[1:]\n",
    "        batch_shape = feats_in[key].reshape(shape_tuple).shape\n",
    "        L = batch_shape[1] #can be ca, ca+mp, mp, k nodes long\n",
    "\n",
    "        if '0' in feats_in.keys():\n",
    "            feats_out['0'] = torch.concat((embedded_t['0'][:,None,:,None].repeat(1,L,1,1), \n",
    "                                           feats_in['0'].reshape((self.B,L,-1,1))),\n",
    "                                          axis=2).reshape((self.B*L,-1,1))\n",
    "        if '1' in feats_in.keys():\n",
    "            \n",
    "            if use_deg1:\n",
    "                feats_out['1'] = torch.multiply(feats_in['1'],\n",
    "                                                embedded_t['1'][:,None,:,None].repeat(1,L,1,1).reshape((self.B*L,-1,1)))\n",
    "            else:\n",
    "                feats_out['1'] = feats_in['1']\n",
    "\n",
    "        return feats_out\n",
    "    \n",
    "    \n",
    "    def forward(self, feat_dict, batched_t):\n",
    "        \n",
    "        \n",
    "        b_graph, nf, ef = feat_dict['batched_graph'], feat_dict['node_feats'], feat_dict['edge_feats'] \n",
    "        b_graph_mp, nf_mp, ef_mp = feat_dict['batched_graph_mp'], feat_dict['node_feats_mp'], feat_dict['edge_feats_mp']\n",
    "        b_graph_mps, nf_mps, ef_mps =  feat_dict['batched_graph_mpself'], feat_dict['node_feats_mpself'], feat_dict['edge_feats_mpself']\n",
    "        b_graph_mpRev = feat_dict['batched_graph_mprev'] \n",
    "\n",
    "        #assumes equal node numbers in g raphs\n",
    "        self.ca_nodes = int(b_graph.batch_num_nodes()[0])\n",
    "        self.mp_nodes = int(b_graph_mp.batch_num_nodes()[0]) #ca+mp nodes number\n",
    "\n",
    "        #SE3 Attention Transformer, c_alpha\n",
    "        embed_t = self.embed_t(batched_t)\n",
    "        t_nf = self.concat_t(nf, embed_t, use_deg1=self.use_tdeg1) #concat_t on\n",
    "        nf_ca_down_out = self.down_ca(b_graph, t_nf, ef)\n",
    "\n",
    "        #concatenate on midpoints feats\n",
    "        \n",
    "        nf_down_cat_mp = self.concat_mp_feats(nf_ca_down_out, nf_mp)\n",
    "\n",
    "        #pool from ca onto selected midpoints via SE3 Attention transformer\n",
    "        #edges from ca to mp only (ca nodes zero after this)\n",
    "        t_nf_down_cat_mp = self.concat_t(nf_down_cat_mp, embed_t,use_deg1=self.use_tdeg1) #concat_t on\n",
    "        nf_down_ca2mp_out = self.down_ca2mp(b_graph_mp, t_nf_down_cat_mp, ef_mp)\n",
    "\n",
    "        #remove ca node feats from tensor \n",
    "        nf_mp_out = self.pull_out_mp_feats(nf_down_ca2mp_out)\n",
    "\n",
    "        t_nf_mp_out = self.concat_t(nf_mp_out, embed_t, use_deg1=self.use_tdeg1) #concat_t on\n",
    "        node_feats_tk, topk_feats, topk_indx = self.mp_topk(b_graph_mps, t_nf_mp_out, ef_mps)\n",
    "\n",
    "        #make new basis for small graph of k selected midpoints\n",
    "        edge_feats_out, basis_out, new_pos = prep_for_gcn(self.gsmall, b_graph_mps.ndata['pos'], self.ef_small,\n",
    "                                                          topk_indx,\n",
    "                                                          max_degree=self.max_degree, comp_grad=True)\n",
    "\n",
    "        down_gcn_out = self.down_gcn(topk_feats, edge_feats_out, self.gsmall,  basis_out)\n",
    "\n",
    "        down_gcnpool_out = self.down_gcn2pool(down_gcn_out, edge_feats_out, self.gsmall,  basis_out)\n",
    "\n",
    "        pooled_tensor = self.global_pool(down_gcnpool_out,self.gsmall)\n",
    "        pooled = {'0':pooled_tensor}\n",
    "        #----------------------------------------- end of down section\n",
    "        lat_unp = self.latent_unpool_layer(pooled,down_gcn_out)\n",
    "\n",
    "        up_gcn_out = self.up_gcn(lat_unp, edge_feats_out, self.gsmall,  basis_out)\n",
    "\n",
    "        k_to_mp  = self.unpool_layer(up_gcn_out,node_feats_tk,topk_indx)\n",
    "\n",
    "        up_mp_gcn_out = self.up_gcn_mp(b_graph_mps, k_to_mp, ef_mps)\n",
    "        \n",
    "        off_mp_add = {}\n",
    "        for k,v in up_mp_gcn_out.items():\n",
    "            off_mp_add[k] = torch.add(up_mp_gcn_out[k],nf_mp_out[k])\n",
    "\n",
    "\n",
    "        #####triple check from here\n",
    "        #midpoints node indices for unpool layer\n",
    "        mp_node_indx = torch.arange(self.ca_nodes,self.mp_nodes, device=self.device)\n",
    "        mp_idx = mp_node_indx[None,...].repeat_interleave(self.B,0)\n",
    "        mp_idx =((torch.arange(self.B,device=self.device)*(self.mp_nodes)).reshape((-1,1))+mp_idx).reshape((-1))\n",
    "        \n",
    "        #during unpool, keep mp=values and ca=zeros\n",
    "        zeros_mp_ca = {}\n",
    "        for k,v in nf_down_cat_mp.items():\n",
    "            zeros_mp_ca[k] = torch.zeros_like(v, device=self.device)\n",
    "\n",
    "\n",
    "        unpoff_out = self.unpool_layer_off_mp(off_mp_add, zeros_mp_ca, mp_idx)\n",
    "        \n",
    "        out_up_off_mp = self.up_off_mp(b_graph_mpRev, unpoff_out, ef_mp)\n",
    "        \n",
    "        #select just ca nodes, mp = zeros from last convolution\n",
    "        inv_mp_idx= torch.arange(0,self.ca_nodes, device=self.device)\n",
    "        inv_mp_idx = inv_mp_idx[None,...].repeat_interleave(self.B,0)\n",
    "        inv_mp_idx =((torch.arange(self.B,device=self.device)*(self.mp_nodes)).reshape((-1,1))\n",
    "                     +inv_mp_idx).reshape((-1))\n",
    "\n",
    "        node_final_ca = {}\n",
    "        for key in out_up_off_mp.keys():\n",
    "            node_final_ca[key] = torch.add(out_up_off_mp[key][inv_mp_idx,...],nf_ca_down_out[key])\n",
    "\n",
    "        #return updates \n",
    "        t_node_final_ca = self.concat_t(node_final_ca, embed_t, use_deg1=self.use_tdeg1) #concat_t on\n",
    "        \n",
    "        output = self.linear(self.up_ca(b_graph, t_node_final_ca, ef))\n",
    "        output['0'] = self.sig(output['0']) #normalize to zero to one for node calculation\n",
    "        \n",
    "        return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 276,
   "id": "02ba860f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_pV_to_points(dict_in):\n",
    "    \n",
    "    CA_fp  = dict_in['bb_firstp']['CA'].reshape(B, L, 3).to(device)\n",
    "    NC_fp = CA_fp + dict_in['bb_firstp']['N_CA'].reshape(B, L, 3).to(device)\n",
    "    CC_fp = CA_fp + dict_in['bb_firstp']['C_CA'].reshape(B, L, 3).to(device)\n",
    "    fp =  torch.cat((NC_fp,CA_fp,CC_fp),dim=2).reshape(B,L,3,3)\n",
    "    \n",
    "    CA_lp  = dict_in['bb_firstp']['CA'].reshape(B, L, 3).to(device)\n",
    "    NC_lp = CA_fp + dict_in['bb_firstp']['N_CA'].reshape(B, L, 3).to(device)\n",
    "    CC_lp = CA_fp + dict_in['bb_firstp']['C_CA'].reshape(B, L, 3).to(device)\n",
    "    lp =  torch.cat((NC_lp,CA_lp,CC_lp),dim=2).reshape(B,L,3,3)\n",
    "    \n",
    "    return fp, lp\n",
    "def get_noise_pred_true_null(noised_dict, batched_t, graph_maker, graph_unet):\n",
    "    \n",
    "    CA_t  = noised_dict['bb_shifted']['CA'].reshape(B, L, 3).to('cuda')\n",
    "    NC_t = CA_t + noised_dict['bb_shifted']['N_CA'].reshape(B, L, 3).to('cuda')*N_CA_dist\n",
    "    CC_t = CA_t + noised_dict['bb_shifted']['C_CA'].reshape(B, L, 3).to('cuda')*C_CA_dist\n",
    "    true =  torch.cat((NC_t,CA_t,CC_t),dim=2).reshape(B,L,3,3)\n",
    "    \n",
    "    CA_n  = noised_dict['bb_noised']['CA'].reshape(B, L, 3).to('cuda')\n",
    "    NC_n = CA_n + noised_dict['bb_noised']['N_CA'].reshape(B, L, 3).to('cuda')*N_CA_dist\n",
    "    CC_n = CA_n + noised_dict['bb_noised']['C_CA'].reshape(B, L, 3).to('cuda')*C_CA_dist\n",
    "    noise_xyz =  torch.cat((NC_n,CA_n,CC_n),dim=2).reshape(B,L,3,3)\n",
    "    \n",
    "    feat_dict = graph_maker.prep_for_network(noised_dict)\n",
    "    out = graph_unet(feat_dict, batched_t)\n",
    "    CA_p = out['1'][:,0,:].reshape(B, L, 3)+CA_n #translation of Calpha\n",
    "    Qs = out['1'][:,1,:] # rotation\n",
    "    Qs = Qs.unsqueeze(1).repeat((1,2,1))\n",
    "    Qs = torch.cat((torch.ones((B*L,2,1),device=Qs.device),Qs),dim=-1).reshape(B,L,2,4)\n",
    "    Qs = normQ(Qs)\n",
    "    Rs = Qs2Rs(Qs)\n",
    "    N_C_to_Rot = torch.cat((noised_dict['bb_noised']['N_CA'].reshape(B, L, 3).to('cuda'),\n",
    "                            noised_dict['bb_noised']['C_CA'].reshape(B, L, 3).to('cuda')),dim=2).reshape(B,L,2,1,3)\n",
    "\n",
    "    \n",
    "    rot_vecs = einsum('bnkij,bnkhj->bnki',Rs, N_C_to_Rot)\n",
    "    NC_p = CA_p + rot_vecs[:,:,0,:].to('cuda')*N_CA_dist\n",
    "    CC_p = CA_p + rot_vecs[:,:,1,:].reshape(B, L, 3).to('cuda')*C_CA_dist\n",
    "\n",
    "    pred = torch.cat((NC_p,CA_p,CC_p),dim=2).reshape(B,L,3,3)\n",
    "    \n",
    "    nf_pred = out['0']\n",
    "    \n",
    "    nf_pred = out['0']\n",
    "    real_nodes_pred = torch.round(nf_pred ).clamp(0,1)\n",
    "    real_nodes_pred_mask = (real_nodes_pred.squeeze().sum(-1)>1.99).reshape(B,L)\n",
    "    \n",
    "    real_nodes_true_mask = noised_dict['real_nodes_mask']\n",
    "    #place roll here later\n",
    "#     true = true.to('cpu').numpy()*10\n",
    "#     noise_xyz = noise_xyz.to('cpu').numpy()*10\n",
    "#     pred = pred.detach().to('cpu').numpy()*10\n",
    "    \n",
    "    \n",
    "    return true, noise_xyz, pred , real_nodes_pred_mask, real_nodes_true_mask\n",
    "        \n",
    "def roll2_continous_true(real_mask_in):\n",
    "    \"\"\"Return roll amount to set zero on Nterminal residue for pdb file view\"\"\"\n",
    "\n",
    "    roll_con_out = []\n",
    "    for i,rmr in enumerate(real_mask_in):\n",
    "        ep_bool = (rmr^rmr.roll(-1) | rmr^rmr.roll(1)) & rmr\n",
    "        si = torch.arange(ep_bool.shape[0])[ep_bool]\n",
    "        #circular if start/end real nodes and we need to roll\n",
    "        if rmr[0] and rmr[-1]:\n",
    "            #roll last group across barrier\n",
    "            roll_con = -si[-1]\n",
    "        elif not rmr[0]: #move first group to front\n",
    "            roll_con = -si[0]\n",
    "        else:\n",
    "            roll_con=0\n",
    "\n",
    "        roll_con_out.append(roll_con)\n",
    "\n",
    "    return roll_con_out\n",
    "      \n",
    "def dump_tnp_null(true, noise, pred, t_val, e=0, numOut=1, real_mask=None, pred_mask=None, outdir='output/'):\n",
    "    \n",
    "    if numOut>true.shape[0]:\n",
    "        numOut = true.shape[0]\n",
    "    \n",
    "    tnk_dir = f'{outdir}/true_node_mask/'\n",
    "    pnk_dir = f'{outdir}/pred_node_mask/'\n",
    "    f_dir = f'{outdir}/full/'\n",
    "    \n",
    "    if not os.path.isdir(tnk_dir) and real_mask is not None:\n",
    "        os.makedirs(tnk_dir)\n",
    "    if not os.path.isdir(pnk_dir) and pred_mask is not None:\n",
    "        os.makedirs(pnk_dir)\n",
    "    if not os.path.isdir(f_dir) and real_mask is not None:\n",
    "        os.makedirs(f_dir)\n",
    "    \n",
    "    if real_mask is not None:\n",
    "        rc = roll2_continous_true(real_mask)\n",
    "        for x in range(numOut):\n",
    "            t_o = true[x].roll(int(rc[x]),dims=0).detach().to('cpu').numpy()*10\n",
    "            n_o = noise[x].roll(int(rc[x]),dims=0).detach().to('cpu').numpy()*10\n",
    "            p_o = pred[x].roll(int(rc[x]),dims=0).detach().to('cpu').numpy()*10\n",
    "            dump_coord_pdb(t_o, fileOut=f'{f_dir}/true_{t_val[x]*100:.0f}_e{e}_{x}.pdb')\n",
    "            dump_coord_pdb(n_o, fileOut=f'{f_dir}/noise_{t_val[x]*100:.0f}_e{e}_{x}.pdb')\n",
    "            dump_coord_pdb(p_o, fileOut=f'{f_dir}/pred_{t_val[x]*100:.0f}_e{e}_{x}.pdb')\n",
    "        \n",
    "    if pred_mask is not None:\n",
    "        rc = roll2_continous_true(pred_mask)\n",
    "        for x,c in enumerate(np.arange(numOut)):\n",
    "            t_o = true[x].roll(int(rc[x]),dims=0).detach().to('cpu').numpy()*10\n",
    "            n_o = noise[x].roll(int(rc[x]),dims=0).detach().to('cpu').numpy()*10\n",
    "            p_o = pred[x].roll(int(rc[x]),dims=0).detach().to('cpu').numpy()*10\n",
    "            pm = pred_mask[x].roll(int(rc[x]),dims=0)\n",
    "            dump_coord_pdb(t_o[pm], fileOut=f'{pnk_dir}/true_{t_val[x]*100:.0f}_e{e}_{x}.pdb')\n",
    "            dump_coord_pdb(n_o[pm], fileOut=f'{pnk_dir}/noise_{t_val[x]*100:.0f}_e{e}_{x}.pdb')\n",
    "            dump_coord_pdb(p_o[pm], fileOut=f'{pnk_dir}/pred_{t_val[x]*100:.0f}_e{e}_{x}.pdb')\n",
    "            \n",
    "    if real_mask is not None:\n",
    "        rc = roll2_continous_true(real_mask)\n",
    "        for x,c in enumerate(np.arange(numOut)):\n",
    "            t_o = true[x].roll(int(rc[x]),dims=0).detach().to('cpu').numpy()*10\n",
    "            n_o = noise[x].roll(int(rc[x]),dims=0).detach().to('cpu').numpy()*10\n",
    "            p_o = pred[x].roll(int(rc[x]),dims=0).detach().to('cpu').numpy()*10\n",
    "            rm = real_mask[x].roll(int(rc[x]),dims=0)\n",
    "            dump_coord_pdb(t_o[rm], fileOut=f'{pnk_dir}/true_{t_val[x]*100:.0f}_e{e}_{x}.pdb')\n",
    "            dump_coord_pdb(n_o[rm], fileOut=f'{pnk_dir}/noise_{t_val[x]*100:.0f}_e{e}_{x}.pdb')\n",
    "            dump_coord_pdb(p_o[rm], fileOut=f'{pnk_dir}/pred_{t_val[x]*100:.0f}_e{e}_{x}.pdb')\n",
    "            \n",
    "#     if real_mask is not None:\n",
    "#         rc = roll2_continous_true(real_mask)\n",
    "#         for x in range(numOut):\n",
    "#             dump_coord_pdb(true[x][real_mask[x]], fileOut=f'{tnk_dir}/true_{t_val[x]*100:.0f}_e{e}_{x}.pdb')\n",
    "#             dump_coord_pdb(noise[x][real_mask[x]], fileOut=f'{tnk_dir}/noise_{t_val[x]*100:.0f}_e{e}_{x}.pdb')\n",
    "#             dump_coord_pdb(pred[x][real_mask[x]], fileOut=f'{tnk_dir}/pred_{t_val[x]*100:.0f}_e{e}_{x}.pdb')\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 277,
   "id": "d7e3e99d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_pV_to_points(dict_in,device='cuda'):\n",
    "    \n",
    "    CA_fp  = dict_in['bb_firstp']['CA'].to(device)\n",
    "    NC_fp = CA_fp + dict_in['bb_firstp']['N_CA'].to(device)\n",
    "    CC_fp = CA_fp +dict_in['bb_firstp']['C_CA'].to(device)\n",
    "    fp =  torch.cat((NC_fp,CA_fp,CC_fp),dim=2).reshape(B,1,3,3)\n",
    "    \n",
    "    CA_lp  = dict_in['bb_lastp']['CA'].to(device)\n",
    "    NC_lp = CA_lp + dict_in['bb_lastp']['N_CA'].to(device)\n",
    "    CC_lp = CA_lp + dict_in['bb_lastp']['C_CA'].to(device)\n",
    "    lp =  torch.cat((NC_lp,CA_lp,CC_lp),dim=2).reshape(B,1,3,3)\n",
    "    \n",
    "    return fp, lp\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 278,
   "id": "7eeb65f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "def model_step_null(noised_dict, batched_t, graph_maker, graph_unet, train=True):\n",
    "    #prep coordinates for output display from and comparison via FAPE\n",
    "    \n",
    "    CA_t  = noised_dict['bb_shifted']['CA'].reshape(B, L, 3).to(device)\n",
    "    NC_t = CA_t + noised_dict['bb_shifted']['N_CA'].reshape(B, L, 3).to(device)#not mult by bond distance, seems to help?\n",
    "    CC_t = CA_t + noised_dict['bb_shifted']['C_CA'].reshape(B, L, 3).to(device)#not mult \n",
    "    true =  torch.cat((NC_t,CA_t,CC_t),dim=2).reshape(B,L,3,3)\n",
    "\n",
    "    CA_n  = noised_dict['bb_noised']['CA'].reshape(B, L, 3).to(device)\n",
    "    NC_n = CA_n + noised_dict['bb_noised']['N_CA'].reshape(B, L, 3).to(device)\n",
    "    CC_n = CA_n + noised_dict['bb_noised']['C_CA'].reshape(B, L, 3).to(device)\n",
    "    noise_xyz =  torch.cat((NC_n,CA_n,CC_n),dim=2).reshape(B,L,3,3)\n",
    "\n",
    "    #prepare graphs\n",
    "    feat_dict = graph_maker.prep_for_network(noised_dict, cuda=True)\n",
    "    out =graph_unet(feat_dict,batched_t)\n",
    "    \n",
    "    \n",
    "    #FAPE Loss for the prediction\n",
    "    CA_p = out['1'][:,0,:].reshape(B, L, 3)+CA_n #translation of Calpha\n",
    "    Qs = out['1'][:,1,:] # rotation , convert from x,y,z (Quat) to rotate input vectors\n",
    "    Qs = Qs.unsqueeze(1).repeat((1,2,1))\n",
    "    Qs = torch.cat((torch.ones((B*L,2,1),device=Qs.device),Qs),dim=-1).reshape(B,L,2,4)\n",
    "    Qs = normQ(Qs)\n",
    "    Rs = Qs2Rs(Qs)\n",
    "    N_C_to_Rot = torch.cat((noised_dict['bb_noised']['N_CA'].reshape(B, L, 3).to(device),\n",
    "                            noised_dict['bb_noised']['C_CA'].reshape(B, L, 3).to(device)),dim=2).reshape(B,L,2,1,3)\n",
    "    rot_vecs = einsum('bnkij,bnkhj->bnki',Rs, N_C_to_Rot)\n",
    "    NC_p = CA_p + rot_vecs[:,:,0,:]*N_CA_dist #comparable but seems better not have it for true, but have it for pred\n",
    "    CC_p = CA_p + rot_vecs[:,:,1,:]*C_CA_dist #maybe this helep prevent \n",
    "\n",
    "    pred = torch.cat((NC_p,CA_p,CC_p),dim=2).reshape(B,L,3,3)\n",
    "    \n",
    "    #divide loss by real and null nodes\n",
    "    \n",
    "    fp, lp  = convert_pV_to_points(noised_dict)\n",
    "\n",
    "    real_mask = noised_dict['real_nodes_mask'].to('cuda')\n",
    "    score_scales = noised_dict['score_scales'].to('cuda')\n",
    "\n",
    "    lr, lr_d = FAPE_loss_real(pred, true, score_scales, real_mask,  d_clamp=10.0, d_clamp_inter=30.0,\n",
    "                   A=10.0, gamma=score_weights['3D_real'], eps=1e-6)\n",
    "    ln, ln_d = FAPE_loss_null(pred, fp, lp, real_mask, true, score_scales,  d_clamp=10.0,\n",
    "                       d_clamp_inter=30.0, A=10.0, gamma=score_weights['3D_null'], eps=1e-6)\n",
    "    \n",
    "    structure_loss = lr*score_weights['3D_real']+ln*score_weights['3D_null']\n",
    "    \n",
    "    #score for node feats determining whether node is real or fake\n",
    "    nf_pred = out['0']\n",
    "\n",
    "    nf_feat_dim = noised_dict['real_nodes_noise'].shape[-1]\n",
    "    nf_true = torch.ones(noised_dict['real_nodes_mask'].shape+(nf_feat_dim,) + (1,),\n",
    "                         dtype=torch.float,device=device)\n",
    "\n",
    "    nf_real_mask_mult = real_mask.unsqueeze(-1).unsqueeze(-1).to(device)\n",
    "    nf_true = nf_true*nf_real_mask_mult\n",
    "\n",
    "    nf_pred = nf_pred.reshape(B,-1,nf_feat_dim)\n",
    "    pred_nf_loss = torch.sum(torch.abs(nf_true.squeeze()-nf_pred),dim=-1) #absolute value loss\n",
    "    pred_nf_loss = pred_nf_loss.to(device)\n",
    "    \n",
    "    ss_scales = to_cuda(noised_dict['score_scales'])[:,None,None]\n",
    "    pnfloss = (torch.sum((pred_nf_loss*ss_scales/L)))*score_weights['nf_real']\n",
    "    \n",
    "    final_loss = structure_loss + pnfloss\n",
    "    \n",
    "    \n",
    "    return final_loss, pnfloss.detach().cpu(), structure_loss.detach().cpu()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c9e308d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 279,
   "id": "97322803",
   "metadata": {},
   "outputs": [],
   "source": [
    "device='cuda'\n",
    "\n",
    "B = 2\n",
    "L=128\n",
    "limit = 1028\n",
    "prot_trainData = Data_Graph.ProteinBB_Dataset(coords_tog[:limit], n_nodes=L,\n",
    "              n_atoms=5, coord_div=10, cast_type=torch.float32)\n",
    "train_dL = DataLoader(prot_trainData, batch_size=B, shuffle=True, drop_last=True)\n",
    "stride=4\n",
    "mkg = Make_nullKNN_MP_Graphs(KNN=30, mp_stride=stride, n_nodes=L)\n",
    "\n",
    "score_weights = {}\n",
    "score_weights['nf_real'] = torch.tensor(0,device=device)\n",
    "score_weights['3D_real'] = torch.tensor(1.0,device=device)\n",
    "score_weights['3D_null'] = torch.tensor(1.0,device=device)\n",
    "\n",
    "config_path='data_rigid_diffuser/base.yaml'\n",
    "fnd = FrameDiffNoise(config_path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 280,
   "id": "77cce375",
   "metadata": {},
   "outputs": [],
   "source": [
    "gunn= GraphUNet_Null(fiber_start = Fiber({0:17, 1:2}),\n",
    "                     fiber_out = Fiber({0:5,1:2}),\n",
    "                      k=8,\n",
    "                      batch_size = B,\n",
    "                      stride=stride,\n",
    "                       max_degree=3,\n",
    "                       channels=32,\n",
    "                      num_heads = 8,\n",
    "                      channels_div=4,\n",
    "                      num_layers = 1,\n",
    "                     num_layers_ca = 2,\n",
    "                     edge_feature_dim=1,\n",
    "                     latent_pool_type = 'avg',\n",
    "                     t_size = 12,\n",
    "                    zero_lin=True,\n",
    "                   use_tdeg1 = False,\n",
    "                 cuda=True).to('cuda')\n",
    "\n",
    "opti = torch.optim.Adam(gunn.parameters(), lr=0.001, weight_decay=5e-7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 449,
   "id": "df44e18d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def FAPE_loss(pred, true, score_scales,  d_clamp=10.0, d_clamp_inter=30.0, A=10.0, gamma=1.0, eps=1e-6):\n",
    "    '''\n",
    "    Calculate Backbone FAPE loss from RosettaTTAFold\n",
    "    https://github.com/uw-ipd/RoseTTAFold2/blob/main/network/loss.py\n",
    "    Input:\n",
    "        - pred: predicted coordinates (I, B, L, n_atom, 3)\n",
    "        - true: true coordinates (B, L, n_atom, 3)\n",
    "    Output: str loss\n",
    "    '''\n",
    "    I = pred.shape[0]\n",
    "    true = true.unsqueeze(0)\n",
    "    t_tilde_ij = get_t(true[:,:,:,0], true[:,:,:,1], true[:,:,:,2])\n",
    "    t_ij = get_t(pred[:,:,:,0], pred[:,:,:,1], pred[:,:,:,2])\n",
    "\n",
    "    difference = torch.sqrt(torch.square(t_tilde_ij-t_ij).sum(dim=-1) + eps)\n",
    "    eij_label = difference[-1].clone().detach()\n",
    "\n",
    "    clamp = torch.zeros_like(difference)\n",
    "\n",
    "    # intra vs inter#me coded\n",
    "    clamp[:,True] = d_clamp\n",
    "\n",
    "    difference = torch.clamp(difference, max=clamp)\n",
    "    loss = difference / A # (I, B, L, L)\n",
    "    # calculate masked loss (ignore missing regions when calculate loss)\n",
    "    loss = (loss[:,True]).sum(dim=-1) / (torch.ones_like(loss).sum()+eps) # (I)\n",
    "    \n",
    "    # weighting loss\n",
    "#     w_loss = torch.pow(torch.full((I,), gamma, device=pred.device), torch.arange(I, device=pred.device))\n",
    "#     w_loss = torch.flip(w_loss, (0,))\n",
    "#     w_loss = w_loss / w_loss.sum()\n",
    "    w_loss = score_scales[None,None,:,None]\n",
    "\n",
    "    tot_loss = (w_loss * loss).sum()\n",
    "    \n",
    "    return tot_loss, loss.detach()\n",
    "def FAPE_loss_real(pred, true, score_scales, real_mask, \n",
    "                   d_clamp=10.0, d_clamp_inter=30.0, A=10.0, gamma=1.0, eps=1e-6):\n",
    "    '''\n",
    "    Calculate Backbone FAPE loss from RosettaTTAFold\n",
    "    https://github.com/uw-ipd/RoseTTAFold2/blob/main/network/loss.py\n",
    "    Input:\n",
    "        - pred: predicted coordinates (I, B, L, n_atom, 3)\n",
    "        - true: true coordinates (B, L, n_atom, 3)\n",
    "    Output: str loss\n",
    "    '''\n",
    "    batch = true.shape[0]\n",
    "    length = true.shape[1]\n",
    "    pred = pred.unsqueeze(0) #maybe swap back for consistenccy\n",
    "    true = true.unsqueeze(0)\n",
    "    \n",
    "    t_tilde_ij = get_t(true[:,:,:,0], true[:,:,:,1], true[:,:,:,2])\n",
    "    t_ij = get_t(pred[:,:,:,0], pred[:,:,:,1], pred[:,:,:,2])\n",
    "    \n",
    "    difference = torch.sqrt(torch.square(t_tilde_ij-t_ij).sum(dim=-1) + eps)\n",
    "    clamp = torch.zeros_like(difference)\n",
    "    # intra vs inter#me coded\n",
    "    clamp[:,True] = torch.tensor(d_clamp)\n",
    "    difference = torch.clamp(difference, max=clamp)\n",
    "    loss = difference / A # (I, B, L, L)\n",
    "\n",
    "    # n points, becomes nxn comparisons for FAPE LOSS, need to mask both dimensions\n",
    "    rm_e = real_mask.repeat((1,length)).reshape(1,batch,length,length)\n",
    "    rm_et =  torch.transpose(rm_e,2,3)\n",
    "\n",
    "    loss_norm_masked = (rm_e*loss*rm_et).sum(dim=(2,3))/((rm_e*rm_et).sum(dim=(2,3)))\n",
    "    w_loss = score_scales[None,:]\n",
    "\n",
    "    tot_loss = (w_loss * loss_norm_masked).sum()\n",
    "    \n",
    "    return tot_loss, loss.detach()\n",
    "\n",
    "def FAPE_loss_null(pred, first_point, last_point, real_mask, score_scales,  d_clamp=10.0,\n",
    "                   d_clamp_inter=30.0, A=10.0, gamma=0.1, eps=1e-6):\n",
    "    '''\n",
    "    Calculate Backbone FAPE loss from RosettaTTAFold\n",
    "    https://github.com/uw-ipd/RoseTTAFold2/blob/main/network/loss.py\n",
    "    Input:\n",
    "        - pred: predicted coordinates (I, B, L, n_atom, 3)\n",
    "        - first_point: true coordinate (B, 1, n_atom, 3) N-terminal location\n",
    "        - last_point: true coordinates (B, 1, n_atom, 3) C-terminal location\n",
    "        chooses lowest loss of null to c-terminal/ n-terminal since its indeterminant\n",
    "        gamma set to overweight weight of null\n",
    "    Output: str loss\n",
    "    \n",
    "    \n",
    "    '''\n",
    "    first_point = first_point.unsqueeze(0)\n",
    "    last_point = last_point.unsqueeze(0)\n",
    "\n",
    "    pred = pred.unsqueeze(0) #maybe swap back for consistenccy\n",
    "    true = torch.ones_like(pred)\n",
    "    null_mask = (~real_mask).unsqueeze(0) \n",
    "\n",
    "    #add first and last point to characterize FAPE loss to the closest proper null node (endpoints)\n",
    "    flp_pred = torch.concat((first_point,last_point,pred),2)\n",
    "    flp_true = torch.concat((first_point,last_point,true),2)\n",
    "\n",
    "    t_tilde_ij = get_t(flp_true[:,:,:,0], flp_true[:,:,:,1], flp_true[:,:,:,2])\n",
    "    t_ij = get_t(flp_pred[:,:,:,0], flp_pred[:,:,:,1], flp_pred[:,:,:,2])\n",
    "\n",
    "    difference = torch.sqrt(torch.square(t_tilde_ij-t_ij).sum(dim=-1) + eps)\n",
    "    clamp = torch.zeros_like(difference)\n",
    "    \n",
    "    # intra vs inter #multimer monomer i think, #coding out\n",
    "    clamp[:,True] = torch.tensor(d_clamp)\n",
    "    difference = torch.clamp(difference, max=clamp)\n",
    "    \n",
    "    #null nodes, least difference to just two points\n",
    "    #reduces shape by last dimension\n",
    "    difference_fp = difference[:,:,2:,0]\n",
    "    difference_lp = difference[:,:,2:,1]\n",
    "    nearest_endpoint = difference_lp.clone()\n",
    "    nearest_endpoint[difference_fp<difference_lp] = difference_fp[difference_fp<difference_lp]\n",
    "    \n",
    "    loss = nearest_endpoint / A # (I, B, L)\n",
    "    (null_mask*loss).sum(dim=(2))/((null_mask).sum(dim=(2)))\n",
    "\n",
    "    loss_norm_masked= (null_mask*loss).sum(dim=(2))/((null_mask).sum(dim=(2)))\n",
    "    \n",
    "    w_loss = score_scales[None,:]\n",
    "    tot_loss = (w_loss * loss_norm_masked).sum()\n",
    "    \n",
    "    return tot_loss, loss.detach()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 433,
   "id": "226a8656",
   "metadata": {},
   "outputs": [],
   "source": [
    "testiter = iter(train_dL)\n",
    "bb_dict = next(testiter)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 460,
   "id": "7f850dea",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0.0179)\n"
     ]
    }
   ],
   "source": [
    "B=2\n",
    "L=128\n",
    "t=0.0000001\n",
    "t_cpu = np.ones((B,))*t\n",
    "noised_dict = fnd.forward(bb_dict,t_vec=t_cpu)\n",
    "batched_t = to_cuda(noised_dict['t_vec'])\n",
    "\n",
    "CA_t  = noised_dict['bb_shifted']['CA'].reshape(B, L, 3)\n",
    "NC_t = CA_t + noised_dict['bb_shifted']['N_CA'].reshape(B, L, 3)#not mult by bond distance, seems to help?\n",
    "CC_t = CA_t + noised_dict['bb_shifted']['C_CA'].reshape(B, L, 3)#not mult \n",
    "true_save =  torch.cat((NC_t,CA_t,CC_t),dim=2).reshape(B,L,3,3)\n",
    "\n",
    "CA_n  = noised_dict['bb_noised']['CA'].reshape(B, L, 3)\n",
    "NC_n = CA_n + noised_dict['bb_noised']['N_CA'].reshape(B, L, 3)\n",
    "CC_n = CA_n + noised_dict['bb_noised']['C_CA'].reshape(B, L, 3)\n",
    "noise_xyz_save =  torch.cat((NC_n,CA_n,CC_n),dim=2).reshape(B,L,3,3)\n",
    "\n",
    "score_scales = torch.ones_like(noised_dict['score_scales'])\n",
    "real_mask_save =  noised_dict['real_nodes_mask']\n",
    "\n",
    "fp_save, lp_save  = convert_pV_to_points(noised_dict,device='cpu')\n",
    "\n",
    "n=0\n",
    "ld, ln_d = FAPE_loss(noise_xyz_save[n][real_mask_save[n]].unsqueeze(0).unsqueeze(0),\n",
    "                     true_save[n][real_mask_save[n]].unsqueeze(0),\n",
    "                     score_scales[0].unsqueeze(0),  d_clamp=10.0, d_clamp_inter=30.0, A=10.0, gamma=1.0, eps=1e-6)\n",
    "print(ld)\n",
    "\n",
    "ld, ln_d = FAPE_loss_null(noise_xyz_save, fp_save, lp_save, real_mask_save,score_scales,  d_clamp=10.0,\n",
    "                   d_clamp_inter=30.0, A=10.0, gamma=0.1, eps=1e-6)\n",
    "# ld, ln_d = FAPE_loss(noise_xyz_save.unsqueeze(0), true_save, score_scales,  d_clamp=10.0, \n",
    "#                      d_clamp_inter=30.0, A=10.0, gamma=1.0, eps=1e-6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 464,
   "id": "43b754cf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 1, 128, 128])\n",
      "tensor([[75.5072]])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor([[0.0179]])"
      ]
     },
     "execution_count": 464,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "d_clamp=10.0,\n",
    "d_clamp_inter=30.0\n",
    "A=10.0\n",
    "gamma=0.1\n",
    "eps=1e-6\n",
    "\n",
    "pred = noise_xyz_save.unsqueeze(0) #maybe swap back for consistenccy\n",
    "true = true_save.unsqueeze(0)\n",
    "real_mask = real_mask_save[0].unsqueeze(0)\n",
    "    \n",
    "t_tilde_ij = get_t(true[:,:,:,0], true[:,:,:,1], true[:,:,:,2])\n",
    "t_ij = get_t(pred[:,:,:,0], pred[:,:,:,1], pred[:,:,:,2])\n",
    "    \n",
    "difference = torch.sqrt(torch.square(t_tilde_ij-t_ij).sum(dim=-1) + eps)\n",
    "clamp = torch.zeros_like(difference)\n",
    "# intra vs inter#me coded\n",
    "clamp[:,True] = torch.tensor(d_clamp)\n",
    "difference = torch.clamp(difference, max=clamp)\n",
    "loss = difference / A # (I, B, L, L)\n",
    "\n",
    "loss = loss[:,0,...].unsqueeze(0)\n",
    "\n",
    "rm_e = real_mask.repeat((1,L)).reshape(1,1,L,L)\n",
    "rm_et =  torch.transpose(rm_e,2,3)\n",
    "print(rm_et.shape)\n",
    "print((rm_e*loss*rm_et).sum(dim=(2,3)))\n",
    "(rm_e*loss*rm_et).sum(dim=(2,3))/((rm_e*rm_et).sum(dim=(2,3)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 437,
   "id": "fe525aef",
   "metadata": {},
   "outputs": [],
   "source": [
    "n=0\n",
    "ld, ln_d =  FAPE_loss_real(noise_xyz_save[n].unsqueeze(0),\n",
    "                     true_save[n].unsqueeze(0),\n",
    "                     score_scales[0].unsqueeze(0), \n",
    "                            real_mask[0].unsqueeze(0),\n",
    "                           d_clamp=10.0, d_clamp_inter=30.0, A=10.0, gamma=1.0, eps=1e-6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 438,
   "id": "40bdb673",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 2, 1, 3, 3])\n",
      "torch.Size([1, 2, 128, 3, 3])\n",
      "diff torch.Size([1, 2, 130, 130])\n",
      "torch.Size([1, 2, 130, 130])\n",
      "torch.Size([1, 2, 128])\n",
      "torch.Size([1, 2, 128])\n",
      "tensor(1.9719)\n",
      "torch.Size([1, 2, 128])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor([[0.0001, 0.0001]])"
      ]
     },
     "execution_count": 438,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "d_clamp=10.0,\n",
    "d_clamp_inter=30.0\n",
    "A=10.0\n",
    "gamma=0.1\n",
    "eps=1e-6\n",
    "\n",
    "first_point = fp_save.clone().unsqueeze(0)\n",
    "last_point = lp_save.clone().unsqueeze(0)\n",
    "#first_point = lp_save.clone().unsqueeze(0)\n",
    "\n",
    "pred = noise_xyz_save.unsqueeze(0) #maybe swap back for consistenccy\n",
    "true = true_save.unsqueeze(0)\n",
    "null_mask = ~real_mask_save.unsqueeze(0) \n",
    "\n",
    "#fp = lp_save.repeat((1,L,1,1)).unsqueeze(0)\n",
    "print(first_point.shape)\n",
    "print(pred.shape)\n",
    "\n",
    "#add first and last point to characterize FAPE loss to the closest proper null node (endpoints)\n",
    "flp_pred = torch.concat((first_point,last_point,pred),2)\n",
    "flp_true = torch.concat((first_point,last_point,true),2)\n",
    "\n",
    "\n",
    "#this doesn't work since all points are the same\n",
    "t_tilde_ij = get_t(flp_true[:,:,:,0], flp_true[:,:,:,1], flp_true[:,:,:,2])\n",
    "t_ij = get_t(flp_pred[:,:,:,0], flp_pred[:,:,:,1], flp_pred[:,:,:,2])\n",
    "\n",
    "difference = torch.sqrt(torch.square(t_tilde_ij-t_ij).sum(dim=-1) + eps)\n",
    "\n",
    "print('diff',difference.shape)\n",
    "clamp = torch.zeros_like(difference)\n",
    "# intra vs inter#me coded\n",
    "clamp[:,True] = torch.tensor(d_clamp)\n",
    "difference = torch.clamp(difference, max=clamp)\n",
    "print(difference.shape)\n",
    "#null nodes\n",
    "difference_fp = difference[:,:,2:,0]\n",
    "difference_lp = difference[:,:,2:,1]\n",
    "\n",
    "difference_fp\n",
    "print(difference_lp.shape)\n",
    "nearest_endpoint = difference_lp.clone()\n",
    "nearest_endpoint[difference_fp<difference_lp] = difference_fp[difference_fp<difference_lp]\n",
    "print(nearest_endpoint.shape)\n",
    "loss = nearest_endpoint / A # (I, B, L, L)\n",
    "print(loss.sum())\n",
    "print(loss.shape)\n",
    "#nm_et =  torch.transpose(nm_e,1,2)\n",
    "(null_mask*loss).sum(dim=(2))/((null_mask).sum(dim=(2)))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30925e9f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 470,
   "id": "6f483789",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0.0148) FAPE_Regular_ALL\n",
      "tensor(0.0148) FAPE_REAL\n",
      "tensor(0.0002) FAPE_null\n"
     ]
    }
   ],
   "source": [
    "check(bb_dict,t=0.0000001, jp_fape=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 471,
   "id": "08c498b9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0.0220) FAPE_Regular_ALL\n",
      "tensor(0.0220) FAPE_REAL\n",
      "tensor(0.0148) FAPE_null\n"
     ]
    }
   ],
   "source": [
    "check(bb_dict,t=0.01, jp_fape=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 472,
   "id": "638b98f6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0.0548) FAPE_Regular_ALL\n",
      "tensor(0.0548) FAPE_REAL\n",
      "tensor(0.0544) FAPE_null\n"
     ]
    }
   ],
   "source": [
    "check(bb_dict,t=0.05, jp_fape=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 473,
   "id": "056e5f38",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0.0927) FAPE_Regular_ALL\n",
      "tensor(0.0927) FAPE_REAL\n",
      "tensor(0.1014) FAPE_null\n"
     ]
    }
   ],
   "source": [
    "check(bb_dict,t=0.1, jp_fape=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 474,
   "id": "33ece146",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0.2540) FAPE_Regular_ALL\n",
      "tensor(0.2540) FAPE_REAL\n",
      "tensor(0.3128) FAPE_null\n"
     ]
    }
   ],
   "source": [
    "check(bb_dict,t=0.5, jp_fape=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 475,
   "id": "9e879adc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0.2560) FAPE_Regular_ALL\n",
      "tensor(0.2560) FAPE_REAL\n",
      "tensor(0.3526) FAPE_null\n"
     ]
    }
   ],
   "source": [
    "check(bb_dict,t=1.0, jp_fape=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 469,
   "id": "06fde4fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def check(bb_dict, t=0.1,n=0, jp_fape=True):\n",
    "    \n",
    "    t_cpu = np.ones((B,))*t\n",
    "    noised_dict = fnd.forward(bb_dict,t_vec=t_cpu)\n",
    "    batched_t = to_cuda(noised_dict['t_vec'])\n",
    "\n",
    "    if not jp_fape:\n",
    "        rnm = noised_dict['real_nodes_mask'][n]\n",
    "        rr = roll2_continous_true(noised_dict['real_nodes_mask'])\n",
    "        real_indices = torch.arange(128).roll(int(rr[n]))\n",
    "        rnm = rnm.roll((int(rr[n])))\n",
    "        first_real_index = real_indices[rnm][0]\n",
    "        last_real_index = real_indices[rnm][-1]\n",
    "\n",
    "        print('first real index',first_real_index)\n",
    "        print('last_real_index',last_real_index)\n",
    "        print('real_indices',real_indices)\n",
    "\n",
    "        fpc1 = noised_dict['bb_firstp']['CA'][n]\n",
    "        fpc1t = noised_dict['bb_shifted']['CA'][n][first_real_index ]\n",
    "        print('fp_ca_recorded:   ',fpc1)\n",
    "        print('fp_cafpc1t_found: ',fpc1t )\n",
    "        print()\n",
    "        lpc1 = noised_dict['bb_lastp']['CA'][n]\n",
    "        lpc1t = noised_dict['bb_shifted']['CA'][n][last_real_index ]\n",
    "        print('lp_ca_recorded:   ',lpc1)\n",
    "        print('lp_cafpc1t_found: ',lpc1t )\n",
    "        print()\n",
    "        fpc1 = noised_dict['bb_firstp']['N_CA'][n]\n",
    "        fpc1t = noised_dict['bb_shifted']['N_CA'][first_real_index ]\n",
    "        print('fp_nca_recorded:   ',fpc1)\n",
    "        print('fpc1t_nca_found: ',fpc1t )\n",
    "\n",
    "        print()\n",
    "        lpc1 = noised_dict['bb_lastp']['N_CA'][n]\n",
    "        lpc1t = noised_dict['bb_shifted']['N_CA'][last_real_index ]\n",
    "        print('lp_nca_recorded:   ',lpc1)\n",
    "        print('lpc1t_nca_found: ',lpc1t )\n",
    "\n",
    "        fpc1 = noised_dict['bb_firstp']['C_CA'][n]\n",
    "        fpc1t = noised_dict['bb_shifted']['C_CA'][first_real_index ]\n",
    "        print('fp_nca_recorded:   ',fpc1)\n",
    "        print('fpc1t_nca_found: ',fpc1t )\n",
    "\n",
    "        print()\n",
    "        lpc1 = noised_dict['bb_lastp']['C_CA'][n]\n",
    "        lpc1t = noised_dict['bb_shifted']['C_CA'][last_real_index ]\n",
    "        print('lp_nca_recorded:   ',lpc1)\n",
    "        print('lpc1t_nca_found: ',lpc1t )\n",
    "    \n",
    "    CA_t  = noised_dict['bb_shifted']['CA'].reshape(B, L, 3)\n",
    "    NC_t = CA_t + noised_dict['bb_shifted']['N_CA'].reshape(B, L, 3)#not mult by bond distance, seems to help?\n",
    "    CC_t = CA_t + noised_dict['bb_shifted']['C_CA'].reshape(B, L, 3)#not mult \n",
    "    true =  torch.cat((NC_t,CA_t,CC_t),dim=2).reshape(B,L,3,3)\n",
    "\n",
    "    CA_n  = noised_dict['bb_noised']['CA'].reshape(B, L, 3)\n",
    "    NC_n = CA_n + noised_dict['bb_noised']['N_CA'].reshape(B, L, 3)\n",
    "    CC_n = CA_n + noised_dict['bb_noised']['C_CA'].reshape(B, L, 3)\n",
    "    noise_xyz =  torch.cat((NC_n,CA_n,CC_n),dim=2).reshape(B,L,3,3)\n",
    "    \n",
    "    fp_save, lp_save  = convert_pV_to_points(noised_dict,device='cpu')\n",
    "\n",
    "    score_scales = torch.ones_like(noised_dict['score_scales'])\n",
    "    real_mask =  noised_dict['real_nodes_mask']\n",
    "    ld, ln_d = FAPE_loss(noise_xyz.unsqueeze(0), true,score_scales,  d_clamp=10.0,\n",
    "                       d_clamp_inter=30.0, A=10.0, gamma=1.0, eps=1e-6)\n",
    "    print(ld,\"FAPE_Regular_ALL\")\n",
    "    \n",
    "    lr, ln_dr = FAPE_loss_real(noise_xyz, true, score_scales, real_mask, d_clamp=10.0,\n",
    "                   d_clamp_inter=30.0, A=10.0, gamma=1.0, eps=1e-6)\n",
    "    print(ld,\"FAPE_REAL\")\n",
    "    \n",
    "    pred, first_point, last_point, real_mask, score_scales\n",
    "    \n",
    "    ln, ln_dr = FAPE_loss_null(noise_xyz, fp_save, lp_save, real_mask, score_scales, d_clamp=10.0,\n",
    "                   d_clamp_inter=30.0, A=10.0, gamma=1.0, eps=1e-6)\n",
    "    print(ln,\"FAPE_null\")\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cbd494d3",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "se33",
   "language": "python",
   "name": "se33"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
