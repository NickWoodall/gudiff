{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "7acea87f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from gudiff_model import PDBDataSet_GraphCon\n",
    "from gudiff_model.Graph_UNet import GraphUNet\n",
    "from data_rigid_diffuser.diffuser import FrameDiffNoise\n",
    "from se3_transformer.model.fiber import Fiber\n",
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "076c447f",
   "metadata": {},
   "outputs": [],
   "source": [
    "conf = {'batch_size'  : 16,\n",
    "              'topk'  : 4,\n",
    "            'stride'  : 4,\n",
    "                'KNN' : 30,\n",
    "          'num_heads' : 8,\n",
    "           'channels' : 32,\n",
    "       'channels_div' : 4,\n",
    "        'nodefeats_0': 32,\n",
    "        'nodefeats_1':  6,\n",
    "         'num_layers' : 1,\n",
    "     'num_layers_ca'  : 2,\n",
    "   'edge_feature_dim' : 1,\n",
    "  'latent_pool_type'  : 'avg',\n",
    "            't_size'  : 12,\n",
    "             'max_t'  : 0.2,\n",
    "               'mult' : 2,\n",
    "           'zero_lin' : True,\n",
    "          'use_tdeg1' : True,\n",
    "                'cuda': True,\n",
    "      'learning rate' : 0.0005,\n",
    "       'weight_decay' :  5e-6,\n",
    "        'device'      : 'cuda',\n",
    "        'num_epoch'   : 100,\n",
    "        'log_freq'    : 1000,\n",
    "        'ckpt_freq'   : 10000,\n",
    "        'early_chkpt' : 2,\n",
    "        'coord_scale' : 10.0,\n",
    "        'dataset_max' : 5000,\n",
    "        'meta_data_path' : '/mnt/h/datasets/bCov_4H/metadata.csv',\n",
    "        'sample_mode' : 'single_length'}\n",
    "\n",
    "#check use_tdeg1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "ad33c215",
   "metadata": {},
   "outputs": [],
   "source": [
    "def optimizer_to(optim, device):\n",
    "    for param in optim.state.values():\n",
    "        # Not sure there are any global tensors in the state dict\n",
    "        if isinstance(param, torch.Tensor):\n",
    "            param.data = param.data.to(device)\n",
    "            if param._grad is not None:\n",
    "                param._grad.data = param._grad.data.to(device)\n",
    "        elif isinstance(param, dict):\n",
    "            for subparam in param.values():\n",
    "                if isinstance(subparam, torch.Tensor):\n",
    "                    subparam.data = subparam.data.to(device)\n",
    "                    if subparam._grad is not None:\n",
    "                        subparam._grad.data = subparam._grad.data.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "d5eb8587",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Experiment:\n",
    "\n",
    "    def __init__(self,\n",
    "                 conf=None,\n",
    "                 ckpt_model=None,\n",
    "                 cur_step=None,\n",
    "                 cur_epoch=None,\n",
    "                 name='gu_null',\n",
    "                 cast_type=torch.float32,\n",
    "                 ckpt_opt=None):\n",
    "        \"\"\"Initialize experiment.\n",
    "        Args:\n",
    "            exp_cfg: Experiment configuration.\n",
    "        \"\"\"\n",
    "#         with open(config_path, 'r') as file:\n",
    "#             config = yaml.safe_load(file)\n",
    "#         conf = Struct(config)\n",
    "        #figure out logging\n",
    "        logging.basicConfig(filename='test.log', level=logging.INFO)\n",
    "        self._log = logging.getLogger(__name__)\n",
    "        \n",
    "\n",
    "        self.name=name\n",
    "        self._conf = conf\n",
    "        \n",
    "        self.coord_scale = conf['coord_scale']\n",
    "        self.N_CA_dist = (Data_Graph.N_CA_dist/self.coord_scale).to('cuda')\n",
    "        self.C_CA_dist = (Data_Graph.C_CA_dist/self.coord_scale).to('cuda')\n",
    "        self.cast_type = cast_type\n",
    "        \n",
    "        self.num_epoch = conf['num_epoch']\n",
    "        self.log_freq = conf['log_freq']\n",
    "        self.ckpt_freq = conf['ckpt_freq']\n",
    "        self.early_ckpt = conf['early_chkpt']\n",
    "        \n",
    "        \n",
    "        self.meta_data_path = conf['/mnt/h/datasets/bCov_4H/metadata.csv']\n",
    "        self.sample_mode = conf['sample_mode']\n",
    "        self.B = conf['batch_size']\n",
    "        self.limit = conf['dataset_max']\n",
    "        \n",
    "        #graph properties\n",
    "        self.KNN = conf['KNN']\n",
    "        self.KNN_radius = conf['KNN_radius']\n",
    "        self.stride = conf['stride']\n",
    "        \n",
    "        #gudiff params\n",
    "        self.channels_start = conf['channels']\n",
    "        \n",
    "        \n",
    "        self._diffuser = FrameDiffNoise()\n",
    "        self._graphmaker =  PDBDataSet_GraphCon.Make_KNN_MP_Graphs(mp_stride = self.stride, \n",
    "                                                           coord_div = self.coord_scale, \n",
    "                                                           cast_type = self.cast_type, \n",
    "                                                           channels_start = self.channels_start,\n",
    "                                                           ndf1= conf['nodefeats_1'], \n",
    "                                                           ndf0= conf['nodefeats_0'],\n",
    "                                                           cuda=True)\n",
    "        #single_t dataset, for testing\n",
    "        # sd = smallPDBDataset(fdn , meta_data_path = '/mnt/h/datasets/bCov_4H/metadata.csv', \n",
    "        #                      filter_dict=False, maxlen=1000, input_t=0.05)\n",
    "        \n",
    "\n",
    "        \n",
    "        self._model = GraphUNet(fiber_start = Fiber({0:12, 1:2}),\n",
    "                                fiber_out = Fiber({1:2}),\n",
    "                                batch_size = self.B, \n",
    "                                num_layers_ca = conf['num_layers_ca'],\n",
    "                                k = conf['topk'],\n",
    "                                stride = conf['stride'],\n",
    "                                max_degree = 3,\n",
    "                                channels_div =  conf['channels_div'],\n",
    "                                num_heads = conf['num_heads'],\n",
    "                                num_layers = conf['num_layers'],\n",
    "                                edge_feature_dim = conf['edge_feature_dim'],\n",
    "                                latent_pool_type = conf['latent_pool_type'],\n",
    "                                t_size = conf['t_size'],\n",
    "                                zero_lin = conf['zero_lin'],\n",
    "                                use_tdeg1 = conf['use_tdeg1'],\n",
    "                                cuda = conf['cuda']).to('cuda')\n",
    "\n",
    "        \n",
    "\n",
    "        \n",
    "        num_parameters = sum(p.numel() for p in self._model.parameters())\n",
    "        self.num_parameters = num_parameters\n",
    "        self._log.info(f'Number of model parameters {num_parameters}')\n",
    "#         self._optimizer = EMA(0.980)\n",
    "#         for name, param in self._model.named_parameters():\n",
    "#             if param.requires_grad:\n",
    "#                 self._optimizer.register(name, param.data)\n",
    "\n",
    "        if ckpt_model is not None:\n",
    "            ckpt_model = {k.replace('module.', ''):v for k,v in ckpt_model.items()}\n",
    "            self._model.load_state_dict(ckpt_model, strict=True)\n",
    "        \n",
    "        \n",
    "        self._optimizer = torch.optim.Adam( self._model.parameters(),\n",
    "                                                       lr=conf['learning rate'],\n",
    "                                                       weight_decay=conf['weight_decay'])\n",
    "        if ckpt_opt is not None:\n",
    "            self._optimizer.load_state_dict(ckpt_opt)\n",
    "            optimizer_to(self._optimizer, self.device)\n",
    "        \n",
    "        \n",
    "        dt_string = datetime.now().strftime(\"%dD_%mM_%YY_%Hh_%Mm_%Ss\")\n",
    "        dt_string_short = datetime.now().strftime(\"%dD_%mM_%YY\")\n",
    "        self.ckpt_dir =  conf_check['ckpt_dir']\n",
    "        self.eval_dir = conf_check['eval_dir']\n",
    "        eval_name = f'{self.name}_{dt_string_short}'\n",
    "        if self.ckpt_dir is not None:\n",
    "            # Set-up checkpoint location\n",
    "            ckpt_dir = os.path.join(\n",
    "                 self.ckpt_dir,\n",
    "                 self.name,\n",
    "                 dt_string)\n",
    "            if not os.path.exists(ckpt_dir):\n",
    "                os.makedirs(ckpt_dir, exist_ok=True)\n",
    "            self.ckpt_dir = ckpt_dir\n",
    "            self._log.info(f'Checkpoints saved to: {ckpt_dir}')\n",
    "        else:  \n",
    "            self._log.info('Checkpoint not being saved.')\n",
    "            \n",
    "        if self.eval_dir is not None :\n",
    "            self.eval_dir = os.path.join(\n",
    "                self.eval_dir,\n",
    "                eval_name,\n",
    "                dt_string)\n",
    "            self.eval_dir = self.eval_dir\n",
    "            self._log.info(f'Evaluation saved to: {self.eval_dir}')\n",
    "        else:\n",
    "            self.eval_dir = os.devnull\n",
    "            self._log.info(f'Evaluation will not be saved.')\n",
    "    #         self._aux_data_history = deque(maxlen=100)\n",
    "    \n",
    "        if cur_epoch is None:\n",
    "            self.trained_epochs = 0\n",
    "        else:\n",
    "            self.trained_epochs = cur_epoch\n",
    "            \n",
    "        if cur_step is None:\n",
    "            self.trained_steps = 0\n",
    "        else:\n",
    "            self.trained_steps = cur_step\n",
    "            \n",
    "    @property\n",
    "    def diffuser(self):\n",
    "        return self._diffuser\n",
    "\n",
    "    @property\n",
    "    def model(self):\n",
    "        return self._model\n",
    "\n",
    "    @property\n",
    "    def conf(self):\n",
    "        return self._conf\n",
    "    \n",
    "    def create_dataset(self, fake_valid=True):\n",
    "        \n",
    "        \n",
    "        self.dataset = PDBDataSet_GraphCon.smallPDBDataset(self.fdn , meta_data_path = self.meta_data_path, \n",
    "                             filter_dict=False, maxlen=self.limit)\n",
    "        \n",
    "        self.train_sample = PDBDataSet_GraphCon.TrainSampler(self.B, self.dataset, sample_mode='single_length')\n",
    "        \n",
    "        train_dL = torch.utils.data.DataLoader(self.dataset, sampler=self.train_sample,\n",
    "                                                     batch_size=self.B, shuffle=False, collate_fn=None)\n",
    "        \n",
    "        if fake_valid:\n",
    "            valid_dL = train_dL\n",
    "        else:\n",
    "            valid_dL = train_dL\n",
    "            #not implemented yet\n",
    "        \n",
    "        return train_dL, valid_dL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa505c2d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
