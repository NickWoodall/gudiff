{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 120,
   "id": "a02a1c0f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 120,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "#clear memory better\n",
    "with torch.no_grad():\n",
    "    torch.cuda.empty_cache()\n",
    "import numpy as np\n",
    "import util.npose_util as nu\n",
    "import util.framediff_utils as du\n",
    "import os\n",
    "import pathlib\n",
    "import dgl\n",
    "import copy\n",
    "from dgl import backend as F\n",
    "import torch_geometric\n",
    "from torch.utils.data import random_split, DataLoader, Dataset\n",
    "from typing import Dict\n",
    "from torch import Tensor\n",
    "from dgl import DGLGraph\n",
    "from torch import nn\n",
    "from chemical import cos_ideal_NCAC #from RoseTTAFold2\n",
    "from torch import einsum\n",
    "import time\n",
    "import logging\n",
    "from collections import defaultdict\n",
    "torch.cuda.is_available()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "id": "936c747c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from gudiff_model.Graph_UNet_Null import  GraphUNet_Null\n",
    "from gudiff_model import Data_Graph\n",
    "from gudiff_model.Data_Graph_Null import build_npose_from_coords, dump_coord_pdb, define_graph_edges, make_pe_encoding\n",
    "from gudiff_model.Data_Graph_Null import  Make_nullKNN_MP_Graphs\n",
    "from data_rigid_diffuser.diffuser import FrameDiffNoise\n",
    "from se3_transformer.model.FAPE_Loss import FAPE_loss, Qs2Rs, normQ\n",
    "from se3_transformer.model.FAPE_Loss import FAPE_loss_null, FAPE_loss_real\n",
    "from se3_transformer.model.fiber import Fiber\n",
    "from se3_transformer.runtime.utils import str2bool, to_cuda"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3062c7e1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "id": "d298f50f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#indices for, unsure if needed\n",
    "CA = Data_Graph.CA\n",
    "N = Data_Graph.N\n",
    "C = Data_Graph.C\n",
    "\n",
    "# #find better way to incorporate coord_scale\n",
    "\n",
    "#needed\n",
    "N_CA_dist = (Data_Graph.N_CA_dist/10.).to('cuda')\n",
    "C_CA_dist = (Data_Graph.C_CA_dist/10.).to('cuda')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "id": "27011d76",
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import datetime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "id": "f3b7b32c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.utils.data as data_utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "id": "72ce141d",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Experiment:\n",
    "\n",
    "    def __init__(self,\n",
    "                 config_path= 'test.config',\n",
    "                 config_path_diffuser = 'data_rigid_diffuser/base.yaml',\n",
    "                 limit=5028,\n",
    "                 ckpt_model=None,\n",
    "                name='gu_null',\n",
    "                ckpt_opt=None):\n",
    "        \"\"\"Initialize experiment.\n",
    "        Args:\n",
    "            exp_cfg: Experiment configuration.\n",
    "        \"\"\"\n",
    "#         with open(config_path, 'r') as file:\n",
    "#             config = yaml.safe_load(file)\n",
    "#         conf = Struct(config)\n",
    "        \n",
    "        logging.basicConfig(filename='test.log', level=logging.INFO)\n",
    "        self._log = logging.getLogger(__name__)\n",
    "        \n",
    "        \n",
    "        #indices for, unsure if needed\n",
    "        self.CA = Data_Graph.CA\n",
    "        self.N = Data_Graph.N\n",
    "        self.C = Data_Graph.C\n",
    "\n",
    "        self.name=name\n",
    "        \n",
    "        config_path='data_rigid_diffuser/base.yaml'\n",
    "        fnd = FrameDiffNoise(config_path)\n",
    "        \n",
    "        conf = {'batch_size'  : 8,\n",
    "                      'topk'  : 4,\n",
    "                    'stride'  : 4,\n",
    "                        'KNN' : 30,\n",
    "                  'num_heads' : 16,\n",
    "                   'channels' : 64,\n",
    "               'channels_div' : 8,\n",
    "                 'num_layers' : 1,\n",
    "             'num_layers_ca'  : 2,\n",
    "           'edge_feature_dim' : 1,\n",
    "          'latent_pool_type'  : 'avg',\n",
    "                    't_size'  : 12,\n",
    "                       'mult' : 2,\n",
    "                   'zero_lin' : True,\n",
    "                  'use_tdeg1' : False,\n",
    "                        'cuda': True,\n",
    "              'learning rate' : 0.005,\n",
    "               'weight_decay' : 0.000001,\n",
    "                'sc_nf_real'  : 0.2 ,\n",
    "                'sc_3D_real'  : 1.0 ,\n",
    "                'sc_3D_null'  : 1.0 ,\n",
    "                'device'      : 'cuda',\n",
    "                'num_epoch'   : 100,\n",
    "                'log_freq'    : 50,\n",
    "                'ckpt_freq'   : 1000,\n",
    "                'early_chkpt' : 10,\n",
    "                'coord_scale' : 10.0\n",
    "               }\n",
    "        \n",
    "        \n",
    "\n",
    "        \n",
    "        conf_check = {'ckpt_dir' : 'GUN_checkpoints/',\n",
    "                      'eval_dir' : 'Eval_Direc',\n",
    "                      'apa_path' : 'data_npose/h4_apa_coords.npz',\n",
    "                      'tog_path' : 'data_npose/h4_tog_coords.npz',\n",
    "                     }\n",
    "        self._conf = conf\n",
    "        \n",
    "\n",
    "        \n",
    "        self.device = conf['device']\n",
    "        self.paths_valid = conf_check['apa_path']\n",
    "        self.paths_train = conf_check['tog_path']\n",
    "        self.score_weights = {}\n",
    "        self.score_weights['nf_real'] = torch.tensor(float(conf['sc_nf_real']),device=self.device)\n",
    "        self.score_weights['3D_real'] = torch.tensor(float(conf['sc_3D_real']),device=self.device)\n",
    "        self.score_weights['3D_null'] = torch.tensor(float(conf['sc_3D_null']),device=self.device)\n",
    "\n",
    "        #needed\n",
    "        self.coord_scale = conf['coord_scale']\n",
    "        self.N_CA_dist = (Data_Graph.N_CA_dist/self.coord_scale).to('cuda')\n",
    "        self.C_CA_dist = (Data_Graph.C_CA_dist/self.coord_scale).to('cuda')\n",
    "        \n",
    "        self.num_epoch = conf['num_epoch']\n",
    "        self.log_freq = conf['log_freq']\n",
    "        self.ckpt_freq = conf['ckpt_freq']\n",
    "        self.early_ckpt = conf['early_chkpt']\n",
    "        \n",
    "        self.B = conf['batch_size']\n",
    "        self.L = 128\n",
    "        self.limit = limit\n",
    "        self.KNN = conf['KNN']\n",
    "        self.stride = conf['stride']\n",
    "        \n",
    "        \n",
    "        \n",
    "        self.fnd = FrameDiffNoise(config_path_diffuser)\n",
    "        self.mkg = Make_nullKNN_MP_Graphs(KNN = self.KNN, mp_stride = self.stride, n_nodes = self.L)\n",
    "        self._model = GraphUNet_Null(fiber_start = Fiber({0:17, 1:2}),\n",
    "                                     fiber_out = Fiber({0:5,1:2}),\n",
    "                                          k = conf['topk'],\n",
    "                                batch_size  = self.B,\n",
    "                                     stride = conf['stride'],\n",
    "                                 max_degree = 3,\n",
    "                                   channels = conf['channels'],\n",
    "                                  num_heads = conf['num_heads'],\n",
    "                               channels_div = conf['channels_div'],\n",
    "                                 num_layers = conf['num_layers'],\n",
    "                              num_layers_ca = conf['num_layers_ca'],\n",
    "                           edge_feature_dim = conf['edge_feature_dim'],\n",
    "                           latent_pool_type = conf['latent_pool_type'],\n",
    "                                     t_size = conf['t_size'],\n",
    "                                       mult = conf['mult'],\n",
    "                                   zero_lin = conf['zero_lin'],\n",
    "                                  use_tdeg1 = conf['use_tdeg1'],\n",
    "                                        cuda= conf['cuda'])\n",
    "        \n",
    "        \n",
    "        num_parameters = sum(p.numel() for p in self._model.parameters())\n",
    "        self.num_parameters = num_parameters\n",
    "        self._log.info(f'Number of model parameters {num_parameters}')\n",
    "#         self._optimizer = EMA(0.980)\n",
    "#         for name, param in self._model.named_parameters():\n",
    "#             if param.requires_grad:\n",
    "#                 self._optimizer.register(name, param.data)\n",
    "\n",
    "        if ckpt_model is not None:\n",
    "            ckpt_model = {k.replace('module.', ''):v for k,v in ckpt_model.items()}\n",
    "            self._model.load_state_dict(ckpt_model, strict=True)\n",
    "        \n",
    "        \n",
    "        self._optimizer = torch.optim.Adam( self._model.parameters(),\n",
    "                                                       lr=conf['learning rate'],\n",
    "                                                       weight_decay=conf['weight_decay'])\n",
    "        if ckpt_opt is not None:\n",
    "            self._optimizer.load_state_dict(ckpt_opt)\n",
    "        \n",
    "        \n",
    "        dt_string = datetime.now().strftime(\"%dD_%mM_%YY_%Hh_%Mm_%Ss\")\n",
    "        self.ckpt_dir =  conf_check['ckpt_dir']\n",
    "        self.eval_dir = conf_check['eval_dir']\n",
    "        if self.ckpt_dir is not None:\n",
    "            # Set-up checkpoint location\n",
    "            ckpt_dir = os.path.join(\n",
    "                 self.ckpt_dir,\n",
    "                 self.name,\n",
    "                 dt_string)\n",
    "            if not os.path.exists(ckpt_dir):\n",
    "                os.makedirs(ckpt_dir, exist_ok=True)\n",
    "            self.ckpt_dir = ckpt_dir\n",
    "            self._log.info(f'Checkpoints saved to: {ckpt_dir}')\n",
    "        else:  \n",
    "            self._log.info('Checkpoint not being saved.')\n",
    "            \n",
    "        if self.eval_dir is not None :\n",
    "            self.eval_dir = os.path.join(\n",
    "                self.eval_dir,\n",
    "                self.name,\n",
    "                dt_string)\n",
    "            self.eval_dir = self.eval_dir\n",
    "            self._log.info(f'Evaluation saved to: {self.eval_dir}')\n",
    "        else:\n",
    "            self.eval_dir = os.devnull\n",
    "            self._log.info(f'Evaluation will not be saved.')\n",
    "    #         self._aux_data_history = deque(maxlen=100)\n",
    "    \n",
    "        self.trained_epochs = 0\n",
    "        self.trained_steps = 0\n",
    "    \n",
    "    \n",
    "    @property\n",
    "    def diffuser(self):\n",
    "        return self._diffuser\n",
    "\n",
    "    @property\n",
    "    def model(self):\n",
    "        return self._model\n",
    "\n",
    "    @property\n",
    "    def conf(self):\n",
    "        return self._conf\n",
    "    \n",
    "    def create_dataset(self):\n",
    "        \n",
    "        \n",
    "        \n",
    "        #grab the first 3 atoms which are N,CA,C\n",
    "        rr = np.load(self.paths_train)\n",
    "        coords_train = [rr[f] for f in rr.files][0][:self.limit,:]\n",
    "        \n",
    "        rr = np.load(self.paths_valid)\n",
    "        coords_valid = [rr[f] for f in rr.files][0][:self.limit,:]\n",
    "        \n",
    "        self.B\n",
    "        \n",
    "        device='cuda'\n",
    "        \n",
    "        prot_trainData = Data_Graph.ProteinBB_Dataset(coords_train[:self.limit], n_nodes=self.L,\n",
    "                      n_atoms=5, coord_div=10, cast_type=torch.float32)\n",
    "        train_dL = DataLoader(prot_trainData, batch_size=self.B, shuffle=True, drop_last=True)\n",
    "        \n",
    "        prot_validData = Data_Graph.ProteinBB_Dataset(coords_valid[:self.limit], n_nodes=self.L,\n",
    "                      n_atoms=5, coord_div=10, cast_type=torch.float32)\n",
    "        valid_dL = DataLoader(prot_trainData, batch_size=self.B, shuffle=True, drop_last=True)\n",
    "        \n",
    "        return train_dL, valid_dL\n",
    "    \n",
    "    def start_training(self, return_logs=False):\n",
    "\n",
    "\n",
    "        self._model = self._model.to(self.device)\n",
    "        print(f\"Using device: {self.device}\")\n",
    "\n",
    "        self._model.train()\n",
    "        (train_loader, valid_loader) = self.create_dataset()\n",
    "\n",
    "        logs = []\n",
    "        print('number of epochs', self.num_epoch)\n",
    "        for epoch in range(self.trained_epochs, self.num_epoch):\n",
    "            self.trained_epochs = epoch\n",
    "            print('epoch', epoch)\n",
    "            epoch_log = self.train_epoch(\n",
    "                train_loader,\n",
    "                valid_loader,\n",
    "                return_logs=return_logs\n",
    "            )\n",
    "            if return_logs:\n",
    "                logs.append(epoch_log)\n",
    "\n",
    "        self._log.info('Done')\n",
    "        return logs\n",
    "    \n",
    "    \n",
    "    \n",
    "    def train_epoch(self, train_loader, valid_loader, return_logs=False):\n",
    "        \n",
    "        log_lossses = defaultdict(list)\n",
    "        \n",
    "        global_logs = []\n",
    "        \n",
    "        log_time = time.time()\n",
    "        step_time = time.time()\n",
    "        losskeeper = []\n",
    "        for train_feats in train_loader:\n",
    "            \n",
    "            #train_feats = tree.map_structure(lambda x: x.to(device), train_feats)\n",
    "            loss, aux_data = self.update_fn(train_feats)\n",
    "            losskeeper.append(float(loss.detach().cpu()))\n",
    "            \n",
    "            if return_logs:\n",
    "                global_logs.append(loss)\n",
    "            \n",
    "            for k,v in aux_data.items():\n",
    "                log_lossses[k].append(du.move_to_np(v))\n",
    "            \n",
    "            self.trained_steps += 1\n",
    "            \n",
    "            # Logging to terminal\n",
    "            if self.trained_steps == 1 or self.trained_steps % self.log_freq == 0:\n",
    "                elapsed_time = time.time() - log_time\n",
    "                log_time = time.time()\n",
    "                step_per_sec = self.log_freq / elapsed_time\n",
    "                \n",
    "                rolling_losses = tree.map_structure(np.mean, log_lossses)\n",
    "                loss_log = ' '.join([\n",
    "                    f'{k}={v[0]:.4f}'\n",
    "                    for k,v in rolling_losses.items() if 'batch' not in k\n",
    "                ])\n",
    "                \n",
    "                self._log.info(\n",
    "                    f'[{self.trained_steps}]: {loss_log}, steps/sec={step_per_sec:.5f}')\n",
    "                log_lossses = defaultdict(list)\n",
    "                \n",
    "                print(f'[{self.trained_steps}]: {loss_log}, steps/sec={step_per_sec:.5f}')\n",
    "                print(np.mean(losskeeper[-1000:]))\n",
    "\n",
    "            # Take checkpoint\n",
    "            \n",
    "            if self.ckpt_dir is not None and (\n",
    "                    (self.trained_steps % self.ckpt_freq) == 0\n",
    "                    or (self.early_ckpt and self.trained_steps == 2)\n",
    "                ):\n",
    "                ckpt_path = os.path.join(\n",
    "                    self.ckpt_dir, f'step_{self.trained_steps}.pth')\n",
    "                du.write_checkpoint(\n",
    "                    ckpt_path,\n",
    "                    copy.deepcopy(self.model.state_dict()),\n",
    "                    self._conf,\n",
    "                    copy.deepcopy(self._optimizer.state_dict()),\n",
    "                    self.trained_epochs,\n",
    "                    self.trained_steps,\n",
    "                    logger=self._log,\n",
    "                    use_torch=True\n",
    "                )\n",
    "                \n",
    "\n",
    "                # Run evaluation\n",
    "                self._log.info(f'Running evaluation of {ckpt_path}')\n",
    "                start_time = time.time()\n",
    "                self.eval_dir = 'output/'\n",
    "                eval_dir = os.path.join(\n",
    "                    self.eval_dir, f'step_{self.trained_steps}')\n",
    "                print(eval_dir)\n",
    "                os.makedirs(eval_dir, exist_ok=True)\n",
    "                #_\n",
    "                #figure out endpoints for this\n",
    "#                 ckpt_metrics = self.eval_fn(\n",
    "#                     eval_dir, valid_loader, device,\n",
    "#                     noise_scale=self.noise_scale\n",
    "#                 )\n",
    "                eval_time = time.time() - start_time\n",
    "                self._log.info(f'Finished evaluation in {eval_time:.2f}s')\n",
    "            else:\n",
    "                ckpt_metrics = None\n",
    "                eval_time = None\n",
    "\n",
    "\n",
    "            if torch.isnan(loss):                \n",
    "                raise Exception(f'NaN encountered')\n",
    "\n",
    "        if return_logs:\n",
    "            return global_logs\n",
    "\n",
    "\n",
    "    def update_fn(self, data):\n",
    "        \"\"\"Updates the state using some data and returns metrics.\"\"\"\n",
    "        self._optimizer.zero_grad()\n",
    "        loss, aux_data = self.loss_fn(data)\n",
    "        loss.backward()\n",
    "        self._optimizer.step()\n",
    "        return loss, aux_data\n",
    "    \n",
    "    def loss_fn(self, bb_dict, t_val=None):\n",
    "        \n",
    "        def convert_pV_to_points(dict_in, L, key_in='bb_firstp', return_indiv=False):\n",
    "            \"\"\"Concatenates to xyz from Calpha+atom vectors\"\"\"\n",
    "            CA_fp  = dict_in[key_in]['CA'].reshape(self.B, L, 3).to(self.device)\n",
    "            NC_fp = CA_fp + dict_in[key_in]['N_CA'].reshape(self.B, L, 3).to(self.device)\n",
    "            CC_fp = CA_fp + dict_in[key_in]['C_CA'].reshape(self.B, L, 3).to(self.device)\n",
    "            fp =  torch.cat((NC_fp,CA_fp,CC_fp),dim=2).reshape(self.B,L,3,3)\n",
    "            if return_indiv:\n",
    "                return fp, CA_fp, NC_fp, CC_fp\n",
    "            return fp\n",
    "        \n",
    "        if t_val is not None:\n",
    "            noised_dict = self.fnd.forward(bb_dict, t_vec=t_val)\n",
    "        else:\n",
    "            #generates with random t\n",
    "            noised_dict = self.fnd.forward(bb_dict)\n",
    "        \n",
    "        batched_t = noised_dict['t_vec'].to(self.device)\n",
    "        \n",
    "        #not converted to distance by multiplying by bond distance, seems to work better\n",
    "        true =  convert_pV_to_points(noised_dict, self.L, key_in='bb_shifted')\n",
    "        noise_xyz, CA_n, NC_n, CC_n =   convert_pV_to_points(noised_dict, self.L, key_in='bb_noised', return_indiv=True)\n",
    "                                                                                                            \n",
    "        #prepare graphs\n",
    "        feat_dict = self.mkg.prep_for_network(noised_dict, cuda=True)\n",
    "        out  = self._model(feat_dict,batched_t)\n",
    "                                                                    \n",
    "        #FAPE Loss for the prediction\n",
    "        CA_p = out['1'][:,0,:].reshape(self.B, self.L, 3) + CA_n #translation of Calpha\n",
    "        Qs = out['1'][:,1,:] # rotation , convert from x,y,z (Quat) to rotate input vectors\n",
    "        Qs = Qs.unsqueeze(1).repeat((1,2,1))\n",
    "        Qs = torch.cat((torch.ones((self.B*self.L,2,1), device=Qs.device),Qs),dim=-1).reshape(self.B, self.L, 2, 4)\n",
    "        Qs = normQ(Qs)\n",
    "        Rs = Qs2Rs(Qs)\n",
    "        N_C_to_Rot = torch.cat((noised_dict['bb_noised']['N_CA'].reshape(self.B, self.L, 3).to(self.device),\n",
    "                                noised_dict['bb_noised']['C_CA'].reshape(self.B, self.L, 3).to(self.device)),dim=2).reshape(self.B,self.L,2,1,3)\n",
    "        rot_vecs = einsum('bnkij,bnkhj->bnki',Rs, N_C_to_Rot)\n",
    "        NC_p = CA_p + rot_vecs[:,:,0,:]*self.N_CA_dist #comparable but seems better not have it for true, but have it for pred\n",
    "        CC_p = CA_p + rot_vecs[:,:,1,:]*self.C_CA_dist #maybe this helep prevent \n",
    "\n",
    "        pred = torch.cat((NC_p,CA_p,CC_p),dim=2).reshape(self.B,self.L,3,3)\n",
    "                                                                \n",
    "                                                                                                                     \n",
    "        fp = convert_pV_to_points(noised_dict, 1, key_in='bb_firstp')\n",
    "        lp = convert_pV_to_points(noised_dict,1,  key_in='bb_lastp')                                             \n",
    "        real_mask = noised_dict['real_nodes_mask'].to(self.device)\n",
    "        score_scales = noised_dict['score_scales'].to(self.device)\n",
    "\n",
    "        lr, lr_d = FAPE_loss_real(pred, true, score_scales, real_mask,  d_clamp=10.0, d_clamp_inter=30.0,\n",
    "                       A=10.0, gamma=1.0, eps=1e-6)\n",
    "\n",
    "        ln, ln_d = FAPE_loss_null(pred, fp, lp, real_mask, score_scales,  d_clamp=10.0,\n",
    "                           d_clamp_inter=30.0, A=10.0, gamma=1.0, eps=1e-6)\n",
    "        \n",
    "        ln = ln*self.score_weights['3D_null']\n",
    "        lr = lr*self.score_weights['3D_real']\n",
    "\n",
    "        structure_loss = lr + ln\n",
    "\n",
    "        #score for node feats determining whether node is real or fake\n",
    "        nf_pred = out['0']\n",
    "\n",
    "        nf_feat_dim = noised_dict['real_nodes_noise'].shape[-1]\n",
    "        nf_true = torch.ones(noised_dict['real_nodes_mask'].shape+(nf_feat_dim,) + (1,),\n",
    "                             dtype=torch.float,device = self.device)\n",
    "\n",
    "        nf_real_mask_mult = real_mask.unsqueeze(-1).unsqueeze(-1).to(self.device)\n",
    "        nf_true = nf_true*nf_real_mask_mult\n",
    "\n",
    "        nf_pred = nf_pred.reshape(self.B,-1,nf_feat_dim)\n",
    "        pred_nf_loss = torch.sum(torch.abs(nf_true.squeeze()-nf_pred),dim=-1) #absolute value loss\n",
    "\n",
    "        ss_scales = to_cuda(noised_dict['score_scales'])[:,None,None]\n",
    "        pnfloss = (torch.sum((pred_nf_loss*ss_scales/self.L)))*self.score_weights['nf_real']\n",
    "\n",
    "        final_loss = structure_loss + pnfloss\n",
    "        \n",
    "        aux_loss = {'pnf_loss':pnfloss,\n",
    "                    'structure_loss':structure_loss,\n",
    "                    'structure_null':ln,\n",
    "                    'structure_real':lr}\n",
    "                                                                \n",
    "        return final_loss, aux_loss\n",
    "                                                                \n",
    "                                                                \n",
    "            \n",
    "                                                                \n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "903b6477",
   "metadata": {},
   "outputs": [],
   "source": [
    "#need to add eval code, / dump conversion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "id": "4a8e64ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "exp = Experiment()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "id": "8c8f2e97",
   "metadata": {},
   "outputs": [],
   "source": [
    "tl, vl = exp.create_dataset()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "id": "0ce2c47f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cuda\n",
      "number of epochs 100\n",
      "epoch 0\n",
      "[1]: pnf_loss=75.6255 structure_loss=3.5394 structure_null=1.3346 structure_real=2.2048, steps/sec=44.85314\n",
      "79.16490936279297\n",
      "output/step_2\n",
      "[50]: pnf_loss=36.9373 structure_loss=3.7276 structure_null=1.4043 structure_real=2.3233, steps/sec=1.06283\n",
      "77.387943649292\n",
      "[100]: pnf_loss=49.8326 structure_loss=3.6549 structure_null=1.1571 structure_real=2.4978, steps/sec=1.07475\n",
      "73.74939380645752\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[143], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mexp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstart_training\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[0;32mIn[140], line 224\u001b[0m, in \u001b[0;36mExperiment.start_training\u001b[0;34m(self, return_logs)\u001b[0m\n\u001b[1;32m    222\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtrained_epochs \u001b[38;5;241m=\u001b[39m epoch\n\u001b[1;32m    223\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mepoch\u001b[39m\u001b[38;5;124m'\u001b[39m, epoch)\n\u001b[0;32m--> 224\u001b[0m epoch_log \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrain_epoch\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    225\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtrain_loader\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    226\u001b[0m \u001b[43m    \u001b[49m\u001b[43mvalid_loader\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    227\u001b[0m \u001b[43m    \u001b[49m\u001b[43mreturn_logs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mreturn_logs\u001b[49m\n\u001b[1;32m    228\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    229\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m return_logs:\n\u001b[1;32m    230\u001b[0m     logs\u001b[38;5;241m.\u001b[39mappend(epoch_log)\n",
      "Cell \u001b[0;32mIn[140], line 249\u001b[0m, in \u001b[0;36mExperiment.train_epoch\u001b[0;34m(self, train_loader, valid_loader, return_logs)\u001b[0m\n\u001b[1;32m    245\u001b[0m losskeeper \u001b[38;5;241m=\u001b[39m []\n\u001b[1;32m    246\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m train_feats \u001b[38;5;129;01min\u001b[39;00m train_loader:\n\u001b[1;32m    247\u001b[0m     \n\u001b[1;32m    248\u001b[0m     \u001b[38;5;66;03m#train_feats = tree.map_structure(lambda x: x.to(device), train_feats)\u001b[39;00m\n\u001b[0;32m--> 249\u001b[0m     loss, aux_data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mupdate_fn\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrain_feats\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    250\u001b[0m     losskeeper\u001b[38;5;241m.\u001b[39mappend(\u001b[38;5;28mfloat\u001b[39m(loss\u001b[38;5;241m.\u001b[39mdetach()\u001b[38;5;241m.\u001b[39mcpu()))\n\u001b[1;32m    252\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m return_logs:\n",
      "Cell \u001b[0;32mIn[140], line 331\u001b[0m, in \u001b[0;36mExperiment.update_fn\u001b[0;34m(self, data)\u001b[0m\n\u001b[1;32m    329\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_optimizer\u001b[38;5;241m.\u001b[39mzero_grad()\n\u001b[1;32m    330\u001b[0m loss, aux_data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mloss_fn(data)\n\u001b[0;32m--> 331\u001b[0m \u001b[43mloss\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbackward\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    332\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_optimizer\u001b[38;5;241m.\u001b[39mstep()\n\u001b[1;32m    333\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m loss, aux_data\n",
      "File \u001b[0;32m~/miniconda3/envs/se33/lib/python3.9/site-packages/torch/_tensor.py:487\u001b[0m, in \u001b[0;36mTensor.backward\u001b[0;34m(self, gradient, retain_graph, create_graph, inputs)\u001b[0m\n\u001b[1;32m    477\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m has_torch_function_unary(\u001b[38;5;28mself\u001b[39m):\n\u001b[1;32m    478\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m handle_torch_function(\n\u001b[1;32m    479\u001b[0m         Tensor\u001b[38;5;241m.\u001b[39mbackward,\n\u001b[1;32m    480\u001b[0m         (\u001b[38;5;28mself\u001b[39m,),\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    485\u001b[0m         inputs\u001b[38;5;241m=\u001b[39minputs,\n\u001b[1;32m    486\u001b[0m     )\n\u001b[0;32m--> 487\u001b[0m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mautograd\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbackward\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    488\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgradient\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mretain_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcreate_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minputs\u001b[49m\n\u001b[1;32m    489\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/envs/se33/lib/python3.9/site-packages/torch/autograd/__init__.py:200\u001b[0m, in \u001b[0;36mbackward\u001b[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001b[0m\n\u001b[1;32m    195\u001b[0m     retain_graph \u001b[38;5;241m=\u001b[39m create_graph\n\u001b[1;32m    197\u001b[0m \u001b[38;5;66;03m# The reason we repeat same the comment below is that\u001b[39;00m\n\u001b[1;32m    198\u001b[0m \u001b[38;5;66;03m# some Python versions print out the first line of a multi-line function\u001b[39;00m\n\u001b[1;32m    199\u001b[0m \u001b[38;5;66;03m# calls in the traceback and some print out the last line\u001b[39;00m\n\u001b[0;32m--> 200\u001b[0m \u001b[43mVariable\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_execution_engine\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun_backward\u001b[49m\u001b[43m(\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# Calls into the C++ engine to run the backward pass\u001b[39;49;00m\n\u001b[1;32m    201\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtensors\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgrad_tensors_\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mretain_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcreate_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    202\u001b[0m \u001b[43m    \u001b[49m\u001b[43mallow_unreachable\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maccumulate_grad\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "exp.start_training()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6518214f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tree\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f538488",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_epoch(self, train_loader, valid_loader, device, return_logs=False):\n",
    "        log_lossses = defaultdict(list)\n",
    "        global_logs = []\n",
    "        log_time = time.time()\n",
    "        step_time = time.time()\n",
    "        losskeeper = []\n",
    "        for train_feats in train_loader:\n",
    "            train_feats = tree.map_structure(lambda x: x.to(device), train_feats)\n",
    "            loss, aux_data = self.update_fn(train_feats)\n",
    "            losskeeper.append(float(loss.detach().cpu()))\n",
    "            if return_logs:\n",
    "                global_logs.append(loss)\n",
    "            for k,v in aux_data.items():\n",
    "                log_lossses[k].append(du.move_to_np(v))\n",
    "            self.trained_steps += 1\n",
    "\n",
    "            # Logging to terminal\n",
    "            if self.trained_steps == 1 or self.trained_steps % self._exp_conf.log_freq == 0:\n",
    "                elapsed_time = time.time() - log_time\n",
    "                log_time = time.time()\n",
    "                step_per_sec = self._exp_conf.log_freq / elapsed_time\n",
    "                rolling_losses = tree.map_structure(np.mean, log_lossses)\n",
    "                loss_log = ' '.join([\n",
    "                    f'{k}={v[0]:.4f}'\n",
    "                    for k,v in rolling_losses.items() if 'batch' not in k\n",
    "                ])\n",
    "                self._log.info(\n",
    "                    f'[{self.trained_steps}]: {loss_log}, steps/sec={step_per_sec:.5f}')\n",
    "                log_lossses = defaultdict(list)\n",
    "                \n",
    "                print(f'[{self.trained_steps}]: {loss_log}, steps/sec={step_per_sec:.5f}')\n",
    "                print(np.mean(losskeeper[-1000:]))\n",
    "\n",
    "            # Take checkpoint\n",
    "            if self._exp_conf.ckpt_dir is not None and (\n",
    "                    (self.trained_steps % self._exp_conf.ckpt_freq) == 0\n",
    "                    or (self._exp_conf.early_ckpt and self.trained_steps == 2)\n",
    "                ):\n",
    "                ckpt_path = os.path.join(\n",
    "                    self._exp_conf.ckpt_dir, f'step_{self.trained_steps}.pth')\n",
    "                du.write_checkpoint(\n",
    "                    ckpt_path,\n",
    "                    copy.deepcopy(self.model.state_dict()),\n",
    "                    self._conf,\n",
    "                    copy.deepcopy(self._optimizer.state_dict()),\n",
    "                    self.trained_epochs,\n",
    "                    self.trained_steps,\n",
    "                    logger=self._log,\n",
    "                    use_torch=True\n",
    "                )\n",
    "                \n",
    "\n",
    "                # Run evaluation\n",
    "                self._log.info(f'Running evaluation of {ckpt_path}')\n",
    "                start_time = time.time()\n",
    "                self._exp_conf.eval_dir = 'output/'\n",
    "                eval_dir = os.path.join(\n",
    "                    self._exp_conf.eval_dir, f'step_{self.trained_steps}')\n",
    "                print(eval_dir)\n",
    "                os.makedirs(eval_dir, exist_ok=True)\n",
    "                ckpt_metrics = self.eval_fn(\n",
    "                    eval_dir, valid_loader, device,\n",
    "                    noise_scale=self._exp_conf.noise_scale\n",
    "                )\n",
    "                eval_time = time.time() - start_time\n",
    "                self._log.info(f'Finished evaluation in {eval_time:.2f}s')\n",
    "            else:\n",
    "                ckpt_metrics = None\n",
    "                eval_time = None\n",
    "\n",
    "\n",
    "            if torch.isnan(loss):\n",
    "                if self._use_wandb:\n",
    "                    wandb.alert(\n",
    "                        title=\"Encountered NaN loss\",\n",
    "                        text=f\"Loss NaN after {self.trained_epochs} epochs, {self.trained_steps} steps\"\n",
    "                    )\n",
    "                raise Exception(f'NaN encountered')\n",
    "\n",
    "        if return_logs:\n",
    "            return global_logs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c79ced54",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b717659a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48458147",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "def model_step_null(noised_dict, batched_t, graph_maker, graph_unet, train=True):\n",
    "    #prep coordinates for output display from and comparison via FAPE\n",
    "    \n",
    "    CA_t  = noised_dict['bb_shifted']['CA'].reshape(B, L, 3).to(device)\n",
    "    NC_t = CA_t + noised_dict['bb_shifted']['N_CA'].reshape(B, L, 3).to(device)#not mult by bond distance, seems to help?\n",
    "    CC_t = CA_t + noised_dict['bb_shifted']['C_CA'].reshape(B, L, 3).to(device)#not mult \n",
    "    true =  torch.cat((NC_t,CA_t,CC_t),dim=2).reshape(B,L,3,3)\n",
    "\n",
    "    CA_n  = noised_dict['bb_noised']['CA'].reshape(B, L, 3).to(device)\n",
    "    NC_n = CA_n + noised_dict['bb_noised']['N_CA'].reshape(B, L, 3).to(device)\n",
    "    CC_n = CA_n + noised_dict['bb_noised']['C_CA'].reshape(B, L, 3).to(device)\n",
    "    noise_xyz =  torch.cat((NC_n,CA_n,CC_n),dim=2).reshape(B,L,3,3)\n",
    "\n",
    "    #prepare graphs\n",
    "    feat_dict = graph_maker.prep_for_network(noised_dict, cuda=True)\n",
    "    out =graph_unet(feat_dict,batched_t)\n",
    "    \n",
    "    \n",
    "    #FAPE Loss for the prediction\n",
    "    CA_p = out['1'][:,0,:].reshape(B, L, 3)+CA_n #translation of Calpha\n",
    "    Qs = out['1'][:,1,:] # rotation , convert from x,y,z (Quat) to rotate input vectors\n",
    "    Qs = Qs.unsqueeze(1).repeat((1,2,1))\n",
    "    Qs = torch.cat((torch.ones((B*L,2,1),device=Qs.device),Qs),dim=-1).reshape(B,L,2,4)\n",
    "    Qs = normQ(Qs)\n",
    "    Rs = Qs2Rs(Qs)\n",
    "    N_C_to_Rot = torch.cat((noised_dict['bb_noised']['N_CA'].reshape(B, L, 3).to(device),\n",
    "                            noised_dict['bb_noised']['C_CA'].reshape(B, L, 3).to(device)),dim=2).reshape(B,L,2,1,3)\n",
    "    rot_vecs = einsum('bnkij,bnkhj->bnki',Rs, N_C_to_Rot)\n",
    "    NC_p = CA_p + rot_vecs[:,:,0,:]*N_CA_dist #comparable but seems better not have it for true, but have it for pred\n",
    "    CC_p = CA_p + rot_vecs[:,:,1,:]*C_CA_dist #maybe this helep prevent \n",
    "\n",
    "    pred = torch.cat((NC_p,CA_p,CC_p),dim=2).reshape(B,L,3,3)\n",
    "    \n",
    "    #divide loss by real and null nodes\n",
    "    \n",
    "    fp, lp  = convert_pV_to_points(noised_dict)\n",
    "\n",
    "    real_mask = noised_dict['real_nodes_mask'].to('cuda')\n",
    "    score_scales = noised_dict['score_scales'].to('cuda')\n",
    "\n",
    "    lr, lr_d = FAPE_loss_real(pred, true, score_scales, real_mask,  d_clamp=10.0, d_clamp_inter=30.0,\n",
    "                   A=10.0, gamma=1.0, eps=1e-6)\n",
    "    \n",
    "    ln, ln_d = FAPE_loss_null(pred, fp, lp, real_mask, score_scales,  d_clamp=10.0,\n",
    "                       d_clamp_inter=30.0, A=10.0, gamma=1.0, eps=1e-6)\n",
    "    \n",
    "    structure_loss = lr*score_weights['3D_real']+ln*score_weights['3D_null']\n",
    "    \n",
    "    #score for node feats determining whether node is real or fake\n",
    "    nf_pred = out['0']\n",
    "\n",
    "    nf_feat_dim = noised_dict['real_nodes_noise'].shape[-1]\n",
    "    nf_true = torch.ones(noised_dict['real_nodes_mask'].shape+(nf_feat_dim,) + (1,),\n",
    "                         dtype=torch.float,device=device)\n",
    "\n",
    "    nf_real_mask_mult = real_mask.unsqueeze(-1).unsqueeze(-1).to(device)\n",
    "    nf_true = nf_true*nf_real_mask_mult\n",
    "\n",
    "    nf_pred = nf_pred.reshape(B,-1,nf_feat_dim)\n",
    "    pred_nf_loss = torch.sum(torch.abs(nf_true.squeeze()-nf_pred),dim=-1) #absolute value loss\n",
    "    pred_nf_loss = pred_nf_loss.to(device)\n",
    "    \n",
    "    ss_scales = to_cuda(noised_dict['score_scales'])[:,None,None]\n",
    "    pnfloss = (torch.sum((pred_nf_loss*ss_scales/L)))*score_weights['nf_real']\n",
    "    \n",
    "    final_loss = structure_loss + pnfloss\n",
    "    \n",
    "    \n",
    "    return final_loss, pnfloss.detach().cpu(), structure_loss.detach().cpu(), lr.detach().cpu(), ln.detach().cpu()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2999b08",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_epoch(self, train_loader, valid_loader, device, return_logs=False):\n",
    "        log_lossses = defaultdict(list)\n",
    "        global_logs = []\n",
    "        log_time = time.time()\n",
    "        step_time = time.time()\n",
    "        losskeeper = []\n",
    "        for train_feats in train_loader:\n",
    "            train_feats = tree.map_structure(lambda x: x.to(device), train_feats)\n",
    "            loss, aux_data = self.update_fn(train_feats)\n",
    "            losskeeper.append(float(loss.detach().cpu()))\n",
    "            if return_logs:\n",
    "                global_logs.append(loss)\n",
    "            for k,v in aux_data.items():\n",
    "                log_lossses[k].append(du.move_to_np(v))\n",
    "            self.trained_steps += 1\n",
    "\n",
    "            # Logging to terminal\n",
    "            if self.trained_steps == 1 or self.trained_steps % self._exp_conf.log_freq == 0:\n",
    "                elapsed_time = time.time() - log_time\n",
    "                log_time = time.time()\n",
    "                step_per_sec = self._exp_conf.log_freq / elapsed_time\n",
    "                rolling_losses = tree.map_structure(np.mean, log_lossses)\n",
    "                loss_log = ' '.join([\n",
    "                    f'{k}={v[0]:.4f}'\n",
    "                    for k,v in rolling_losses.items() if 'batch' not in k\n",
    "                ])\n",
    "                self._log.info(\n",
    "                    f'[{self.trained_steps}]: {loss_log}, steps/sec={step_per_sec:.5f}')\n",
    "                log_lossses = defaultdict(list)\n",
    "                \n",
    "                print(f'[{self.trained_steps}]: {loss_log}, steps/sec={step_per_sec:.5f}')\n",
    "                print(np.mean(losskeeper[-1000:]))\n",
    "\n",
    "            # Take checkpoint\n",
    "            if self._exp_conf.ckpt_dir is not None and (\n",
    "                    (self.trained_steps % self._exp_conf.ckpt_freq) == 0\n",
    "                    or (self._exp_conf.early_ckpt and self.trained_steps == 2)\n",
    "                ):\n",
    "                ckpt_path = os.path.join(\n",
    "                    self._exp_conf.ckpt_dir, f'step_{self.trained_steps}.pth')\n",
    "                du.write_checkpoint(\n",
    "                    ckpt_path,\n",
    "                    copy.deepcopy(self.model.state_dict()),\n",
    "                    self._conf,\n",
    "                    copy.deepcopy(self._optimizer.state_dict()),\n",
    "                    self.trained_epochs,\n",
    "                    self.trained_steps,\n",
    "                    logger=self._log,\n",
    "                    use_torch=True\n",
    "                )\n",
    "                \n",
    "\n",
    "                # Run evaluation\n",
    "                self._log.info(f'Running evaluation of {ckpt_path}')\n",
    "                start_time = time.time()\n",
    "                self._exp_conf.eval_dir = 'output/'\n",
    "                eval_dir = os.path.join(\n",
    "                    self._exp_conf.eval_dir, f'step_{self.trained_steps}')\n",
    "                print(eval_dir)\n",
    "                os.makedirs(eval_dir, exist_ok=True)\n",
    "                ckpt_metrics = self.eval_fn(\n",
    "                    eval_dir, valid_loader, device,\n",
    "                    noise_scale=self._exp_conf.noise_scale\n",
    "                )\n",
    "                eval_time = time.time() - start_time\n",
    "                self._log.info(f'Finished evaluation in {eval_time:.2f}s')\n",
    "            else:\n",
    "                ckpt_metrics = None\n",
    "                eval_time = None\n",
    "\n",
    "\n",
    "            if torch.isnan(loss):\n",
    "                if self._use_wandb:\n",
    "                    wandb.alert(\n",
    "                        title=\"Encountered NaN loss\",\n",
    "                        text=f\"Loss NaN after {self.trained_epochs} epochs, {self.trained_steps} steps\"\n",
    "                    )\n",
    "                raise Exception(f'NaN encountered')\n",
    "\n",
    "        if return_logs:\n",
    "            return global_logs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75573c13",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62506e98",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "    \n",
    "# class EMA(nn.Module):\n",
    "#     def __init__(self, mu):\n",
    "#         super(EMA, self).__init__()\n",
    "#         self.mu = mu\n",
    "#         self.shadow = {}\n",
    "\n",
    "#     def register(self, name, val):\n",
    "#         self.shadow[name] = val.clone()\n",
    "\n",
    "#     def forward(self, name, x):\n",
    "#         assert name in self.shadow\n",
    "#         new_average = (1.0 - self.mu) * x + self.mu * self.shadow[name]\n",
    "#         self.shadow[name] = new_average.clone()\n",
    "#         return new_average\n",
    "\n",
    "class Experiment:\n",
    "\n",
    "    def __init__(self,*,config_path= 'config/base_static_4H_norot.yaml', simple=True, limit=5028):\n",
    "        \"\"\"Initialize experiment.\n",
    "        Currently does not incorporate psi pred (just taken from starting points)\n",
    "        Args:\n",
    "            exp_cfg: Experiment configuration.\n",
    "        \"\"\"\n",
    "        with open(config_path, 'r') as file:\n",
    "            config = yaml.safe_load(file)\n",
    "        conf = Struct(config)\n",
    "        \n",
    "        logging.basicConfig(filename='test.log', level=logging.INFO)\n",
    "        self._log = logging.getLogger(__name__)\n",
    "        \n",
    "        self.simple = simple\n",
    "        self.limit = limit\n",
    "        \n",
    "        self._use_wandb = False\n",
    "        \n",
    "        self.rot=False\n",
    "        self.bbloss=False\n",
    "        self.device='cuda'\n",
    "        \n",
    "        # Configs\n",
    "        self._conf = conf\n",
    "        self._exp_conf = conf.experiment\n",
    "        self._diff_conf = conf.diffuser\n",
    "        self._model_conf = conf.model\n",
    "        self._data_conf = conf.data\n",
    "        self.ipa_conf = conf.model.ipa\n",
    "        \n",
    "        \n",
    "        self.B=self._exp_conf.batch_size\n",
    "        L=65 #HARDDDCODE\n",
    "        \n",
    "        self._diffuser = se3_diffuser.SE3Diffuser(self._diff_conf)\n",
    "        self._model = ScoreNetwork(\n",
    "            self._model_conf, self._diffuser,B=self.B,L=L)\n",
    "        num_parameters = sum(p.numel() for p in self._model.parameters())\n",
    "        self._exp_conf.num_parameters = num_parameters\n",
    "        self._log.info(f'Number of model parameters {num_parameters}')\n",
    "#         self._optimizer = EMA(0.980)\n",
    "#         for name, param in self._model.named_parameters():\n",
    "#             if param.requires_grad:\n",
    "#                 self._optimizer.register(name, param.data)\n",
    "        \n",
    "        \n",
    "        self._optimizer = torch.optim.Adam(\n",
    "            self._model.score_model.parameters(), lr=self._exp_conf.learning_rate)\n",
    "        dt_string = datetime.now().strftime(\"%dD_%mM_%YY_%Hh_%Mm_%Ss\")\n",
    "        self._exp_conf.ckpt_dir = 'log/'\n",
    "        if self._exp_conf.ckpt_dir is not None:\n",
    "            # Set-up checkpoint location\n",
    "            ckpt_dir = os.path.join(\n",
    "                self._exp_conf.ckpt_dir,\n",
    "                self._exp_conf.name,\n",
    "                dt_string)\n",
    "            if not os.path.exists(ckpt_dir):\n",
    "                os.makedirs(ckpt_dir, exist_ok=True)\n",
    "            self._exp_conf.ckpt_dir = ckpt_dir\n",
    "            self._log.info(f'Checkpoints saved to: {ckpt_dir}')\n",
    "        else:  \n",
    "            self._log.info('Checkpoint not being saved.')\n",
    "            \n",
    "        if self._exp_conf.eval_dir is not None :\n",
    "            eval_dir = os.path.join(\n",
    "                self._exp_conf.eval_dir,\n",
    "                self._exp_conf.name,\n",
    "                dt_string)\n",
    "            self._exp_conf.eval_dir = eval_dir\n",
    "            self._log.info(f'Evaluation saved to: {eval_dir}')\n",
    "        else:\n",
    "            self._exp_conf.eval_dir = os.devnull\n",
    "            self._log.info(f'Evaluation will not be saved.')\n",
    "    #         self._aux_data_history = deque(maxlen=100)\n",
    "\n",
    "        # Warm starting\n",
    "        ckpt_model = None\n",
    "        ckpt_opt = None\n",
    "        self.trained_epochs = 0\n",
    "        self.trained_steps = 0\n",
    "\n",
    "        # Initialize experiment objects\n",
    "\n",
    "        if ckpt_model is not None:\n",
    "            ckpt_model = {k.replace('module.', ''):v for k,v in ckpt_model.items()}\n",
    "            self._model.load_state_dict(ckpt_model, strict=True)\n",
    "\n",
    "        num_parameters = sum(p.numel() for p in self._model.parameters())\n",
    "        self._exp_conf.num_parameters = num_parameters\n",
    "        self._log.info(f'Number of model parameters {num_parameters}')\n",
    "        self._optimizer = torch.optim.Adam(\n",
    "            self._model.parameters(), lr=self._exp_conf.learning_rate)\n",
    "        if ckpt_opt is not None:\n",
    "            self._optimizer.load_state_dict(ckpt_opt)\n",
    "\n",
    "        dt_string = datetime.now().strftime(\"%dD_%mM_%YY_%Hh_%Mm_%Ss\")\n",
    "        if self._exp_conf.ckpt_dir is not None:\n",
    "            # Set-up checkpoint location\n",
    "            ckpt_dir = os.path.join(\n",
    "                self._exp_conf.ckpt_dir,\n",
    "                self._exp_conf.name,\n",
    "                dt_string)\n",
    "            if not os.path.exists(ckpt_dir):\n",
    "                os.makedirs(ckpt_dir, exist_ok=True)\n",
    "            self._exp_conf.ckpt_dir = ckpt_dir\n",
    "            self._log.info(f'Checkpoints saved to: {ckpt_dir}')\n",
    "        else:  \n",
    "            self._log.info('Checkpoint not being saved.')\n",
    "        if self._exp_conf.eval_dir is not None :\n",
    "            eval_dir = os.path.join(\n",
    "                self._exp_conf.eval_dir,\n",
    "                self._exp_conf.name,\n",
    "                dt_string)\n",
    "            self._exp_conf.eval_dir = eval_dir\n",
    "            self._log.info(f'Evaluation saved to: {eval_dir}')\n",
    "        else:\n",
    "            self._exp_conf.eval_dir = os.devnull\n",
    "            self._log.info(f'Evaluation will not be saved.')\n",
    "        self._aux_data_history = deque(maxlen=100)\n",
    "        \n",
    "    @property\n",
    "    def diffuser(self):\n",
    "        return self._diffuser\n",
    "\n",
    "    @property\n",
    "    def model(self):\n",
    "        return self._model\n",
    "\n",
    "    @property\n",
    "    def conf(self):\n",
    "        return self._conf\n",
    "    \n",
    "    def create_dataset(self):\n",
    "        self._exp_conf.eval_batch_size=self.B\n",
    "        #valid limit set\n",
    "        num_workers = self._exp_conf.num_loader_workers\n",
    "        train_dataset = pdb_data_loader.PdbDataset(\n",
    "                    data_conf=self._data_conf,\n",
    "                    diffuser=self._diffuser,\n",
    "                    is_training=True,\n",
    "                    simple = self.simple\n",
    "                )\n",
    "        valid_dataset = pdb_data_loader.PdbDataset(\n",
    "                    data_conf=self._data_conf,\n",
    "                    diffuser=self._diffuser,\n",
    "                    is_training=False,\n",
    "                    simple = self.simple\n",
    "                )\n",
    "\n",
    "        train_dataset.csv = train_dataset.csv.iloc[:self.limit]\n",
    "        valid_dataset.csv = valid_dataset.csv.iloc[:256] #valid\n",
    "\n",
    "        valid_sampler=None\n",
    "        train_sampler = pdb_data_loader.TrainSampler(\n",
    "                data_conf=self._data_conf,\n",
    "                dataset=train_dataset,\n",
    "                batch_size=self.B,\n",
    "                sample_mode=self._exp_conf.sample_mode,\n",
    "            )\n",
    "\n",
    "\n",
    "        train_loader = du.create_data_loader(\n",
    "            train_dataset,\n",
    "            sampler=train_sampler,\n",
    "            np_collate=False,\n",
    "            length_batch=False,\n",
    "            batch_size=self.B,\n",
    "            shuffle=False,\n",
    "            num_workers=num_workers,\n",
    "            drop_last=False,\n",
    "            max_squared_res=100*2,\n",
    "        )\n",
    "        \n",
    "        # Loaders\n",
    "        \n",
    "        train_loader = du.create_data_loader(\n",
    "            train_dataset,\n",
    "            sampler=train_sampler,\n",
    "            np_collate=False,\n",
    "            length_batch=False,\n",
    "            batch_size=self.B,\n",
    "            shuffle=False,\n",
    "            num_workers=num_workers,\n",
    "            drop_last=False,\n",
    "            max_squared_res=self._exp_conf.max_squared_res,\n",
    "        )\n",
    "        \n",
    "        #####TRAIN DATASET again##########\n",
    "        valid_loader = du.create_data_loader(\n",
    "            valid_dataset,\n",
    "            sampler=valid_sampler,\n",
    "            np_collate=False,\n",
    "            length_batch=False,\n",
    "            batch_size=self.B,\n",
    "            shuffle=False,\n",
    "            num_workers=1,\n",
    "            drop_last=False,\n",
    "        )\n",
    "        \n",
    "        \n",
    "        \n",
    "        return train_loader, train_sampler, valid_loader, valid_sampler\n",
    "    \n",
    "    def start_training(self, return_logs=False):\n",
    "\n",
    "        # GPU mode\n",
    "        if torch.cuda.is_available():\n",
    "            device = f\"cuda\"\n",
    "            self._model = self.model.to(device)\n",
    "            print(f\"Using device: {device}\")\n",
    "            self._log.info(f\"Using device: {device}\")\n",
    "        else:\n",
    "            device = 'cpu'\n",
    "            self._model = self.model.to(device)\n",
    "            self._log.info(f\"Using device: {device}\")\n",
    "\n",
    "        self._model.train()\n",
    "        #removed valid\n",
    "        (train_loader, train_sampler, valid_loader, valid_sampler) = self.create_dataset()\n",
    "\n",
    "        logs = []\n",
    "        print(self._exp_conf.num_epoch)\n",
    "        for epoch in range(self.trained_epochs, self._exp_conf.num_epoch):\n",
    "            if train_sampler is not None:\n",
    "                train_sampler.set_epoch(epoch)\n",
    "            self.trained_epochs = epoch\n",
    "            print(epoch)\n",
    "            epoch_log = self.train_epoch(\n",
    "                train_loader,\n",
    "                valid_loader,\n",
    "                device,\n",
    "                return_logs=return_logs\n",
    "            )\n",
    "            if return_logs:\n",
    "                logs.append(epoch_log)\n",
    "\n",
    "        self._log.info('Done')\n",
    "        return logs\n",
    "    \n",
    "    def train_epoch(self, train_loader, valid_loader, device, return_logs=False):\n",
    "        log_lossses = defaultdict(list)\n",
    "        global_logs = []\n",
    "        log_time = time.time()\n",
    "        step_time = time.time()\n",
    "        losskeeper = []\n",
    "        for train_feats in train_loader:\n",
    "            train_feats = tree.map_structure(lambda x: x.to(device), train_feats)\n",
    "            loss, aux_data = self.update_fn(train_feats)\n",
    "            losskeeper.append(float(loss.detach().cpu()))\n",
    "            if return_logs:\n",
    "                global_logs.append(loss)\n",
    "            for k,v in aux_data.items():\n",
    "                log_lossses[k].append(du.move_to_np(v))\n",
    "            self.trained_steps += 1\n",
    "\n",
    "            # Logging to terminal\n",
    "            if self.trained_steps == 1 or self.trained_steps % self._exp_conf.log_freq == 0:\n",
    "                elapsed_time = time.time() - log_time\n",
    "                log_time = time.time()\n",
    "                step_per_sec = self._exp_conf.log_freq / elapsed_time\n",
    "                rolling_losses = tree.map_structure(np.mean, log_lossses)\n",
    "                loss_log = ' '.join([\n",
    "                    f'{k}={v[0]:.4f}'\n",
    "                    for k,v in rolling_losses.items() if 'batch' not in k\n",
    "                ])\n",
    "                self._log.info(\n",
    "                    f'[{self.trained_steps}]: {loss_log}, steps/sec={step_per_sec:.5f}')\n",
    "                log_lossses = defaultdict(list)\n",
    "                \n",
    "                print(f'[{self.trained_steps}]: {loss_log}, steps/sec={step_per_sec:.5f}')\n",
    "                print(np.mean(losskeeper[-1000:]))\n",
    "\n",
    "            # Take checkpoint\n",
    "            if self._exp_conf.ckpt_dir is not None and (\n",
    "                    (self.trained_steps % self._exp_conf.ckpt_freq) == 0\n",
    "                    or (self._exp_conf.early_ckpt and self.trained_steps == 2)\n",
    "                ):\n",
    "                ckpt_path = os.path.join(\n",
    "                    self._exp_conf.ckpt_dir, f'step_{self.trained_steps}.pth')\n",
    "                du.write_checkpoint(\n",
    "                    ckpt_path,\n",
    "                    copy.deepcopy(self.model.state_dict()),\n",
    "                    self._conf,\n",
    "                    copy.deepcopy(self._optimizer.state_dict()),\n",
    "                    self.trained_epochs,\n",
    "                    self.trained_steps,\n",
    "                    logger=self._log,\n",
    "                    use_torch=True\n",
    "                )\n",
    "                \n",
    "\n",
    "                # Run evaluation\n",
    "                self._log.info(f'Running evaluation of {ckpt_path}')\n",
    "                start_time = time.time()\n",
    "                self._exp_conf.eval_dir = 'output/'\n",
    "                eval_dir = os.path.join(\n",
    "                    self._exp_conf.eval_dir, f'step_{self.trained_steps}')\n",
    "                print(eval_dir)\n",
    "                os.makedirs(eval_dir, exist_ok=True)\n",
    "                ckpt_metrics = self.eval_fn(\n",
    "                    eval_dir, valid_loader, device,\n",
    "                    noise_scale=self._exp_conf.noise_scale\n",
    "                )\n",
    "                eval_time = time.time() - start_time\n",
    "                self._log.info(f'Finished evaluation in {eval_time:.2f}s')\n",
    "            else:\n",
    "                ckpt_metrics = None\n",
    "                eval_time = None\n",
    "\n",
    "\n",
    "            if torch.isnan(loss):\n",
    "                if self._use_wandb:\n",
    "                    wandb.alert(\n",
    "                        title=\"Encountered NaN loss\",\n",
    "                        text=f\"Loss NaN after {self.trained_epochs} epochs, {self.trained_steps} steps\"\n",
    "                    )\n",
    "                raise Exception(f'NaN encountered')\n",
    "\n",
    "        if return_logs:\n",
    "            return global_logs\n",
    "        \n",
    "    def eval_fn(self, eval_dir, valid_loader, device, min_t=None, num_t=None, noise_scale=1.0):\n",
    "        ckpt_eval_metrics = []\n",
    "        self._exp_conf.eval_batch_size=self.B\n",
    "        for valid_feats, pdb_names in valid_loader:\n",
    "            res_mask = du.move_to_np(valid_feats['res_mask'].bool())\n",
    "            fixed_mask = du.move_to_np(valid_feats['fixed_mask'].bool())\n",
    "            aatype = du.move_to_np(valid_feats['aatype'])\n",
    "            gt_prot = du.move_to_np(valid_feats['atom37_pos'])\n",
    "            batch_size = res_mask.shape[0]\n",
    "            valid_feats = tree.map_structure(\n",
    "                lambda x: x.to(device), valid_feats)\n",
    "            \n",
    "            # Run inference\n",
    "            infer_out = self.inference_fn(\n",
    "                valid_feats, min_t=min_t, num_t=num_t, noise_scale=noise_scale)\n",
    "            final_prot = infer_out['prot_traj'][0]\n",
    "            for i in range(batch_size):\n",
    "                num_res = int(np.sum(res_mask[i]).item())\n",
    "                unpad_fixed_mask = fixed_mask[i][res_mask[i]]\n",
    "                unpad_diffused_mask = 1 - unpad_fixed_mask\n",
    "                unpad_prot = final_prot[i][res_mask[i]]\n",
    "                unpad_gt_prot = gt_prot[i][res_mask[i]]\n",
    "                unpad_gt_aatype = aatype[i][res_mask[i]]\n",
    "                percent_diffused = np.sum(unpad_diffused_mask) / num_res\n",
    "\n",
    "                # Extract argmax predicted aatype\n",
    "                saved_path = au.write_prot_to_pdb(\n",
    "                    unpad_prot,\n",
    "                    os.path.join(\n",
    "                        eval_dir,\n",
    "                        f'len_{num_res}_sample_{i}_diffused_{percent_diffused:.2f}.pdb'\n",
    "                    ),\n",
    "                    no_indexing=True,\n",
    "                    b_factors=np.tile(1 - unpad_fixed_mask[..., None], 37) * 100\n",
    "                )\n",
    "                try:\n",
    "                    sample_metrics = metrics.protein_metrics(\n",
    "                        pdb_path=saved_path,\n",
    "                        atom37_pos=unpad_prot,\n",
    "                        gt_atom37_pos=unpad_gt_prot,\n",
    "                        gt_aatype=unpad_gt_aatype,\n",
    "                        diffuse_mask=unpad_diffused_mask,\n",
    "                         )\n",
    "                except ValueError as e:\n",
    "                    self._log.warning(\n",
    "                        f'Failed evaluation of length {num_res} sample {i}: {e}')\n",
    "                    continue\n",
    "                sample_metrics['step'] = self.trained_steps\n",
    "                sample_metrics['num_res'] = num_res\n",
    "                sample_metrics['fixed_residues'] = np.sum(unpad_fixed_mask)\n",
    "                sample_metrics['diffused_percentage'] = percent_diffused\n",
    "                sample_metrics['sample_path'] = saved_path\n",
    "                sample_metrics['gt_pdb'] = pdb_names[i]\n",
    "                ckpt_eval_metrics.append(sample_metrics)\n",
    "\n",
    "        # Save metrics as CSV.\n",
    "        eval_metrics_csv_path = os.path.join(eval_dir, 'metrics.csv')\n",
    "        ckpt_eval_metrics = pd.DataFrame(ckpt_eval_metrics)\n",
    "        ckpt_eval_metrics.to_csv(eval_metrics_csv_path, index=False)\n",
    "        return ckpt_eval_metrics\n",
    "    \n",
    "    \n",
    "    def _self_conditioning(self, batch):\n",
    "        model_sc = self.model(batch)\n",
    "        batch['sc_ca_t'] = model_sc['rigids'][..., 4:]\n",
    "        return batch\n",
    "    \n",
    "    def loss_fn(self,batch):\n",
    "        \n",
    "        \n",
    "        \n",
    "        model_out = self._model(batch) #score network calls graph maker/gu_net\n",
    "    \n",
    "        #loss\n",
    "        bb_mask = batch['res_mask']\n",
    "        diffuse_mask = 1 - batch['fixed_mask']\n",
    "        loss_mask = bb_mask * diffuse_mask\n",
    "        batch_size, num_res = bb_mask.shape\n",
    "\n",
    "        gt_rot_score = batch['rot_score']\n",
    "        gt_trans_score = batch['trans_score']\n",
    "        rot_score_scaling = batch['rot_score_scaling']\n",
    "        trans_score_scaling = batch['trans_score_scaling']\n",
    "        batch_loss_mask = torch.any(bb_mask, dim=-1)\n",
    "\n",
    "        pred_rot_score = model_out['rot_score'] * diffuse_mask[..., None]\n",
    "        pred_trans_score = model_out['trans_score'] * diffuse_mask[..., None]\n",
    "\n",
    "        # Translation score loss\n",
    "        trans_score_mse = (gt_trans_score - pred_trans_score)**2 * loss_mask[..., None]\n",
    "        trans_score_loss = torch.sum(\n",
    "            trans_score_mse / trans_score_scaling[:, None, None]**2,\n",
    "            dim=(-1, -2)\n",
    "        ) / (loss_mask.sum(dim=-1) + 1e-10)\n",
    "\n",
    "        # Translation x0 loss\n",
    "        gt_trans_x0 = batch['rigids_0'][..., 4:] * self._exp_conf.coordinate_scaling\n",
    "        pred_trans_x0 = model_out['rigids'][..., 4:] * self._exp_conf.coordinate_scaling\n",
    "        trans_x0_loss = torch.sum(\n",
    "            (gt_trans_x0 - pred_trans_x0)**2 * loss_mask[..., None],\n",
    "            dim=(-1, -2)\n",
    "        ) / (loss_mask.sum(dim=-1) + 1e-10)\n",
    "\n",
    "        trans_loss = (\n",
    "            trans_score_loss * (batch['t'] > self._exp_conf.trans_x0_threshold)\n",
    "            + trans_x0_loss * (batch['t'] <= self._exp_conf.trans_x0_threshold)\n",
    "        )\n",
    "        if self.rot:\n",
    "            # Rotation loss\n",
    "            if self._exp_conf.separate_rot_loss:\n",
    "                gt_rot_angle = torch.norm(gt_rot_score, dim=-1, keepdim=True)\n",
    "                gt_rot_axis = gt_rot_score / (gt_rot_angle + 1e-6)\n",
    "\n",
    "                pred_rot_angle = torch.norm(pred_rot_score, dim=-1, keepdim=True)\n",
    "                pred_rot_axis = pred_rot_score / (pred_rot_angle + 1e-6)\n",
    "\n",
    "                # Separate loss on the axis\n",
    "                axis_loss = (gt_rot_axis - pred_rot_axis)**2 * loss_mask[..., None]\n",
    "                axis_loss = torch.sum(\n",
    "                    axis_loss, dim=(-1, -2)\n",
    "                ) / (loss_mask.sum(dim=-1) + 1e-10)\n",
    "\n",
    "                # Separate loss on the angle\n",
    "                angle_loss = (gt_rot_angle - pred_rot_angle)**2 * loss_mask[..., None]\n",
    "                angle_loss = torch.sum(\n",
    "                    angle_loss / rot_score_scaling[:, None, None]**2,\n",
    "                    dim=(-1, -2)\n",
    "                ) / (loss_mask.sum(dim=-1) + 1e-10)\n",
    "                angle_loss *= self._exp_conf.rot_loss_weight\n",
    "                angle_loss *= batch['t'] > self._exp_conf.rot_loss_t_threshold\n",
    "                rot_loss = angle_loss + axis_loss\n",
    "            else:\n",
    "                rot_mse = (gt_rot_score - pred_rot_score)**2 * loss_mask[..., None]\n",
    "                rot_loss = torch.sum(\n",
    "                    rot_mse / rot_score_scaling[:, None, None]**2,\n",
    "                    dim=(-1, -2)\n",
    "                ) / (loss_mask.sum(dim=-1) + 1e-10)\n",
    "                rot_loss *= self._exp_conf.rot_loss_weight\n",
    "                rot_loss *= batch['t'] > self._exp_conf.rot_loss_t_threshold\n",
    "            rot_loss *= int(self._diff_conf.diffuse_rot)\n",
    "            \n",
    "        else:\n",
    "            rot_loss = torch.zeros_like(trans_loss,device=self.device)\n",
    "        \n",
    "\n",
    "        if self.bbloss:\n",
    "            # Backbone atom loss\n",
    "            pred_atom37 = model_out['atom37'][:, :, :5]\n",
    "            gt_rigids = ru.Rigid.from_tensor_7(batch['rigids_0'].type(torch.float32))\n",
    "            gt_psi = batch['torsion_angles_sin_cos'][..., 2, :]\n",
    "            gt_atom37, atom37_mask, _, _ = all_atom.compute_backbone(\n",
    "                gt_rigids, gt_psi)\n",
    "            gt_atom37 = gt_atom37[:, :, :5]\n",
    "            atom37_mask = atom37_mask[:, :, :5]\n",
    "\n",
    "            gt_atom37 = gt_atom37.to(pred_atom37.device)\n",
    "            atom37_mask = atom37_mask.to(pred_atom37.device)\n",
    "            bb_atom_loss_mask = atom37_mask * loss_mask[..., None]\n",
    "            bb_atom_loss = torch.sum(\n",
    "                (pred_atom37 - gt_atom37)**2 * bb_atom_loss_mask[..., None],\n",
    "                dim=(-1, -2, -3)\n",
    "            ) / (bb_atom_loss_mask.sum(dim=(-1, -2)) + 1e-10)\n",
    "            bb_atom_loss *= self._exp_conf.bb_atom_loss_weight\n",
    "            bb_atom_loss *= batch['t'] < self._exp_conf.bb_atom_loss_t_filter\n",
    "            bb_atom_loss *= self._exp_conf.aux_loss_weight\n",
    "\n",
    "\n",
    "            # Pairwise distance loss\n",
    "            gt_flat_atoms = gt_atom37.reshape([batch_size, num_res*5, 3])\n",
    "            gt_pair_dists = torch.linalg.norm(\n",
    "                gt_flat_atoms[:, :, None, :] - gt_flat_atoms[:, None, :, :], dim=-1)\n",
    "            pred_flat_atoms = pred_atom37.reshape([batch_size, num_res*5, 3])\n",
    "            pred_pair_dists = torch.linalg.norm(\n",
    "                pred_flat_atoms[:, :, None, :] - pred_flat_atoms[:, None, :, :], dim=-1)\n",
    "\n",
    "            flat_loss_mask = torch.tile(loss_mask[:, :, None], (1, 1, 5))\n",
    "            flat_loss_mask = flat_loss_mask.reshape([batch_size, num_res*5])\n",
    "            flat_res_mask = torch.tile(bb_mask[:, :, None], (1, 1, 5))\n",
    "            flat_res_mask = flat_res_mask.reshape([batch_size, num_res*5])\n",
    "\n",
    "            gt_pair_dists = gt_pair_dists * flat_loss_mask[..., None]\n",
    "            pred_pair_dists = pred_pair_dists * flat_loss_mask[..., None]\n",
    "            pair_dist_mask = flat_loss_mask[..., None] * flat_res_mask[:, None, :]\n",
    "\n",
    "            # No loss on anything >6A\n",
    "            proximity_mask = gt_pair_dists < 6\n",
    "            pair_dist_mask  = pair_dist_mask * proximity_mask\n",
    "\n",
    "            dist_mat_loss = torch.sum(\n",
    "                (gt_pair_dists - pred_pair_dists)**2 * pair_dist_mask,\n",
    "                dim=(1, 2))\n",
    "            dist_mat_loss /= (torch.sum(pair_dist_mask, dim=(1, 2)) - num_res)\n",
    "            dist_mat_loss *= self._exp_conf.dist_mat_loss_weight\n",
    "            dist_mat_loss *= batch['t'] < self._exp_conf.dist_mat_loss_t_filter\n",
    "            dist_mat_loss *= self._exp_conf.aux_loss_weight\n",
    "            \n",
    "        else:\n",
    "            bb_atom_loss = torch.zeros_like(trans_loss,device=self.device)\n",
    "            dist_mat_loss = torch.zeros_like(trans_loss,device=self.device)\n",
    "\n",
    "         \n",
    "        final_loss = (\n",
    "            rot_loss\n",
    "            + trans_loss\n",
    "            + bb_atom_loss\n",
    "            + dist_mat_loss\n",
    "        )\n",
    "\n",
    "        def normalize_loss(x):\n",
    "            return x.sum() /  (batch_loss_mask.sum() + 1e-9)\n",
    "\n",
    "        aux_data = {\n",
    "            'batch_train_loss': final_loss,\n",
    "            'batch_rot_loss': rot_loss,\n",
    "            'batch_trans_loss': trans_loss,\n",
    "            'batch_bb_atom_loss': bb_atom_loss,\n",
    "            'batch_dist_mat_loss': dist_mat_loss,\n",
    "            'total_loss': normalize_loss(final_loss),\n",
    "            'rot_loss': normalize_loss(rot_loss),\n",
    "            'trans_loss': normalize_loss(trans_loss),\n",
    "            'bb_atom_loss': normalize_loss(bb_atom_loss),\n",
    "            'dist_mat_loss': normalize_loss(dist_mat_loss),\n",
    "            'examples_per_step': torch.tensor(batch_size),\n",
    "            'res_length': torch.mean(torch.sum(bb_mask, dim=-1)),\n",
    "        }\n",
    "\n",
    "        return normalize_loss(final_loss),aux_data\n",
    "        \n",
    "        \n",
    "    def update_fn(self, data):\n",
    "        \"\"\"Updates the state using some data and returns metrics.\"\"\"\n",
    "        self._optimizer.zero_grad()\n",
    "        loss, aux_data = self.loss_fn(data)\n",
    "        loss.backward()\n",
    "        self._optimizer.step()\n",
    "        return loss, aux_data\n",
    "\n",
    "    def _calc_trans_0(self, trans_score, trans_t, t):\n",
    "        beta_t = self._diffuser._se3_diffuser._r3_diffuser.marginal_b_t(t)\n",
    "        beta_t = beta_t[..., None, None]\n",
    "        cond_var = 1 - torch.exp(-beta_t)\n",
    "        return (trans_score * cond_var + trans_t) / torch.exp(-1/2*beta_t)\n",
    "\n",
    "    def _set_t_feats(self, feats, t, t_placeholder):\n",
    "        feats['t'] = t * t_placeholder\n",
    "        rot_score_scaling, trans_score_scaling = self.diffuser.score_scaling(t)\n",
    "        feats['rot_score_scaling'] = rot_score_scaling * t_placeholder\n",
    "        feats['trans_score_scaling'] = trans_score_scaling * t_placeholder\n",
    "        return feats\n",
    "\n",
    "    def forward_traj(self, x_0, min_t, num_t):\n",
    "        forward_steps = np.linspace(min_t, 1.0, num_t)[:-1]\n",
    "        x_traj = [x_0]\n",
    "        for t in forward_steps:\n",
    "            x_t = self.diffuser.se3_diffuser._r3_diffuser.forward(\n",
    "                x_traj[-1], t, num_t)\n",
    "            x_traj.append(x_t)\n",
    "        x_traj = torch.stack(x_traj, axis=0)\n",
    "        return x_traj\n",
    "\n",
    "    def inference_fn(\n",
    "            self,\n",
    "            data_init,\n",
    "            num_t=None,\n",
    "            min_t=None,\n",
    "            center=True,\n",
    "            aux_traj=False,\n",
    "            self_condition=True,\n",
    "            noise_scale=1.0,\n",
    "        ):\n",
    "        \"\"\"Inference function.\n",
    "\n",
    "        Args:\n",
    "            data_init: Initial data values for sampling.\n",
    "        \"\"\"\n",
    "        \n",
    "        # Run reverse process.\n",
    "        sample_feats = copy.deepcopy(data_init)\n",
    "        device = sample_feats['rigids_t'].device\n",
    "#         for k,v in sample_feats.items():\n",
    "#             sample_feats[k] = torch.repeat_interleave(sample_feats[k],torch.tensor([2]*8).to(device),dim=0)\n",
    "        device = sample_feats['rigids_t'].device\n",
    "        if sample_feats['rigids_t'].ndim == 2:\n",
    "            t_placeholder = torch.ones((1,)).to(device)#test remove\n",
    "#             t_placeholder = torch.ones(\n",
    "#                 (self.B,)).to(device)\n",
    "        else:\n",
    "            t_placeholder = torch.ones(\n",
    "                (sample_feats['rigids_t'].shape[0],)).to(device)\n",
    "        if num_t is None:\n",
    "            num_t = self._data_conf.num_t\n",
    "        if min_t is None:\n",
    "            min_t = self._data_conf.min_t\n",
    "        reverse_steps = np.linspace(min_t, 1.0, num_t)[::-1]\n",
    "        dt = 1/num_t\n",
    "        all_rigids = [du.move_to_np(copy.deepcopy(sample_feats['rigids_t']))]\n",
    "        all_bb_prots = []\n",
    "        all_trans_0_pred = []\n",
    "        all_bb_0_pred = []\n",
    "        with torch.no_grad():\n",
    "#             if self._model_conf.embed.embed_self_conditioning and self_condition:\n",
    "#                 sample_feats = self._set_t_feats(\n",
    "#                     sample_feats, reverse_steps[0], t_placeholder)\n",
    "#                 sample_feats = self._self_conditioning(sample_feats)\n",
    "            for t in reverse_steps:\n",
    "                if t > min_t:\n",
    "                    sample_feats = self._set_t_feats(sample_feats, t, t_placeholder)\n",
    "                    model_out = self._model(sample_feats)\n",
    "                    #model_out = self.model(sample_feats)\n",
    "                    rot_score = model_out['rot_score']\n",
    "                    trans_score = model_out['trans_score']\n",
    "                    rigid_pred = model_out['rigids']\n",
    "#                     if self._model_conf.embed.embed_self_conditioning:\n",
    "#                         sample_feats['sc_ca_t'] = rigid_pred[..., 4:]\n",
    "                    fixed_mask = sample_feats['fixed_mask'] * sample_feats['res_mask']\n",
    "                    diffuse_mask = (1 - sample_feats['fixed_mask']) * sample_feats['res_mask']\n",
    "                    rigids_t = self.diffuser.reverse(\n",
    "                        rigid_t=ru.Rigid.from_tensor_7(sample_feats['rigids_t']),\n",
    "                        rot_score=du.move_to_np(rot_score),\n",
    "                        trans_score=du.move_to_np(trans_score),\n",
    "                        diffuse_mask=du.move_to_np(diffuse_mask),\n",
    "                        t=t,\n",
    "                        dt=dt,\n",
    "                        center=center,\n",
    "                        noise_scale=noise_scale,\n",
    "                    )\n",
    "                else:\n",
    "                    model_out = self._model(sample_feats)\n",
    "                    #model_out = self.model(sample_feats)\n",
    "                    rigids_t = ru.Rigid.from_tensor_7(model_out['rigids'])\n",
    "                sample_feats['rigids_t'] = rigids_t.to_tensor_7().to(device)\n",
    "                if aux_traj:\n",
    "                    all_rigids.append(du.move_to_np(rigids_t.to_tensor_7()))\n",
    "\n",
    "                # Calculate x0 prediction derived from score predictions.\n",
    "                gt_trans_0 = sample_feats['rigids_t'][..., 4:]\n",
    "                pred_trans_0 = rigid_pred[..., 4:]\n",
    "                trans_pred_0 = diffuse_mask[..., None] * pred_trans_0 + fixed_mask[..., None] * gt_trans_0\n",
    "                psi_pred = model_out['psi']\n",
    "                if aux_traj:\n",
    "                    atom37_0 = all_atom.compute_backbone(\n",
    "                        ru.Rigid.from_tensor_7(rigid_pred),\n",
    "                        psi_pred\n",
    "                    )[0]\n",
    "                    all_bb_0_pred.append(du.move_to_np(atom37_0))\n",
    "                    all_trans_0_pred.append(du.move_to_np(trans_pred_0))\n",
    "                atom37_t = all_atom.compute_backbone(\n",
    "                    rigids_t, psi_pred)[0]\n",
    "                all_bb_prots.append(du.move_to_np(atom37_t))\n",
    "\n",
    "        # Flip trajectory so that it starts from t=0.\n",
    "        # This helps visualization.\n",
    "        flip = lambda x: np.flip(np.stack(x), (0,))\n",
    "        all_bb_prots = flip(all_bb_prots)\n",
    "        if aux_traj:\n",
    "            all_rigids = flip(all_rigids)\n",
    "            all_trans_0_pred = flip(all_trans_0_pred)\n",
    "            all_bb_0_pred = flip(all_bb_0_pred)\n",
    "\n",
    "        ret = {\n",
    "            'prot_traj': all_bb_prots,\n",
    "        }\n",
    "        if aux_traj:\n",
    "            ret['rigid_traj'] = all_rigids\n",
    "            ret['trans_traj'] = all_trans_0_pred\n",
    "            ret['psi_pred'] = psi_pred[None]\n",
    "            ret['rigid_0_traj'] = all_bb_0_pred\n",
    "        return ret\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "33e16cff",
   "metadata": {},
   "outputs": [],
   "source": [
    "import se3_diffuse.utils as du"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6a31f547",
   "metadata": {},
   "outputs": [],
   "source": [
    "from data_rigid_diffuser import so3_diffuser\n",
    "from data_rigid_diffuser import r3_diffuser\n",
    "from data_rigid_diffuser import oneHot_diffuser\n",
    "from scipy.spatial.transform import Rotation\n",
    "from data_rigid_diffuser import rigid_utils as ru\n",
    "import yaml\n",
    "from data_rigid_diffuser.diffuser import FrameDiffNoise\n",
    "from gudiff_model import Data_Graph\n",
    "from gudiff_model.Data_Graph import build_npose_from_coords, dump_coord_pdb, define_graph_edges, make_pe_encoding\n",
    "from gudiff_model.Data_Graph import Helix4_Dataset, Make_KNN_MP_Graphs\n",
    "from gudiff_model.Data_Graph_Null import  Make_nullKNN_MP_Graphs\n",
    "from data_rigid_diffuser import diffuser"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "bf443f63",
   "metadata": {},
   "outputs": [],
   "source": [
    "from se3_transformer.model.basis import get_basis, update_basis_with_fused\n",
    "from se3_transformer.model.transformer import Sequential, SE3Transformer\n",
    "from se3_transformer.model.transformer_topk import SE3Transformer_topK\n",
    "from se3_transformer.model.FAPE_Loss import FAPE_loss, Qs2Rs, normQ\n",
    "from se3_transformer.model.layers.attentiontopK import AttentionBlockSE3\n",
    "from se3_transformer.model.layers.linear import LinearSE3\n",
    "from se3_transformer.model.layers.convolution import ConvSE3, ConvSE3FuseLevel\n",
    "from se3_transformer.model.layers.norm import NormSE3\n",
    "from se3_transformer.model.layers.pooling import GPooling, Latent_Unpool, Unpool_Layer\n",
    "from se3_transformer.runtime.utils import str2bool, to_cuda\n",
    "from se3_transformer.model.fiber import Fiber\n",
    "from se3_transformer.model.transformer import get_populated_edge_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "48bf9476",
   "metadata": {},
   "outputs": [],
   "source": [
    "from se3_transformer.model.FAPE_Loss import FAPE_loss_null, FAPE_loss_real\n",
    "from se3_transformer.model.FAPE_Loss import get_t"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e213e885",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "f3eae2f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# B = 16\n",
    "# L=65\n",
    "# limit = 1028\n",
    "# h4_trainData = Helix4_Dataset(coords_tog[:limit])\n",
    "# h4_valData = Helix4_Dataset(coords_apa[:limit])\n",
    "# train_dL = DataLoader(h4_trainData, batch_size=B, shuffle=True, drop_last=True)\n",
    "# val_dL   = DataLoader(h4_valData, batch_size=B, shuffle=True, drop_last=True)\n",
    "# testiter = iter(train_dL)\n",
    "# bb_dict = next(testiter)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3fbf8e13",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "87f67d73",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "581b3006",
   "metadata": {},
   "outputs": [],
   "source": [
    "#I think I adjusted inputs and outputs,\n",
    "#sigmoid for nodes features for real/null pred?\n",
    "#need loss function for real/null nodes\n",
    "#need to get function to just pull real nodes for viewing?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d16c6656",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27b0ba79",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "02ba860f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_pV_to_points(dict_in):\n",
    "    \n",
    "    CA_fp  = dict_in['bb_firstp']['CA'].reshape(B, L, 3).to(device)\n",
    "    NC_fp = CA_fp + dict_in['bb_firstp']['N_CA'].reshape(B, L, 3).to(device)\n",
    "    CC_fp = CA_fp + dict_in['bb_firstp']['C_CA'].reshape(B, L, 3).to(device)\n",
    "    fp =  torch.cat((NC_fp,CA_fp,CC_fp),dim=2).reshape(B,L,3,3)\n",
    "    \n",
    "    CA_lp  = dict_in['bb_firstp']['CA'].reshape(B, L, 3).to(device)\n",
    "    NC_lp = CA_fp + dict_in['bb_firstp']['N_CA'].reshape(B, L, 3).to(device)\n",
    "    CC_lp = CA_fp + dict_in['bb_firstp']['C_CA'].reshape(B, L, 3).to(device)\n",
    "    lp =  torch.cat((NC_lp,CA_lp,CC_lp),dim=2).reshape(B,L,3,3)\n",
    "    \n",
    "    return fp, lp\n",
    "def get_noise_pred_true_null(noised_dict, batched_t, graph_maker, graph_unet):\n",
    "    \n",
    "    CA_t  = noised_dict['bb_shifted']['CA'].reshape(B, L, 3).to('cuda')\n",
    "    NC_t = CA_t + noised_dict['bb_shifted']['N_CA'].reshape(B, L, 3).to('cuda')*N_CA_dist\n",
    "    CC_t = CA_t + noised_dict['bb_shifted']['C_CA'].reshape(B, L, 3).to('cuda')*C_CA_dist\n",
    "    true =  torch.cat((NC_t,CA_t,CC_t),dim=2).reshape(B,L,3,3)\n",
    "    \n",
    "    CA_n  = noised_dict['bb_noised']['CA'].reshape(B, L, 3).to('cuda')\n",
    "    NC_n = CA_n + noised_dict['bb_noised']['N_CA'].reshape(B, L, 3).to('cuda')*N_CA_dist\n",
    "    CC_n = CA_n + noised_dict['bb_noised']['C_CA'].reshape(B, L, 3).to('cuda')*C_CA_dist\n",
    "    noise_xyz =  torch.cat((NC_n,CA_n,CC_n),dim=2).reshape(B,L,3,3)\n",
    "    \n",
    "    feat_dict = graph_maker.prep_for_network(noised_dict)\n",
    "    out = graph_unet(feat_dict, batched_t)\n",
    "    CA_p = out['1'][:,0,:].reshape(B, L, 3)+CA_n #translation of Calpha\n",
    "    Qs = out['1'][:,1,:] # rotation\n",
    "    Qs = Qs.unsqueeze(1).repeat((1,2,1))\n",
    "    Qs = torch.cat((torch.ones((B*L,2,1),device=Qs.device),Qs),dim=-1).reshape(B,L,2,4)\n",
    "    Qs = normQ(Qs)\n",
    "    Rs = Qs2Rs(Qs)\n",
    "    N_C_to_Rot = torch.cat((noised_dict['bb_noised']['N_CA'].reshape(B, L, 3).to('cuda'),\n",
    "                            noised_dict['bb_noised']['C_CA'].reshape(B, L, 3).to('cuda')),dim=2).reshape(B,L,2,1,3)\n",
    "\n",
    "    \n",
    "    rot_vecs = einsum('bnkij,bnkhj->bnki',Rs, N_C_to_Rot)\n",
    "    NC_p = CA_p + rot_vecs[:,:,0,:].to('cuda')*N_CA_dist\n",
    "    CC_p = CA_p + rot_vecs[:,:,1,:].reshape(B, L, 3).to('cuda')*C_CA_dist\n",
    "\n",
    "    pred = torch.cat((NC_p,CA_p,CC_p),dim=2).reshape(B,L,3,3)\n",
    "    \n",
    "    nf_pred = out['0']\n",
    "    \n",
    "    nf_pred = out['0']\n",
    "    real_nodes_pred = torch.round(nf_pred ).clamp(0,1)\n",
    "    real_nodes_pred_mask = (real_nodes_pred.squeeze().sum(-1)>1.99).reshape(B,L)\n",
    "    \n",
    "    real_nodes_true_mask = noised_dict['real_nodes_mask']\n",
    "    #place roll here later\n",
    "#     true = true.to('cpu').numpy()*10\n",
    "#     noise_xyz = noise_xyz.to('cpu').numpy()*10\n",
    "#     pred = pred.detach().to('cpu').numpy()*10\n",
    "    \n",
    "    \n",
    "    return true, noise_xyz, pred , real_nodes_pred_mask, real_nodes_true_mask\n",
    "        \n",
    "def roll2_continous_true(real_mask_in):\n",
    "    \"\"\"Return roll amount to set zero on Nterminal residue for pdb file view\"\"\"\n",
    "\n",
    "    roll_con_out = []\n",
    "    for i,rmr in enumerate(real_mask_in):\n",
    "        ep_bool = (rmr^rmr.roll(-1) | rmr^rmr.roll(1)) & rmr\n",
    "        si = torch.arange(ep_bool.shape[0])[ep_bool]\n",
    "        #circular if start/end real nodes and we need to roll\n",
    "        if rmr[0] and rmr[-1]:\n",
    "            #roll last group across barrier\n",
    "            roll_con = -si[-1]\n",
    "        elif not rmr[0]: #move first group to front\n",
    "            roll_con = -si[0]\n",
    "        else:\n",
    "            roll_con=0\n",
    "\n",
    "        roll_con_out.append(roll_con)\n",
    "\n",
    "    return roll_con_out\n",
    "      \n",
    "def dump_tnp_null(true, noise, pred, t_val, e=0, numOut=1, real_mask=None, pred_mask=None, outdir='output/'):\n",
    "    \n",
    "    if numOut>true.shape[0]:\n",
    "        numOut = true.shape[0]\n",
    "    \n",
    "    tnk_dir = f'{outdir}/true_node_mask/'\n",
    "    pnk_dir = f'{outdir}/pred_node_mask/'\n",
    "    f_dir = f'{outdir}/full/'\n",
    "    \n",
    "    if not os.path.isdir(tnk_dir) and real_mask is not None:\n",
    "        os.makedirs(tnk_dir)\n",
    "    if not os.path.isdir(pnk_dir) and pred_mask is not None:\n",
    "        os.makedirs(pnk_dir)\n",
    "    if not os.path.isdir(f_dir) and real_mask is not None:\n",
    "        os.makedirs(f_dir)\n",
    "    \n",
    "    if real_mask is not None:\n",
    "        rc = roll2_continous_true(real_mask)\n",
    "        for x in range(numOut):\n",
    "            t_o = true[x].roll(int(rc[x]),dims=0).detach().to('cpu').numpy()*10\n",
    "            n_o = noise[x].roll(int(rc[x]),dims=0).detach().to('cpu').numpy()*10\n",
    "            p_o = pred[x].roll(int(rc[x]),dims=0).detach().to('cpu').numpy()*10\n",
    "            dump_coord_pdb(t_o, fileOut=f'{f_dir}/true_{t_val[x]*100:.0f}_e{e}_{x}.pdb')\n",
    "            dump_coord_pdb(n_o, fileOut=f'{f_dir}/noise_{t_val[x]*100:.0f}_e{e}_{x}.pdb')\n",
    "            dump_coord_pdb(p_o, fileOut=f'{f_dir}/pred_{t_val[x]*100:.0f}_e{e}_{x}.pdb')\n",
    "        \n",
    "    if pred_mask is not None:\n",
    "        rc = roll2_continous_true(pred_mask)\n",
    "        for x,c in enumerate(np.arange(numOut)):\n",
    "            t_o = true[x].roll(int(rc[x]),dims=0).detach().to('cpu').numpy()*10\n",
    "            n_o = noise[x].roll(int(rc[x]),dims=0).detach().to('cpu').numpy()*10\n",
    "            p_o = pred[x].roll(int(rc[x]),dims=0).detach().to('cpu').numpy()*10\n",
    "            pm = pred_mask[x].roll(int(rc[x]),dims=0)\n",
    "            dump_coord_pdb(t_o[pm], fileOut=f'{pnk_dir}/true_{t_val[x]*100:.0f}_e{e}_{x}.pdb')\n",
    "            dump_coord_pdb(n_o[pm], fileOut=f'{pnk_dir}/noise_{t_val[x]*100:.0f}_e{e}_{x}.pdb')\n",
    "            dump_coord_pdb(p_o[pm], fileOut=f'{pnk_dir}/pred_{t_val[x]*100:.0f}_e{e}_{x}.pdb')\n",
    "            \n",
    "    if real_mask is not None:\n",
    "        rc = roll2_continous_true(real_mask)\n",
    "        for x,c in enumerate(np.arange(numOut)):\n",
    "            t_o = true[x].roll(int(rc[x]),dims=0).detach().to('cpu').numpy()*10\n",
    "            n_o = noise[x].roll(int(rc[x]),dims=0).detach().to('cpu').numpy()*10\n",
    "            p_o = pred[x].roll(int(rc[x]),dims=0).detach().to('cpu').numpy()*10\n",
    "            rm = real_mask[x].roll(int(rc[x]),dims=0)\n",
    "            dump_coord_pdb(t_o[rm], fileOut=f'{pnk_dir}/true_{t_val[x]*100:.0f}_e{e}_{x}.pdb')\n",
    "            dump_coord_pdb(n_o[rm], fileOut=f'{pnk_dir}/noise_{t_val[x]*100:.0f}_e{e}_{x}.pdb')\n",
    "            dump_coord_pdb(p_o[rm], fileOut=f'{pnk_dir}/pred_{t_val[x]*100:.0f}_e{e}_{x}.pdb')\n",
    "            \n",
    "#     if real_mask is not None:\n",
    "#         rc = roll2_continous_true(real_mask)\n",
    "#         for x in range(numOut):\n",
    "#             dump_coord_pdb(true[x][real_mask[x]], fileOut=f'{tnk_dir}/true_{t_val[x]*100:.0f}_e{e}_{x}.pdb')\n",
    "#             dump_coord_pdb(noise[x][real_mask[x]], fileOut=f'{tnk_dir}/noise_{t_val[x]*100:.0f}_e{e}_{x}.pdb')\n",
    "#             dump_coord_pdb(pred[x][real_mask[x]], fileOut=f'{tnk_dir}/pred_{t_val[x]*100:.0f}_e{e}_{x}.pdb')\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "d7e3e99d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_pV_to_points(dict_in):\n",
    "    \n",
    "    CA_fp  = dict_in['bb_firstp']['CA'].to(device)\n",
    "    NC_fp = CA_fp + dict_in['bb_firstp']['N_CA'].to(device)\n",
    "    CC_fp = CA_fp +dict_in['bb_firstp']['C_CA'].to(device)\n",
    "    fp =  torch.cat((NC_fp,CA_fp,CC_fp),dim=2).reshape(B,1,3,3)\n",
    "    \n",
    "    CA_lp  = dict_in['bb_lastp']['CA'].to(device)\n",
    "    NC_lp = CA_fp + dict_in['bb_lastp']['N_CA'].to(device)\n",
    "    CC_lp = CA_fp + dict_in['bb_lastp']['C_CA'].to(device)\n",
    "    lp =  torch.cat((NC_lp,CA_lp,CC_lp),dim=2).reshape(B,1,3,3)\n",
    "    \n",
    "    return fp, lp\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "7eeb65f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "def model_step_null(noised_dict, batched_t, graph_maker, graph_unet, train=True):\n",
    "    #prep coordinates for output display from and comparison via FAPE\n",
    "    \n",
    "    CA_t  = noised_dict['bb_shifted']['CA'].reshape(B, L, 3).to(device)\n",
    "    NC_t = CA_t + noised_dict['bb_shifted']['N_CA'].reshape(B, L, 3).to(device)#not mult by bond distance, seems to help?\n",
    "    CC_t = CA_t + noised_dict['bb_shifted']['C_CA'].reshape(B, L, 3).to(device)#not mult \n",
    "    true =  torch.cat((NC_t,CA_t,CC_t),dim=2).reshape(B,L,3,3)\n",
    "\n",
    "    CA_n  = noised_dict['bb_noised']['CA'].reshape(B, L, 3).to(device)\n",
    "    NC_n = CA_n + noised_dict['bb_noised']['N_CA'].reshape(B, L, 3).to(device)\n",
    "    CC_n = CA_n + noised_dict['bb_noised']['C_CA'].reshape(B, L, 3).to(device)\n",
    "    noise_xyz =  torch.cat((NC_n,CA_n,CC_n),dim=2).reshape(B,L,3,3)\n",
    "\n",
    "    #prepare graphs\n",
    "    feat_dict = graph_maker.prep_for_network(noised_dict, cuda=True)\n",
    "    out =graph_unet(feat_dict,batched_t)\n",
    "    \n",
    "    \n",
    "    #FAPE Loss for the prediction\n",
    "    CA_p = out['1'][:,0,:].reshape(B, L, 3)+CA_n #translation of Calpha\n",
    "    Qs = out['1'][:,1,:] # rotation , convert from x,y,z (Quat) to rotate input vectors\n",
    "    Qs = Qs.unsqueeze(1).repeat((1,2,1))\n",
    "    Qs = torch.cat((torch.ones((B*L,2,1),device=Qs.device),Qs),dim=-1).reshape(B,L,2,4)\n",
    "    Qs = normQ(Qs)\n",
    "    Rs = Qs2Rs(Qs)\n",
    "    N_C_to_Rot = torch.cat((noised_dict['bb_noised']['N_CA'].reshape(B, L, 3).to(device),\n",
    "                            noised_dict['bb_noised']['C_CA'].reshape(B, L, 3).to(device)),dim=2).reshape(B,L,2,1,3)\n",
    "    rot_vecs = einsum('bnkij,bnkhj->bnki',Rs, N_C_to_Rot)\n",
    "    NC_p = CA_p + rot_vecs[:,:,0,:]*N_CA_dist #comparable but seems better not have it for true, but have it for pred\n",
    "    CC_p = CA_p + rot_vecs[:,:,1,:]*C_CA_dist #maybe this helep prevent \n",
    "\n",
    "    pred = torch.cat((NC_p,CA_p,CC_p),dim=2).reshape(B,L,3,3)\n",
    "    \n",
    "    #divide loss by real and null nodes\n",
    "    \n",
    "    fp, lp  = convert_pV_to_points(noised_dict)\n",
    "\n",
    "    real_mask = noised_dict['real_nodes_mask'].to('cuda')\n",
    "    score_scales = noised_dict['score_scales'].to('cuda')\n",
    "\n",
    "    lr, lr_d = FAPE_loss_real(pred, true, score_scales, real_mask,  d_clamp=10.0, d_clamp_inter=30.0,\n",
    "                   A=10.0, gamma=1.0, eps=1e-6)\n",
    "    \n",
    "    ln, ln_d = FAPE_loss_null(pred, fp, lp, real_mask, score_scales,  d_clamp=10.0,\n",
    "                       d_clamp_inter=30.0, A=10.0, gamma=1.0, eps=1e-6)\n",
    "    \n",
    "    structure_loss = lr*score_weights['3D_real']+ln*score_weights['3D_null']\n",
    "    \n",
    "    #score for node feats determining whether node is real or fake\n",
    "    nf_pred = out['0']\n",
    "\n",
    "    nf_feat_dim = noised_dict['real_nodes_noise'].shape[-1]\n",
    "    nf_true = torch.ones(noised_dict['real_nodes_mask'].shape+(nf_feat_dim,) + (1,),\n",
    "                         dtype=torch.float,device=device)\n",
    "\n",
    "    nf_real_mask_mult = real_mask.unsqueeze(-1).unsqueeze(-1).to(device)\n",
    "    nf_true = nf_true*nf_real_mask_mult\n",
    "\n",
    "    nf_pred = nf_pred.reshape(B,-1,nf_feat_dim)\n",
    "    pred_nf_loss = torch.sum(torch.abs(nf_true.squeeze()-nf_pred),dim=-1) #absolute value loss\n",
    "    pred_nf_loss = pred_nf_loss.to(device)\n",
    "    \n",
    "    ss_scales = to_cuda(noised_dict['score_scales'])[:,None,None]\n",
    "    pnfloss = (torch.sum((pred_nf_loss*ss_scales/L)))*score_weights['nf_real']\n",
    "    \n",
    "    final_loss = structure_loss + pnfloss\n",
    "    \n",
    "    \n",
    "    return final_loss, pnfloss.detach().cpu(), structure_loss.detach().cpu(), lr.detach().cpu(), ln.detach().cpu()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c9e308d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8ea96ff",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8bfa33c0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d4d19f1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "97322803",
   "metadata": {},
   "outputs": [],
   "source": [
    "device='cuda'\n",
    "\n",
    "B = 8\n",
    "L= 128\n",
    "limit = 1028\n",
    "prot_trainData = Data_Graph.ProteinBB_Dataset(coords_tog[:limit], n_nodes=L,\n",
    "              n_atoms=5, coord_div=10, cast_type=torch.float32)\n",
    "train_dL = DataLoader(prot_trainData, batch_size=B, shuffle=True, drop_last=True)\n",
    "stride=4##########\n",
    "mkg = Make_nullKNN_MP_Graphs(KNN=30, mp_stride=stride, n_nodes=L)\n",
    "\n",
    "score_weights = {}\n",
    "score_weights['nf_real'] = torch.tensor(0.2,device=device)\n",
    "score_weights['3D_real'] = torch.tensor(1.0,device=device)\n",
    "score_weights['3D_null'] = torch.tensor(1.0,device=device)\n",
    "\n",
    "config_path='data_rigid_diffuser/base.yaml'\n",
    "fnd = FrameDiffNoise(config_path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "77cce375",
   "metadata": {},
   "outputs": [],
   "source": [
    "gunn= GraphUNet_Null(fiber_start = Fiber({0:17, 1:2}),\n",
    "                     fiber_out = Fiber({0:5,1:2}),\n",
    "                      k=4,\n",
    "                      batch_size = B,\n",
    "                      stride=stride,\n",
    "                       max_degree=3,\n",
    "                       channels=64,\n",
    "                      num_heads = 16,\n",
    "                      channels_div=8,\n",
    "                      num_layers = 1,\n",
    "                     num_layers_ca = 2,\n",
    "                     edge_feature_dim=1,\n",
    "                     latent_pool_type = 'max',\n",
    "                     t_size = 12,\n",
    "                     mult=2,\n",
    "                    zero_lin=True,\n",
    "                   use_tdeg1 = False,\n",
    "                 cuda=True).to('cuda')\n",
    "\n",
    "opti = torch.optim.Adam(gunn.parameters(), lr=0.0005, weight_decay=5e-6)\n",
    "#opti =torch.optim.Adadelta(gunn.parameters(), lr=0.0005, weight_decay=5e-7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "7bf8bd0c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.optim.adadelta.Adadelta"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.optim.Adadelta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "8b7af006",
   "metadata": {},
   "outputs": [],
   "source": [
    "testiter = iter(train_dL)\n",
    "bb_dict = next(testiter)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "1be1401e",
   "metadata": {},
   "outputs": [],
   "source": [
    "t_cpu = np.ones((B,))*0.01\n",
    "noised_dict = fnd.forward(bb_dict,t_vec=t_cpu)\n",
    "batched_t = to_cuda(noised_dict['t_vec'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "4b615080",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/nwoodall/miniconda3/envs/se33/lib/python3.9/site-packages/torch/utils/checkpoint.py:31: UserWarning: None of the inputs have requires_grad=True. Gradients will be None\n",
      "  warnings.warn(\"None of the inputs have requires_grad=True. Gradients will be None\")\n",
      "/home/nwoodall/miniconda3/envs/se33/lib/python3.9/site-packages/dgl/backend/pytorch/tensor.py:449: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()\n",
      "  assert input.numel() == input.storage().size(), (\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 tensor(3221.5481, device='cuda:0') tensor(2649.7085) tensor(443.5340) tensor(128.3047)\n",
      "1 tensor(721.7962, device='cuda:0') tensor(187.8804) tensor(426.0406) tensor(107.8751)\n",
      "2 tensor(524.7708, device='cuda:0') tensor(6.3072) tensor(419.9707) tensor(98.4929)\n",
      "3 tensor(509.0513, device='cuda:0') tensor(4.0618) tensor(413.1630) tensor(91.8263)\n",
      "4 tensor(499.3692, device='cuda:0') tensor(1.8367) tensor(408.9172) tensor(88.6152)\n",
      "5 tensor(495.5051, device='cuda:0') tensor(0.8494) tensor(407.3964) tensor(87.2594)\n",
      "6 tensor(496.9202, device='cuda:0') tensor(1.4569) tensor(408.6588) tensor(86.8044)\n",
      "7 tensor(493.8044, device='cuda:0') tensor(0.7936) tensor(407.4102) tensor(85.6007)\n",
      "8 tensor(491.7913, device='cuda:0') tensor(1.2068) tensor(406.0603) tensor(84.5241)\n",
      "9 tensor(488.5466, device='cuda:0') tensor(1.5562) tensor(403.9198) tensor(83.0707)\n",
      "10 tensor(484.4487, device='cuda:0') tensor(0.5390) tensor(403.2652) tensor(80.6445)\n",
      "11 tensor(481.1455, device='cuda:0') tensor(0.4078) tensor(401.9539) tensor(78.7837)\n",
      "12 tensor(478.2026, device='cuda:0') tensor(0.2079) tensor(400.9020) tensor(77.0928)\n",
      "13 tensor(474.8612, device='cuda:0') tensor(0.2196) tensor(400.6619) tensor(73.9797)\n",
      "14 tensor(473.4901, device='cuda:0') tensor(0.8739) tensor(399.3948) tensor(73.2215)\n",
      "15 tensor(468.6091, device='cuda:0') tensor(0.2750) tensor(397.2854) tensor(71.0488)\n",
      "16 tensor(467.0658, device='cuda:0') tensor(0.1887) tensor(397.2616) tensor(69.6156)\n",
      "17 tensor(464.7002, device='cuda:0') tensor(0.1762) tensor(396.1198) tensor(68.4043)\n",
      "18 tensor(462.8651, device='cuda:0') tensor(0.1286) tensor(396.0864) tensor(66.6500)\n",
      "19 tensor(459.7138, device='cuda:0') tensor(0.1261) tensor(394.3859) tensor(65.2017)\n",
      "20 tensor(460.9500, device='cuda:0') tensor(2.4028) tensor(394.8625) tensor(63.6847)\n",
      "21 tensor(455.2230, device='cuda:0') tensor(0.4518) tensor(390.8613) tensor(63.9100)\n",
      "22 tensor(450.2308, device='cuda:0') tensor(0.2255) tensor(388.4796) tensor(61.5258)\n",
      "23 tensor(450.7272, device='cuda:0') tensor(2.1631) tensor(386.9889) tensor(61.5751)\n",
      "24 tensor(441.6721, device='cuda:0') tensor(0.2580) tensor(381.2077) tensor(60.2064)\n",
      "25 tensor(438.3170, device='cuda:0') tensor(0.0759) tensor(378.9686) tensor(59.2725)\n",
      "26 tensor(537.4526, device='cuda:0') tensor(57.8400) tensor(399.1910) tensor(80.4215)\n",
      "27 tensor(486.5722, device='cuda:0') tensor(1.7096) tensor(402.2144) tensor(82.6480)\n",
      "28 tensor(475.6711, device='cuda:0') tensor(1.0660) tensor(399.8142) tensor(74.7909)\n",
      "29 tensor(469.0255, device='cuda:0') tensor(1.4766) tensor(396.2985) tensor(71.2503)\n",
      "30 tensor(464.1310, device='cuda:0') tensor(0.0390) tensor(395.4902) tensor(68.6020)\n",
      "31 tensor(461.4666, device='cuda:0') tensor(0.4446) tensor(395.1832) tensor(65.8387)\n",
      "32 tensor(457.6926, device='cuda:0') tensor(0.1059) tensor(393.2300) tensor(64.3567)\n",
      "33 tensor(458.2358, device='cuda:0') tensor(0.0622) tensor(392.7801) tensor(65.3935)\n",
      "34 tensor(453.8103, device='cuda:0') tensor(0.0083) tensor(391.5746) tensor(62.2274)\n",
      "35 tensor(453.1089, device='cuda:0') tensor(0.0334) tensor(390.2734) tensor(62.8024)\n",
      "36 tensor(449.2149, device='cuda:0') tensor(0.1153) tensor(388.7463) tensor(60.3533)\n",
      "37 tensor(448.2466, device='cuda:0') tensor(0.0767) tensor(387.2961) tensor(60.8739)\n",
      "38 tensor(445.4190, device='cuda:0') tensor(0.0535) tensor(385.8611) tensor(59.5045)\n",
      "39 tensor(440.4971, device='cuda:0') tensor(0.0025) tensor(382.0197) tensor(58.4749)\n",
      "40 tensor(435.1274, device='cuda:0') tensor(0.0033) tensor(377.9801) tensor(57.1440)\n",
      "41 tensor(430.5036, device='cuda:0') tensor(0.0040) tensor(374.7790) tensor(55.7205)\n",
      "42 tensor(427.2604, device='cuda:0') tensor(0.0032) tensor(371.5925) tensor(55.6646)\n",
      "43 tensor(423.3967, device='cuda:0') tensor(0.1755) tensor(369.4853) tensor(53.7358)\n",
      "44 tensor(419.2504, device='cuda:0') tensor(0.1910) tensor(366.3576) tensor(52.7019)\n",
      "45 tensor(416.0633, device='cuda:0') tensor(0.0026) tensor(364.3643) tensor(51.6964)\n",
      "46 tensor(410.9224, device='cuda:0') tensor(0.0026) tensor(360.4525) tensor(50.4673)\n",
      "47 tensor(434.8892, device='cuda:0') tensor(0.0041) tensor(374.6582) tensor(60.2270)\n",
      "48 tensor(439.4052, device='cuda:0') tensor(0.0061) tensor(378.2735) tensor(61.1257)\n",
      "49 tensor(429.1835, device='cuda:0') tensor(0.0038) tensor(372.5628) tensor(56.6169)\n",
      "50 tensor(425.2114, device='cuda:0') tensor(0.0041) tensor(369.6381) tensor(55.5692)\n",
      "51 tensor(419.3882, device='cuda:0') tensor(0.0030) tensor(365.3520) tensor(54.0332)\n",
      "52 tensor(416.2638, device='cuda:0') tensor(0.0031) tensor(363.6121) tensor(52.6486)\n",
      "53 tensor(413.5621, device='cuda:0') tensor(0.0028) tensor(362.1032) tensor(51.4561)\n",
      "54 tensor(410.8506, device='cuda:0') tensor(0.0018) tensor(359.9374) tensor(50.9116)\n",
      "55 tensor(409.0936, device='cuda:0') tensor(0.0018) tensor(357.7891) tensor(51.3026)\n",
      "56 tensor(404.7655, device='cuda:0') tensor(0.0017) tensor(355.8239) tensor(48.9401)\n",
      "57 tensor(403.5749, device='cuda:0') tensor(0.0143) tensor(354.6316) tensor(48.9290)\n",
      "58 tensor(403.5695, device='cuda:0') tensor(0.3414) tensor(355.1867) tensor(48.0413)\n",
      "59 tensor(402.5637, device='cuda:0') tensor(0.0143) tensor(354.0202) tensor(48.5291)\n",
      "60 tensor(401.1631, device='cuda:0') tensor(0.2449) tensor(353.6154) tensor(47.3030)\n",
      "61 tensor(399.3080, device='cuda:0') tensor(0.0009) tensor(352.7016) tensor(46.6053)\n",
      "62 tensor(398.5374, device='cuda:0') tensor(0.0012) tensor(350.9989) tensor(47.5372)\n",
      "63 tensor(396.4164, device='cuda:0') tensor(0.0002) tensor(349.6059) tensor(46.8103)\n",
      "64 tensor(395.2093, device='cuda:0') tensor(0.0003) tensor(347.7632) tensor(47.4457)\n",
      "65 tensor(393.5380, device='cuda:0') tensor(0.0003) tensor(347.6620) tensor(45.8757)\n",
      "66 tensor(393.0102, device='cuda:0') tensor(0.0003) tensor(347.1361) tensor(45.8738)\n",
      "67 tensor(390.4869, device='cuda:0') tensor(0.0008) tensor(345.3205) tensor(45.1658)\n",
      "68 tensor(390.7988, device='cuda:0') tensor(0.0003) tensor(345.2515) tensor(45.5470)\n",
      "69 tensor(389.1422, device='cuda:0') tensor(0.0002) tensor(344.3288) tensor(44.8130)\n",
      "70 tensor(386.8400, device='cuda:0') tensor(0.0002) tensor(342.0103) tensor(44.8295)\n",
      "71 tensor(385.0645, device='cuda:0') tensor(0.0007) tensor(339.5315) tensor(45.5323)\n",
      "72 tensor(379.3577, device='cuda:0') tensor(0.0004) tensor(335.0187) tensor(44.3386)\n",
      "73 tensor(375.7636, device='cuda:0') tensor(0.0007) tensor(330.6038) tensor(45.1592)\n",
      "74 tensor(376.6469, device='cuda:0') tensor(0.0002) tensor(331.6874) tensor(44.9592)\n",
      "75 tensor(373.7442, device='cuda:0') tensor(0.0001) tensor(329.0865) tensor(44.6577)\n",
      "76 tensor(373.9803, device='cuda:0') tensor(0.0001) tensor(329.8415) tensor(44.1387)\n",
      "77 tensor(370.4177, device='cuda:0') tensor(0.3239) tensor(326.2426) tensor(43.8513)\n",
      "78 tensor(365.5276, device='cuda:0') tensor(0.0001) tensor(322.7634) tensor(42.7641)\n",
      "79 tensor(364.3218, device='cuda:0') tensor(0.0001) tensor(321.3036) tensor(43.0182)\n",
      "80 tensor(363.8008, device='cuda:0') tensor(9.0403e-05) tensor(320.7256) tensor(43.0749)\n",
      "81 tensor(361.2311, device='cuda:0') tensor(8.6470e-05) tensor(317.9082) tensor(43.3227)\n",
      "82 tensor(366.3040, device='cuda:0') tensor(1.1817) tensor(320.8825) tensor(44.2399)\n",
      "83 tensor(364.5942, device='cuda:0') tensor(0.0051) tensor(320.7852) tensor(43.8039)\n",
      "84 tensor(360.9010, device='cuda:0') tensor(0.1629) tensor(318.2293) tensor(42.5089)\n",
      "85 tensor(360.3383, device='cuda:0') tensor(0.0007) tensor(317.5934) tensor(42.7442)\n",
      "86 tensor(358.7050, device='cuda:0') tensor(0.0005) tensor(316.7149) tensor(41.9896)\n",
      "87 tensor(357.5758, device='cuda:0') tensor(0.0004) tensor(315.3867) tensor(42.1886)\n",
      "88 tensor(355.6270, device='cuda:0') tensor(0.0003) tensor(313.3973) tensor(42.2292)\n",
      "89 tensor(355.4436, device='cuda:0') tensor(0.0003) tensor(312.8431) tensor(42.6002)\n",
      "90 tensor(353.3784, device='cuda:0') tensor(0.0002) tensor(311.9073) tensor(41.4709)\n",
      "91 tensor(352.8914, device='cuda:0') tensor(0.0004) tensor(310.2683) tensor(42.6228)\n",
      "92 tensor(350.3728, device='cuda:0') tensor(0.0002) tensor(309.6812) tensor(40.6916)\n",
      "93 tensor(348.7525, device='cuda:0') tensor(0.0004) tensor(307.4651) tensor(41.2870)\n",
      "94 tensor(348.5085, device='cuda:0') tensor(0.0003) tensor(307.4258) tensor(41.0823)\n",
      "95 tensor(348.5995, device='cuda:0') tensor(0.0001) tensor(308.1937) tensor(40.4057)\n",
      "96 tensor(348.4612, device='cuda:0') tensor(0.0002) tensor(306.4120) tensor(42.0491)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "97 tensor(347.9015, device='cuda:0') tensor(0.0001) tensor(307.3578) tensor(40.5437)\n",
      "98 tensor(347.9319, device='cuda:0') tensor(0.0002) tensor(306.9611) tensor(40.9706)\n",
      "99 tensor(345.1673, device='cuda:0') tensor(0.0002) tensor(305.2675) tensor(39.8996)\n"
     ]
    }
   ],
   "source": [
    "t=0.02\n",
    "for e in range(100):\n",
    "    pnf_Score=0\n",
    "    e_score = 0\n",
    "    r_score = 0\n",
    "    l_score = 0\n",
    "    for i, bb_dict in enumerate(train_dL):\n",
    "        t_cpu = np.ones((B,))*t\n",
    "        \n",
    "        noised_dict = fnd.forward(bb_dict,t_vec=t_cpu)\n",
    "        batched_t = to_cuda(noised_dict['t_vec'])\n",
    "\n",
    "\n",
    "        #final_loss, pred_nf_loss, loss_3D = model_step_null(noised_dict,batched_t, mkg, gunn, train=True)\n",
    "        final_loss, pnfloss, structure_loss, real_loss, null_loss = model_step_null(noised_dict,batched_t, mkg, gunn, train=True)\n",
    "        \n",
    "        opti.zero_grad()\n",
    "        final_loss.backward()\n",
    "        opti.step()\n",
    "        fl = final_loss.detach()\n",
    "        e_score += fl\n",
    "        pnf_Score += pnfloss\n",
    "        r_score += real_loss\n",
    "        l_score += null_loss\n",
    "    #print(e,e_score,pred_nf_loss.sum(), loss_3D.sum())\n",
    "    if e%5==1:\n",
    "        true, noise_xyz, pred , real_nodes_pred_mask, real_nodes_true_mask = get_noise_pred_true_null(noised_dict, batched_t, mkg, gunn)\n",
    "        dump_tnp_null(true, noise_xyz, pred, t_cpu,e=e, numOut=1, real_mask=real_nodes_true_mask, pred_mask=None, outdir='output/')\n",
    "        \n",
    "    print(e,e_score,pnf_Score,r_score,l_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c0873f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i, bb_dict in enumerate(train_dL):\n",
    "    t_cpu = np.ones((B,))*0.05\n",
    "    batched_t = to_cuda(noised_dict['t_vec'])\n",
    "    noised_dict = fnd.forward(bb_dict,t_vec=t_cpu)\n",
    "    break\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6291b623",
   "metadata": {},
   "outputs": [],
   "source": [
    "feat_dict = mkg.prep_for_network(noised_dict)\n",
    "out = gunn(feat_dict, batched_t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "333b5d31",
   "metadata": {},
   "outputs": [],
   "source": [
    "noised_dict['real_nodes_noise'].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8b3613b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#final_loss, pred_nf_loss, loss_3D = model_step_null(noised_dict, batched_t, mkg, gunn, train=True)\n",
    "#final_loss, pred_nf_loss, loss_3D = model_step_null(noised_dict, batched_t, mkg, gunn, train=True)\n",
    "true, noise_xyz, pred , real_nodes_pred_mask, real_nodes_true_mask = get_noise_pred_true_null(noised_dict, batched_t, mkg, gunn)\n",
    "dump_tnp_null(true, noise_xyz, pred, t_cpu, numOut=1, real_mask=real_nodes_true_mask, pred_mask=None, outdir='output/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77c515ab",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ebc1824c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c89d1e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# device='cuda'\n",
    "\n",
    "# B = 8\n",
    "# L= 128\n",
    "# limit = 1028\n",
    "# prot_trainData = Data_Graph.ProteinBB_Dataset(coords_tog[:limit], n_nodes=L,\n",
    "#               n_atoms=5, coord_div=10, cast_type=torch.float32)\n",
    "# train_dL = DataLoader(prot_trainData, batch_size=B, shuffle=True, drop_last=True)\n",
    "# stride=4##########\n",
    "# mkg = Make_nullKNN_MP_Graphs(KNN=30, mp_stride=stride, n_nodes=L)\n",
    "\n",
    "# score_weights = {}\n",
    "# score_weights['nf_real'] = torch.tensor(0.2,device=device)\n",
    "# score_weights['3D_real'] = torch.tensor(1.0,device=device)\n",
    "# score_weights['3D_null'] = torch.tensor(1.0,device=device)\n",
    "\n",
    "# config_path='data_rigid_diffuser/base.yaml'\n",
    "# fnd = FrameDiffNoise(config_path)\n",
    "\n",
    "# gunn= GraphUNet_Null(fiber_start = Fiber({0:17, 1:2}),\n",
    "#                      fiber_out = Fiber({0:5,1:2}),\n",
    "#                       k=4,\n",
    "#                       batch_size = B,\n",
    "#                       stride=stride,\n",
    "#                        max_degree=3,\n",
    "#                        channels=64,\n",
    "#                       num_heads = 16,\n",
    "#                       channels_div=8,\n",
    "#                       num_layers = 1,\n",
    "#                      num_layers_ca = 2,\n",
    "#                      edge_feature_dim=1,\n",
    "#                      latent_pool_type = 'max',\n",
    "#                      t_size = 12,\n",
    "#                      mult=2,\n",
    "#                     zero_lin=True,\n",
    "#                    use_tdeg1 = False,\n",
    "#                  cuda=True).to('cuda')\n",
    "\n",
    "# opti = torch.optim.Adam(gunn.parameters(), lr=0.0005, weight_decay=5e-6)\n",
    "# #opti =torch.optim.Adadelta(gunn.parameters(), lr=0.0005, weight_decay=5e-7)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "fc000156",
   "metadata": {},
   "outputs": [],
   "source": [
    "# testiter = iter(train_dL)\n",
    "# bb_dict = next(testiter)\n",
    "\n",
    "# t_cpu = np.ones((B,))*0.05\n",
    "# noised_dict = fnd.forward(bb_dict,t_vec=t_cpu)\n",
    "# batched_t = to_cuda(noised_dict['t_vec'])\n",
    "# CA_t  = noised_dict['bb_shifted']['CA'].reshape(B, L, 3).to(device)\n",
    "# NC_t = CA_t + noised_dict['bb_shifted']['N_CA'].reshape(B, L, 3).to(device)#not mult by bond distance, seems to help?\n",
    "# CC_t = CA_t + noised_dict['bb_shifted']['C_CA'].reshape(B, L, 3).to(device)#not mult \n",
    "# true =  torch.cat((NC_t,CA_t,CC_t),dim=2).reshape(B,L,3,3)\n",
    "\n",
    "# CA_n  = noised_dict['bb_noised']['CA'].reshape(B, L, 3).to(device)\n",
    "# NC_n = CA_n + noised_dict['bb_noised']['N_CA'].reshape(B, L, 3).to(device)\n",
    "# CC_n = CA_n + noised_dict['bb_noised']['C_CA'].reshape(B, L, 3).to(device)\n",
    "# noise_xyz =  torch.cat((NC_n,CA_n,CC_n),dim=2).reshape(B,L,3,3)\n",
    "\n",
    "# #prepare graphs\n",
    "# feat_dict = mkg.prep_for_network(noised_dict, cuda=True)\n",
    "# out =gunn(feat_dict,batched_t)\n",
    "\n",
    "\n",
    "# #FAPE Loss for the prediction\n",
    "# CA_p = out['1'][:,0,:].reshape(B, L, 3)+CA_n #translation of Calpha\n",
    "# Qs = out['1'][:,1,:] # rotation , convert from x,y,z (Quat) to rotate input vectors\n",
    "# Qs = Qs.unsqueeze(1).repeat((1,2,1))\n",
    "# Qs = torch.cat((torch.ones((B*L,2,1),device=Qs.device),Qs),dim=-1).reshape(B,L,2,4)\n",
    "# Qs = normQ(Qs)\n",
    "# Rs = Qs2Rs(Qs)\n",
    "# N_C_to_Rot = torch.cat((noised_dict['bb_noised']['N_CA'].reshape(B, L, 3).to(device),\n",
    "#                         noised_dict['bb_noised']['C_CA'].reshape(B, L, 3).to(device)),dim=2).reshape(B,L,2,1,3)\n",
    "# rot_vecs = einsum('bnkij,bnkhj->bnki',Rs, N_C_to_Rot)\n",
    "# NC_p = CA_p + rot_vecs[:,:,0,:]*N_CA_dist #comparable but seems better not have it for true, but have it for pred\n",
    "# CC_p = CA_p + rot_vecs[:,:,1,:]*C_CA_dist #maybe this helep prevent \n",
    "\n",
    "# pred = torch.cat((NC_p,CA_p,CC_p),dim=2).reshape(B,L,3,3)\n",
    "\n",
    "# #divide loss by real and null nodes\n",
    "\n",
    "# fp, lp  = convert_pV_to_points(noised_dict)\n",
    "\n",
    "# real_mask = noised_dict['real_nodes_mask'].to('cuda')\n",
    "# score_scales = noised_dict['score_scales'].to('cuda')\n",
    "\n",
    "# lr, lr_d = FAPE_loss_real(pred, true, score_scales, real_mask,  d_clamp=10.0, d_clamp_inter=30.0,\n",
    "#                A=10.0, gamma=1.0, eps=1e-6)\n",
    "# ln, ln_d = FAPE_loss_null(pred, fp, lp, real_mask, true, score_scales,  d_clamp=10.0,\n",
    "#                    d_clamp_inter=30.0, A=10.0, gamma=0.1, eps=1e-6)\n",
    "# ld, ln_d = FAPE_loss(pred.unsqueeze(0), true,score_scales,  d_clamp=10.0,\n",
    "#                    d_clamp_inter=30.0, A=10.0, gamma=1.0, eps=1e-6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3586095",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "se33",
   "language": "python",
   "name": "se33"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
