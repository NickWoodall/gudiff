{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "7acea87f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from gudiff_model import PDBDataSet_GraphCon\n",
    "from gudiff_model.Graph_UNet import GraphUNet\n",
    "from data_rigid_diffuser.diffuser import FrameDiffNoise\n",
    "from se3_transformer.model.fiber import Fiber\n",
    "import torch\n",
    "import os\n",
    "import logging\n",
    "from datetime import datetime\n",
    "from collections import defaultdict\n",
    "import time\n",
    "import tree\n",
    "from se3_transformer.model.FAPE_Loss import FAPE_loss, Qs2Rs, normQ\n",
    "from torch import einsum\n",
    "import numpy as np\n",
    "import se3_diffuse.utils as du\n",
    "import copy\n",
    "import util.pdb_writer "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "076c447f",
   "metadata": {},
   "outputs": [],
   "source": [
    "conf = {'batch_size'  : 16,\n",
    "              'topk'  : 4,\n",
    "            'stride'  : 4,\n",
    "                'KNN' : 30,\n",
    "          'num_heads' : 8,\n",
    "           'channels' : 32,\n",
    "       'channels_div' : 4,\n",
    "        'nodefeats_0': 32,\n",
    "        'nodefeats_1':  6,\n",
    "         'num_layers' : 1,\n",
    "     'num_layers_ca'  : 2,\n",
    "   'edge_feature_dim' : 1,\n",
    "  'latent_pool_type'  : 'avg',\n",
    "            't_size'  : 12,\n",
    "             'max_t'  : 0.2,\n",
    "               'mult' : 2,\n",
    "           'zero_lin' : True,\n",
    "          'use_tdeg1' : True,\n",
    "                'cuda': True,\n",
    "      'learning rate' : 0.0005,\n",
    "       'weight_decay' :  5e-6,\n",
    "        'device'      : 'cuda',\n",
    "        'num_epoch'   : 100,\n",
    "        'log_freq'    : 1000,\n",
    "        'ckpt_freq'   : 10000,\n",
    "        'early_chkpt' : 2,\n",
    "        'coord_scale' : 10.0,\n",
    "        'dataset_max' : 5000,\n",
    "        'meta_data_path' : '/mnt/h/datasets/bCov_4H/metadata.csv',\n",
    "        'sample_mode' : 'single_length',\n",
    "           'ckpt_dir' : 'GUN_checkpoints/',\n",
    "              'eval_dir' : 'Eval_Direc/',\n",
    "       }\n",
    "\n",
    "#check use_tdeg1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "ad33c215",
   "metadata": {},
   "outputs": [],
   "source": [
    "def optimizer_to(optim, device):\n",
    "    for param in optim.state.values():\n",
    "        # Not sure there are any global tensors in the state dict\n",
    "        if isinstance(param, torch.Tensor):\n",
    "            param.data = param.data.to(device)\n",
    "            if param._grad is not None:\n",
    "                param._grad.data = param._grad.data.to(device)\n",
    "        elif isinstance(param, dict):\n",
    "            for subparam in param.values():\n",
    "                if isinstance(subparam, torch.Tensor):\n",
    "                    subparam.data = subparam.data.to(device)\n",
    "                    if subparam._grad is not None:\n",
    "                        subparam._grad.data = subparam._grad.data.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "d5eb8587",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Experiment:\n",
    "\n",
    "    def __init__(self,\n",
    "                 conf,\n",
    "                 ckpt_model=None,\n",
    "                 cur_step=None,\n",
    "                 cur_epoch=None,\n",
    "                 name='gu_null',\n",
    "                 cast_type=torch.float32,\n",
    "                 ckpt_opt=None):\n",
    "        \"\"\"Initialize experiment.\n",
    "        Args:\n",
    "            exp_cfg: Experiment configuration.\n",
    "        \"\"\"\n",
    "#         with open(config_path, 'r') as file:\n",
    "#             config = yaml.safe_load(file)\n",
    "#         conf = Struct(config)\n",
    "        #figure out logging\n",
    "        logging.basicConfig(filename='test.log', level=logging.INFO)\n",
    "        self._log = logging.getLogger(__name__)\n",
    "        \n",
    "\n",
    "        self.name=name\n",
    "        self._conf = conf\n",
    "        if conf['cuda']:\n",
    "            self.device = 'cuda'\n",
    "        else:\n",
    "            self.device = 'cpu'\n",
    "        \n",
    "        self.coord_scale = conf['coord_scale']\n",
    "        self.N_CA_dist = (PDBDataSet_GraphCon.N_CA_dist/self.coord_scale).to(self.device)\n",
    "        self.C_CA_dist = (PDBDataSet_GraphCon.C_CA_dist/self.coord_scale).to(self.device)\n",
    "        self.cast_type = cast_type\n",
    "        \n",
    "        self.num_epoch = conf['num_epoch']\n",
    "        self.log_freq = conf['log_freq']\n",
    "        self.ckpt_freq = conf['ckpt_freq']\n",
    "        self.early_ckpt = conf['early_chkpt']\n",
    "        \n",
    "        \n",
    "        self.meta_data_path = conf['meta_data_path']\n",
    "        self.sample_mode = conf['sample_mode']\n",
    "        self.B = conf['batch_size']\n",
    "        self.limit = conf['dataset_max']\n",
    "        \n",
    "        #graph properties\n",
    "        self.KNN = conf['KNN']\n",
    "        self.stride = conf['stride']\n",
    "        \n",
    "        #gudiff params\n",
    "        self.channels_start = conf['channels']\n",
    "        \n",
    "        \n",
    "        self._diffuser = FrameDiffNoise()\n",
    "        self._graphmaker =  PDBDataSet_GraphCon.Make_KNN_MP_Graphs(mp_stride = self.stride, \n",
    "                                                           coord_div = self.coord_scale, \n",
    "                                                           cast_type = self.cast_type, \n",
    "                                                           channels_start = self.channels_start,\n",
    "                                                           ndf1= conf['nodefeats_1'], \n",
    "                                                           ndf0= conf['nodefeats_0'],\n",
    "                                                           cuda=conf['cuda']) #cuda is bool True, mod at some point\n",
    "        #single_t dataset, for testing\n",
    "        # sd = smallPDBDataset(fdn , meta_data_path = '/mnt/h/datasets/bCov_4H/metadata.csv', \n",
    "        #                      filter_dict=False, maxlen=1000, input_t=0.05)\n",
    "        \n",
    "\n",
    "\n",
    "        \n",
    "        self._model = GraphUNet(fiber_start = Fiber({0:12, 1:2}),\n",
    "                                fiber_out = Fiber({1:2}),\n",
    "                                batch_size = self.B, \n",
    "                                num_layers_ca = conf['num_layers_ca'],\n",
    "                                k = conf['topk'],\n",
    "                                stride = conf['stride'],\n",
    "                                max_degree = 3,\n",
    "                                channels_div =  conf['channels_div'],\n",
    "                                num_heads = conf['num_heads'],\n",
    "                                num_layers = conf['num_layers'],\n",
    "                                edge_feature_dim = conf['edge_feature_dim'],\n",
    "                                latent_pool_type = conf['latent_pool_type'],\n",
    "                                t_size = conf['t_size'],\n",
    "                                zero_lin = conf['zero_lin'],\n",
    "                                use_tdeg1 = conf['use_tdeg1'],\n",
    "                                cuda = conf['cuda']).to(self.device) #cuda is bool True, mod at some point\n",
    "\n",
    "        \n",
    "\n",
    "        \n",
    "        num_parameters = sum(p.numel() for p in self._model.parameters())\n",
    "        self.num_parameters = num_parameters\n",
    "        self._log.info(f'Number of model parameters {num_parameters}')\n",
    "#         self._optimizer = EMA(0.980)\n",
    "#         for name, param in self._model.named_parameters():\n",
    "#             if param.requires_grad:\n",
    "#                 self._optimizer.register(name, param.data)\n",
    "\n",
    "        if ckpt_model is not None:\n",
    "            ckpt_model = {k.replace('module.', ''):v for k,v in ckpt_model.items()}\n",
    "            self._model.load_state_dict(ckpt_model, strict=True)\n",
    "        \n",
    "        \n",
    "        self._optimizer = torch.optim.Adam( self._model.parameters(),\n",
    "                                                       lr=conf['learning rate'],\n",
    "                                                       weight_decay=conf['weight_decay'])\n",
    "        if ckpt_opt is not None:\n",
    "            self._optimizer.load_state_dict(ckpt_opt)\n",
    "            optimizer_to(self._optimizer, self.device)\n",
    "        \n",
    "        \n",
    "        dt_string = datetime.now().strftime(\"%dD_%mM_%YY_%Hh_%Mm_%Ss\")\n",
    "        dt_string_short = datetime.now().strftime(\"%dD_%mM_%YY\")\n",
    "        self.ckpt_dir =  conf['ckpt_dir']\n",
    "        self.eval_dir = conf['eval_dir']\n",
    "        eval_name = f'{self.name}_{dt_string_short}'\n",
    "        if self.ckpt_dir is not None:\n",
    "            # Set-up checkpoint location\n",
    "            ckpt_dir = os.path.join(\n",
    "                 self.ckpt_dir,\n",
    "                 self.name,\n",
    "                 dt_string)\n",
    "            if not os.path.exists(ckpt_dir):\n",
    "                os.makedirs(ckpt_dir, exist_ok=True)\n",
    "            self.ckpt_dir = ckpt_dir\n",
    "            self._log.info(f'Checkpoints saved to: {ckpt_dir}')\n",
    "        else:  \n",
    "            self._log.info('Checkpoint not being saved.')\n",
    "            \n",
    "        if self.eval_dir is not None :\n",
    "            self.eval_dir = os.path.join(\n",
    "                self.eval_dir,\n",
    "                eval_name,\n",
    "                dt_string)\n",
    "            self.eval_dir = self.eval_dir\n",
    "            self._log.info(f'Evaluation saved to: {self.eval_dir}')\n",
    "        else:\n",
    "            self.eval_dir = os.devnull\n",
    "            self._log.info(f'Evaluation will not be saved.')\n",
    "    #         self._aux_data_history = deque(maxlen=100)\n",
    "    \n",
    "        if cur_epoch is None:\n",
    "            self.trained_epochs = 0\n",
    "        else:\n",
    "            self.trained_epochs = cur_epoch\n",
    "            \n",
    "        if cur_step is None:\n",
    "            self.trained_steps = 0\n",
    "        else:\n",
    "            self.trained_steps = cur_step\n",
    "            \n",
    "    @property\n",
    "    def diffuser(self):\n",
    "        return self._diffuser\n",
    "\n",
    "    @property\n",
    "    def model(self):\n",
    "        return self._model\n",
    "\n",
    "    @property\n",
    "    def conf(self):\n",
    "        return self._conf\n",
    "    \n",
    "    def create_dataset(self, fake_valid=True):\n",
    "        \n",
    "        \n",
    "        self.dataset = PDBDataSet_GraphCon.smallPDBDataset( self._diffuser , meta_data_path = self.meta_data_path, \n",
    "                             filter_dict=False, maxlen=self.limit)\n",
    "        \n",
    "        self.train_sample = PDBDataSet_GraphCon.TrainSampler(self.B, self.dataset, sample_mode='single_length')\n",
    "        \n",
    "        train_dL = torch.utils.data.DataLoader(self.dataset, sampler=self.train_sample,\n",
    "                                                     batch_size=self.B, shuffle=False, collate_fn=None)\n",
    "        \n",
    "        if fake_valid:\n",
    "            valid_dL = train_dL\n",
    "        else:\n",
    "            valid_dL = train_dL\n",
    "            #not implemented yet\n",
    "        \n",
    "        return train_dL, valid_dL\n",
    "    #unchecked\n",
    "    def start_training(self, return_logs=False):\n",
    "\n",
    "\n",
    "        self._model = self._model.to(self.device)\n",
    "        print(f\"Using device: {self.device}\")\n",
    "\n",
    "        self._model.train()\n",
    "        (train_loader, valid_loader) = self.create_dataset()\n",
    "\n",
    "        logs = []\n",
    "        print('number of epochs', self.num_epoch)\n",
    "        for epoch in range(self.trained_epochs, self.num_epoch+self.trained_epochs):\n",
    "            print('epoch', epoch)\n",
    "            print('mem_used',torch.cuda.memory_allocated('cuda:0'))\n",
    "            epoch_log = self.train_epoch(\n",
    "                train_loader,\n",
    "                valid_loader,\n",
    "                epoch=epoch,\n",
    "                return_logs=return_logs\n",
    "            )\n",
    "            if return_logs:\n",
    "                logs.append(epoch_log)\n",
    "\n",
    "        self._log.info('Done')\n",
    "        return logs\n",
    "    #unchecked\n",
    "    def train_epoch(self, train_loader, valid_loader,epoch=0, return_logs=False):\n",
    "        \n",
    "        log_lossses = defaultdict(list)\n",
    "    \n",
    "        global_logs = []\n",
    "        log_time = time.time()\n",
    "        step_time = time.time()\n",
    "        losskeeper = []\n",
    "        for train_feats in train_loader:\n",
    "            \n",
    "            #train_feats = tree.map_structure(lambda x: x.to(device), train_feats)\n",
    "            loss, aux_data = self.update_fn(train_feats)\n",
    "#             for k,v in aux_data.items():\n",
    "#                 log_lossses[k].append(np.array(v))\n",
    "            log_lossses['loss'].append(loss.to('cpu').numpy())\n",
    "            \n",
    "            self.trained_steps += 1\n",
    "\n",
    "            \n",
    "            \n",
    "            # Logging to terminal\n",
    "            if self.trained_steps == 1 or self.trained_steps % self.log_freq == 0:\n",
    "                elapsed_time = time.time() - log_time\n",
    "                log_time = time.time()\n",
    "                step_per_sec = self.log_freq / elapsed_time\n",
    "                rolling_losses = tree.map_structure(np.mean, log_lossses)\n",
    "                loss_log = ' '.join([\n",
    "                    f'{k}={v[0]:.4f}'\n",
    "                    for k,v in rolling_losses.items() if 'batch' not in k\n",
    "                ])\n",
    "                \n",
    "                self._log.info(\n",
    "                    f'[{self.trained_steps}]: {loss_log}, steps/sec={step_per_sec:.5f}')\n",
    "                log_lossses = defaultdict(list)\n",
    "                \n",
    "                print(f'[{self.trained_steps}]: {loss_log}, steps/sec={step_per_sec:.5f}')\n",
    "                print(np.mean(losskeeper[-1000:]))\n",
    "\n",
    "            # Take checkpoint\n",
    "            \n",
    "            if self.ckpt_dir is not None and (\n",
    "                    (self.trained_steps % self.ckpt_freq) == 0\n",
    "                    or (self.early_ckpt and self.trained_steps == 2)\n",
    "                ):\n",
    "                ckpt_path = os.path.join(\n",
    "                    self.ckpt_dir, f'step_{self.trained_steps}.pth')\n",
    "                du.write_checkpoint(\n",
    "                    ckpt_path,\n",
    "                    copy.deepcopy(self.model.state_dict()),\n",
    "                    self._conf,\n",
    "                    copy.deepcopy(self._optimizer.state_dict()),\n",
    "                    self.trained_epochs,\n",
    "                    self.trained_steps,\n",
    "                    logger=self._log,\n",
    "                    use_torch=True\n",
    "                )\n",
    "                \n",
    "\n",
    "                # Run evaluation\n",
    "                self._log.info(f'Running evaluation of {ckpt_path}')\n",
    "                start_time = time.time()\n",
    "                eval_dir = os.path.join(self.eval_dir, f'step_{self.trained_steps}')\n",
    "                print('eval',eval_dir)\n",
    "                os.makedirs(eval_dir, exist_ok=True)\n",
    "                ckpt_metrics = self.eval_fn(valid_loader,eval_dir,epoch=epoch)\n",
    "                eval_time = time.time() - start_time\n",
    "                self._log.info(f'Finished evaluation in {eval_time:.2f}s')\n",
    "            else:\n",
    "                ckpt_metrics = None\n",
    "                eval_time = None\n",
    "\n",
    "\n",
    "            if torch.isnan(loss):                \n",
    "                raise Exception(f'NaN encountered')\n",
    "                \n",
    "    def update_fn(self, data):\n",
    "        \"\"\"Updates the state using some data and returns metrics.\"\"\"\n",
    "        self._optimizer.zero_grad()\n",
    "        \n",
    "        batch_feats= tree.map_structure(\n",
    "                        lambda x: x.to(self.device), data)\n",
    "        noised_dict =   {'CA': batch_feats['CA_noised'] ,\n",
    "                         'N_CA': batch_feats['N_CA_noised'].unsqueeze(-2) ,\n",
    "                         'C_CA': batch_feats['C_CA_noised'].unsqueeze(-2)  }\n",
    "        \n",
    "        \n",
    "        loss, aux_data = self.loss_fn(batch_feats, noised_dict)\n",
    "        loss.backward()\n",
    "        self._optimizer.step()\n",
    "        loss_out = loss.detach().cpu()\n",
    "        return loss_out , aux_data\n",
    "    \n",
    "    \n",
    "    def generate_tbatch(self, index_in, input_t):\n",
    "        batch_list = []\n",
    "        for i,t in enumerate(input_t):\n",
    "            batch_list.append(self.dataset.get_specific_t(index_in[i], input_t[i]))\n",
    "\n",
    "        batch_feats = {}\n",
    "        for k in batch_list[0].keys():\n",
    "            batch_feats[k] = torch.stack([batch_list[i][k] for i in range(len(batch_list))])\n",
    "            \n",
    "        return batch_feats\n",
    "    \n",
    "    def eval_model(self, batch_feats, noised_dict, t_val=None):\n",
    "    \n",
    "        L = batch_feats['CA'].shape[1]\n",
    "        B = batch_feats['CA'].shape[0]\n",
    "        CA_t  = batch_feats['CA']\n",
    "        NC_t = CA_t +  batch_feats['N_CA']\n",
    "        CC_t = CA_t +  batch_feats['C_CA']\n",
    "        true =  torch.cat((NC_t,CA_t,CC_t),dim=2).reshape(B,L,3,3)\n",
    "\n",
    "        CA_n  = batch_feats['CA_noised'].reshape(B, L, 3)\n",
    "        NC_n = CA_n + batch_feats['N_CA_noised'].reshape(B, L, 3)\n",
    "        CC_n = CA_n + batch_feats['C_CA_noised'].reshape(B, L, 3)\n",
    "        noise_xyz =  torch.cat((NC_n,CA_n,CC_n),dim=2).reshape(B,L,3,3)\n",
    "\n",
    "        x = self._graphmaker.prep_for_network(noised_dict)\n",
    "        \n",
    "        with torch.no_grad():\n",
    "            out = self._model(x, batch_feats['t'])\n",
    "            CA_p = out['1'][:,0,:].reshape(B, L, 3) + CA_n #translation of Calpha\n",
    "            Qs = out['1'][:,1,:] # rotation of frame\n",
    "            Qs = Qs.unsqueeze(1).repeat((1,2,1))\n",
    "            Qs = torch.cat((torch.ones((B*L,2,1),device=Qs.device),Qs),dim=-1).reshape(B,L,2,4)\n",
    "            Qs = normQ(Qs)\n",
    "            Rs = Qs2Rs(Qs)\n",
    "            N_C_to_Rot = torch.cat((noised_dict['N_CA'].reshape(B, L, 3),\n",
    "                                    noised_dict['C_CA'].reshape(B, L, 3)),dim=2).reshape(B,L,2,1,3)\n",
    "\n",
    "            rot_vecs = einsum('bnkij,bnkhj->bnki',Rs, N_C_to_Rot)\n",
    "            NC_p = CA_p + rot_vecs[:,:,0,:]*self.N_CA_dist \n",
    "            CC_p = CA_p + rot_vecs[:,:,1,:]*self.C_CA_dist \n",
    "\n",
    "            pred = torch.cat((NC_p,CA_p,CC_p),dim=2).reshape(B,L,3,3)\n",
    "\n",
    "            tloss, loss = FAPE_loss(pred.unsqueeze(0), true, batch_feats['score_scale'])\n",
    "            \n",
    "            eval_dict = {'true'  : true.to('cpu').numpy()*self.coord_scale,\n",
    "                    'noise' : noise_xyz.to('cpu').numpy()*self.coord_scale,\n",
    "                    'pred'  : pred.to('cpu').numpy()*self.coord_scale,\n",
    "                    'loss'  : tloss.to('cpu').numpy()}\n",
    "            \n",
    "        return eval_dict\n",
    "    \n",
    "    def eval_fn(self, valid_loader, eval_dir, epoch=0, input_t=None, max_cycles=10):\n",
    "        \n",
    "        train_feats = next(iter(valid_loader))\n",
    "\n",
    "        if input_t is None:\n",
    "            #visualize_T\n",
    "            vis_t = np.array([0.01,0.05,0.1,0.2,0.3,0.5,0.8,1.0])\n",
    "            vis_t = vis_t[None,...].repeat(int(np.ceil(self.B/len(vis_t))),axis=0).flatten()[:self.B]\n",
    "        elif type(input_t) == float:\n",
    "            vis_t = np.ones((self.B,))*input_t\n",
    "        else:\n",
    "            vis_t = input_t\n",
    "            \n",
    "            \n",
    "        index_in = np.random.choice(np.arange(len(self.dataset)), size=len(vis_t))\n",
    "        batch_feats = self.generate_tbatch( index_in,vis_t)\n",
    "\n",
    "        batch_feats= tree.map_structure(\n",
    "                        lambda x: x.to(self.device), batch_feats)\n",
    "        noised_dict =   {'CA': batch_feats['CA_noised'] ,\n",
    "                         'N_CA': batch_feats['N_CA_noised'].unsqueeze(-2) ,\n",
    "                         'C_CA': batch_feats['C_CA_noised'].unsqueeze(-2)  }\n",
    "\n",
    "\n",
    "        eval_dict = self.eval_model(batch_feats,noised_dict)\n",
    "        util.pdb_writer.dump_tnp(eval_dict['true'], \n",
    "                                      eval_dict['noise'], \n",
    "                                      eval_dict['pred'], vis_t, e=epoch, \n",
    "                                      numOut=len(vis_t), outdir=eval_dir)\n",
    "        losskeeper = []\n",
    "        eval_steps = 0\n",
    "\n",
    "\n",
    "        for i,train_feats in enumerate(valid_loader):\n",
    "            \n",
    "            batch_feats= tree.map_structure(\n",
    "                lambda x: x.to(self.device),train_feats)\n",
    "            noised_dict =   {'CA': batch_feats['CA_noised'] ,\n",
    "                             'N_CA': batch_feats['N_CA_noised'].unsqueeze(-2) ,\n",
    "                             'C_CA': batch_feats['C_CA_noised'].unsqueeze(-2)  }\n",
    "\n",
    "            eval_dict = self.eval_model(batch_feats, noised_dict)\n",
    "            eval_steps += 1\n",
    "            losskeeper.append(eval_dict['loss'])   \n",
    "\n",
    "            if i>max_cycles:\n",
    "                break\n",
    "        print('eval_loss',np.mean(losskeeper[-1000:]),len(losskeeper))\n",
    "\n",
    "    \n",
    "    def loss_fn(self, batch_feats, noised_dict, t_val=None):\n",
    "        \n",
    "        L = batch_feats['CA'].shape[1]\n",
    "        B = batch_feats['CA'].shape[0]\n",
    "        CA_t  = batch_feats['CA']\n",
    "        NC_t = CA_t +  batch_feats['N_CA']\n",
    "        CC_t = CA_t +  batch_feats['C_CA']\n",
    "        true =  torch.cat((NC_t,CA_t,CC_t),dim=2).reshape(B,L,3,3)\n",
    "\n",
    "        CA_n  = batch_feats['CA_noised'].reshape(B, L, 3)\n",
    "        NC_n = CA_n + batch_feats['N_CA_noised'].reshape(B, L, 3)\n",
    "        CC_n = CA_n + batch_feats['C_CA_noised'].reshape(B, L, 3)\n",
    "        noise_xyz =  torch.cat((NC_n,CA_n,CC_n),dim=2).reshape(B,L,3,3)\n",
    "\n",
    "        x = self._graphmaker.prep_for_network(noised_dict)\n",
    "        out = self._model(x, batch_feats['t'])\n",
    "        CA_p = out['1'][:,0,:].reshape(B, L, 3) + CA_n #translation of Calpha\n",
    "        Qs = out['1'][:,1,:] # rotation of frame\n",
    "        Qs = Qs.unsqueeze(1).repeat((1,2,1))\n",
    "        Qs = torch.cat((torch.ones((B*L,2,1),device=Qs.device),Qs),dim=-1).reshape(B,L,2,4)\n",
    "        Qs = normQ(Qs)\n",
    "        Rs = Qs2Rs(Qs)\n",
    "        N_C_to_Rot = torch.cat((noised_dict['N_CA'].reshape(B, L, 3),\n",
    "                                noised_dict['C_CA'].reshape(B, L, 3)),dim=2).reshape(B,L,2,1,3)\n",
    "\n",
    "        rot_vecs = einsum('bnkij,bnkhj->bnki',Rs, N_C_to_Rot)\n",
    "        NC_p = CA_p + rot_vecs[:,:,0,:]*self.N_CA_dist \n",
    "        CC_p = CA_p + rot_vecs[:,:,1,:]*self.C_CA_dist \n",
    "\n",
    "        pred = torch.cat((NC_p,CA_p,CC_p),dim=2).reshape(B,L,3,3)\n",
    "\n",
    "        tloss, loss = FAPE_loss(pred.unsqueeze(0), true, batch_feats['score_scale'])\n",
    "\n",
    "        return tloss, loss #final_loss, aux_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "aa505c2d",
   "metadata": {},
   "outputs": [],
   "source": [
    "exp = Experiment(conf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "b20d7957",
   "metadata": {},
   "outputs": [],
   "source": [
    "tl, vl = exp.create_dataset()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "6f398761",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1]: loss=0.2667, steps/sec=638.73152\n",
      "nan\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/nwoodall/miniconda3/envs/se33/lib/python3.9/site-packages/numpy/core/fromnumeric.py:3464: RuntimeWarning: Mean of empty slice.\n",
      "  return _methods._mean(a, axis=axis, dtype=dtype,\n",
      "/home/nwoodall/miniconda3/envs/se33/lib/python3.9/site-packages/numpy/core/_methods.py:192: RuntimeWarning: invalid value encountered in scalar divide\n",
      "  ret = ret.dtype.type(ret / rcount)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "eval Eval_Direc/gu_null_09D_08M_2024Y/09D_08M_2024Y_00h_53m_42s/step_2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/nwoodall/miniconda3/envs/se33/lib/python3.9/site-packages/torch/utils/checkpoint.py:31: UserWarning: None of the inputs have requires_grad=True. Gradients will be None\n",
      "  warnings.warn(\"None of the inputs have requires_grad=True. Gradients will be None\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "eval_loss 0.24677116 12\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[75], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mexp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrain_epoch\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtl\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mvl\u001b[49m\u001b[43m,\u001b[49m\u001b[43mepoch\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mreturn_logs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[0;32mIn[72], line 218\u001b[0m, in \u001b[0;36mExperiment.train_epoch\u001b[0;34m(self, train_loader, valid_loader, epoch, return_logs)\u001b[0m\n\u001b[1;32m    214\u001b[0m         losskeeper \u001b[38;5;241m=\u001b[39m []\n\u001b[1;32m    215\u001b[0m         \u001b[38;5;28;01mfor\u001b[39;00m train_feats \u001b[38;5;129;01min\u001b[39;00m train_loader:\n\u001b[1;32m    216\u001b[0m             \n\u001b[1;32m    217\u001b[0m             \u001b[38;5;66;03m#train_feats = tree.map_structure(lambda x: x.to(device), train_feats)\u001b[39;00m\n\u001b[0;32m--> 218\u001b[0m             loss, aux_data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mupdate_fn\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrain_feats\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    219\u001b[0m \u001b[38;5;66;03m#             for k,v in aux_data.items():\u001b[39;00m\n\u001b[1;32m    220\u001b[0m \u001b[38;5;66;03m#                 log_lossses[k].append(np.array(v))\u001b[39;00m\n\u001b[1;32m    221\u001b[0m             log_lossses[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mloss\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39mappend(loss\u001b[38;5;241m.\u001b[39mto(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcpu\u001b[39m\u001b[38;5;124m'\u001b[39m)\u001b[38;5;241m.\u001b[39mnumpy())\n",
      "Cell \u001b[0;32mIn[72], line 293\u001b[0m, in \u001b[0;36mExperiment.update_fn\u001b[0;34m(self, data)\u001b[0m\n\u001b[1;32m    286\u001b[0m batch_feats\u001b[38;5;241m=\u001b[39m tree\u001b[38;5;241m.\u001b[39mmap_structure(\n\u001b[1;32m    287\u001b[0m                 \u001b[38;5;28;01mlambda\u001b[39;00m x: x\u001b[38;5;241m.\u001b[39mto(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdevice), data)\n\u001b[1;32m    288\u001b[0m noised_dict \u001b[38;5;241m=\u001b[39m   {\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mCA\u001b[39m\u001b[38;5;124m'\u001b[39m: batch_feats[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mCA_noised\u001b[39m\u001b[38;5;124m'\u001b[39m] ,\n\u001b[1;32m    289\u001b[0m                  \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mN_CA\u001b[39m\u001b[38;5;124m'\u001b[39m: batch_feats[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mN_CA_noised\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39munsqueeze(\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m2\u001b[39m) ,\n\u001b[1;32m    290\u001b[0m                  \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mC_CA\u001b[39m\u001b[38;5;124m'\u001b[39m: batch_feats[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mC_CA_noised\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39munsqueeze(\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m2\u001b[39m)  }\n\u001b[0;32m--> 293\u001b[0m loss, aux_data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mloss_fn\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbatch_feats\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnoised_dict\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    294\u001b[0m loss\u001b[38;5;241m.\u001b[39mbackward()\n\u001b[1;32m    295\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_optimizer\u001b[38;5;241m.\u001b[39mstep()\n",
      "Cell \u001b[0;32mIn[72], line 417\u001b[0m, in \u001b[0;36mExperiment.loss_fn\u001b[0;34m(self, batch_feats, noised_dict, t_val)\u001b[0m\n\u001b[1;32m    414\u001b[0m CC_n \u001b[38;5;241m=\u001b[39m CA_n \u001b[38;5;241m+\u001b[39m batch_feats[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mC_CA_noised\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39mreshape(B, L, \u001b[38;5;241m3\u001b[39m)\n\u001b[1;32m    415\u001b[0m noise_xyz \u001b[38;5;241m=\u001b[39m  torch\u001b[38;5;241m.\u001b[39mcat((NC_n,CA_n,CC_n),dim\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m2\u001b[39m)\u001b[38;5;241m.\u001b[39mreshape(B,L,\u001b[38;5;241m3\u001b[39m,\u001b[38;5;241m3\u001b[39m)\n\u001b[0;32m--> 417\u001b[0m x \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_graphmaker\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mprep_for_network\u001b[49m\u001b[43m(\u001b[49m\u001b[43mnoised_dict\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    418\u001b[0m out \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_model(x, batch_feats[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mt\u001b[39m\u001b[38;5;124m'\u001b[39m])\n\u001b[1;32m    419\u001b[0m CA_p \u001b[38;5;241m=\u001b[39m out[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m1\u001b[39m\u001b[38;5;124m'\u001b[39m][:,\u001b[38;5;241m0\u001b[39m,:]\u001b[38;5;241m.\u001b[39mreshape(B, L, \u001b[38;5;241m3\u001b[39m) \u001b[38;5;241m+\u001b[39m CA_n \u001b[38;5;66;03m#translation of Calpha\u001b[39;00m\n",
      "File \u001b[0;32m/mnt/c/Users/nwood/OneDrive/Desktop/gudiff/gudiff_model/PDBDataSet_GraphCon.py:487\u001b[0m, in \u001b[0;36mMake_KNN_MP_Graphs.prep_for_network\u001b[0;34m(self, bb_dict, cuda)\u001b[0m\n\u001b[1;32m    484\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mprep_for_network\u001b[39m(\u001b[38;5;28mself\u001b[39m, bb_dict, cuda\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m):\n\u001b[1;32m    486\u001b[0m     n_nodes \u001b[38;5;241m=\u001b[39m bb_dict[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mCA\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m1\u001b[39m]\n\u001b[0;32m--> 487\u001b[0m     batched_graph, batched_mpgraph, batched_mpself_graph, batched_mpRevgraph \u001b[38;5;241m=\u001b[39m  \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcreate_and_batch\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbb_dict\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mn_nodes\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    489\u001b[0m     edge_feats        \u001b[38;5;241m=\u001b[39m    {\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m0\u001b[39m\u001b[38;5;124m'\u001b[39m:   batched_graph\u001b[38;5;241m.\u001b[39medata[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcon\u001b[39m\u001b[38;5;124m'\u001b[39m][:, :\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mEDGE_FEATURE_DIM, \u001b[38;5;28;01mNone\u001b[39;00m]}\n\u001b[1;32m    490\u001b[0m     edge_feats_mp     \u001b[38;5;241m=\u001b[39m {\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m0\u001b[39m\u001b[38;5;124m'\u001b[39m: batched_mpgraph\u001b[38;5;241m.\u001b[39medata[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcon\u001b[39m\u001b[38;5;124m'\u001b[39m][:, :\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mEDGE_FEATURE_DIM, \u001b[38;5;28;01mNone\u001b[39;00m]} \u001b[38;5;66;03m#def all zero now\u001b[39;00m\n",
      "File \u001b[0;32m/mnt/c/Users/nwood/OneDrive/Desktop/gudiff/gudiff_model/PDBDataSet_GraphCon.py:434\u001b[0m, in \u001b[0;36mMake_KNN_MP_Graphs.create_and_batch\u001b[0;34m(self, bb_dict, n_nodes)\u001b[0m\n\u001b[1;32m    432\u001b[0m i\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0\u001b[39m\u001b[38;5;66;03m#mp list counter\u001b[39;00m\n\u001b[1;32m    433\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m x \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;241m0\u001b[39m, n_nodes, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmp_stride):\n\u001b[0;32m--> 434\u001b[0m     src, dst \u001b[38;5;241m=\u001b[39m \u001b[43mgraph\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43min_edges\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;66;03m#dst repeats x\u001b[39;00m\n\u001b[1;32m    435\u001b[0m     n_tot \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mcat((torch\u001b[38;5;241m.\u001b[39mtensor(x,device\u001b[38;5;241m=\u001b[39mcaXYZ\u001b[38;5;241m.\u001b[39mdevice)\u001b[38;5;241m.\u001b[39munsqueeze(\u001b[38;5;241m0\u001b[39m),src)) \u001b[38;5;66;03m#add x to node list\u001b[39;00m\n\u001b[1;32m    436\u001b[0m     mp_list[i] \u001b[38;5;241m=\u001b[39m caXYZ[n_tot]\u001b[38;5;241m.\u001b[39msum(axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0\u001b[39m)\u001b[38;5;241m/\u001b[39mn_tot\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m0\u001b[39m]\n",
      "File \u001b[0;32m~/miniconda3/envs/se33/lib/python3.9/site-packages/dgl/heterograph.py:3416\u001b[0m, in \u001b[0;36mDGLGraph.in_edges\u001b[0;34m(self, v, form, etype)\u001b[0m\n\u001b[1;32m   3343\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Return the incoming edges of the given nodes.\u001b[39;00m\n\u001b[1;32m   3344\u001b[0m \n\u001b[1;32m   3345\u001b[0m \u001b[38;5;124;03mParameters\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   3413\u001b[0m \u001b[38;5;124;03mout_edges\u001b[39;00m\n\u001b[1;32m   3414\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m   3415\u001b[0m v \u001b[38;5;241m=\u001b[39m utils\u001b[38;5;241m.\u001b[39mprepare_tensor(\u001b[38;5;28mself\u001b[39m, v, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mv\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m-> 3416\u001b[0m src, dst, eid \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_graph\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43min_edges\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_etype_id\u001b[49m\u001b[43m(\u001b[49m\u001b[43metype\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mv\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   3417\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m form \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mall\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[1;32m   3418\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m src, dst, eid\n",
      "File \u001b[0;32m~/miniconda3/envs/se33/lib/python3.9/site-packages/dgl/heterograph_index.py:633\u001b[0m, in \u001b[0;36mHeteroGraphIndex.in_edges\u001b[0;34m(self, etype, v)\u001b[0m\n\u001b[1;32m    612\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21min_edges\u001b[39m(\u001b[38;5;28mself\u001b[39m, etype, v):\n\u001b[1;32m    613\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Return the in edges of the node(s).\u001b[39;00m\n\u001b[1;32m    614\u001b[0m \n\u001b[1;32m    615\u001b[0m \u001b[38;5;124;03m    Assume that node_type(v) == dst_type(etype). Thus, the ntype argument is omitted.\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    631\u001b[0m \u001b[38;5;124;03m        The edge ids.\u001b[39;00m\n\u001b[1;32m    632\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 633\u001b[0m     edge_array \u001b[38;5;241m=\u001b[39m \u001b[43m_CAPI_DGLHeteroInEdges_2\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mint\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43metype\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mF\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mto_dgl_nd\u001b[49m\u001b[43m(\u001b[49m\u001b[43mv\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    634\u001b[0m     src \u001b[38;5;241m=\u001b[39m F\u001b[38;5;241m.\u001b[39mfrom_dgl_nd(edge_array(\u001b[38;5;241m0\u001b[39m))\n\u001b[1;32m    635\u001b[0m     dst \u001b[38;5;241m=\u001b[39m F\u001b[38;5;241m.\u001b[39mfrom_dgl_nd(edge_array(\u001b[38;5;241m1\u001b[39m))\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "exp.train_epoch(tl, vl,epoch=0, return_logs=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e563ac43",
   "metadata": {},
   "outputs": [],
   "source": [
    "def eval_fn(self, valid_loader, eval_dir, epoch=0, input_t=None, max_cycles=10):\n",
    "        \n",
    "    train_feats = next(iter(valid_loader))\n",
    "\n",
    "    if input_t is None:\n",
    "        #visualize_T\n",
    "        vis_t = np.array([0.01,0.05,0.1,0.2,0.3,0.5,0.8,1.0])\n",
    "        vis_t = vis_t[None,...].repeat(int(np.ceil(self.B/len(vis_t))),axis=0).flatten()[:self.B]\n",
    "    elif type(input_t) == float:\n",
    "        vis_t = np.ones((self.B,))*input_t\n",
    "    else:\n",
    "        vis_t = input_t\n",
    "\n",
    "    noised_dict = self.fnd.forward(train_feats, t_vec=vis_t)\n",
    "    batched_t = to_cuda( noised_dict['t_vec'] )\n",
    "\n",
    "    eval_dict = self.eval_model(noised_dict, batched_t)\n",
    "    util.pdb_writer.dump_tnp(eval_dict['true'], \n",
    "                                  eval_dict['noise_xyz'], \n",
    "                                  eval_dict['pred'], vis_t, e=epoch, \n",
    "                                  numOut=len(vis_t), outdir=eval_dir)\n",
    "    losskeeper = []\n",
    "    eval_steps = 0\n",
    "\n",
    "\n",
    "    for i,train_feats in enumerate(valid_loader):\n",
    "        noised_dict = self.fnd.forward(train_feats)\n",
    "        batched_t = to_cuda( noised_dict['t_vec'] )\n",
    "        eval_dict = self.eval_model(noised_dict, batched_t)\n",
    "        eval_steps += 1\n",
    "        losskeeper.append(eval_dict['loss'])   \n",
    "\n",
    "        if i>max_cycles:\n",
    "            break\n",
    "\n",
    "    print(f'[{eval_steps}]: {loss_log}')\n",
    "    print('eval_loss',np.mean(losskeeper[-1000:]),len(losskeeper))\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83f2c290",
   "metadata": {},
   "outputs": [],
   "source": [
    "            eval_dict = {'true'  : true.to('cpu').numpy()*self.coords_scale,\n",
    "                    'noise' : noise_xyz.to('cpu').numpy()*self.coords_scale,\n",
    "                    'pred'  : pred.to('cpu').numpy()*self.coords_scale,\n",
    "                    'loss'  : tloss.to('cpu').numpy()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4cec6e58",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96d68d52",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f242d4ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "    def eval_model(self, noised_dict, batched_t):\n",
    "        \n",
    "        def convert_pV_to_points(dict_in, L, key_in='bb_firstp', return_indiv=False):\n",
    "            \"\"\"Concatenates to xyz from Calpha+atom vectors\"\"\"\n",
    "            CA_fp  = dict_in[key_in]['CA'].reshape(self.B, L, 3).to(self.device)\n",
    "            NC_fp = CA_fp + dict_in[key_in]['N_CA'].reshape(self.B, L, 3).to(self.device)\n",
    "            CC_fp = CA_fp + dict_in[key_in]['C_CA'].reshape(self.B, L, 3).to(self.device)\n",
    "            fp =  torch.cat((NC_fp,CA_fp,CC_fp),dim=2).reshape(self.B,L,3,3)\n",
    "            if return_indiv:\n",
    "                return fp, CA_fp, NC_fp, CC_fp\n",
    "            return fp\n",
    "    \n",
    "        CA_t  = noised_dict['bb_shifted']['CA'].reshape(self.B, self.L, 3).to(self.device)\n",
    "        NC_t = CA_t + noised_dict['bb_shifted']['N_CA'].reshape(self.B, self.L, 3).to(self.device)*self.N_CA_dist\n",
    "        CC_t = CA_t + noised_dict['bb_shifted']['C_CA'].reshape(self.B, self.L, 3).to(self.device)*self.C_CA_dist\n",
    "        true =  torch.cat((NC_t,CA_t,CC_t),dim=2).reshape(self.B,self.L,3,3)\n",
    "\n",
    "        CA_n  = noised_dict['bb_noised']['CA'].reshape(self.B, self.L, 3).to(self.device)\n",
    "        NC_n = CA_n + noised_dict['bb_noised']['N_CA'].reshape(self.B, self.L, 3).to(self.device)*self.N_CA_dist\n",
    "        CC_n = CA_n + noised_dict['bb_noised']['C_CA'].reshape(self.B, self.L, 3).to(self.device)*self.C_CA_dist\n",
    "        noise_xyz =  torch.cat((NC_n,CA_n,CC_n),dim=2).reshape(self.B, self.L,3,3)\n",
    "        \n",
    "        feat_dict = self.mkg.prep_for_network(noised_dict) #prepares graphs\n",
    "        with torch.no_grad():\n",
    "            out = self._model(feat_dict, batched_t)\n",
    "            CA_p = out['1'][:,0,:].reshape(self.B, self.L, 3) + CA_n #translation of Calpha\n",
    "            Qs = out['1'][:,1,:] # rotation\n",
    "            Qs = Qs.unsqueeze(1).repeat((1,2,1))\n",
    "            Qs = torch.cat((torch.ones((self.B*self.L,2,1),device=Qs.device),Qs),dim=-1).reshape(self.B,self.L,2,4)\n",
    "            Qs = normQ(Qs)\n",
    "            Rs = Qs2Rs(Qs)\n",
    "            N_C_to_Rot = torch.cat((noised_dict['bb_noised']['N_CA'].reshape(self.B, self.L, 3).to(self.device),\n",
    "                                    noised_dict['bb_noised']['C_CA'].reshape(self.B, self.L, 3).to(self.device)),\n",
    "                                   dim=2).reshape(self.B,self.L,2,1,3)\n",
    "\n",
    "\n",
    "            rot_vecs = einsum('bnkij,bnkhj->bnki',Rs, N_C_to_Rot)\n",
    "            NC_p = CA_p + rot_vecs[:,:,0,:].to(self.device)*self.N_CA_dist\n",
    "            CC_p = CA_p + rot_vecs[:,:,1,:].reshape(self.B, self.L, 3).to(self.device)*self.C_CA_dist\n",
    "\n",
    "            pred = torch.cat((NC_p,CA_p,CC_p),dim=2).reshape(self.B,self.L,3,3)\n",
    "            \n",
    "            fp = convert_pV_to_points(noised_dict, 1, key_in='bb_firstp')\n",
    "            lp = convert_pV_to_points(noised_dict,1,  key_in='bb_lastp')                                             \n",
    "            real_mask = noised_dict['real_nodes_mask'].to(self.device)\n",
    "            score_scales = noised_dict['score_scales'].to(self.device)\n",
    "\n",
    "            nf_pred = out['0']\n",
    "            real_nodes_pred = torch.round(nf_pred).clamp(0,1)\n",
    "            real_nodes_pred_mask = (real_nodes_pred.squeeze().sum(-1)>self.real_threshold).reshape(self.B,self.L)\n",
    "            \n",
    "            lr, lr_d = FAPE_loss_real(pred, true, score_scales, real_mask,  d_clamp=10.0, d_clamp_inter=30.0,\n",
    "                           A=10.0, gamma=1.0, eps=1e-6)\n",
    "\n",
    "            ln, ln_d = FAPE_loss_null(pred, fp, lp, real_mask, score_scales,  d_clamp=10.0,\n",
    "                               d_clamp_inter=30.0, A=10.0, gamma=1.0, eps=1e-6)\n",
    "\n",
    "            ln = ln*self.score_weights['3D_null']\n",
    "            lr = lr*self.score_weights['3D_real']\n",
    "\n",
    "            structure_loss = lr + ln\n",
    "\n",
    "            #score for node feats determining whether node is real or fake\n",
    "            nf_pred = out['0']\n",
    "\n",
    "            nf_feat_dim = noised_dict['real_nodes_noise'].shape[-1]\n",
    "            nf_true = torch.ones(noised_dict['real_nodes_mask'].shape+(nf_feat_dim,) + (1,),\n",
    "                                 dtype=torch.float,device = self.device)\n",
    "\n",
    "            nf_real_mask_mult = real_mask.unsqueeze(-1).unsqueeze(-1).to(self.device)\n",
    "            nf_true = nf_true*nf_real_mask_mult\n",
    "\n",
    "            nf_pred = nf_pred.reshape(self.B,-1,nf_feat_dim)\n",
    "            pred_nf_loss = torch.sum(torch.square(nf_true.squeeze()-nf_pred),dim=-1)\n",
    "\n",
    "            ss_scales = to_cuda(noised_dict['score_scales'])[:,None,None]\n",
    "            pnfloss = (torch.sum((pred_nf_loss*ss_scales))/(self.L*self.nf_dim))*self.score_weights['nf_real']\n",
    "\n",
    "            final_loss = structure_loss + pnfloss\n",
    "            val_loss = {'pnf_loss': pnfloss.detach().cpu(),\n",
    "                        'structure_loss':structure_loss.detach().cpu(),\n",
    "                        'structure_null':ln.detach().cpu(),\n",
    "                        'structure_real':lr.detach().cpu()}\n",
    "\n",
    "        real_nodes_true_mask = noised_dict['real_nodes_mask']\n",
    "        \n",
    "        del nf_real_mask_mult\n",
    "        del ss_scales\n",
    "        del real_mask\n",
    "        del score_scales\n",
    "        del batched_t\n",
    "        del structure_loss\n",
    "        del pnfloss\n",
    "        del nf_pred\n",
    "        del nf_true\n",
    "        del N_C_to_Rot\n",
    "        del CA_n, NC_n, CC_n\n",
    "        \n",
    "        for k,v in out.items():\n",
    "            del v\n",
    "        for k,v in feat_dict.items():\n",
    "            del v\n",
    "        \n",
    "        #needs to be rolled to N-terminal = 0 for pymol output, add coord_scale\n",
    "        return true.detach().cpu(), noise_xyz.detach().cpu(), pred.detach().cpu() , real_nodes_pred_mask.detach().cpu(), real_nodes_true_mask.detach().cpu(), val_loss\n",
    "    \n",
    "    def eval_fn(self, valid_loader, eval_dir, epoch=0, input_t=None, max_cycles=10):\n",
    "        \n",
    "        train_feats = next(iter(valid_loader))\n",
    "        \n",
    "        if input_t is None:\n",
    "            #visualize_T\n",
    "            vis_t = np.array([0.01,0.05,0.1,0.2,0.3,0.5,0.8,1.0])\n",
    "            vis_t = vis_t[None,...].repeat(int(np.ceil(self.B/len(vis_t))),axis=0).flatten()[:self.B]\n",
    "        elif type(input_t) == float:\n",
    "            vis_t = np.ones((self.B,))*input_t\n",
    "        else:\n",
    "            vis_t = input_t\n",
    "\n",
    "        noised_dict = self.fnd.forward(train_feats, t_vec=vis_t)\n",
    "        batched_t = to_cuda( noised_dict['t_vec'] )\n",
    "\n",
    "        true, noise_xyz, pred, real_nodes_pred_mask, real_nodes_true_mask, val_loss = self.eval_model(noised_dict, batched_t)\n",
    "        util.pdb_writer.dump_tnp_null(true, noise_xyz, pred, vis_t, e=epoch, \n",
    "                      numOut=len(vis_t), real_mask=real_nodes_true_mask, \n",
    "                      pred_mask=real_nodes_pred_mask.detach().cpu(), outdir=eval_dir)\n",
    "        \n",
    "        log_lossses = defaultdict(list)\n",
    "        losskeeper = []\n",
    "        eval_steps = 0\n",
    "        \n",
    "        \n",
    "        for i,train_feats in enumerate(valid_loader):\n",
    "            noised_dict = self.fnd.forward(train_feats)\n",
    "            batched_t = to_cuda( noised_dict['t_vec'] )\n",
    "            true, noise_xyz, pred, real_nodes_pred_mask, real_nodes_true_mask, val_loss = self.eval_model(noised_dict, batched_t)\n",
    "            eval_steps += 1\n",
    "            lsum = 0 \n",
    "            for k,v in val_loss.items():\n",
    "                log_lossses[k].append(np.array(v))\n",
    "                lsum+=v.detach().cpu()\n",
    "            losskeeper.append(lsum)   \n",
    "            \n",
    "            del true\n",
    "            del noise_xyz\n",
    "            del pred\n",
    "            del real_nodes_pred_mask\n",
    "            for k,v in val_loss.items():\n",
    "                del v\n",
    "            del batched_t\n",
    "            if i>max_cycles:\n",
    "                break\n",
    "            \n",
    "            \n",
    "        # Logging to terminal\n",
    "        rolling_losses = tree.map_structure(np.mean, log_lossses)\n",
    "        loss_log = ' '.join([\n",
    "            f'{k}={v[0]:.4f}'\n",
    "            for k,v in rolling_losses.items() if 'batch' not in k\n",
    "        ])\n",
    "\n",
    "        log_lossses = defaultdict(list)\n",
    "        print(f'[{eval_steps}]: {loss_log}')\n",
    "        print('eval_loss',np.mean(losskeeper[-1000:]),len(losskeeper))\n",
    "        \n",
    "        for k,v in noised_dict.items():\n",
    "            del v"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
