{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a02a1c0f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "#clear memory better\n",
    "with torch.no_grad():\n",
    "    torch.cuda.empty_cache()\n",
    "import numpy as np\n",
    "import util.npose_util as nu\n",
    "import os\n",
    "import pathlib\n",
    "import dgl\n",
    "from dgl import backend as F\n",
    "import torch_geometric\n",
    "from torch.utils.data import random_split, DataLoader, Dataset\n",
    "from typing import Dict\n",
    "from torch import Tensor\n",
    "from dgl import DGLGraph\n",
    "from torch import nn\n",
    "# from chemical import cos_ideal_NCAC #from RoseTTAFold2\n",
    "from torch import einsum\n",
    "import time\n",
    "torch.cuda.is_available()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6a31f547",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from data_rigid_diffuser import so3_diffuser\n",
    "# from data_rigid_diffuser import r3_diffuser\n",
    "# from scipy.spatial.transform import Rotation\n",
    "# from data_rigid_diffuser import rigid_utils as ru\n",
    "# import yaml\n",
    "from data_rigid_diffuser.diffuser import FrameDiffNoise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "bf443f63",
   "metadata": {},
   "outputs": [],
   "source": [
    "from se3_transformer.model.basis import get_basis, update_basis_with_fused\n",
    "from se3_transformer.model.transformer import Sequential, SE3Transformer\n",
    "from se3_transformer.model.transformer_topk import SE3Transformer_topK\n",
    "from se3_transformer.model.FAPE_Loss import FAPE_loss, Qs2Rs, normQ\n",
    "from se3_transformer.model.layers.attentiontopK import AttentionBlockSE3\n",
    "from se3_transformer.model.layers.linear import LinearSE3\n",
    "from se3_transformer.model.layers.convolution import ConvSE3, ConvSE3FuseLevel\n",
    "from se3_transformer.model.layers.norm import NormSE3\n",
    "from se3_transformer.model.layers.pooling import GPooling, Latent_Unpool, Unpool_Layer\n",
    "from se3_transformer.runtime.utils import str2bool, to_cuda\n",
    "from se3_transformer.model.fiber import Fiber\n",
    "from se3_transformer.model.transformer import get_populated_edge_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "2511634d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#npose indexing\n",
    "# Useful numbers\n",
    "# N [-1.45837285,  0 , 0]\n",
    "# CA [0., 0., 0.]\n",
    "# C [0.55221403, 1.41890368, 0.        ]\n",
    "# CB [ 0.52892494, -0.77445692, -1.19923854]\n",
    "\n",
    "N_CA_dist = torch.tensor(1.458/10.0).to('cuda')\n",
    "C_CA_dist = torch.tensor(1.523/10.0).to('cuda')\n",
    "\n",
    "if ( hasattr(os, 'ATOM_NAMES') ):\n",
    "    assert( hasattr(os, 'PDB_ORDER') )\n",
    "\n",
    "    ATOM_NAMES = os.ATOM_NAMES\n",
    "    PDB_ORDER = os.PDB_ORDER\n",
    "else:\n",
    "    ATOM_NAMES=['N', 'CA', 'CB', 'C', 'O']\n",
    "    PDB_ORDER = ['N', 'CA', 'C', 'O', 'CB']\n",
    "\n",
    "_byte_atom_names = []\n",
    "_atom_names = []\n",
    "for i, atom_name in enumerate(ATOM_NAMES):\n",
    "    long_name = \" \" + atom_name + \"       \"\n",
    "    _atom_names.append(long_name[:4])\n",
    "    _byte_atom_names.append(atom_name.encode())\n",
    "\n",
    "    globals()[atom_name] = i\n",
    "\n",
    "R = len(ATOM_NAMES)\n",
    "\n",
    "if ( \"N\" not in globals() ):\n",
    "    N = -1\n",
    "if ( \"C\" not in globals() ):\n",
    "    C = -1\n",
    "if ( \"CB\" not in globals() ):\n",
    "    CB = -1\n",
    "\n",
    "\n",
    "_pdb_order = []\n",
    "for name in PDB_ORDER:\n",
    "    _pdb_order.append( ATOM_NAMES.index(name) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e213e885",
   "metadata": {},
   "outputs": [],
   "source": [
    "# data_path_str  = 'data/h4_ca_coords.npz'\n",
    "# test_limit = 1028\n",
    "# rr = np.load(data_path_str)\n",
    "# ca_coords = [rr[f] for f in rr.files][0][:test_limit,:,:3]\n",
    "# ca_coords.shape\n",
    "\n",
    "# getting N-Ca, Ca-C vectors to add as typeI features\n",
    "#apa = apart helices for val/train split\n",
    "#tog = together helices for val/train split\n",
    "apa_path_str  = 'data_npose/h4_apa_coords.npz'\n",
    "tog_path_str  = 'data_npose/h4_tog_coords.npz'\n",
    "\n",
    "#grab the first 3 atoms which are N,CA,C\n",
    "test_limit = 5048\n",
    "rr = np.load(apa_path_str)\n",
    "coords_apa = [rr[f] for f in rr.files][0][:test_limit,:]\n",
    "\n",
    "rr = np.load(tog_path_str)\n",
    "coords_tog = [rr[f] for f in rr.files][0][:test_limit,:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d4c2ed33",
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_npose_from_coords(coords_in):\n",
    "    \"\"\"Use N, CA, C coordinates to generate O an CB atoms\"\"\"\n",
    "    rot_mat_cat = np.ones(sum((coords_in.shape[:-1], (1,)), ()))\n",
    "    \n",
    "    coords = np.concatenate((coords_in,rot_mat_cat),axis=-1)\n",
    "    \n",
    "    npose = np.ones((coords_in.shape[0]*5,4)) #5 is atoms per res\n",
    "\n",
    "    by_res = npose.reshape(-1, 5, 4)\n",
    "    \n",
    "    if ( \"N\" in ATOM_NAMES ):\n",
    "        by_res[:,N,:3] = coords_in[:,0,:3]\n",
    "    if ( \"CA\" in ATOM_NAMES ):\n",
    "        by_res[:,CA,:3] = coords_in[:,1,:3]\n",
    "    if ( \"C\" in ATOM_NAMES ):\n",
    "        by_res[:,C,:3] = coords_in[:,2,:3]\n",
    "    if ( \"O\" in ATOM_NAMES ):\n",
    "        by_res[:,O,:3] = nu.build_O(npose)\n",
    "    if ( \"CB\" in ATOM_NAMES ):\n",
    "        tpose = nu.tpose_from_npose(npose)\n",
    "        by_res[:,CB,:] = nu.build_CB(tpose)\n",
    "\n",
    "    return npose\n",
    "\n",
    "def dump_coord_pdb(coords_in, fileOut='fileOut.pdb'):\n",
    "    \n",
    "    npose =  build_npose_from_coords(coords_in)\n",
    "    nu.dump_npdb(npose,fileOut)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "508327fa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([0., 1., 0., 1., 0., 1., 0., 1., 0., 1., 0., 1.])\n",
      "tensor([0.6000, 0.8000, 0.4000, 0.9000, 0.3000, 1.0000, 0.2000, 1.0000, 0.1000,\n",
      "        1.0000, 0.1000, 1.0000])\n",
      "tensor([1.0000, 0.2000, 0.8000, 0.6000, 0.6000, 0.8000, 0.4000, 0.9000, 0.3000,\n",
      "        1.0000, 0.2000, 1.0000])\n",
      "tensor([ 0.9000, -0.5000,  1.0000,  0.2000,  0.8000,  0.6000,  0.6000,  0.8000,\n",
      "         0.4000,  0.9000,  0.3000,  1.0000])\n",
      "tensor([ 0.4000, -0.9000,  1.0000, -0.3000,  1.0000,  0.3000,  0.8000,  0.7000,\n",
      "         0.6000,  0.8000,  0.4000,  0.9000])\n"
     ]
    }
   ],
   "source": [
    "#goal define edges of\n",
    "#connected backbone 1, \n",
    "#unconnected atoms 0,\n",
    "\n",
    "\n",
    "def get_midpoint(ep_in):\n",
    "    \"\"\"Get midpoint, of each batched set of points\"\"\"\n",
    "    \n",
    "    #calculate midpoint\n",
    "    midpoint = ep_in.sum(axis=1)/np.repeat(ep_in.shape[1], ep_in.shape[2])\n",
    "    \n",
    "    return midpoint\n",
    "\n",
    "# def normQ(Q):\n",
    "#     \"\"\"normalize a quaternions\n",
    "#     \"\"\"\n",
    "#     return Q / torch.linalg.norm(Q, keepdim=True, dim=-1)\n",
    "\n",
    "# def Rs2Qs(Rs):\n",
    "#     Qs = torch.zeros((*Rs.shape[:-2],4), device=Rs.device)\n",
    "\n",
    "#     Qs[...,0] = 1.0 + Rs[...,0,0] + Rs[...,1,1] + Rs[...,2,2]\n",
    "#     Qs[...,1] = 1.0 + Rs[...,0,0] - Rs[...,1,1] - Rs[...,2,2]\n",
    "#     Qs[...,2] = 1.0 - Rs[...,0,0] + Rs[...,1,1] - Rs[...,2,2]\n",
    "#     Qs[...,3] = 1.0 - Rs[...,0,0] - Rs[...,1,1] + Rs[...,2,2]\n",
    "#     Qs[Qs<0.0] = 0.0\n",
    "#     Qs = torch.sqrt(Qs) / 2.0\n",
    "#     Qs[...,1] *= torch.sign( Rs[...,2,1] - Rs[...,1,2] )\n",
    "#     Qs[...,2] *= torch.sign( Rs[...,0,2] - Rs[...,2,0] )\n",
    "#     Qs[...,3] *= torch.sign( Rs[...,1,0] - Rs[...,0,1] )\n",
    "\n",
    "#     return Qs\n",
    "\n",
    "# def Qs2Rs(Qs):\n",
    "#     Rs = torch.zeros((*Qs.shape[:-1],3,3), device=Qs.device)\n",
    "\n",
    "#     Rs[...,0,0] = Qs[...,0]*Qs[...,0]+Qs[...,1]*Qs[...,1]-Qs[...,2]*Qs[...,2]-Qs[...,3]*Qs[...,3]\n",
    "#     Rs[...,0,1] = 2*Qs[...,1]*Qs[...,2] - 2*Qs[...,0]*Qs[...,3]\n",
    "#     Rs[...,0,2] = 2*Qs[...,1]*Qs[...,3] + 2*Qs[...,0]*Qs[...,2]\n",
    "#     Rs[...,1,0] = 2*Qs[...,1]*Qs[...,2] + 2*Qs[...,0]*Qs[...,3]\n",
    "#     Rs[...,1,1] = Qs[...,0]*Qs[...,0]-Qs[...,1]*Qs[...,1]+Qs[...,2]*Qs[...,2]-Qs[...,3]*Qs[...,3]\n",
    "#     Rs[...,1,2] = 2*Qs[...,2]*Qs[...,3] - 2*Qs[...,0]*Qs[...,1]\n",
    "#     Rs[...,2,0] = 2*Qs[...,1]*Qs[...,3] - 2*Qs[...,0]*Qs[...,2]\n",
    "#     Rs[...,2,1] = 2*Qs[...,2]*Qs[...,3] + 2*Qs[...,0]*Qs[...,1]\n",
    "#     Rs[...,2,2] = Qs[...,0]*Qs[...,0]-Qs[...,1]*Qs[...,1]-Qs[...,2]*Qs[...,2]+Qs[...,3]*Qs[...,3]\n",
    "\n",
    "#     return Rs\n",
    "\n",
    "\n",
    "def normalize_points(input_xyz, print_dist=False):\n",
    "    \n",
    "    #broadcast to distance matrix [Batch, M, R3] to [Batch,M,1, R3] to [Batch,1,M, R3] to [Batch, M,M, R3] \n",
    "    vec_diff = input_xyz[...,None,:]-input_xyz[...,None,:,:]\n",
    "    dist = np.sqrt(np.sum(np.square(vec_diff),axis=len(input_xyz.shape)))\n",
    "    furthest_dist = np.max(dist)\n",
    "    centroid  = get_midpoint(input_xyz)\n",
    "    if print_dist:\n",
    "        print(f'largest distance {furthest_dist:0.1f}')\n",
    "    \n",
    "    xyz_mean_zero = input_xyz - centroid[:,None,:]\n",
    "    return xyz_mean_zero/furthest_dist\n",
    "\n",
    "def define_graph_edges(n_nodes):\n",
    "    #connected backbone\n",
    "\n",
    "    con_v1 = np.arange(n_nodes-1) #vertex 1 of edges in chronological order\n",
    "    con_v2 = np.arange(1,n_nodes) #vertex 2 of edges in chronological order\n",
    "\n",
    "    ind = con_v1*(n_nodes-1)+con_v2-1 #account for removed self connections (-1)\n",
    "\n",
    "\n",
    "    #unconnected backbone\n",
    "\n",
    "    nodes = np.arange(n_nodes)\n",
    "    v1 = np.repeat(nodes,n_nodes-1) #starting vertices, same number repeated for each edge\n",
    "\n",
    "    start_v2 = np.repeat(np.arange(n_nodes)[None,:],n_nodes,axis=0)\n",
    "    diag_ind = np.diag_indices(n_nodes)\n",
    "    start_v2[diag_ind] = -1 #diagonal of matrix is self connections which we remove (self connections are managed by SE3 Conv channels)\n",
    "    v2 = start_v2[start_v2>-0.5] #remove diagonal and flatten\n",
    "\n",
    "    edge_data = torch.zeros(len(v2))\n",
    "    edge_data[ind] = 1\n",
    "    \n",
    "    return v1,v2,edge_data, ind\n",
    "\n",
    "\n",
    "\n",
    "def make_pe_encoding(n_nodes=65, embed_dim = 12, scale = 1000, cast_type=torch.float32, print_out=False):\n",
    "    #positional encoding of node\n",
    "    i_array = np.arange(1,(embed_dim/2)+1)\n",
    "    wk = (1/(scale**(i_array*2/embed_dim)))\n",
    "    t_array = np.arange(n_nodes)\n",
    "    si = torch.tensor(np.sin(wk*t_array.reshape((-1,1))))\n",
    "    ci = torch.tensor(np.cos(wk*t_array.reshape((-1,1))))\n",
    "    pe = torch.stack((si,ci),axis=2).reshape(t_array.shape[0],embed_dim).type(cast_type)\n",
    "    \n",
    "    if print_out == True:\n",
    "        for x in range(int(n_nodes/12)):\n",
    "            print(np.round(pe[x],1))\n",
    "    \n",
    "    return pe\n",
    "    \n",
    "    \n",
    "#v1,v2,edge_data, ind = define_graph_edges(n_nodes)\n",
    "#norm_p = normalize_points(ca_coords,print_dist=True)\n",
    "pe = make_pe_encoding(n_nodes=65, embed_dim = 12, scale = 10, print_out=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "321dc5e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "#?dgl.nn.pytorch.KNNGraph, nearest neighbor graph maker\n",
    "def define_graph(batch_size=8,n_nodes=65):\n",
    "    \n",
    "    v1,v2,edge_data, ind = define_graph_edges(n_nodes)\n",
    "    pe = make_pe_encoding(n_nodes=n_nodes)\n",
    "    \n",
    "    graphList = []\n",
    "    \n",
    "    for i in range(batch_size):\n",
    "        \n",
    "        g = dgl.graph((v1,v2))\n",
    "        g.edata['con'] = edge_data\n",
    "        g.ndata['pe'] = pe\n",
    "\n",
    "        graphList.append(g)\n",
    "        \n",
    "    batched_graph = dgl.batch(graphList)\n",
    "\n",
    "    return batched_graph\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "d1a60cff",
   "metadata": {},
   "outputs": [],
   "source": [
    "def torch_normalize(v, eps=1e-6):\n",
    "    \"\"\"Normalize vector in last axis\"\"\"\n",
    "    norm = torch.linalg.vector_norm(v, dim=len(v.shape)-1)+eps\n",
    "    return v / norm[...,None]\n",
    "\n",
    "def normalize(v):\n",
    "    \"\"\"Normalize vector in last axis\"\"\"\n",
    "    norm = np.linalg.norm(v,axis=len(v.shape)-1)\n",
    "    norm[norm == 0] = 1\n",
    "    return v / norm[...,None]\n",
    "\n",
    "def get_CN_vector(coords_in):\n",
    "    N_CA_vec = normalize(coords_in[...,N,:3]-coords_in[...,CA,:3])\n",
    "    C_CA_vec = normalize(coords_in[...,C,:3]-coords_in[...,CA,:3])\n",
    "    return N_CA_vec, C_CA_vec\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "5cc4e2ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "def _get_relative_pos(graph_in: dgl.DGLGraph) -> torch.Tensor:\n",
    "    x = graph_in.ndata['pos']\n",
    "    src, dst = graph_in.edges()\n",
    "    rel_pos = x[dst] - x[src]\n",
    "    return rel_pos\n",
    "\n",
    "class Helix4_Dataset(Dataset):\n",
    "    def __init__(self, coordinates: np.array, cast_type=torch.float32):\n",
    "        #prots,#length_prot in aa, #residues/aa, #xyz per atom\n",
    "           \n",
    "        #alphaFold reduce by 10\n",
    "        coord_div = 10\n",
    "        \n",
    "        coordinates = coordinates/coord_div\n",
    "        self.ca_coords = torch.tensor(coordinates[:,:,CA,:], dtype=cast_type)\n",
    "        #unsqueeze to stack together later\n",
    "        self.N_CA_vec = torch.tensor(coordinates[:,:,N,:] - coordinates[:,:,CA,:], dtype=cast_type)\n",
    "        self.C_CA_vec = torch.tensor(coordinates[:,:,C,:] - coordinates[:,:,CA,:], dtype=cast_type)\n",
    "        \n",
    "        self.N_CA_vec = torch_normalize(self.N_CA_vec).unsqueeze(2)\n",
    "        self.C_CA_vec = torch_normalize(self.C_CA_vec).unsqueeze(2)\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.ca_coords)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        return {'CA':self.ca_coords[idx], 'N_CA':self.N_CA_vec[idx], 'C_CA':self.C_CA_vec[idx]}\n",
    "    \n",
    "    \n",
    "\n",
    "    \n",
    "    \n",
    "class Make_KNN_MP_Graphs():\n",
    "    \n",
    "    #8 long positional encoding\n",
    "    NODE_FEATURE_DIM_0 = 12\n",
    "    EDGE_FEATURE_DIM = 1 # 0 or 1 primary seq connection or not\n",
    "    NODE_FEATURE_DIM_1 = 2\n",
    "    \n",
    "    def __init__(self, mp_stride=4, n_nodes=65, radius=15, coord_div=10, cast_type=torch.float32, channels_start=32,\n",
    "                       ndf1=6, ndf0=32,cuda=True):\n",
    "        \n",
    "        self.KNN = 30\n",
    "        self.n_nodes = n_nodes\n",
    "        self.pe = make_pe_encoding(n_nodes=n_nodes)\n",
    "        self.mp_stride = mp_stride\n",
    "        self.cast_type = cast_type\n",
    "        self.channels_start = channels_start\n",
    "        \n",
    "        self.cuda = cuda\n",
    "        self.ndf1 = ndf1 #awkard adding of nodes features to mpGraph\n",
    "        self.ndf0 = ndf0\n",
    "        \n",
    "    def create_and_batch(self, bb_dict):\n",
    "        \n",
    "        graphList = []\n",
    "        mpGraphList = []\n",
    "        mpRevGraphList = []\n",
    "        mpSelfGraphList = []\n",
    "        \n",
    "        for j, caXYZ in enumerate(bb_dict['CA']):\n",
    "            graph = dgl.knn_graph(caXYZ, self.KNN)\n",
    "            graph.ndata['pe'] = pe\n",
    "            graph.ndata['pos'] = caXYZ\n",
    "            graph.ndata['bb_ori'] = torch.cat((bb_dict['N_CA'][j],  bb_dict['C_CA'][j]),axis=1)\n",
    "            \n",
    "            #define covalent connections\n",
    "            esrc, edst = graph.edges()\n",
    "            graph.edata['con'] = (torch.abs(esrc-edst)==1).type(self.cast_type).reshape((-1,1))\n",
    "            \n",
    "            mp_list = torch.zeros((len(list(range(0,self.n_nodes, self.mp_stride))),caXYZ.shape[1]))\n",
    "            \n",
    "            new_src = torch.tensor([],dtype=torch.int)\n",
    "            new_dst = torch.tensor([],dtype=torch.int)\n",
    "            \n",
    "            new_src_rev = torch.tensor([], dtype=torch.int)\n",
    "            new_dst_rev = torch.tensor([], dtype=torch.int)\n",
    "           \n",
    "            i=0#mp list counter\n",
    "            for x in range(0,self.n_nodes, self.mp_stride):\n",
    "                src, dst = graph.in_edges(x) #dst repeats x\n",
    "                n_tot = torch.cat((torch.tensor(x).unsqueeze(0),src)) #add x to node list\n",
    "                mp_list[i] = caXYZ[n_tot].sum(axis=0)/n_tot.shape[0]\n",
    "                mp_node = i + graph.num_nodes() #add midpoints nodes at end of graph\n",
    "                #define edges between midpoint nodes and nodes defining midpoint for midpointGraph\n",
    "                \n",
    "                new_src = torch.cat((new_src,n_tot))\n",
    "                new_dst = torch.cat((new_dst,\n",
    "                                     (torch.tensor(mp_node).unsqueeze(0).repeat(n_tot.shape[0]))))\n",
    "                #and reverse graph for coming off\n",
    "                new_src_rev = torch.cat((new_src_rev,\n",
    "                                         (torch.tensor(mp_node).unsqueeze(0).repeat(n_tot.shape[0]))))\n",
    "                new_dst_rev = torch.cat((new_dst_rev,n_tot))\n",
    "                \n",
    "                i+=1\n",
    "                \n",
    "            mpGraph = dgl.graph((new_src,new_dst))\n",
    "            mpGraph.ndata['pos'] = torch.cat((caXYZ,mp_list),axis=0).type(self.cast_type)\n",
    "            mp_node_indx = torch.arange(0,self.n_nodes, self.mp_stride).type(torch.int)\n",
    "            #match output shape of first transformer\n",
    "            pe_mp = torch.cat((pe,torch.zeros((pe.shape[0],self.channels_start-pe.shape[1]))),axis=1)\n",
    "            mpGraph.ndata['pe'] = torch.cat((pe_mp,pe_mp[mp_node_indx]))\n",
    "            mpGraph.edata['con'] = torch.zeros((mpGraph.num_edges(),1))\n",
    "            \n",
    "            mpGraph_rev = dgl.graph((new_src_rev,new_dst_rev))\n",
    "            mpGraph_rev.ndata['pos'] = torch.cat((caXYZ,mp_list),axis=0).type(self.cast_type)\n",
    "            mpGraph_rev.ndata['pe'] = torch.cat((pe_mp,pe_mp[mp_node_indx]))\n",
    "            mpGraph_rev.edata['con'] = torch.zeros((mpGraph_rev.num_edges(),1))\n",
    "            \n",
    "            #make graph for self interaction of midpoints\n",
    "            v1,v2,edge_data, ind = define_graph_edges(len(mp_list))\n",
    "            mpSelfGraph = dgl.graph((v1,v2))\n",
    "            mpSelfGraph.edata['con'] = edge_data.reshape((-1,1))\n",
    "            mpSelfGraph.ndata['pe'] = pe[mp_node_indx] #not really needed\n",
    "            mpSelfGraph.ndata['pos'] = mp_list.type(self.cast_type)\n",
    "            \n",
    "            \n",
    "            mpSelfGraphList.append(mpSelfGraph) \n",
    "            mpGraphList.append(mpGraph)\n",
    "            mpRevGraphList.append(mpGraph_rev)\n",
    "            graphList.append(graph)\n",
    "        \n",
    "        return dgl.batch(graphList), dgl.batch(mpGraphList), dgl.batch(mpSelfGraphList), dgl.batch(mpRevGraphList)\n",
    "    \n",
    "    def prep_for_network(self, bb_dict, cuda=True):\n",
    "    \n",
    "        batched_graph, batched_mpgraph, batched_mpself_graph, batched_mpRevgraph =  self.create_and_batch(bb_dict)\n",
    "        \n",
    "        edge_feats        =    {'0':   batched_graph.edata['con'][:, :self.EDGE_FEATURE_DIM, None]}\n",
    "        edge_feats_mp     = {'0': batched_mpgraph.edata['con'][:, :self.EDGE_FEATURE_DIM, None]} #def all zero now\n",
    "        edge_feats_mpself = {'0': batched_mpself_graph.edata['con'][:, :self.EDGE_FEATURE_DIM, None]}\n",
    "#         edge_feats_mp     = {'0': batched_mpRevgraph.edata['con'][:, :self.EDGE_FEATURE_DIM, None]}\n",
    "        batched_graph.edata['rel_pos']   = _get_relative_pos(batched_graph)\n",
    "        batched_mpgraph.edata['rel_pos'] = _get_relative_pos(batched_mpgraph)\n",
    "        batched_mpself_graph.edata['rel_pos'] = _get_relative_pos(batched_mpself_graph)\n",
    "        batched_mpRevgraph.edata['rel_pos'] = _get_relative_pos(batched_mpRevgraph)\n",
    "        # get node features\n",
    "        node_feats =         {'0': batched_graph.ndata['pe'][:, :self.NODE_FEATURE_DIM_0, None],\n",
    "                              '1': batched_graph.ndata['bb_ori'][:,:self.NODE_FEATURE_DIM_1, :3]}\n",
    "        node_feats_mp =      {'0': batched_mpgraph.ndata['pe'][:, :self.ndf0, None],\n",
    "                              '1': torch.ones((batched_mpgraph.num_nodes(),self.ndf1,3))}\n",
    "        #unused\n",
    "        node_feats_mpself =  {'0': batched_mpself_graph.ndata['pe'][:, :self.NODE_FEATURE_DIM_0, None]}\n",
    "        \n",
    "        if cuda:\n",
    "            bg,nf,ef = to_cuda(batched_graph), to_cuda(node_feats), to_cuda(edge_feats)\n",
    "            bg_mp, nf_mp, ef_mp = to_cuda(batched_mpgraph), to_cuda(node_feats_mp), to_cuda(edge_feats_mp)\n",
    "            bg_mps, nf_mps, ef_mps = to_cuda(batched_mpself_graph), to_cuda(node_feats_mpself), to_cuda(edge_feats_mpself)\n",
    "            bg_mpRev = to_cuda(batched_mpRevgraph)\n",
    "            \n",
    "            return bg,nf,ef, bg_mp, nf_mp, ef_mp, bg_mps, nf_mps, ef_mps, bg_mpRev\n",
    "        \n",
    "        else:\n",
    "            bg,nf,ef = batched_graph, node_feats, edge_feats\n",
    "            bg_mp, nf_mp, ef_mp = batched_mpgraph, node_feats_mp, edge_feats_mp\n",
    "            bg_mps, nf_mps, ef_mps = batched_mpself_graph, node_feats_mpself, edge_feats_mpself\n",
    "            bg_mpRev = batched_mpRevgraph\n",
    "            \n",
    "            return bg,nf,ef, bg_mp, nf_mp, ef_mp, bg_mps, nf_mps, ef_mps, bg_mpRev\n",
    "        \n",
    "            \n",
    "\n",
    "def get_edge_features(graph,edge_feature_dim=1):\n",
    "    return {'0': graph.edata['con'][:, :edge_feature_dim, None]}\n",
    "\n",
    "def define_poolGraph(n_nodes, batch_size, cast_type=torch.float32, cuda_out=True ):\n",
    "    \n",
    "    v1,v2,edge_data, ind = define_graph_edges(n_nodes)\n",
    "    #pe = make_pe_encoding(n_nodes=n_nodes)#pe e\n",
    "    \n",
    "    graphList = []\n",
    "    \n",
    "    for i in range(batch_size):\n",
    "        \n",
    "        g = dgl.graph((v1,v2))\n",
    "        g.edata['con'] = edge_data.type(cast_type).reshape((-1,1))\n",
    "        g.ndata['pos'] = torch.zeros((n_nodes,3),dtype=torch.float32)\n",
    "\n",
    "        graphList.append(g)\n",
    "        \n",
    "    batched_graph = dgl.batch(graphList)\n",
    "    \n",
    "    if cuda_out:\n",
    "        return to_cuda(batched_graph)\n",
    "    else:\n",
    "        return batched_graph            \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "e69a49f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def pull_edge_features(graph, edge_feat_dim=1):\n",
    "    return {'0': graph.edata['con'][:, :edge_feat_dim, None]}\n",
    "\n",
    "def prep_for_gcn(graph, xyz_pos, edge_feats_input, idx, max_degree=3, comp_grad=True):\n",
    "    \n",
    "    src, dst = graph.edges()\n",
    "    \n",
    "    new_pos = F.gather_row(xyz_pos, idx)\n",
    "    rel_pos = F.gather_row(new_pos,dst) - F.gather_row(new_pos,src) \n",
    "    \n",
    "    basis_out = get_basis(rel_pos, max_degree=max_degree,\n",
    "                                   compute_gradients=comp_grad,\n",
    "                                   use_pad_trick=False)\n",
    "    basis_out = update_basis_with_fused(basis_out, max_degree, use_pad_trick=False,\n",
    "                                            fully_fused=False)\n",
    "    edge_feats_out = get_populated_edge_features(rel_pos, edge_feats_input)\n",
    "    return edge_feats_out, basis_out, new_pos    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "eeb3cdb3",
   "metadata": {},
   "outputs": [],
   "source": [
    "class GaussianFourierProjection(nn.Module):\n",
    "    \"\"\"Gaussian random features for encoding time steps.\"\"\"  \n",
    "    #From Yang Song, Tutorial on Score based diffusion models\n",
    "    def __init__(self, embed_dim, scale=30.):\n",
    "        super().__init__()\n",
    "        # Randomly sample weights during initialization. These weights are fixed \n",
    "        # during optimization and are not trainable.\n",
    "        self.W = nn.Parameter(torch.randn(embed_dim // 2) * scale, requires_grad=False)\n",
    "    def forward(self, x):\n",
    "        x_proj = x[:, None] * self.W[None, :] * 2 * np.pi\n",
    "        return torch.cat([torch.sin(x_proj), torch.cos(x_proj)], dim=-1)\n",
    "    \n",
    "class GaussianFourierProjection_Linear(nn.Module):\n",
    "    \"\"\"Gaussian random features for encoding time steps.\"\"\"  \n",
    "    #From Yang Song, Tutorial on Score based diffusion models\n",
    "    def __init__(self, embed_dim, scale=30., use_deg1 = True):\n",
    "        super().__init__()\n",
    "        self.GFP = GaussianFourierProjection(embed_dim, scale=scale)\n",
    "        self.linear0 = nn.Linear(embed_dim,embed_dim)\n",
    "        self.use_deg1 = use_deg1\n",
    "        self.act = nn.SiLU()\n",
    "        if use_deg1:\n",
    "            self.linear1 = nn.Linear(embed_dim,1) #create a scalar for multiplication to vector '1'\n",
    "            #according to to some toronto math notes I believe this retains invariance\n",
    "\n",
    "    def forward(self, t):\n",
    "        if self.use_deg1:\n",
    "            return {'0': self.act(self.linear0(self.GFP(t))), '1':self.act(self.linear1(self.GFP(t)))}\n",
    "        else:\n",
    "            return {'0' : self.act(self.linear0(self.GFP(t)))}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "401432e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "class GraphUNet(torch.nn.Module):\n",
    "    def __init__(self, \n",
    "                 fiber_start = Fiber({0:12, 1:2}),\n",
    "                 fiber_out = Fiber({1:2}),\n",
    "                 k=4,\n",
    "                 batch_size = 8,\n",
    "                 stride=4,\n",
    "                 max_degree=3,\n",
    "                 channels=32,\n",
    "                 num_heads = 8,\n",
    "                 channels_div=4,\n",
    "                 num_layers = 1,\n",
    "                 num_layers_ca = 1,\n",
    "                 edge_feature_dim=1,\n",
    "                 latent_pool_type = 'avg',\n",
    "                 t_size = 12,\n",
    "                 use_tdeg1 = True,\n",
    "                 cuda=True):\n",
    "        super(GraphUNet, self).__init__()\n",
    "        \n",
    "        \n",
    "        self.comp_basis_grad = True\n",
    "        self.cuda = cuda\n",
    "        \n",
    "        if cuda:\n",
    "            self.device='cuda:0'\n",
    "        else:\n",
    "            self.device='cpu'\n",
    "        \n",
    "        self.max_degree=max_degree\n",
    "        self.B = batch_size\n",
    "        self.k = k\n",
    "        self.ts = t_size\n",
    "        self.use_tdeg1 = use_tdeg1\n",
    "        \n",
    "        self.embed_t = GaussianFourierProjection_Linear(self.ts, use_deg1=self.use_tdeg1)\n",
    "        self.t_fiber = Fiber({0:self.ts}) #add for change in fiber with self.concat_t\n",
    "        \n",
    "        self.num_layers = 1\n",
    "        self.num_layers_ca = num_layers_ca\n",
    "        self.channels = 32\n",
    "        self.feat0 = 32\n",
    "        self.feat1 = 6\n",
    "        self.channels_div = 4\n",
    "        self.num_heads = 8\n",
    "        self.mult = int(stride/2)\n",
    "        self.fiber_edge=Fiber({0:edge_feature_dim})\n",
    "        self.edge_feat_dim = edge_feature_dim\n",
    "        \n",
    "        self.pool_type = latent_pool_type\n",
    "        \n",
    "        self.channels_down_ca = channels\n",
    "        #down c_alpha interactions by radius\n",
    "        self.fiber_start =  fiber_start\n",
    "        self.fiber_hidden_down_ca = Fiber.create(self.max_degree, self.channels_down_ca)\n",
    "        self.fiber_out_down_ca =Fiber({0: self.feat0, 1: self.feat1})\n",
    "        \n",
    "        #concat_t, plus one on input fiber, run concat_t method on forward\n",
    "        self.down_ca = SE3Transformer(num_layers = self.num_layers_ca,\n",
    "                        fiber_in=self.fiber_start+self.t_fiber,\n",
    "                        fiber_hidden= self.fiber_hidden_down_ca, \n",
    "                        fiber_out=self.fiber_out_down_ca,\n",
    "                        num_heads = self.num_heads,\n",
    "                        channels_div = self.channels_div,\n",
    "                        fiber_edge=self.fiber_edge,\n",
    "                        low_memory=True,\n",
    "                        tensor_cores=False)\n",
    "        \n",
    "        self.channels_down_ca2mp = self.channels_down_ca*self.mult\n",
    "        \n",
    "        #pool from c_alpha onto midpoints\n",
    "        self.fiber_in_down_ca2mp     = self.fiber_out_down_ca\n",
    "        self.fiber_hidden_down_ca2mp = Fiber.create(max_degree, self.channels_down_ca2mp)\n",
    "        self.fiber_out_down_ca2mp    = Fiber({0: self.feat0*self.mult, 1: self.feat1*self.mult})\n",
    "        \n",
    "        #concat_t, plus one on input fiber, run concat_t method on forward\n",
    "        self.down_ca2mp = SE3Transformer(num_layers = self.num_layers,\n",
    "                            fiber_in     = self.fiber_in_down_ca2mp+self.t_fiber,\n",
    "                            fiber_hidden = self.fiber_hidden_down_ca2mp, \n",
    "                            fiber_out    = self.fiber_out_down_ca2mp,\n",
    "                            num_heads =    self.num_heads,\n",
    "                            channels_div = self.channels_div,\n",
    "                            fiber_edge=self. fiber_edge,\n",
    "                            low_memory=True,\n",
    "                            tensor_cores=False)\n",
    "        \n",
    "        self.fiber_in_mptopk =  self.fiber_out_down_ca2mp\n",
    "        self.fiber_hidden_down_mp  =self.fiber_hidden_down_ca2mp\n",
    "        self.fiber_out_down_mp_out =self.fiber_out_down_ca2mp\n",
    "        self.fiber_out_topkpool=Fiber({0: self.feat0*self.mult*self.mult})\n",
    "        \n",
    "        #concat_t, plus one on input fiber, run concat_t method on forward\n",
    "        self.mp_topk = SE3Transformer_topK(num_layers      = self.num_layers,\n",
    "                                        fiber_in      = self.fiber_in_mptopk+self.t_fiber,\n",
    "                                        fiber_hidden  = self.fiber_hidden_down_mp, \n",
    "                                        fiber_out     = self.fiber_out_down_mp_out ,\n",
    "                                        fiber_out_topk= self.fiber_out_topkpool,\n",
    "                                        k             = self.k,\n",
    "                                        num_heads     = self.num_heads,\n",
    "                                        channels_div  = self.channels_div,\n",
    "                                        fiber_edge    =  self.fiber_edge,\n",
    "                                        low_memory=True,\n",
    "                                        tensor_cores=False)\n",
    "        \n",
    "        self.gsmall = define_poolGraph(self.k, self.B, cast_type=torch.float32, cuda_out=self.cuda)\n",
    "        self.ef_small = pull_edge_features(self.gsmall, edge_feat_dim=self.edge_feat_dim)\n",
    "        \n",
    "        #change to doing convolutions instead of points\n",
    "        self.fiber_in_down_gcn   =  self.fiber_out_topkpool\n",
    "        self.fiber_out_down_gcn  = Fiber({0: self.feat0*self.mult*self.mult, 1: self.feat1*self.mult})\n",
    "\n",
    "        self.down_gcn = ConvSE3(fiber_in  = self.fiber_in_down_gcn,\n",
    "                           fiber_out = self.fiber_out_down_gcn,\n",
    "                           fiber_edge= self.fiber_edge,\n",
    "                             self_interaction=True,\n",
    "                             use_layer_norm=True,\n",
    "                             max_degree=self.max_degree,\n",
    "                             fuse_level= ConvSE3FuseLevel.NONE,\n",
    "                             low_memory= True)\n",
    "        \n",
    "        \n",
    "        self.fiber_in_down_gcnp = self.fiber_out_down_gcn\n",
    "        #probably rename latent\n",
    "        self.latent_size = self.feat0*self.mult*self.mult\n",
    "        self.fiber_latent = Fiber({0: self.latent_size})\n",
    "\n",
    "        self.down_gcn2pool = ConvSE3(fiber_in=self.fiber_in_down_gcnp,\n",
    "                                     fiber_out=self.fiber_latent,\n",
    "                                     fiber_edge=self.fiber_edge,\n",
    "                                     self_interaction=True,\n",
    "                                     use_layer_norm=True,\n",
    "                                     max_degree=self.max_degree,\n",
    "                                     fuse_level= ConvSE3FuseLevel.NONE,\n",
    "                                     low_memory= True)\n",
    "        \n",
    "        self.global_pool = GPooling(pool=self.pool_type, feat_type=0)\n",
    "\n",
    "        self.latent_unpool_layer = Latent_Unpool(fiber_in = self.fiber_latent, fiber_add = self.fiber_out_down_gcn, \n",
    "                                            knodes = self.k)\n",
    "\n",
    "        self.up_gcn = ConvSE3(fiber_in=self.fiber_out_down_gcn,\n",
    "                             fiber_out=self.fiber_out_down_gcn,\n",
    "                             fiber_edge=self.fiber_edge,\n",
    "                             self_interaction=True,\n",
    "                             use_layer_norm=True,\n",
    "                             max_degree=self.max_degree,\n",
    "                             fuse_level= ConvSE3FuseLevel.NONE,\n",
    "                             low_memory= True)\n",
    "        \n",
    "        self.unpool_layer = Unpool_Layer(fiber_in=self.fiber_out_down_gcn, fiber_add=self.fiber_out_down_ca)\n",
    "        \n",
    "        self.fiber_in_up_gcn_mp = self.unpool_layer.fiber_out\n",
    "        self.fiber_hidden_up_mp= self.fiber_hidden_down_ca2mp\n",
    "        self.fiber_out_up_gcn_mp = self.fiber_out_down_mp_out\n",
    "\n",
    "        self.up_gcn_mp = SE3Transformer(num_layers = num_layers,\n",
    "                        fiber_in=self.fiber_in_up_gcn_mp,\n",
    "                        fiber_hidden= self.fiber_hidden_up_mp, \n",
    "                        fiber_out=self.fiber_out_up_gcn_mp,\n",
    "                        num_heads = self.num_heads,\n",
    "                        channels_div = self.channels_div,\n",
    "                        fiber_edge=self.fiber_edge,\n",
    "                        low_memory=True,\n",
    "                        tensor_cores=False)\n",
    "        \n",
    "        self.unpool_layer_off_mp = Unpool_Layer(fiber_in=self.fiber_out_down_mp_out, fiber_add=self.fiber_out_down_mp_out)\n",
    "\n",
    "        self.fiber_in_up_off_mp = self.fiber_out_up_gcn_mp\n",
    "        self.fiber_hidden_up_off_mp = self.fiber_hidden_up_mp\n",
    "        self.fiber_out_up_off_mp = self.fiber_out_down_ca \n",
    "        \n",
    "        #uses reverse graph to move mp off \n",
    "        \n",
    "        self.up_off_mp = SE3Transformer(num_layers = self.num_layers,\n",
    "                        fiber_in=self.fiber_in_up_off_mp,\n",
    "                        fiber_hidden= self.fiber_hidden_up_off_mp, \n",
    "                        fiber_out=self.fiber_out_up_off_mp,\n",
    "                        num_heads = self.num_heads,\n",
    "                        channels_div = self.channels_div,\n",
    "                        fiber_edge=self.fiber_edge,\n",
    "                        low_memory=True,\n",
    "                        tensor_cores=False)\n",
    "        \n",
    "        self.pre_linear = Fiber({1:36})\n",
    "        \n",
    "        #concat_t, plus one on input fiber, run concat_t method on forward\n",
    "        \n",
    "        self.up_ca = SE3Transformer(num_layers = self.num_layers_ca,\n",
    "                                    fiber_in=self.fiber_out_down_ca+self.t_fiber,\n",
    "                                    fiber_hidden= self.fiber_hidden_down_ca, \n",
    "                                    fiber_out=self.pre_linear,\n",
    "                                    num_heads = self.num_heads,\n",
    "                                    channels_div = self.channels_div,\n",
    "                                    fiber_edge= self.fiber_edge,\n",
    "                                    low_memory=True,\n",
    "                                    tensor_cores=False)\n",
    "        \n",
    "        self.fiber_out = fiber_out\n",
    "        \n",
    "        self.linear = LinearSE3(fiber_in=self.pre_linear,\n",
    "                                fiber_out=fiber_out)\n",
    "        \n",
    "        self.zero_linear()\n",
    "        self.act = nn.SiLU()\n",
    "        \n",
    "    def zero_linear(self):\n",
    "        nn.init.zeros_(self.linear.weights['1'])\n",
    "        \n",
    "    def concat_mp_feats(self, ca_feats_in, mp_feats):\n",
    "\n",
    "        nf0_c = ca_feats_in['0'].shape[-2]\n",
    "        nf1_c = ca_feats_in['1'].shape[-2]\n",
    "\n",
    "        out0_cat_shape = (B,self.ca_nodes,-1,1)\n",
    "        mp0_cat_shape  = (B,self.mp_nodes,-1,1)\n",
    "        out1_cat_shape = (B,self.ca_nodes,-1,3)\n",
    "        mp1_cat_shape  = (B,self.mp_nodes,-1,3)\n",
    "\n",
    "        nf_c = {} #nf_cat\n",
    "        nf_c['0'] = torch.cat((ca_feats_in['0'].reshape(out0_cat_shape), \n",
    "                                 mp_feats['0'].reshape(mp0_cat_shape)[:,-(self.mp_nodes-self.ca_nodes):,:,:]),\n",
    "                              axis=1).reshape((-1,nf0_c,1))\n",
    "\n",
    "        nf_c['1'] = torch.cat((ca_feats_in['1'].reshape(out1_cat_shape), \n",
    "                                 mp_feats['1'].reshape(mp1_cat_shape)[:,-(self.mp_nodes-self.ca_nodes):,:,:]),\n",
    "                              axis=1).reshape((-1,nf1_c,3))\n",
    "\n",
    "        return nf_c\n",
    "        \n",
    "    def pull_out_mp_feats(self, ca_mp_feats):\n",
    "\n",
    "        nf0_c = ca_mp_feats['0'].shape[1]\n",
    "        nf1_c = ca_mp_feats['1'].shape[1]\n",
    "\n",
    "        nf_mp_ = {}\n",
    "        #select just mp nodes to move on, the other nodes don't connect but mainting self connections\n",
    "        nf_mp_['0'] = ca_mp_feats['0'].reshape(B,self.mp_nodes,\n",
    "                                               nf0_c,1)[:,-(self.mp_nodes-self.ca_nodes):,...].reshape((-1,nf0_c,1))\n",
    "        nf_mp_['1'] = ca_mp_feats['1'].reshape(B,self.mp_nodes,\n",
    "                                               nf1_c,3)[:,-(self.mp_nodes-self.ca_nodes):,...].reshape((-1,nf1_c,3))\n",
    "\n",
    "        return nf_mp_\n",
    "    \n",
    "    def concat_t(self, feats_in, embedded_t, use_deg1=True):\n",
    "        \"\"\"Concatenate T to first position of each tensor. Pad Zeros left for degree 1.\"\"\"\n",
    "        feats_out = {}\n",
    "        key = next(iter(feats_in.keys()))\n",
    "        shape_tuple = (self.B,-1)+feats_in[key].shape[1:]\n",
    "        batch_shape = feats_in[key].reshape(shape_tuple).shape\n",
    "        L = batch_shape[1] #can be ca, ca+mp, mp, k nodes long\n",
    "\n",
    "        if '0' in feats_in.keys():\n",
    "            feats_out['0'] = torch.concat((embedded_t['0'][:,None,:,None].repeat(1,L,1,1), \n",
    "                                           feats_in['0'].reshape((self.B,L,-1,1))),\n",
    "                                          axis=2).reshape((self.B*L,-1,1))\n",
    "        if '1' in feats_in.keys():\n",
    "            \n",
    "            if use_deg1:\n",
    "                feats_out['1'] = torch.multiply(feats_in['1'],\n",
    "                                                embedded_t['1'][:,None,:,None].repeat(1,L,1,1).reshape((self.B*L,-1,1)))\n",
    "            else:\n",
    "                feats_out['1'] = feats_in['1']\n",
    "\n",
    "        return feats_out\n",
    "        \n",
    "    def forward(self, input_tuple, batched_t):\n",
    "\n",
    "        b_graph, nf, ef, b_graph_mp, nf_mp, ef_mp, b_graph_mps, nf_mps, ef_mps, b_graph_mpRev = input_tuple\n",
    "        #assumes equal node numbers in g raphs\n",
    "        self.ca_nodes = int(b_graph.batch_num_nodes()[0])\n",
    "        self.mp_nodes = int(b_graph_mp.batch_num_nodes()[0]) #ca+mp nodes number\n",
    "\n",
    "        #SE3 Attention Transformer, c_alpha\n",
    "        embed_t = self.embed_t(batched_t)\n",
    "        t_nf = self.concat_t(nf, embed_t, use_deg1=self.use_tdeg1) #concat_t on\n",
    "        nf_ca_down_out = self.down_ca(b_graph, t_nf, ef)\n",
    "\n",
    "        #concatenate on midpoints feats\n",
    "        \n",
    "        nf_down_cat_mp = self.concat_mp_feats(nf_ca_down_out, nf_mp)\n",
    "\n",
    "        #pool from ca onto selected midpoints via SE3 Attention transformer\n",
    "        #edges from ca to mp only (ca nodes zero after this)\n",
    "        t_nf_down_cat_mp = self.concat_t(nf_down_cat_mp, embed_t,use_deg1=self.use_tdeg1) #concat_t on\n",
    "        nf_down_ca2mp_out = self.down_ca2mp(b_graph_mp, t_nf_down_cat_mp, ef_mp)\n",
    "\n",
    "        #remove ca node feats from tensor \n",
    "        nf_mp_out = self.pull_out_mp_feats(nf_down_ca2mp_out)\n",
    "\n",
    "        t_nf_mp_out = self.concat_t(nf_mp_out, embed_t, use_deg1=self.use_tdeg1) #concat_t on\n",
    "        node_feats_tk, topk_feats, topk_indx = self.mp_topk(b_graph_mps, t_nf_mp_out, ef_mps)\n",
    "\n",
    "        #make new basis for small graph of k selected midpoints\n",
    "        edge_feats_out, basis_out, new_pos = prep_for_gcn(self.gsmall, b_graph_mps.ndata['pos'], self.ef_small,\n",
    "                                                          topk_indx,\n",
    "                                                          max_degree=self.max_degree, comp_grad=True)\n",
    "\n",
    "        down_gcn_out = self.down_gcn(topk_feats, edge_feats_out, self.gsmall,  basis_out)\n",
    "\n",
    "        down_gcnpool_out = self.down_gcn2pool(down_gcn_out, edge_feats_out, self.gsmall,  basis_out)\n",
    "\n",
    "        pooled_tensor = self.global_pool(down_gcnpool_out,self.gsmall)\n",
    "        pooled = {'0':pooled_tensor}\n",
    "        #----------------------------------------- end of down section\n",
    "        lat_unp = self.latent_unpool_layer(pooled,down_gcn_out)\n",
    "\n",
    "        up_gcn_out = self.up_gcn(lat_unp, edge_feats_out, self.gsmall,  basis_out)\n",
    "\n",
    "        k_to_mp  = self.unpool_layer(up_gcn_out,node_feats_tk,topk_indx)\n",
    "\n",
    "        up_mp_gcn_out = self.up_gcn_mp(b_graph_mps, k_to_mp, ef_mps)\n",
    "        \n",
    "        off_mp_add = {}\n",
    "        for k,v in up_mp_gcn_out.items():\n",
    "            off_mp_add[k] = torch.add(up_mp_gcn_out[k],nf_mp_out[k])\n",
    "\n",
    "\n",
    "        #####triple check from here\n",
    "        #midpoints node indices for unpool layer\n",
    "        mp_node_indx = torch.arange(self.ca_nodes,self.mp_nodes, device=self.device)\n",
    "        mp_idx = mp_node_indx[None,...].repeat_interleave(self.B,0)\n",
    "        mp_idx =((torch.arange(self.B,device=self.device)*(self.mp_nodes)).reshape((-1,1))+mp_idx).reshape((-1))\n",
    "        \n",
    "        #during unpool, keep mp=values and ca=zeros\n",
    "        zeros_mp_ca = {}\n",
    "        for k,v in nf_down_cat_mp.items():\n",
    "            zeros_mp_ca[k] = torch.zeros_like(v, device=self.device)\n",
    "\n",
    "\n",
    "        unpoff_out = self.unpool_layer_off_mp(off_mp_add, zeros_mp_ca, mp_idx)\n",
    "        \n",
    "        out_up_off_mp = self.up_off_mp(b_graph_mpRev, unpoff_out, ef_mp)\n",
    "        \n",
    "        #select just ca nodes, mp = zeros from last convolution\n",
    "        inv_mp_idx= torch.arange(0,self.ca_nodes, device=self.device)\n",
    "        inv_mp_idx = inv_mp_idx[None,...].repeat_interleave(self.B,0)\n",
    "        inv_mp_idx =((torch.arange(self.B,device=self.device)*(self.mp_nodes)).reshape((-1,1))\n",
    "                     +inv_mp_idx).reshape((-1))\n",
    "\n",
    "        node_final_ca = {}\n",
    "        for key in out_up_off_mp.keys():\n",
    "            node_final_ca[key] = torch.add(out_up_off_mp[key][inv_mp_idx,...],nf_ca_down_out[key])\n",
    "\n",
    "        #return updates \n",
    "        t_node_final_ca = self.concat_t(node_final_ca, embed_t, use_deg1=self.use_tdeg1) #concat_t on\n",
    "        \n",
    "        return self.linear(self.up_ca(b_graph, t_node_final_ca, ef))\n",
    "                \n",
    "        \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "a5a815da",
   "metadata": {},
   "outputs": [],
   "source": [
    "def model_step(backbone_dict, noised_dict, batched_t, scores_scales, graph_maker, graph_unet, train=True):\n",
    "    \n",
    "    CA_t  = backbone_dict['CA'].reshape(B, L, 3).to('cuda')\n",
    "    NC_t = CA_t + backbone_dict['N_CA'].reshape(B, L, 3).to('cuda')\n",
    "    CC_t = CA_t + backbone_dict['C_CA'].reshape(B, L, 3).to('cuda')\n",
    "    true =  torch.cat((NC_t,CA_t,CC_t),dim=2).reshape(B,L,3,3)\n",
    "    \n",
    "    CA_n  = noised_dict['CA'].reshape(B, L, 3).to('cuda')\n",
    "    NC_n = CA_n + noised_dict['N_CA'].reshape(B, L, 3).to('cuda')\n",
    "    CC_n = CA_n + noised_dict['C_CA'].reshape(B, L, 3).to('cuda')\n",
    "    noise_xyz =  torch.cat((NC_n,CA_n,CC_n),dim=2).reshape(B,L,3,3)\n",
    "    \n",
    "    x = graph_maker.prep_for_network(noised_dict)\n",
    "    out = graph_unet(x, batched_t)\n",
    "    CA_p = out['1'][:,0,:].reshape(B, L, 3)+CA_n #translation of Calpha\n",
    "    Qs = out['1'][:,1,:] # rotation\n",
    "    Qs = Qs.unsqueeze(1).repeat((1,2,1))\n",
    "    Qs = torch.cat((torch.ones((B*L,2,1),device=Qs.device),Qs),dim=-1).reshape(B,L,2,4)\n",
    "    Qs = normQ(Qs)\n",
    "    Rs = Qs2Rs(Qs)\n",
    "    N_C_to_Rot = torch.cat((noised_dict['N_CA'].reshape(B, L, 3).to('cuda'),\n",
    "                            noised_dict['C_CA'].reshape(B, L, 3).to('cuda')),dim=2).reshape(B,L,2,1,3)\n",
    "\n",
    "    \n",
    "    \n",
    "    rot_vecs = einsum('bnkij,bnkhj->bnki',Rs, N_C_to_Rot)\n",
    "    NC_p = CA_p + rot_vecs[:,:,0,:].to('cuda')*N_CA_dist\n",
    "    CC_p = CA_p + rot_vecs[:,:,1,:].reshape(B, L, 3).to('cuda')*C_CA_dist\n",
    "\n",
    "    pred = torch.cat((NC_p,CA_p,CC_p),dim=2).reshape(B,L,3,3)\n",
    "    \n",
    "    tloss, loss = FAPE_loss(pred.unsqueeze(0), true, scores_scales)\n",
    "    \n",
    "    return tloss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "02f23891",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_noise_pred_true(backbone_dict, noised_dict, batched_t, graph_maker, graph_unet):\n",
    "    \n",
    "    CA_t  = backbone_dict['CA'].reshape(B, L, 3).to('cuda')\n",
    "    NC_t = CA_t + backbone_dict['N_CA'].reshape(B, L, 3).to('cuda')*N_CA_dist\n",
    "    CC_t = CA_t + backbone_dict['C_CA'].reshape(B, L, 3).to('cuda')*C_CA_dist\n",
    "    true =  torch.cat((NC_t,CA_t,CC_t),dim=2).reshape(B,L,3,3)\n",
    "    \n",
    "    CA_n  = noised_dict['CA'].reshape(B, L, 3).to('cuda')\n",
    "    NC_n = CA_n + noised_dict['N_CA'].reshape(B, L, 3).to('cuda')*N_CA_dist\n",
    "    CC_n = CA_n + noised_dict['C_CA'].reshape(B, L, 3).to('cuda')*C_CA_dist\n",
    "    noise_xyz =  torch.cat((NC_n,CA_n,CC_n),dim=2).reshape(B,L,3,3)\n",
    "    \n",
    "    x = graph_maker.prep_for_network(noised_dict)\n",
    "    out = graph_unet(x, batched_t)\n",
    "    CA_p = out['1'][:,0,:].reshape(B, L, 3)+CA_n #translation of Calpha\n",
    "    Qs = out['1'][:,1,:] # rotation\n",
    "    Qs = Qs.unsqueeze(1).repeat((1,2,1))\n",
    "    Qs = torch.cat((torch.ones((B*L,2,1),device=Qs.device),Qs),dim=-1).reshape(B,L,2,4)\n",
    "    Qs = normQ(Qs)\n",
    "    Rs = Qs2Rs(Qs)\n",
    "    N_C_to_Rot = torch.cat((noised_dict['N_CA'].reshape(B, L, 3).to('cuda'),\n",
    "                            noised_dict['C_CA'].reshape(B, L, 3).to('cuda')),dim=2).reshape(B,L,2,1,3)\n",
    "    \n",
    "    \n",
    "    rot_vecs = einsum('bnkij,bnkhj->bnki',Rs, N_C_to_Rot)\n",
    "    NC_p = CA_p + rot_vecs[:,:,0,:].to('cuda')*N_CA_dist\n",
    "    CC_p = CA_p + rot_vecs[:,:,1,:].reshape(B, L, 3).to('cuda')*C_CA_dist\n",
    "\n",
    "    pred = torch.cat((NC_p,CA_p,CC_p),dim=2).reshape(B,L,3,3)\n",
    "    \n",
    "    return true.to('cpu').numpy()*10, noise_xyz.to('cpu').numpy()*10, pred.detach().to('cpu').numpy()*10\n",
    "\n",
    "def dump_tnp(true, noise, pred, t_val, e=0, numOut=1,outdir='output/'):\n",
    "    \n",
    "    if numOut>true.shape[0]:\n",
    "        numOut = true.shape[0]\n",
    "    \n",
    "    for x in range(numOut):\n",
    "        dump_coord_pdb(true[x], fileOut=f'{outdir}/true_{t_val[x]*100:.0f}_e{e}_{x}.pdb')\n",
    "        dump_coord_pdb(noise[x], fileOut=f'{outdir}/noise_{t_val[x]*100:.0f}_e{e}_{x}.pdb')\n",
    "        dump_coord_pdb(pred[x], fileOut=f'{outdir}/pred_{t_val[x]*100:.0f}_e{e}_{x}.pdb')\n",
    "        \n",
    "def visualize_model(bb_dict, noised_bb, batched_t, epoch, numOut=1, outdir='output/'):\n",
    "    true, noise, pred = get_noise_pred_true(bb_dict, noised_bb, batched_t, gm, gu)\n",
    "    dump_tnp(true,noise,pred, batched_t, e=epoch, numOut=numOut, outdir=f'{outdir}/models/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "5d28184c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_save_folder(name=''):\n",
    "    base_folder = time.strftime(f'log/%y%b%d_%I%M%p_{name}/', time.localtime())\n",
    "    if not os.path.exists(base_folder):\n",
    "        os.makedirs(base_folder)\n",
    "    subfolders = ['models']\n",
    "    for subfolder in subfolders:\n",
    "        if not os.path.exists(base_folder + subfolder):\n",
    "            os.makedirs(base_folder + subfolder)\n",
    "            \n",
    "    return base_folder\n",
    "        \n",
    "def save_chkpt(model_path, model, optimizer, epoch, batch, val_losses, train_losses):\n",
    "    \"\"\"Save a training checkpoint\n",
    "    Args:\n",
    "        model_path (str): the path to save the model to\n",
    "        model (nn.Module): the model to save\n",
    "        optimizer (torch.optim.Optimizer): the optimizer to save\n",
    "        epoch (int): the current epoch\n",
    "        batch (int): the current batch in the epoch\n",
    "        loss_domain (list of int): a list of the shared domain for val and training \n",
    "            losses\n",
    "        val_losses (list of float): a list containing the validation losses\n",
    "        train_losses (list of float): a list containing the training losses\n",
    "    \"\"\"\n",
    "    os.makedirs(os.path.dirname(model_path), exist_ok=True)\n",
    "    state_dict = dict()\n",
    "    state_dict.update({'model':model.state_dict(),\n",
    "                       'optimizer':optimizer.state_dict(),\n",
    "                       'epoch':epoch,\n",
    "                       'batch':batch,\n",
    "                       'train_losses':train_losses,\n",
    "                       'val_losses':val_losses\n",
    "                       })\n",
    "    torch.save(state_dict, f'{model_path}model_e{epoch}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "149c44dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "B = 32\n",
    "L=65\n",
    "limit = 5048\n",
    "h4_trainData = Helix4_Dataset(coords_tog[:limit])\n",
    "h4_valData = Helix4_Dataset(coords_apa[:limit])\n",
    "train_dL = DataLoader(h4_trainData, batch_size=B, shuffle=True, drop_last=True)\n",
    "val_dL   = DataLoader(h4_valData, batch_size=B, shuffle=True, drop_last=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "58ac8828",
   "metadata": {},
   "outputs": [],
   "source": [
    "gu = GraphUNet(batch_size = B, num_layers_ca = 2).to('cuda')\n",
    "opti = torch.optim.Adam(gu.parameters(), lr=0.0005, weight_decay=5e-6)\n",
    "gm = Make_KNN_MP_Graphs() #consider precalculating graphs for training\n",
    "fdn= FrameDiffNoise()\n",
    "useR3 = False\n",
    "\n",
    "\n",
    "#visualize_T\n",
    "vis_t = np.array([0.01,0.05,0.1,0.2,0.3,0.5,0.8,1.0])\n",
    "vis_t = vis_t[None,...].repeat(int(np.ceil(B/len(vis_t))),axis=0).flatten()[:B]\n",
    "#vis_t =  torch.tensor(vis_t, dtype=torch.float32).to('cuda')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "78b15462",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/nwoodall/miniconda3/envs/se33/lib/python3.9/site-packages/dgl/backend/pytorch/tensor.py:449: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()\n",
      "  assert input.numel() == input.storage().size(), (\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Train Loss Epoch 0: 0.13032618165016174;   Epoch time: 236\n",
      "Average Train Loss Epoch 1: 0.11648102849721909;   Epoch time: 232\n",
      "Average Train Loss Epoch 2: 0.11673513054847717;   Epoch time: 233\n",
      "Average Train Loss Epoch 3: 0.11582014709711075;   Epoch time: 232\n",
      "Average Train Loss Epoch 4: 0.11521966010332108;   Epoch time: 231\n",
      "Average Train Loss Epoch 5: 0.1164429783821106;   Epoch time: 230\n",
      "Average Train Loss Epoch 6: 0.11519137024879456;   Epoch time: 230\n",
      "Average Train Loss Epoch 7: 0.11422860622406006;   Epoch time: 231\n",
      "Average Train Loss Epoch 8: 0.11362971365451813;   Epoch time: 230\n",
      "Average Train Loss Epoch 9: 0.1123727336525917;   Epoch time: 230\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/nwoodall/miniconda3/envs/se33/lib/python3.9/site-packages/torch/utils/checkpoint.py:31: UserWarning: None of the inputs have requires_grad=True. Gradients will be None\n",
      "  warnings.warn(\"None of the inputs have requires_grad=True. Gradients will be None\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Valid Loss Epoch 9: 0.11280342191457748\n",
      "Average Train Loss Epoch 10: 0.11301227658987045;   Epoch time: 230\n",
      "Average Train Loss Epoch 11: 0.11112093180418015;   Epoch time: 229\n",
      "Average Train Loss Epoch 12: 0.11166320741176605;   Epoch time: 230\n",
      "Average Train Loss Epoch 13: 0.11174662411212921;   Epoch time: 230\n",
      "Average Train Loss Epoch 14: 0.11120522767305374;   Epoch time: 230\n",
      "Average Train Loss Epoch 15: 0.11036743968725204;   Epoch time: 230\n",
      "Average Train Loss Epoch 16: 0.11033247411251068;   Epoch time: 230\n",
      "Average Train Loss Epoch 17: 0.11027906090021133;   Epoch time: 230\n",
      "Average Train Loss Epoch 18: 0.1111677959561348;   Epoch time: 230\n",
      "Average Train Loss Epoch 19: 0.10935744643211365;   Epoch time: 230\n",
      "Average Valid Loss Epoch 19: 0.10951167345046997\n",
      "Average Train Loss Epoch 20: 0.10874605923891068;   Epoch time: 230\n",
      "Average Train Loss Epoch 21: 0.1111672893166542;   Epoch time: 230\n",
      "Average Train Loss Epoch 22: 0.10990917682647705;   Epoch time: 230\n",
      "Average Train Loss Epoch 23: 0.10888347774744034;   Epoch time: 230\n",
      "Average Train Loss Epoch 24: 0.11047320812940598;   Epoch time: 230\n",
      "Average Train Loss Epoch 25: 0.10796833783388138;   Epoch time: 230\n",
      "Average Train Loss Epoch 26: 0.10903899371623993;   Epoch time: 230\n",
      "Average Train Loss Epoch 27: 0.10994327068328857;   Epoch time: 230\n",
      "Average Train Loss Epoch 28: 0.10863194614648819;   Epoch time: 230\n",
      "Average Train Loss Epoch 29: 0.10799837857484818;   Epoch time: 230\n",
      "Average Valid Loss Epoch 29: 0.108461894094944\n",
      "Average Train Loss Epoch 30: 0.1085766926407814;   Epoch time: 231\n",
      "Average Train Loss Epoch 31: 0.10753613710403442;   Epoch time: 230\n",
      "Average Train Loss Epoch 32: 0.10682830959558487;   Epoch time: 230\n",
      "Average Train Loss Epoch 33: 0.10445766150951385;   Epoch time: 230\n",
      "Average Train Loss Epoch 34: 0.10303368419408798;   Epoch time: 231\n",
      "Average Train Loss Epoch 35: 0.1018509492278099;   Epoch time: 230\n",
      "Average Train Loss Epoch 36: 0.1030944287776947;   Epoch time: 230\n",
      "Average Train Loss Epoch 37: 0.10181698203086853;   Epoch time: 230\n",
      "Average Train Loss Epoch 38: 0.10254348814487457;   Epoch time: 230\n",
      "Average Train Loss Epoch 39: 0.09916722029447556;   Epoch time: 230\n",
      "Average Valid Loss Epoch 39: 0.09984709322452545\n",
      "Average Train Loss Epoch 40: 0.09920690953731537;   Epoch time: 230\n",
      "Average Train Loss Epoch 41: 0.09921062737703323;   Epoch time: 230\n",
      "Average Train Loss Epoch 42: 0.09806720167398453;   Epoch time: 230\n",
      "Average Train Loss Epoch 43: 0.09801927953958511;   Epoch time: 229\n",
      "Average Train Loss Epoch 44: 0.097313791513443;   Epoch time: 230\n",
      "Average Train Loss Epoch 45: 0.09674317389726639;   Epoch time: 230\n",
      "Average Train Loss Epoch 46: 0.09695491194725037;   Epoch time: 230\n",
      "Average Train Loss Epoch 47: 0.09445180743932724;   Epoch time: 229\n",
      "Average Train Loss Epoch 48: 0.09429622441530228;   Epoch time: 230\n",
      "Average Train Loss Epoch 49: 0.09494089335203171;   Epoch time: 230\n",
      "Average Valid Loss Epoch 49: 0.0952216312289238\n",
      "Average Train Loss Epoch 50: 0.09338294714689255;   Epoch time: 230\n",
      "Average Train Loss Epoch 51: 0.09328334778547287;   Epoch time: 230\n",
      "Average Train Loss Epoch 52: 0.09325766563415527;   Epoch time: 230\n",
      "Average Train Loss Epoch 53: 0.09160436689853668;   Epoch time: 230\n",
      "Average Train Loss Epoch 54: 0.09231266379356384;   Epoch time: 230\n",
      "Average Train Loss Epoch 55: 0.09243082255125046;   Epoch time: 230\n",
      "Average Train Loss Epoch 56: 0.0922749862074852;   Epoch time: 230\n",
      "Average Train Loss Epoch 57: 0.09025797247886658;   Epoch time: 230\n",
      "Average Train Loss Epoch 58: 0.0905732586979866;   Epoch time: 231\n",
      "Average Train Loss Epoch 59: 0.08992969244718552;   Epoch time: 230\n",
      "Average Valid Loss Epoch 59: 0.09034030884504318\n",
      "Average Train Loss Epoch 60: 0.09002535790205002;   Epoch time: 233\n",
      "Average Train Loss Epoch 61: 0.0893930047750473;   Epoch time: 235\n",
      "Average Train Loss Epoch 62: 0.08944746106863022;   Epoch time: 236\n",
      "Average Train Loss Epoch 63: 0.08986864238977432;   Epoch time: 236\n",
      "Average Train Loss Epoch 64: 0.09489298611879349;   Epoch time: 233\n",
      "Average Train Loss Epoch 65: 0.09034506231546402;   Epoch time: 231\n",
      "Average Train Loss Epoch 66: 0.08893878012895584;   Epoch time: 232\n",
      "Average Train Loss Epoch 67: 0.08908437937498093;   Epoch time: 232\n",
      "Average Train Loss Epoch 68: 0.08862389624118805;   Epoch time: 231\n",
      "Average Train Loss Epoch 69: 0.08866219222545624;   Epoch time: 231\n",
      "Average Valid Loss Epoch 69: 0.0890277549624443\n",
      "Average Train Loss Epoch 70: 0.08828146755695343;   Epoch time: 231\n",
      "Average Train Loss Epoch 71: 0.08846022188663483;   Epoch time: 232\n",
      "Average Train Loss Epoch 72: 0.0877462700009346;   Epoch time: 232\n",
      "Average Train Loss Epoch 73: 0.08721841126680374;   Epoch time: 235\n",
      "Average Train Loss Epoch 74: 0.08805923908948898;   Epoch time: 238\n",
      "Average Train Loss Epoch 75: 0.08803785592317581;   Epoch time: 235\n",
      "Average Train Loss Epoch 76: 0.08820430189371109;   Epoch time: 235\n",
      "Average Train Loss Epoch 77: 0.08755040913820267;   Epoch time: 233\n",
      "Average Train Loss Epoch 78: 0.08746284246444702;   Epoch time: 231\n",
      "Average Train Loss Epoch 79: 0.08746907860040665;   Epoch time: 231\n",
      "Average Valid Loss Epoch 79: 0.08748827129602432\n",
      "Average Train Loss Epoch 80: 0.08684062957763672;   Epoch time: 232\n",
      "Average Train Loss Epoch 81: 0.08635585755109787;   Epoch time: 232\n",
      "Average Train Loss Epoch 82: 0.08704192191362381;   Epoch time: 232\n",
      "Average Train Loss Epoch 83: 0.08728823065757751;   Epoch time: 232\n",
      "Average Train Loss Epoch 84: 0.08686148375272751;   Epoch time: 232\n",
      "Average Train Loss Epoch 85: 0.08689200133085251;   Epoch time: 232\n",
      "Average Train Loss Epoch 86: 0.08671878278255463;   Epoch time: 232\n",
      "Average Train Loss Epoch 87: 0.08685304969549179;   Epoch time: 231\n",
      "Average Train Loss Epoch 88: 0.08595021069049835;   Epoch time: 232\n",
      "Average Train Loss Epoch 89: 0.08590619266033173;   Epoch time: 232\n",
      "Average Valid Loss Epoch 89: 0.08652856200933456\n",
      "Average Train Loss Epoch 90: 0.08593399822711945;   Epoch time: 232\n",
      "Average Train Loss Epoch 91: 0.08507976680994034;   Epoch time: 232\n",
      "Average Train Loss Epoch 92: 0.08569423109292984;   Epoch time: 232\n",
      "Average Train Loss Epoch 93: 0.08553071320056915;   Epoch time: 231\n",
      "Average Train Loss Epoch 94: 0.08530526608228683;   Epoch time: 232\n",
      "Average Train Loss Epoch 95: 0.08548345416784286;   Epoch time: 231\n",
      "Average Train Loss Epoch 96: 0.08506444096565247;   Epoch time: 232\n",
      "Average Train Loss Epoch 97: 0.08627811074256897;   Epoch time: 232\n",
      "Average Train Loss Epoch 98: 0.08494387567043304;   Epoch time: 232\n",
      "Average Train Loss Epoch 99: 0.08486221730709076;   Epoch time: 232\n",
      "Average Valid Loss Epoch 99: 0.08495276421308517\n",
      "Average Train Loss Epoch 100: 0.0839177817106247;   Epoch time: 238\n",
      "Average Train Loss Epoch 101: 0.08556224405765533;   Epoch time: 243\n",
      "Average Train Loss Epoch 102: 0.08496278524398804;   Epoch time: 235\n",
      "Average Train Loss Epoch 103: 0.08498016744852066;   Epoch time: 232\n",
      "Average Train Loss Epoch 104: 0.08528707176446915;   Epoch time: 231\n",
      "Average Train Loss Epoch 105: 0.08417937159538269;   Epoch time: 230\n",
      "Average Train Loss Epoch 106: 0.08457747846841812;   Epoch time: 230\n",
      "Average Train Loss Epoch 107: 0.08457577973604202;   Epoch time: 230\n",
      "Average Train Loss Epoch 108: 0.08458557724952698;   Epoch time: 230\n",
      "Average Train Loss Epoch 109: 0.0843622237443924;   Epoch time: 231\n",
      "Average Valid Loss Epoch 109: 0.08482928574085236\n",
      "Average Train Loss Epoch 110: 0.08432304114103317;   Epoch time: 232\n",
      "Average Train Loss Epoch 111: 0.08368869125843048;   Epoch time: 231\n",
      "Average Train Loss Epoch 112: 0.08392098546028137;   Epoch time: 230\n",
      "Average Train Loss Epoch 113: 0.08421466499567032;   Epoch time: 230\n",
      "Average Train Loss Epoch 114: 0.08369386196136475;   Epoch time: 230\n",
      "Average Train Loss Epoch 115: 0.0839533731341362;   Epoch time: 230\n",
      "Average Train Loss Epoch 116: 0.08373269438743591;   Epoch time: 230\n",
      "Average Train Loss Epoch 117: 0.08319394290447235;   Epoch time: 230\n",
      "Average Train Loss Epoch 118: 0.08323922008275986;   Epoch time: 231\n",
      "Average Train Loss Epoch 119: 0.08401498198509216;   Epoch time: 232\n",
      "Average Valid Loss Epoch 119: 0.08412458002567291\n",
      "Average Train Loss Epoch 120: 0.0832321047782898;   Epoch time: 256\n",
      "Average Train Loss Epoch 121: 0.08296972513198853;   Epoch time: 246\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Train Loss Epoch 122: 0.08350656926631927;   Epoch time: 235\n",
      "Average Train Loss Epoch 123: 0.0834803581237793;   Epoch time: 237\n",
      "Average Train Loss Epoch 124: 0.08378276973962784;   Epoch time: 232\n",
      "Average Train Loss Epoch 125: 0.08261356502771378;   Epoch time: 231\n",
      "Average Train Loss Epoch 126: 0.08230641484260559;   Epoch time: 231\n",
      "Average Train Loss Epoch 127: 0.08189789950847626;   Epoch time: 231\n",
      "Average Train Loss Epoch 128: 0.08204809576272964;   Epoch time: 231\n",
      "Average Train Loss Epoch 129: 0.08223100006580353;   Epoch time: 230\n",
      "Average Valid Loss Epoch 129: 0.08262888342142105\n",
      "Average Train Loss Epoch 130: 0.0814303532242775;   Epoch time: 230\n",
      "Average Train Loss Epoch 131: 0.08083629608154297;   Epoch time: 230\n",
      "Average Train Loss Epoch 132: 0.08173897862434387;   Epoch time: 230\n",
      "Average Train Loss Epoch 133: 0.0815219134092331;   Epoch time: 230\n",
      "Average Train Loss Epoch 134: 0.08024514466524124;   Epoch time: 230\n",
      "Average Train Loss Epoch 135: 0.08037814497947693;   Epoch time: 230\n",
      "Average Train Loss Epoch 136: 0.08059006929397583;   Epoch time: 230\n",
      "Average Train Loss Epoch 137: 0.0812743529677391;   Epoch time: 230\n",
      "Average Train Loss Epoch 138: 0.07998818159103394;   Epoch time: 230\n",
      "Average Train Loss Epoch 139: 0.0807005912065506;   Epoch time: 230\n",
      "Average Valid Loss Epoch 139: 0.08177898824214935\n",
      "Average Train Loss Epoch 140: 0.08016538619995117;   Epoch time: 230\n",
      "Average Train Loss Epoch 141: 0.08062087744474411;   Epoch time: 231\n",
      "Average Train Loss Epoch 142: 0.07985222339630127;   Epoch time: 230\n",
      "Average Train Loss Epoch 143: 0.08005242049694061;   Epoch time: 230\n",
      "Average Train Loss Epoch 144: 0.07979611307382584;   Epoch time: 230\n",
      "Average Train Loss Epoch 145: 0.07995172590017319;   Epoch time: 230\n",
      "Average Train Loss Epoch 146: 0.08047004044055939;   Epoch time: 230\n",
      "Average Train Loss Epoch 147: 0.0801536813378334;   Epoch time: 230\n",
      "Average Train Loss Epoch 148: 0.0792749747633934;   Epoch time: 230\n",
      "Average Train Loss Epoch 149: 0.07992085069417953;   Epoch time: 230\n",
      "Average Valid Loss Epoch 149: 0.08006103336811066\n",
      "Average Train Loss Epoch 150: 0.07887998968362808;   Epoch time: 230\n",
      "Average Train Loss Epoch 151: 0.0808136835694313;   Epoch time: 230\n",
      "Average Train Loss Epoch 152: 0.07900800555944443;   Epoch time: 230\n",
      "Average Train Loss Epoch 153: 0.07932483404874802;   Epoch time: 231\n",
      "Average Train Loss Epoch 154: 0.08006049692630768;   Epoch time: 230\n",
      "Average Train Loss Epoch 155: 0.07896915078163147;   Epoch time: 230\n",
      "Average Train Loss Epoch 156: 0.08019357174634933;   Epoch time: 230\n",
      "Average Train Loss Epoch 157: 0.07879673689603806;   Epoch time: 230\n",
      "Average Train Loss Epoch 158: 0.07932187616825104;   Epoch time: 233\n",
      "Average Train Loss Epoch 159: 0.07955309748649597;   Epoch time: 232\n",
      "Average Valid Loss Epoch 159: 0.07940521091222763\n",
      "Average Train Loss Epoch 160: 0.07975649833679199;   Epoch time: 232\n",
      "Average Train Loss Epoch 161: 0.07910992950201035;   Epoch time: 231\n",
      "Average Train Loss Epoch 162: 0.0787082239985466;   Epoch time: 232\n",
      "Average Train Loss Epoch 163: 0.07851625233888626;   Epoch time: 237\n",
      "Average Train Loss Epoch 164: 0.07827576994895935;   Epoch time: 231\n",
      "Average Train Loss Epoch 165: 0.07965636998414993;   Epoch time: 232\n",
      "Average Train Loss Epoch 166: 0.07888541370630264;   Epoch time: 231\n",
      "Average Train Loss Epoch 167: 0.0782955065369606;   Epoch time: 230\n",
      "Average Train Loss Epoch 168: 0.0785096287727356;   Epoch time: 230\n",
      "Average Train Loss Epoch 169: 0.07898440957069397;   Epoch time: 230\n",
      "Average Valid Loss Epoch 169: 0.07917951792478561\n",
      "Average Train Loss Epoch 170: 0.07834458351135254;   Epoch time: 232\n",
      "Average Train Loss Epoch 171: 0.07841458171606064;   Epoch time: 233\n",
      "Average Train Loss Epoch 172: 0.07978623360395432;   Epoch time: 231\n",
      "Average Train Loss Epoch 173: 0.07908947020769119;   Epoch time: 231\n",
      "Average Train Loss Epoch 174: 0.07871007919311523;   Epoch time: 235\n",
      "Average Train Loss Epoch 175: 0.07866258919239044;   Epoch time: 236\n",
      "Average Train Loss Epoch 176: 0.07826123386621475;   Epoch time: 234\n",
      "Average Train Loss Epoch 177: 0.07787913829088211;   Epoch time: 232\n",
      "Average Train Loss Epoch 178: 0.07857340574264526;   Epoch time: 232\n",
      "Average Train Loss Epoch 179: 0.07765864580869675;   Epoch time: 231\n",
      "Average Valid Loss Epoch 179: 0.0790594071149826\n",
      "Average Train Loss Epoch 180: 0.07812468707561493;   Epoch time: 232\n",
      "Average Train Loss Epoch 181: 0.07846274226903915;   Epoch time: 232\n",
      "Average Train Loss Epoch 182: 0.0776078924536705;   Epoch time: 232\n",
      "Average Train Loss Epoch 183: 0.07772528380155563;   Epoch time: 231\n",
      "Average Train Loss Epoch 184: 0.07793433964252472;   Epoch time: 234\n",
      "Average Train Loss Epoch 185: 0.07812830805778503;   Epoch time: 235\n",
      "Average Train Loss Epoch 186: 0.07843495160341263;   Epoch time: 239\n",
      "Average Train Loss Epoch 187: 0.07773107290267944;   Epoch time: 240\n",
      "Average Train Loss Epoch 188: 0.07786636054515839;   Epoch time: 243\n",
      "Average Train Loss Epoch 189: 0.07782266288995743;   Epoch time: 243\n",
      "Average Valid Loss Epoch 189: 0.07909908890724182\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[19], line 21\u001b[0m\n\u001b[1;32m     19\u001b[0m     opti\u001b[38;5;241m.\u001b[39mzero_grad()\n\u001b[1;32m     20\u001b[0m     train_loss\u001b[38;5;241m.\u001b[39mbackward()\n\u001b[0;32m---> 21\u001b[0m     \u001b[43mopti\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstep\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     23\u001b[0m     running_tloss \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m train_loss\u001b[38;5;241m.\u001b[39mdetach()\u001b[38;5;241m.\u001b[39mcpu()\n\u001b[1;32m     25\u001b[0m end \u001b[38;5;241m=\u001b[39m time\u001b[38;5;241m.\u001b[39mtime()\n",
      "File \u001b[0;32m~/miniconda3/envs/se33/lib/python3.9/site-packages/torch/optim/optimizer.py:280\u001b[0m, in \u001b[0;36mOptimizer.profile_hook_step.<locals>.wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    276\u001b[0m         \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    277\u001b[0m             \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfunc\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m must return None or a tuple of (new_args, new_kwargs),\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    278\u001b[0m                                \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mbut got \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mresult\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m--> 280\u001b[0m out \u001b[38;5;241m=\u001b[39m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    281\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_optimizer_step_code()\n\u001b[1;32m    283\u001b[0m \u001b[38;5;66;03m# call optimizer step post hooks\u001b[39;00m\n",
      "File \u001b[0;32m~/miniconda3/envs/se33/lib/python3.9/site-packages/torch/optim/optimizer.py:33\u001b[0m, in \u001b[0;36m_use_grad_for_differentiable.<locals>._use_grad\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m     31\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m     32\u001b[0m     torch\u001b[38;5;241m.\u001b[39mset_grad_enabled(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdefaults[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdifferentiable\u001b[39m\u001b[38;5;124m'\u001b[39m])\n\u001b[0;32m---> 33\u001b[0m     ret \u001b[38;5;241m=\u001b[39m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     34\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[1;32m     35\u001b[0m     torch\u001b[38;5;241m.\u001b[39mset_grad_enabled(prev_grad)\n",
      "File \u001b[0;32m~/miniconda3/envs/se33/lib/python3.9/site-packages/torch/optim/adam.py:141\u001b[0m, in \u001b[0;36mAdam.step\u001b[0;34m(self, closure)\u001b[0m\n\u001b[1;32m    130\u001b[0m     beta1, beta2 \u001b[38;5;241m=\u001b[39m group[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mbetas\u001b[39m\u001b[38;5;124m'\u001b[39m]\n\u001b[1;32m    132\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_init_group(\n\u001b[1;32m    133\u001b[0m         group,\n\u001b[1;32m    134\u001b[0m         params_with_grad,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    138\u001b[0m         max_exp_avg_sqs,\n\u001b[1;32m    139\u001b[0m         state_steps)\n\u001b[0;32m--> 141\u001b[0m     \u001b[43madam\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    142\u001b[0m \u001b[43m        \u001b[49m\u001b[43mparams_with_grad\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    143\u001b[0m \u001b[43m        \u001b[49m\u001b[43mgrads\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    144\u001b[0m \u001b[43m        \u001b[49m\u001b[43mexp_avgs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    145\u001b[0m \u001b[43m        \u001b[49m\u001b[43mexp_avg_sqs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    146\u001b[0m \u001b[43m        \u001b[49m\u001b[43mmax_exp_avg_sqs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    147\u001b[0m \u001b[43m        \u001b[49m\u001b[43mstate_steps\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    148\u001b[0m \u001b[43m        \u001b[49m\u001b[43mamsgrad\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgroup\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mamsgrad\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    149\u001b[0m \u001b[43m        \u001b[49m\u001b[43mbeta1\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbeta1\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    150\u001b[0m \u001b[43m        \u001b[49m\u001b[43mbeta2\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbeta2\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    151\u001b[0m \u001b[43m        \u001b[49m\u001b[43mlr\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgroup\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mlr\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    152\u001b[0m \u001b[43m        \u001b[49m\u001b[43mweight_decay\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgroup\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mweight_decay\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    153\u001b[0m \u001b[43m        \u001b[49m\u001b[43meps\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgroup\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43meps\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    154\u001b[0m \u001b[43m        \u001b[49m\u001b[43mmaximize\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgroup\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mmaximize\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    155\u001b[0m \u001b[43m        \u001b[49m\u001b[43mforeach\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgroup\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mforeach\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    156\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcapturable\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgroup\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mcapturable\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    157\u001b[0m \u001b[43m        \u001b[49m\u001b[43mdifferentiable\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgroup\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mdifferentiable\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    158\u001b[0m \u001b[43m        \u001b[49m\u001b[43mfused\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgroup\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mfused\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    159\u001b[0m \u001b[43m        \u001b[49m\u001b[43mgrad_scale\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mgetattr\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mgrad_scale\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    160\u001b[0m \u001b[43m        \u001b[49m\u001b[43mfound_inf\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mgetattr\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mfound_inf\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    161\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    163\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m loss\n",
      "File \u001b[0;32m~/miniconda3/envs/se33/lib/python3.9/site-packages/torch/optim/adam.py:281\u001b[0m, in \u001b[0;36madam\u001b[0;34m(params, grads, exp_avgs, exp_avg_sqs, max_exp_avg_sqs, state_steps, foreach, capturable, differentiable, fused, grad_scale, found_inf, amsgrad, beta1, beta2, lr, weight_decay, eps, maximize)\u001b[0m\n\u001b[1;32m    278\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    279\u001b[0m     func \u001b[38;5;241m=\u001b[39m _single_tensor_adam\n\u001b[0;32m--> 281\u001b[0m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[43mparams\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    282\u001b[0m \u001b[43m     \u001b[49m\u001b[43mgrads\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    283\u001b[0m \u001b[43m     \u001b[49m\u001b[43mexp_avgs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    284\u001b[0m \u001b[43m     \u001b[49m\u001b[43mexp_avg_sqs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    285\u001b[0m \u001b[43m     \u001b[49m\u001b[43mmax_exp_avg_sqs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    286\u001b[0m \u001b[43m     \u001b[49m\u001b[43mstate_steps\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    287\u001b[0m \u001b[43m     \u001b[49m\u001b[43mamsgrad\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mamsgrad\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    288\u001b[0m \u001b[43m     \u001b[49m\u001b[43mbeta1\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbeta1\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    289\u001b[0m \u001b[43m     \u001b[49m\u001b[43mbeta2\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbeta2\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    290\u001b[0m \u001b[43m     \u001b[49m\u001b[43mlr\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlr\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    291\u001b[0m \u001b[43m     \u001b[49m\u001b[43mweight_decay\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mweight_decay\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    292\u001b[0m \u001b[43m     \u001b[49m\u001b[43meps\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43meps\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    293\u001b[0m \u001b[43m     \u001b[49m\u001b[43mmaximize\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmaximize\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    294\u001b[0m \u001b[43m     \u001b[49m\u001b[43mcapturable\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcapturable\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    295\u001b[0m \u001b[43m     \u001b[49m\u001b[43mdifferentiable\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdifferentiable\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    296\u001b[0m \u001b[43m     \u001b[49m\u001b[43mgrad_scale\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgrad_scale\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    297\u001b[0m \u001b[43m     \u001b[49m\u001b[43mfound_inf\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfound_inf\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "#t=0.1\n",
    "#t_vec = np.ones((B,))*t\n",
    "#print(t_vec)\n",
    "model_path = make_save_folder(name=f'full_diff_embed_T_btest')\n",
    "num_epochs = 300\n",
    "e_start= 0\n",
    "save_per=10\n",
    "avg_vloss=0\n",
    "\n",
    "for e in range(e_start, e_start+num_epochs):\n",
    "    \n",
    "    running_tloss = 0 \n",
    "    start = time.time()\n",
    "    for i, bb_dict in enumerate(train_dL):\n",
    "        noised_bb, tv, ss = fdn(bb_dict,t_vec=None, useR3=useR3)\n",
    "        tv = tv.to('cuda')\n",
    "        ss = ss.to('cuda')\n",
    "        train_loss = model_step(bb_dict, noised_bb, tv, ss, gm, gu)\n",
    "        opti.zero_grad()\n",
    "        train_loss.backward()\n",
    "        opti.step()\n",
    "\n",
    "        running_tloss += train_loss.detach().cpu()\n",
    "    \n",
    "    end = time.time()\n",
    "    avg_tloss = running_tloss/(i+1)\n",
    "    print(f'Average Train Loss Epoch {e}: {avg_tloss};   Epoch time: {end-start:.0f}')\n",
    "\n",
    "    if e %save_per==save_per-1:\n",
    "        with torch.no_grad():\n",
    "            running_vloss = 0\n",
    "            for i, bb_dictv in enumerate(val_dL):\n",
    "                noised_bb, tv, ss = fdn(bb_dictv,t_vec=None, useR3=useR3)\n",
    "                tv = tv.to('cuda')\n",
    "                ss = ss.to('cuda')\n",
    "                valid_loss = model_step(bb_dictv, noised_bb, tv, ss, gm, gu)\n",
    "                running_vloss += valid_loss\n",
    "                \n",
    "        avg_vloss = running_vloss/(i+1)\n",
    "        print(f'Average Valid Loss Epoch {e}: {avg_vloss}')\n",
    "                \n",
    "        noised_bb, tv, ss = fdn(bb_dict, t_vec=vis_t)\n",
    "        tv = tv.to('cuda')\n",
    "        visualize_model(bb_dict, noised_bb, tv, e, numOut=8,outdir=model_path)\n",
    "        save_chkpt(model_path, gu, opti, e, B, avg_vloss, avg_tloss)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc618c49",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4cf435f6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2ce458c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e6ddcfc",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df7462d2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "cd433a11",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_iter = iter(train_dL)\n",
    "test_batch = next(test_iter)\n",
    "\n",
    "t=0.05\n",
    "t_vec = np.ones((B,))*t\n",
    "nd, tv, ss = fdn(test_batch, t_vec=None, useR3=False)\n",
    "\n",
    "tv = tv.to('cuda')\n",
    "# train_loss = model_step(bb_dict, noised_bb, tv, gm, gu)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "4c7bbc63",
   "metadata": {},
   "outputs": [],
   "source": [
    "visualize_model(test_batch, nd, tv, 1000, numOut=8,outdir=model_path)\n",
    "save_chkpt(model_path, gu, opti, 1000, B, 0, 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f356ac2a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21564364",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ebd3b480",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "c6818ec8",
   "metadata": {},
   "outputs": [],
   "source": [
    "x = gm.prep_for_network(nd)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "ea7b5d5b",
   "metadata": {},
   "outputs": [],
   "source": [
    "out = gu(x,tv)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "f5357d6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "CA_p = out['1'][:,0,:].reshape(B, L, 3)+0 #translation of Calpha\n",
    "Qs = out['1'][:,1,:] # rotation\n",
    "Qs = Qs.unsqueeze(1).repeat((1,2,1))\n",
    "Qs = torch.cat((torch.ones((B*L,2,1),device=Qs.device),Qs),dim=-1).reshape(B,L,2,4)\n",
    "Qs = normQ(Qs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "51c13fe3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([32, 65, 2, 4])"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Qs.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "baef3d23",
   "metadata": {},
   "outputs": [],
   "source": [
    "tq = Qs[:2,:3,0,:]\n",
    "eps = 1e-6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "f22b730e",
   "metadata": {},
   "outputs": [],
   "source": [
    "Q = torch.tensor([0,0,1,0],dtype=torch.float)[None,None,None,...].repeat(2,3,2,1)\n",
    "rv = torch.tensor([[0,0,1]],dtype=torch.float)[None,None,...].repeat(2,3,2,1)\n",
    "Q = normQ(Q)\n",
    "\n",
    "qp = powerQ(Q,0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da6add3c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "c3a9fa55",
   "metadata": {},
   "outputs": [],
   "source": [
    "Rs = Qs2Rs(qp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "d959767d",
   "metadata": {},
   "outputs": [],
   "source": [
    "Rs = Qs2Rs(Q)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "4cb9055a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([2, 3, 2, 1, 3])"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rv = rv.reshape((2,3,2,1,3))\n",
    "rv.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "88567358",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([2, 3, 2, 3, 3])"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Rs.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "5fdd9c79",
   "metadata": {},
   "outputs": [],
   "source": [
    "rot_vecs = einsum('bnkij,bnkhj->bnki',Rs, rv)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "486edbf0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[[ 0.,  0., -1.],\n",
       "          [ 0.,  0., -1.]],\n",
       "\n",
       "         [[ 0.,  0., -1.],\n",
       "          [ 0.,  0., -1.]],\n",
       "\n",
       "         [[ 0.,  0., -1.],\n",
       "          [ 0.,  0., -1.]]],\n",
       "\n",
       "\n",
       "        [[[ 0.,  0., -1.],\n",
       "          [ 0.,  0., -1.]],\n",
       "\n",
       "         [[ 0.,  0., -1.],\n",
       "          [ 0.,  0., -1.]],\n",
       "\n",
       "         [[ 0.,  0., -1.],\n",
       "          [ 0.,  0., -1.]]]])"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rot_vecs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "4e13aa5f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#From\n",
    "#https://math.stackexchange.com/questions/939229/unit-quaternion-to-a-scalar-power\n",
    "\n",
    "#test code\n",
    "# Q = torch.tensor([0,0,1,0],dtype=torch.float)[None,None,None,...].repeat(2,3,2,1) #180 rotation about Y axis\n",
    "# rv = torch.tensor([[0,0,1]],dtype=torch.float)[None,None,...].repeat(2,3,2,1) #unit Z\n",
    "# Q = normQ(Q)\n",
    "#qp = powerQ(Q,0.5) rotate halfway (aka x-axis)\n",
    "#rv = rv.reshape((2,3,2,1,3))\n",
    "#rot_vecs = einsum('bnkij,bnkhj->bnki',Rs, rv) #should be x-axis\n",
    "\n",
    "def powerQ(quat_in, power):\n",
    "    \"\"\"Quaternion to the power, represent number of times to rotate Q. Only works on unit Q\"\"\"\n",
    "    return expQ(scaleQ(lnQ(quat_in),power))\n",
    "\n",
    "\n",
    "def expQ(quat_in, eps=1e-9):\n",
    "    quat_out = torch.zeros_like(quat_in, device=quat_in.device)\n",
    "    r = torch.sqrt(torch.sum(torch.square(quat_in[...,1:]),axis=-1,keepdim=True)+eps)\n",
    "    et = torch.exp(quat_in[...,0][...,None])\n",
    "    s = et*torch.sin(r)/r\n",
    "    s[torch.where(r<eps)[0]] = 0\n",
    "    \n",
    "    quat_out[...,0][...,None] = et*torch.cos(r)\n",
    "    quat_out[...,1] = s[...,0]*quat_in[...,1]\n",
    "    quat_out[...,2] = s[...,0]*quat_in[...,2]\n",
    "    quat_out[...,3] = s[...,0]*quat_in[...,3]\n",
    "    \n",
    "    return quat_out\n",
    "\n",
    "#fix in other location w calc\n",
    "def lnQ(quat_in, eps=1e-9):\n",
    "    quat_out = torch.zeros_like(quat_in, device=quat_in.device)\n",
    "    r = torch.sqrt(torch.sum(torch.square(quat_in[...,1:]),axis=-1,keepdim=True)+eps)\n",
    "    t = torch.atan2(r,quat_in[...,0][...,None])/r\n",
    "    t[torch.where(r<eps)[0]] = 0\n",
    "        \n",
    "    quat_out[...,0][...,None] = 0.5*torch.log(torch.sum(torch.square(quat_in),axis=-1,keepdim=True)+eps)\n",
    "    quat_out[...,1] = t[...,0]*quat_in[...,1]\n",
    "    quat_out[...,2] = t[...,0]*quat_in[...,2]\n",
    "    quat_out[...,3] = t[...,0]*quat_in[...,3]\n",
    "    \n",
    "    return quat_out\n",
    "    \n",
    "\n",
    "def scaleQ(quat_in, scale):\n",
    "    return torch.multiply(quat_in,scale)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26b7b65e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1db68d9c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fbc0c239",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "652bd82b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def model_step(backbone_dict, noised_dict, batched_t, scores_scales, graph_maker, graph_unet, train=True):\n",
    "    \n",
    "    CA_t  = backbone_dict['CA'].reshape(B, L, 3).to('cuda')\n",
    "    NC_t = CA_t + backbone_dict['N_CA'].reshape(B, L, 3).to('cuda')\n",
    "    CC_t = CA_t + backbone_dict['C_CA'].reshape(B, L, 3).to('cuda')\n",
    "    true =  torch.cat((NC_t,CA_t,CC_t),dim=2).reshape(B,L,3,3)\n",
    "    \n",
    "    CA_n  = noised_dict['CA'].reshape(B, L, 3).to('cuda')\n",
    "    NC_n = CA_n + noised_dict['N_CA'].reshape(B, L, 3).to('cuda')\n",
    "    CC_n = CA_n + noised_dict['C_CA'].reshape(B, L, 3).to('cuda')\n",
    "    noise_xyz =  torch.cat((NC_n,CA_n,CC_n),dim=2).reshape(B,L,3,3)\n",
    "    \n",
    "    x = graph_maker.prep_for_network(noised_dict)\n",
    "    out = graph_unet(x, batched_t)\n",
    "    CA_p = out['1'][:,0,:].reshape(B, L, 3)+CA_n #translation of Calpha\n",
    "    Qs = out['1'][:,1,:] # rotation\n",
    "    Qs = Qs.unsqueeze(1).repeat((1,2,1))\n",
    "    Qs = torch.cat((torch.ones((B*L,2,1),device=Qs.device),Qs),dim=-1).reshape(B,L,2,4)\n",
    "    Qs = normQ(Qs)\n",
    "    Rs = Qs2Rs(Qs)\n",
    "    N_C_to_Rot = torch.cat((noised_dict['N_CA'].reshape(B, L, 3).to('cuda'),\n",
    "                            noised_dict['C_CA'].reshape(B, L, 3).to('cuda')),dim=2).reshape(B,L,2,1,3)\n",
    "\n",
    "    \n",
    "    \n",
    "    rot_vecs = einsum('bnkij,bnkhj->bnki',Rs, N_C_to_Rot)\n",
    "    NC_p = CA_p + rot_vecs[:,:,0,:].to('cuda')*N_CA_dist\n",
    "    CC_p = CA_p + rot_vecs[:,:,1,:].reshape(B, L, 3).to('cuda')*C_CA_dist\n",
    "\n",
    "    pred = torch.cat((NC_p,CA_p,CC_p),dim=2).reshape(B,L,3,3)\n",
    "    \n",
    "    tloss, loss = FAPE_loss(pred.unsqueeze(0), true, scores_scales)\n",
    "    \n",
    "    return tloss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "55e49b75",
   "metadata": {},
   "outputs": [],
   "source": [
    "def noise_test(backbone_dict, noised_dict):\n",
    "    CA_t  = bb_dict['CA'].reshape(B, L, 3).to('cuda')\n",
    "    NC_t = CA_t + bb_dict['N_CA'].reshape(B, L, 3).to('cuda')*N_CA_dist\n",
    "    CC_t = CA_t + bb_dict['C_CA'].reshape(B, L, 3).to('cuda')*C_CA_dist\n",
    "    true =  torch.cat((NC_t,CA_t,CC_t),dim=2).reshape(B,L,3,3)\n",
    "    \n",
    "    CA_n  = noised_dict['CA'].reshape(B, L, 3).to('cuda')\n",
    "    NC_n = CA_n + noised_dict['N_CA'].reshape(B, L, 3).to('cuda')*N_CA_dist\n",
    "    CC_n = CA_n + noised_dict['C_CA'].reshape(B, L, 3).to('cuda')*C_CA_dist\n",
    "    noise_xyz =  torch.cat((NC_n,CA_n,CC_n),dim=2).reshape(B,L,3,3)\n",
    "    return true.to('cpu').numpy()*10, noise_xyz.to('cpu').numpy()*10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "00d45bb6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from util.npose_util import makePointPDB\n",
    "#gds = Graph_RadiusMP_4H_Dataset(coords_tog[:100], 10, mp_stride = 3)\n",
    "def view_mp_graph(mps: DGLGraph, coords: np.array ):\n",
    "    p = mps.ndata['pos']*10\n",
    "    \n",
    "    to = np.concatenate((coords, np.ones_like(coords)[:,:,0][...,None]),axis=2)\n",
    "    \n",
    "    makePointPDB(p,'test.pdb',outDirec='output')\n",
    "    nu.dump_npdb(to,'output/test2.pdb')\n",
    "#view_mp_graph(gds.mpSelfGraphList[0], coords_tog[0])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "se33",
   "language": "python",
   "name": "se33"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
