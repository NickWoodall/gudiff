{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a02a1c0f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "import util.npose_util as nu\n",
    "import os\n",
    "import pathlib\n",
    "import dgl\n",
    "from dgl import backend as F\n",
    "import torch_geometric\n",
    "from torch.utils.data import random_split, DataLoader, Dataset\n",
    "from typing import Dict\n",
    "from torch import Tensor\n",
    "from dgl import DGLGraph\n",
    "from torch import nn\n",
    "# from chemical import cos_ideal_NCAC #from RoseTTAFold2\n",
    "from torch import einsum\n",
    "import time\n",
    "torch.cuda.is_available()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6a31f547",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from data_rigid_diffuser import so3_diffuser\n",
    "# from data_rigid_diffuser import r3_diffuser\n",
    "# from scipy.spatial.transform import Rotation\n",
    "# from data_rigid_diffuser import rigid_utils as ru\n",
    "# import yaml\n",
    "from data_rigid_diffuser.diffuser import FrameDiffNoise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "bf443f63",
   "metadata": {},
   "outputs": [],
   "source": [
    "from se3_transformer.model.basis import get_basis, update_basis_with_fused\n",
    "from se3_transformer.model.transformer import Sequential, SE3Transformer\n",
    "from se3_transformer.model.transformer_topk import SE3Transformer_topK\n",
    "from se3_transformer.model.FAPE_Loss import FAPE_loss, Qs2Rs, normQ\n",
    "from se3_transformer.model.layers.attentiontopK import AttentionBlockSE3\n",
    "from se3_transformer.model.layers.linear import LinearSE3\n",
    "from se3_transformer.model.layers.convolution import ConvSE3, ConvSE3FuseLevel\n",
    "from se3_transformer.model.layers.norm import NormSE3\n",
    "from se3_transformer.model.layers.pooling import GPooling, Latent_Unpool, Unpool_Layer\n",
    "from se3_transformer.runtime.utils import str2bool, to_cuda\n",
    "from se3_transformer.model.fiber import Fiber\n",
    "from se3_transformer.model.transformer import get_populated_edge_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "2511634d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#npose indexing\n",
    "# Useful numbers\n",
    "# N [-1.45837285,  0 , 0]\n",
    "# CA [0., 0., 0.]\n",
    "# C [0.55221403, 1.41890368, 0.        ]\n",
    "# CB [ 0.52892494, -0.77445692, -1.19923854]\n",
    "\n",
    "N_CA_dist = torch.tensor(1.458/10.0).to('cuda')\n",
    "C_CA_dist = torch.tensor(1.523/10.0).to('cuda')\n",
    "\n",
    "if ( hasattr(os, 'ATOM_NAMES') ):\n",
    "    assert( hasattr(os, 'PDB_ORDER') )\n",
    "\n",
    "    ATOM_NAMES = os.ATOM_NAMES\n",
    "    PDB_ORDER = os.PDB_ORDER\n",
    "else:\n",
    "    ATOM_NAMES=['N', 'CA', 'CB', 'C', 'O']\n",
    "    PDB_ORDER = ['N', 'CA', 'C', 'O', 'CB']\n",
    "\n",
    "_byte_atom_names = []\n",
    "_atom_names = []\n",
    "for i, atom_name in enumerate(ATOM_NAMES):\n",
    "    long_name = \" \" + atom_name + \"       \"\n",
    "    _atom_names.append(long_name[:4])\n",
    "    _byte_atom_names.append(atom_name.encode())\n",
    "\n",
    "    globals()[atom_name] = i\n",
    "\n",
    "R = len(ATOM_NAMES)\n",
    "\n",
    "if ( \"N\" not in globals() ):\n",
    "    N = -1\n",
    "if ( \"C\" not in globals() ):\n",
    "    C = -1\n",
    "if ( \"CB\" not in globals() ):\n",
    "    CB = -1\n",
    "\n",
    "\n",
    "_pdb_order = []\n",
    "for name in PDB_ORDER:\n",
    "    _pdb_order.append( ATOM_NAMES.index(name) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e213e885",
   "metadata": {},
   "outputs": [],
   "source": [
    "# data_path_str  = 'data/h4_ca_coords.npz'\n",
    "# test_limit = 1028\n",
    "# rr = np.load(data_path_str)\n",
    "# ca_coords = [rr[f] for f in rr.files][0][:test_limit,:,:3]\n",
    "# ca_coords.shape\n",
    "\n",
    "# getting N-Ca, Ca-C vectors to add as typeI features\n",
    "#apa = apart helices for val/train split\n",
    "#tog = together helices for val/train split\n",
    "apa_path_str  = 'data_npose/h4_apa_coords.npz'\n",
    "tog_path_str  = 'data_npose/h4_tog_coords.npz'\n",
    "\n",
    "#grab the first 3 atoms which are N,CA,C\n",
    "test_limit = 5048\n",
    "rr = np.load(apa_path_str)\n",
    "coords_apa = [rr[f] for f in rr.files][0][:test_limit,:]\n",
    "\n",
    "rr = np.load(tog_path_str)\n",
    "coords_tog = [rr[f] for f in rr.files][0][:test_limit,:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d4c2ed33",
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_npose_from_coords(coords_in):\n",
    "    \"\"\"Use N, CA, C coordinates to generate O an CB atoms\"\"\"\n",
    "    rot_mat_cat = np.ones(sum((coords_in.shape[:-1], (1,)), ()))\n",
    "    \n",
    "    coords = np.concatenate((coords_in,rot_mat_cat),axis=-1)\n",
    "    \n",
    "    npose = np.ones((coords_in.shape[0]*5,4)) #5 is atoms per res\n",
    "\n",
    "    by_res = npose.reshape(-1, 5, 4)\n",
    "    \n",
    "    if ( \"N\" in ATOM_NAMES ):\n",
    "        by_res[:,N,:3] = coords_in[:,0,:3]\n",
    "    if ( \"CA\" in ATOM_NAMES ):\n",
    "        by_res[:,CA,:3] = coords_in[:,1,:3]\n",
    "    if ( \"C\" in ATOM_NAMES ):\n",
    "        by_res[:,C,:3] = coords_in[:,2,:3]\n",
    "    if ( \"O\" in ATOM_NAMES ):\n",
    "        by_res[:,O,:3] = nu.build_O(npose)\n",
    "    if ( \"CB\" in ATOM_NAMES ):\n",
    "        tpose = nu.tpose_from_npose(npose)\n",
    "        by_res[:,CB,:] = nu.build_CB(tpose)\n",
    "\n",
    "    return npose\n",
    "\n",
    "def dump_coord_pdb(coords_in, fileOut='fileOut.pdb'):\n",
    "    \n",
    "    npose =  build_npose_from_coords(coords_in)\n",
    "    nu.dump_npdb(npose,fileOut)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "508327fa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([0., 1., 0., 1., 0., 1., 0., 1., 0., 1., 0., 1.])\n",
      "tensor([0.6000, 0.8000, 0.4000, 0.9000, 0.3000, 1.0000, 0.2000, 1.0000, 0.1000,\n",
      "        1.0000, 0.1000, 1.0000])\n",
      "tensor([1.0000, 0.2000, 0.8000, 0.6000, 0.6000, 0.8000, 0.4000, 0.9000, 0.3000,\n",
      "        1.0000, 0.2000, 1.0000])\n",
      "tensor([ 0.9000, -0.5000,  1.0000,  0.2000,  0.8000,  0.6000,  0.6000,  0.8000,\n",
      "         0.4000,  0.9000,  0.3000,  1.0000])\n",
      "tensor([ 0.4000, -0.9000,  1.0000, -0.3000,  1.0000,  0.3000,  0.8000,  0.7000,\n",
      "         0.6000,  0.8000,  0.4000,  0.9000])\n"
     ]
    }
   ],
   "source": [
    "#goal define edges of\n",
    "#connected backbone 1, \n",
    "#unconnected atoms 0,\n",
    "\n",
    "\n",
    "def get_midpoint(ep_in):\n",
    "    \"\"\"Get midpoint, of each batched set of points\"\"\"\n",
    "    \n",
    "    #calculate midpoint\n",
    "    midpoint = ep_in.sum(axis=1)/np.repeat(ep_in.shape[1], ep_in.shape[2])\n",
    "    \n",
    "    return midpoint\n",
    "\n",
    "# def normQ(Q):\n",
    "#     \"\"\"normalize a quaternions\n",
    "#     \"\"\"\n",
    "#     return Q / torch.linalg.norm(Q, keepdim=True, dim=-1)\n",
    "\n",
    "# def Rs2Qs(Rs):\n",
    "#     Qs = torch.zeros((*Rs.shape[:-2],4), device=Rs.device)\n",
    "\n",
    "#     Qs[...,0] = 1.0 + Rs[...,0,0] + Rs[...,1,1] + Rs[...,2,2]\n",
    "#     Qs[...,1] = 1.0 + Rs[...,0,0] - Rs[...,1,1] - Rs[...,2,2]\n",
    "#     Qs[...,2] = 1.0 - Rs[...,0,0] + Rs[...,1,1] - Rs[...,2,2]\n",
    "#     Qs[...,3] = 1.0 - Rs[...,0,0] - Rs[...,1,1] + Rs[...,2,2]\n",
    "#     Qs[Qs<0.0] = 0.0\n",
    "#     Qs = torch.sqrt(Qs) / 2.0\n",
    "#     Qs[...,1] *= torch.sign( Rs[...,2,1] - Rs[...,1,2] )\n",
    "#     Qs[...,2] *= torch.sign( Rs[...,0,2] - Rs[...,2,0] )\n",
    "#     Qs[...,3] *= torch.sign( Rs[...,1,0] - Rs[...,0,1] )\n",
    "\n",
    "#     return Qs\n",
    "\n",
    "# def Qs2Rs(Qs):\n",
    "#     Rs = torch.zeros((*Qs.shape[:-1],3,3), device=Qs.device)\n",
    "\n",
    "#     Rs[...,0,0] = Qs[...,0]*Qs[...,0]+Qs[...,1]*Qs[...,1]-Qs[...,2]*Qs[...,2]-Qs[...,3]*Qs[...,3]\n",
    "#     Rs[...,0,1] = 2*Qs[...,1]*Qs[...,2] - 2*Qs[...,0]*Qs[...,3]\n",
    "#     Rs[...,0,2] = 2*Qs[...,1]*Qs[...,3] + 2*Qs[...,0]*Qs[...,2]\n",
    "#     Rs[...,1,0] = 2*Qs[...,1]*Qs[...,2] + 2*Qs[...,0]*Qs[...,3]\n",
    "#     Rs[...,1,1] = Qs[...,0]*Qs[...,0]-Qs[...,1]*Qs[...,1]+Qs[...,2]*Qs[...,2]-Qs[...,3]*Qs[...,3]\n",
    "#     Rs[...,1,2] = 2*Qs[...,2]*Qs[...,3] - 2*Qs[...,0]*Qs[...,1]\n",
    "#     Rs[...,2,0] = 2*Qs[...,1]*Qs[...,3] - 2*Qs[...,0]*Qs[...,2]\n",
    "#     Rs[...,2,1] = 2*Qs[...,2]*Qs[...,3] + 2*Qs[...,0]*Qs[...,1]\n",
    "#     Rs[...,2,2] = Qs[...,0]*Qs[...,0]-Qs[...,1]*Qs[...,1]-Qs[...,2]*Qs[...,2]+Qs[...,3]*Qs[...,3]\n",
    "\n",
    "#     return Rs\n",
    "\n",
    "\n",
    "def normalize_points(input_xyz, print_dist=False):\n",
    "    \n",
    "    #broadcast to distance matrix [Batch, M, R3] to [Batch,M,1, R3] to [Batch,1,M, R3] to [Batch, M,M, R3] \n",
    "    vec_diff = input_xyz[...,None,:]-input_xyz[...,None,:,:]\n",
    "    dist = np.sqrt(np.sum(np.square(vec_diff),axis=len(input_xyz.shape)))\n",
    "    furthest_dist = np.max(dist)\n",
    "    centroid  = get_midpoint(input_xyz)\n",
    "    if print_dist:\n",
    "        print(f'largest distance {furthest_dist:0.1f}')\n",
    "    \n",
    "    xyz_mean_zero = input_xyz - centroid[:,None,:]\n",
    "    return xyz_mean_zero/furthest_dist\n",
    "\n",
    "def define_graph_edges(n_nodes):\n",
    "    #connected backbone\n",
    "\n",
    "    con_v1 = np.arange(n_nodes-1) #vertex 1 of edges in chronological order\n",
    "    con_v2 = np.arange(1,n_nodes) #vertex 2 of edges in chronological order\n",
    "\n",
    "    ind = con_v1*(n_nodes-1)+con_v2-1 #account for removed self connections (-1)\n",
    "\n",
    "\n",
    "    #unconnected backbone\n",
    "\n",
    "    nodes = np.arange(n_nodes)\n",
    "    v1 = np.repeat(nodes,n_nodes-1) #starting vertices, same number repeated for each edge\n",
    "\n",
    "    start_v2 = np.repeat(np.arange(n_nodes)[None,:],n_nodes,axis=0)\n",
    "    diag_ind = np.diag_indices(n_nodes)\n",
    "    start_v2[diag_ind] = -1 #diagonal of matrix is self connections which we remove (self connections are managed by SE3 Conv channels)\n",
    "    v2 = start_v2[start_v2>-0.5] #remove diagonal and flatten\n",
    "\n",
    "    edge_data = torch.zeros(len(v2))\n",
    "    edge_data[ind] = 1\n",
    "    \n",
    "    return v1,v2,edge_data, ind\n",
    "\n",
    "\n",
    "\n",
    "def make_pe_encoding(n_nodes=65, embed_dim = 12, scale = 1000, cast_type=torch.float32, print_out=False):\n",
    "    #positional encoding of node\n",
    "    i_array = np.arange(1,(embed_dim/2)+1)\n",
    "    wk = (1/(scale**(i_array*2/embed_dim)))\n",
    "    t_array = np.arange(n_nodes)\n",
    "    si = torch.tensor(np.sin(wk*t_array.reshape((-1,1))))\n",
    "    ci = torch.tensor(np.cos(wk*t_array.reshape((-1,1))))\n",
    "    pe = torch.stack((si,ci),axis=2).reshape(t_array.shape[0],embed_dim).type(cast_type)\n",
    "    \n",
    "    if print_out == True:\n",
    "        for x in range(int(n_nodes/12)):\n",
    "            print(np.round(pe[x],1))\n",
    "    \n",
    "    return pe\n",
    "    \n",
    "    \n",
    "#v1,v2,edge_data, ind = define_graph_edges(n_nodes)\n",
    "#norm_p = normalize_points(ca_coords,print_dist=True)\n",
    "pe = make_pe_encoding(n_nodes=65, embed_dim = 12, scale = 10, print_out=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "321dc5e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "#?dgl.nn.pytorch.KNNGraph, nearest neighbor graph maker\n",
    "def define_graph(batch_size=8,n_nodes=65):\n",
    "    \n",
    "    v1,v2,edge_data, ind = define_graph_edges(n_nodes)\n",
    "    pe = make_pe_encoding(n_nodes=n_nodes)\n",
    "    \n",
    "    graphList = []\n",
    "    \n",
    "    for i in range(batch_size):\n",
    "        \n",
    "        g = dgl.graph((v1,v2))\n",
    "        g.edata['con'] = edge_data\n",
    "        g.ndata['pe'] = pe\n",
    "\n",
    "        graphList.append(g)\n",
    "        \n",
    "    batched_graph = dgl.batch(graphList)\n",
    "\n",
    "    return batched_graph\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "d1a60cff",
   "metadata": {},
   "outputs": [],
   "source": [
    "def torch_normalize(v, eps=1e-6):\n",
    "    \"\"\"Normalize vector in last axis\"\"\"\n",
    "    norm = torch.linalg.vector_norm(v, dim=len(v.shape)-1)+eps\n",
    "    return v / norm[...,None]\n",
    "\n",
    "def normalize(v):\n",
    "    \"\"\"Normalize vector in last axis\"\"\"\n",
    "    norm = np.linalg.norm(v,axis=len(v.shape)-1)\n",
    "    norm[norm == 0] = 1\n",
    "    return v / norm[...,None]\n",
    "\n",
    "def get_CN_vector(coords_in):\n",
    "    N_CA_vec = normalize(coords_in[...,N,:3]-coords_in[...,CA,:3])\n",
    "    C_CA_vec = normalize(coords_in[...,C,:3]-coords_in[...,CA,:3])\n",
    "    return N_CA_vec, C_CA_vec\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "5cc4e2ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "def _get_relative_pos(graph_in: dgl.DGLGraph) -> torch.Tensor:\n",
    "    x = graph_in.ndata['pos']\n",
    "    src, dst = graph_in.edges()\n",
    "    rel_pos = x[dst] - x[src]\n",
    "    return rel_pos\n",
    "\n",
    "class Helix4_Dataset(Dataset):\n",
    "    def __init__(self, coordinates: np.array, cast_type=torch.float32):\n",
    "        #prots,#length_prot in aa, #residues/aa, #xyz per atom\n",
    "           \n",
    "        #alphaFold reduce by 10\n",
    "        coord_div = 10\n",
    "        \n",
    "        coordinates = coordinates/coord_div\n",
    "        self.ca_coords = torch.tensor(coordinates[:,:,CA,:], dtype=cast_type)\n",
    "        #unsqueeze to stack together later\n",
    "        self.N_CA_vec = torch.tensor(coordinates[:,:,N,:] - coordinates[:,:,CA,:], dtype=cast_type)\n",
    "        self.C_CA_vec = torch.tensor(coordinates[:,:,C,:] - coordinates[:,:,CA,:], dtype=cast_type)\n",
    "        \n",
    "        self.N_CA_vec = torch_normalize(self.N_CA_vec).unsqueeze(2)\n",
    "        self.C_CA_vec = torch_normalize(self.C_CA_vec).unsqueeze(2)\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.ca_coords)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        return {'CA':self.ca_coords[idx], 'N_CA':self.N_CA_vec[idx], 'C_CA':self.C_CA_vec[idx]}\n",
    "    \n",
    "    \n",
    "\n",
    "    \n",
    "    \n",
    "class Make_KNN_MP_Graphs():\n",
    "    \n",
    "    #8 long positional encoding\n",
    "    NODE_FEATURE_DIM_0 = 12\n",
    "    EDGE_FEATURE_DIM = 1 # 0 or 1 primary seq connection or not\n",
    "    NODE_FEATURE_DIM_1 = 2\n",
    "    \n",
    "    def __init__(self, mp_stride=4, n_nodes=65, radius=15, coord_div=10, cast_type=torch.float32, channels_start=32,\n",
    "                       ndf1=6, ndf0=32,cuda=True):\n",
    "        \n",
    "        self.KNN = 30\n",
    "        self.n_nodes = n_nodes\n",
    "        self.pe = make_pe_encoding(n_nodes=n_nodes)\n",
    "        self.mp_stride = mp_stride\n",
    "        self.cast_type = cast_type\n",
    "        self.channels_start = channels_start\n",
    "        \n",
    "        self.cuda = cuda\n",
    "        self.ndf1 = ndf1 #awkard adding of nodes features to mpGraph\n",
    "        self.ndf0 = ndf0\n",
    "        \n",
    "    def create_and_batch(self, bb_dict):\n",
    "        \n",
    "        graphList = []\n",
    "        mpGraphList = []\n",
    "        mpRevGraphList = []\n",
    "        mpSelfGraphList = []\n",
    "        \n",
    "        for j, caXYZ in enumerate(bb_dict['CA']):\n",
    "            graph = dgl.knn_graph(caXYZ, self.KNN)\n",
    "            graph.ndata['pe'] = pe\n",
    "            graph.ndata['pos'] = caXYZ\n",
    "            graph.ndata['bb_ori'] = torch.cat((bb_dict['N_CA'][j],  bb_dict['C_CA'][j]),axis=1)\n",
    "            \n",
    "            #define covalent connections\n",
    "            esrc, edst = graph.edges()\n",
    "            graph.edata['con'] = (torch.abs(esrc-edst)==1).type(self.cast_type).reshape((-1,1))\n",
    "            \n",
    "            mp_list = torch.zeros((len(list(range(0,self.n_nodes, self.mp_stride))),caXYZ.shape[1]))\n",
    "            \n",
    "            new_src = torch.tensor([],dtype=torch.int)\n",
    "            new_dst = torch.tensor([],dtype=torch.int)\n",
    "            \n",
    "            new_src_rev = torch.tensor([], dtype=torch.int)\n",
    "            new_dst_rev = torch.tensor([], dtype=torch.int)\n",
    "           \n",
    "            i=0#mp list counter\n",
    "            for x in range(0,self.n_nodes, self.mp_stride):\n",
    "                src, dst = graph.in_edges(x) #dst repeats x\n",
    "                n_tot = torch.cat((torch.tensor(x).unsqueeze(0),src)) #add x to node list\n",
    "                mp_list[i] = caXYZ[n_tot].sum(axis=0)/n_tot.shape[0]\n",
    "                mp_node = i + graph.num_nodes() #add midpoints nodes at end of graph\n",
    "                #define edges between midpoint nodes and nodes defining midpoint for midpointGraph\n",
    "                \n",
    "                new_src = torch.cat((new_src,n_tot))\n",
    "                new_dst = torch.cat((new_dst,\n",
    "                                     (torch.tensor(mp_node).unsqueeze(0).repeat(n_tot.shape[0]))))\n",
    "                #and reverse graph for coming off\n",
    "                new_src_rev = torch.cat((new_src_rev,\n",
    "                                         (torch.tensor(mp_node).unsqueeze(0).repeat(n_tot.shape[0]))))\n",
    "                new_dst_rev = torch.cat((new_dst_rev,n_tot))\n",
    "                \n",
    "                i+=1\n",
    "                \n",
    "            mpGraph = dgl.graph((new_src,new_dst))\n",
    "            mpGraph.ndata['pos'] = torch.cat((caXYZ,mp_list),axis=0).type(self.cast_type)\n",
    "            mp_node_indx = torch.arange(0,self.n_nodes, self.mp_stride).type(torch.int)\n",
    "            #match output shape of first transformer\n",
    "            pe_mp = torch.cat((pe,torch.zeros((pe.shape[0],self.channels_start-pe.shape[1]))),axis=1)\n",
    "            mpGraph.ndata['pe'] = torch.cat((pe_mp,pe_mp[mp_node_indx]))\n",
    "            mpGraph.edata['con'] = torch.zeros((mpGraph.num_edges(),1))\n",
    "            \n",
    "            mpGraph_rev = dgl.graph((new_src_rev,new_dst_rev))\n",
    "            mpGraph_rev.ndata['pos'] = torch.cat((caXYZ,mp_list),axis=0).type(self.cast_type)\n",
    "            mpGraph_rev.ndata['pe'] = torch.cat((pe_mp,pe_mp[mp_node_indx]))\n",
    "            mpGraph_rev.edata['con'] = torch.zeros((mpGraph_rev.num_edges(),1))\n",
    "            \n",
    "            #make graph for self interaction of midpoints\n",
    "            v1,v2,edge_data, ind = define_graph_edges(len(mp_list))\n",
    "            mpSelfGraph = dgl.graph((v1,v2))\n",
    "            mpSelfGraph.edata['con'] = edge_data.reshape((-1,1))\n",
    "            mpSelfGraph.ndata['pe'] = pe[mp_node_indx] #not really needed\n",
    "            mpSelfGraph.ndata['pos'] = mp_list.type(self.cast_type)\n",
    "            \n",
    "            \n",
    "            mpSelfGraphList.append(mpSelfGraph) \n",
    "            mpGraphList.append(mpGraph)\n",
    "            mpRevGraphList.append(mpGraph_rev)\n",
    "            graphList.append(graph)\n",
    "        \n",
    "        return dgl.batch(graphList), dgl.batch(mpGraphList), dgl.batch(mpSelfGraphList), dgl.batch(mpRevGraphList)\n",
    "    \n",
    "    def prep_for_network(self, bb_dict, cuda=True):\n",
    "    \n",
    "        batched_graph, batched_mpgraph, batched_mpself_graph, batched_mpRevgraph =  self.create_and_batch(bb_dict)\n",
    "        \n",
    "        edge_feats        =    {'0':   batched_graph.edata['con'][:, :self.EDGE_FEATURE_DIM, None]}\n",
    "        edge_feats_mp     = {'0': batched_mpgraph.edata['con'][:, :self.EDGE_FEATURE_DIM, None]} #def all zero now\n",
    "        edge_feats_mpself = {'0': batched_mpself_graph.edata['con'][:, :self.EDGE_FEATURE_DIM, None]}\n",
    "#         edge_feats_mp     = {'0': batched_mpRevgraph.edata['con'][:, :self.EDGE_FEATURE_DIM, None]}\n",
    "        batched_graph.edata['rel_pos']   = _get_relative_pos(batched_graph)\n",
    "        batched_mpgraph.edata['rel_pos'] = _get_relative_pos(batched_mpgraph)\n",
    "        batched_mpself_graph.edata['rel_pos'] = _get_relative_pos(batched_mpself_graph)\n",
    "        batched_mpRevgraph.edata['rel_pos'] = _get_relative_pos(batched_mpRevgraph)\n",
    "        # get node features\n",
    "        node_feats =         {'0': batched_graph.ndata['pe'][:, :self.NODE_FEATURE_DIM_0, None],\n",
    "                              '1': batched_graph.ndata['bb_ori'][:,:self.NODE_FEATURE_DIM_1, :3]}\n",
    "        node_feats_mp =      {'0': batched_mpgraph.ndata['pe'][:, :self.ndf0, None],\n",
    "                              '1': torch.ones((batched_mpgraph.num_nodes(),self.ndf1,3))}\n",
    "        #unused\n",
    "        node_feats_mpself =  {'0': batched_mpself_graph.ndata['pe'][:, :self.NODE_FEATURE_DIM_0, None]}\n",
    "        \n",
    "        if cuda:\n",
    "            bg,nf,ef = to_cuda(batched_graph), to_cuda(node_feats), to_cuda(edge_feats)\n",
    "            bg_mp, nf_mp, ef_mp = to_cuda(batched_mpgraph), to_cuda(node_feats_mp), to_cuda(edge_feats_mp)\n",
    "            bg_mps, nf_mps, ef_mps = to_cuda(batched_mpself_graph), to_cuda(node_feats_mpself), to_cuda(edge_feats_mpself)\n",
    "            bg_mpRev = to_cuda(batched_mpRevgraph)\n",
    "            \n",
    "            return bg,nf,ef, bg_mp, nf_mp, ef_mp, bg_mps, nf_mps, ef_mps, bg_mpRev\n",
    "        \n",
    "        else:\n",
    "            bg,nf,ef = batched_graph, node_feats, edge_feats\n",
    "            bg_mp, nf_mp, ef_mp = batched_mpgraph, node_feats_mp, edge_feats_mp\n",
    "            bg_mps, nf_mps, ef_mps = batched_mpself_graph, node_feats_mpself, edge_feats_mpself\n",
    "            bg_mpRev = batched_mpRevgraph\n",
    "            \n",
    "            return bg,nf,ef, bg_mp, nf_mp, ef_mp, bg_mps, nf_mps, ef_mps, bg_mpRev\n",
    "        \n",
    "            \n",
    "\n",
    "def get_edge_features(graph,edge_feature_dim=1):\n",
    "    return {'0': graph.edata['con'][:, :edge_feature_dim, None]}\n",
    "\n",
    "def define_poolGraph(n_nodes, batch_size, cast_type=torch.float32, cuda_out=True ):\n",
    "    \n",
    "    v1,v2,edge_data, ind = define_graph_edges(n_nodes)\n",
    "    #pe = make_pe_encoding(n_nodes=n_nodes)#pe e\n",
    "    \n",
    "    graphList = []\n",
    "    \n",
    "    for i in range(batch_size):\n",
    "        \n",
    "        g = dgl.graph((v1,v2))\n",
    "        g.edata['con'] = edge_data.type(cast_type).reshape((-1,1))\n",
    "        g.ndata['pos'] = torch.zeros((n_nodes,3),dtype=torch.float32)\n",
    "\n",
    "        graphList.append(g)\n",
    "        \n",
    "    batched_graph = dgl.batch(graphList)\n",
    "    \n",
    "    if cuda_out:\n",
    "        return to_cuda(batched_graph)\n",
    "    else:\n",
    "        return batched_graph            \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "e69a49f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def pull_edge_features(graph, edge_feat_dim=1):\n",
    "    return {'0': graph.edata['con'][:, :edge_feat_dim, None]}\n",
    "\n",
    "def prep_for_gcn(graph, xyz_pos, edge_feats_input, idx, max_degree=3, comp_grad=True):\n",
    "    \n",
    "    src, dst = graph.edges()\n",
    "    \n",
    "    new_pos = F.gather_row(xyz_pos, idx)\n",
    "    rel_pos = F.gather_row(new_pos,dst) - F.gather_row(new_pos,src) \n",
    "    \n",
    "    basis_out = get_basis(rel_pos, max_degree=max_degree,\n",
    "                                   compute_gradients=comp_grad,\n",
    "                                   use_pad_trick=False)\n",
    "    basis_out = update_basis_with_fused(basis_out, max_degree, use_pad_trick=False,\n",
    "                                            fully_fused=False)\n",
    "    edge_feats_out = get_populated_edge_features(rel_pos, edge_feats_input)\n",
    "    return edge_feats_out, basis_out, new_pos    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "401432e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "class GraphUNet(torch.nn.Module):\n",
    "    def __init__(self, \n",
    "                 fiber_start = Fiber({0:12, 1:2}),\n",
    "                 fiber_out = Fiber({1:2}),\n",
    "                 k=4,\n",
    "                 batch_size = 8,\n",
    "                 stride=4,\n",
    "                 max_degree=3,\n",
    "                 channels=32,\n",
    "                 num_heads = 8,\n",
    "                 channels_div=4,\n",
    "                 num_layers = 1,\n",
    "                 num_layers_ca = 1,\n",
    "                 edge_feature_dim=1,\n",
    "                 latent_pool_type = 'avg',\n",
    "                 t_size = 1,\n",
    "                 cuda=True):\n",
    "        super(GraphUNet, self).__init__()\n",
    "        \n",
    "        \n",
    "        self.comp_basis_grad = True\n",
    "        self.cuda = cuda\n",
    "        \n",
    "        if cuda:\n",
    "            self.device='cuda:0'\n",
    "        else:\n",
    "            self.device='cpu'\n",
    "        \n",
    "        self.max_degree=max_degree\n",
    "        self.B = batch_size\n",
    "        self.k = k\n",
    "        self.ts = t_size\n",
    "        \n",
    "        self.num_layers = 1\n",
    "        self.num_layers_ca = num_layers_ca\n",
    "        self.channels = 32\n",
    "        self.feat0 = 32\n",
    "        self.feat1 = 6\n",
    "        self.channels_div = 4\n",
    "        self.num_heads = 8\n",
    "        self.mult = int(stride/2)\n",
    "        self.fiber_edge=Fiber({0:edge_feature_dim})\n",
    "        self.edge_feat_dim = edge_feature_dim\n",
    "        \n",
    "        self.pool_type = latent_pool_type\n",
    "        \n",
    "        self.channels_down_ca = channels\n",
    "        #down c_alpha interactions by radius\n",
    "        self.fiber_start =  fiber_start\n",
    "        self.fiber_hidden_down_ca = Fiber.create(self.max_degree, self.channels_down_ca)\n",
    "        self.fiber_out_down_ca =Fiber({0: self.feat0, 1: self.feat1})\n",
    "        \n",
    "        #concat_t, plus one on input fiber, run concat_t method on forward\n",
    "        self.down_ca = SE3Transformer(num_layers = self.num_layers_ca,\n",
    "                        fiber_in=self.fiber_start+self.ts,\n",
    "                        fiber_hidden= self.fiber_hidden_down_ca, \n",
    "                        fiber_out=self.fiber_out_down_ca,\n",
    "                        num_heads = self.num_heads,\n",
    "                        channels_div = self.channels_div,\n",
    "                        fiber_edge=self.fiber_edge,\n",
    "                        low_memory=True,\n",
    "                        tensor_cores=False)\n",
    "        \n",
    "        self.channels_down_ca2mp = self.channels_down_ca*self.mult\n",
    "        \n",
    "        #pool from c_alpha onto midpoints\n",
    "        self.fiber_in_down_ca2mp     = self.fiber_out_down_ca\n",
    "        self.fiber_hidden_down_ca2mp = Fiber.create(max_degree, self.channels_down_ca2mp)\n",
    "        self.fiber_out_down_ca2mp    = Fiber({0: self.feat0*self.mult, 1: self.feat1*self.mult})\n",
    "        \n",
    "        #concat_t, plus one on input fiber, run concat_t method on forward\n",
    "        self.down_ca2mp = SE3Transformer(num_layers = self.num_layers,\n",
    "                            fiber_in     = self.fiber_in_down_ca2mp+self.ts,\n",
    "                            fiber_hidden = self.fiber_hidden_down_ca2mp, \n",
    "                            fiber_out    = self.fiber_out_down_ca2mp,\n",
    "                            num_heads =    self.num_heads,\n",
    "                            channels_div = self.channels_div,\n",
    "                            fiber_edge=self. fiber_edge,\n",
    "                            low_memory=True,\n",
    "                            tensor_cores=False)\n",
    "        \n",
    "        self.fiber_in_mptopk =  self.fiber_out_down_ca2mp\n",
    "        self.fiber_hidden_down_mp  =self.fiber_hidden_down_ca2mp\n",
    "        self.fiber_out_down_mp_out =self.fiber_out_down_ca2mp\n",
    "        self.fiber_out_topkpool=Fiber({0: self.feat0*self.mult*self.mult})\n",
    "        \n",
    "        #concat_t, plus one on input fiber, run concat_t method on forward\n",
    "        self.mp_topk = SE3Transformer_topK(num_layers      = self.num_layers,\n",
    "                                        fiber_in      = self.fiber_in_mptopk+self.ts,\n",
    "                                        fiber_hidden  = self.fiber_hidden_down_mp, \n",
    "                                        fiber_out     = self.fiber_out_down_mp_out ,\n",
    "                                        fiber_out_topk= self.fiber_out_topkpool,\n",
    "                                        k             = self.k,\n",
    "                                        num_heads     = self.num_heads,\n",
    "                                        channels_div  = self.channels_div,\n",
    "                                        fiber_edge    =  self.fiber_edge,\n",
    "                                        low_memory=True,\n",
    "                                        tensor_cores=False)\n",
    "        \n",
    "        self.gsmall = define_poolGraph(self.k, self.B, cast_type=torch.float32, cuda_out=self.cuda)\n",
    "        self.ef_small = pull_edge_features(self.gsmall, edge_feat_dim=self.edge_feat_dim)\n",
    "        \n",
    "        #change to doing convolutions instead of points\n",
    "        self.fiber_in_down_gcn   =  self.fiber_out_topkpool\n",
    "        self.fiber_out_down_gcn  = Fiber({0: self.feat0*self.mult*self.mult, 1: self.feat1*self.mult})\n",
    "\n",
    "        self.down_gcn = ConvSE3(fiber_in  = self.fiber_in_down_gcn,\n",
    "                           fiber_out = self.fiber_out_down_gcn,\n",
    "                           fiber_edge= self.fiber_edge,\n",
    "                             self_interaction=True,\n",
    "                             use_layer_norm=True,\n",
    "                             max_degree=self.max_degree,\n",
    "                             fuse_level= ConvSE3FuseLevel.NONE,\n",
    "                             low_memory= True)\n",
    "        \n",
    "        \n",
    "        self.fiber_in_down_gcnp = self.fiber_out_down_gcn\n",
    "        #probably rename latent\n",
    "        self.latent_size = self.feat0*self.mult*self.mult\n",
    "        self.fiber_latent = Fiber({0: self.latent_size})\n",
    "\n",
    "        self.down_gcn2pool = ConvSE3(fiber_in=self.fiber_in_down_gcnp,\n",
    "                                     fiber_out=self.fiber_latent,\n",
    "                                     fiber_edge=self.fiber_edge,\n",
    "                                     self_interaction=True,\n",
    "                                     use_layer_norm=True,\n",
    "                                     max_degree=self.max_degree,\n",
    "                                     fuse_level= ConvSE3FuseLevel.NONE,\n",
    "                                     low_memory= True)\n",
    "        \n",
    "        self.global_pool = GPooling(pool=self.pool_type, feat_type=0)\n",
    "\n",
    "        self.latent_unpool_layer = Latent_Unpool(fiber_in = self.fiber_latent, fiber_add = self.fiber_out_down_gcn, \n",
    "                                            knodes = self.k)\n",
    "\n",
    "        self.up_gcn = ConvSE3(fiber_in=self.fiber_out_down_gcn,\n",
    "                             fiber_out=self.fiber_out_down_gcn,\n",
    "                             fiber_edge=self.fiber_edge,\n",
    "                             self_interaction=True,\n",
    "                             use_layer_norm=True,\n",
    "                             max_degree=self.max_degree,\n",
    "                             fuse_level= ConvSE3FuseLevel.NONE,\n",
    "                             low_memory= True)\n",
    "        \n",
    "        self.unpool_layer = Unpool_Layer(fiber_in=self.fiber_out_down_gcn, fiber_add=self.fiber_out_down_ca)\n",
    "        \n",
    "        self.fiber_in_up_gcn_mp = self.unpool_layer.fiber_out\n",
    "        self.fiber_hidden_up_mp= self.fiber_hidden_down_ca2mp\n",
    "        self.fiber_out_up_gcn_mp = self.fiber_out_down_mp_out\n",
    "\n",
    "        self.up_gcn_mp = SE3Transformer(num_layers = num_layers,\n",
    "                        fiber_in=self.fiber_in_up_gcn_mp,\n",
    "                        fiber_hidden= self.fiber_hidden_up_mp, \n",
    "                        fiber_out=self.fiber_out_up_gcn_mp,\n",
    "                        num_heads = self.num_heads,\n",
    "                        channels_div = self.channels_div,\n",
    "                        fiber_edge=self.fiber_edge,\n",
    "                        low_memory=True,\n",
    "                        tensor_cores=False)\n",
    "        \n",
    "        self.unpool_layer_off_mp = Unpool_Layer(fiber_in=self.fiber_out_down_mp_out, fiber_add=self.fiber_out_down_mp_out)\n",
    "\n",
    "        self.fiber_in_up_off_mp = self.fiber_out_up_gcn_mp\n",
    "        self.fiber_hidden_up_off_mp = self.fiber_hidden_up_mp\n",
    "        self.fiber_out_up_off_mp = self.fiber_out_down_ca \n",
    "        \n",
    "        #uses reverse graph to move mp off \n",
    "        \n",
    "        self.up_off_mp = SE3Transformer(num_layers = self.num_layers,\n",
    "                        fiber_in=self.fiber_in_up_off_mp,\n",
    "                        fiber_hidden= self.fiber_hidden_up_off_mp, \n",
    "                        fiber_out=self.fiber_out_up_off_mp,\n",
    "                        num_heads = self.num_heads,\n",
    "                        channels_div = self.channels_div,\n",
    "                        fiber_edge=self.fiber_edge,\n",
    "                        low_memory=True,\n",
    "                        tensor_cores=False)\n",
    "        \n",
    "        self.pre_linear = Fiber({1:36})\n",
    "        \n",
    "        #concat_t, plus one on input fiber, run concat_t method on forward\n",
    "        \n",
    "        self.up_ca = SE3Transformer(num_layers = self.num_layers_ca,\n",
    "                                    fiber_in=self.fiber_out_down_ca+self.ts,\n",
    "                                    fiber_hidden= self.fiber_hidden_down_ca, \n",
    "                                    fiber_out=self.pre_linear,\n",
    "                                    num_heads = self.num_heads,\n",
    "                                    channels_div = self.channels_div,\n",
    "                                    fiber_edge= self.fiber_edge,\n",
    "                                    low_memory=True,\n",
    "                                    tensor_cores=False)\n",
    "        \n",
    "        self.fiber_out = fiber_out\n",
    "        \n",
    "        self.linear = LinearSE3(fiber_in=self.pre_linear,\n",
    "                                fiber_out=fiber_out)\n",
    "        \n",
    "        self.zero_linear()\n",
    "        \n",
    "    def zero_linear(self):\n",
    "        nn.init.zeros_(self.linear.weights['1'])\n",
    "        \n",
    "    def concat_mp_feats(self, ca_feats_in, mp_feats):\n",
    "\n",
    "        nf0_c = ca_feats_in['0'].shape[-2]\n",
    "        nf1_c = ca_feats_in['1'].shape[-2]\n",
    "\n",
    "        out0_cat_shape = (B,self.ca_nodes,-1,1)\n",
    "        mp0_cat_shape  = (B,self.mp_nodes,-1,1)\n",
    "        out1_cat_shape = (B,self.ca_nodes,-1,3)\n",
    "        mp1_cat_shape  = (B,self.mp_nodes,-1,3)\n",
    "\n",
    "        nf_c = {} #nf_cat\n",
    "        nf_c['0'] = torch.cat((ca_feats_in['0'].reshape(out0_cat_shape), \n",
    "                                 mp_feats['0'].reshape(mp0_cat_shape)[:,-(self.mp_nodes-self.ca_nodes):,:,:]),\n",
    "                              axis=1).reshape((-1,nf0_c,1))\n",
    "\n",
    "        nf_c['1'] = torch.cat((ca_feats_in['1'].reshape(out1_cat_shape), \n",
    "                                 mp_feats['1'].reshape(mp1_cat_shape)[:,-(self.mp_nodes-self.ca_nodes):,:,:]),\n",
    "                              axis=1).reshape((-1,nf1_c,3))\n",
    "\n",
    "        return nf_c\n",
    "        \n",
    "    def pull_out_mp_feats(self, ca_mp_feats):\n",
    "\n",
    "        nf0_c = ca_mp_feats['0'].shape[1]\n",
    "        nf1_c = ca_mp_feats['1'].shape[1]\n",
    "\n",
    "        nf_mp_ = {}\n",
    "        #select just mp nodes to move on, the other nodes don't connect but mainting self connections\n",
    "        nf_mp_['0'] = ca_mp_feats['0'].reshape(B,self.mp_nodes,\n",
    "                                               nf0_c,1)[:,-(self.mp_nodes-self.ca_nodes):,...].reshape((-1,nf0_c,1))\n",
    "        nf_mp_['1'] = ca_mp_feats['1'].reshape(B,self.mp_nodes,\n",
    "                                               nf1_c,3)[:,-(self.mp_nodes-self.ca_nodes):,...].reshape((-1,nf1_c,3))\n",
    "\n",
    "        return nf_mp_\n",
    "    \n",
    "    def concat_t(self, feats_in, t_vec):\n",
    "        \"\"\"Concatenate T to first position of each tensor. Pad Zeros left for degree 1.\"\"\"\n",
    "        feats_out = {}\n",
    "        key = next(iter(feats_in.keys()))\n",
    "        shape_tuple = (self.B,-1)+feats_in[key].shape[1:]\n",
    "        batch_shape = feats_in[key].reshape(shape_tuple).shape\n",
    "        L = batch_shape[1] #can be ca, ca+mp, mp, k nodes long\n",
    "\n",
    "        if '0' in feats_in.keys():\n",
    "            feats_out['0'] = torch.concat((t_vec[...,None,None,None].repeat(1,L,1,1), \n",
    "                                           feats_in['0'].reshape((self.B,L,-1,1))),\n",
    "                                          axis=2).reshape((self.B*L,-1,1))\n",
    "        if '1' in feats_in.keys():\n",
    "            pshape = t_vec[...,None,None,None].repeat(1,L,1,1)\n",
    "            p1d = (2,0)\n",
    "            out = torch.nn.functional.pad(pshape, p1d, \"constant\", 0)\n",
    "            feats_out['1'] = torch.concat((out, feats_in['1'].reshape((self.B,L,-1,3)))\n",
    "                                          , dim=2).reshape((self.B*L,-1,3))\n",
    "\n",
    "        return feats_out\n",
    "        \n",
    "    def forward(self, input_tuple, batched_t):\n",
    "\n",
    "        b_graph, nf, ef, b_graph_mp, nf_mp, ef_mp, b_graph_mps, nf_mps, ef_mps, b_graph_mpRev = input_tuple\n",
    "        #assumes equal node numbers in g raphs\n",
    "        self.ca_nodes = int(b_graph.batch_num_nodes()[0])\n",
    "        self.mp_nodes = int(b_graph_mp.batch_num_nodes()[0]) #ca+mp nodes number\n",
    "\n",
    "        #SE3 Attention Transformer, c_alpha \n",
    "        t_nf = self.concat_t(nf, batched_t) #concat_t on\n",
    "        nf_ca_down_out = self.down_ca(b_graph, t_nf, ef)\n",
    "\n",
    "        #concatenate on midpoints feats\n",
    "        \n",
    "        nf_down_cat_mp = self.concat_mp_feats(nf_ca_down_out, nf_mp)\n",
    "\n",
    "        #pool from ca onto selected midpoints via SE3 Attention transformer\n",
    "        #edges from ca to mp only (ca nodes zero after this)\n",
    "        t_nf_down_cat_mp = self.concat_t(nf_down_cat_mp, batched_t) #concat_t on\n",
    "        nf_down_ca2mp_out = self.down_ca2mp(b_graph_mp, t_nf_down_cat_mp, ef_mp)\n",
    "\n",
    "        #remove ca node feats from tensor \n",
    "        nf_mp_out = self.pull_out_mp_feats(nf_down_ca2mp_out)\n",
    "\n",
    "        t_nf_mp_out = self.concat_t(nf_mp_out, batched_t) #concat_t on\n",
    "        node_feats_tk, topk_feats, topk_indx = self.mp_topk(b_graph_mps, t_nf_mp_out, ef_mps)\n",
    "\n",
    "        #make new basis for small graph of k selected midpoints\n",
    "        edge_feats_out, basis_out, new_pos = prep_for_gcn(self.gsmall, b_graph_mps.ndata['pos'], self.ef_small,\n",
    "                                                          topk_indx,\n",
    "                                                          max_degree=self.max_degree, comp_grad=True)\n",
    "\n",
    "        down_gcn_out = self.down_gcn(topk_feats, edge_feats_out, self.gsmall,  basis_out)\n",
    "\n",
    "        down_gcnpool_out = self.down_gcn2pool(down_gcn_out, edge_feats_out, self.gsmall,  basis_out)\n",
    "\n",
    "        pooled_tensor = self.global_pool(down_gcnpool_out,self.gsmall)\n",
    "        pooled = {'0':pooled_tensor}\n",
    "        #----------------------------------------- end of down section\n",
    "        lat_unp = self.latent_unpool_layer(pooled,down_gcn_out)\n",
    "\n",
    "        up_gcn_out = self.up_gcn(lat_unp, edge_feats_out, self.gsmall,  basis_out)\n",
    "\n",
    "        k_to_mp  = self.unpool_layer(up_gcn_out,node_feats_tk,topk_indx)\n",
    "\n",
    "        up_mp_gcn_out = self.up_gcn_mp(b_graph_mps, k_to_mp, ef_mps)\n",
    "        \n",
    "        off_mp_add = {}\n",
    "        for k,v in up_mp_gcn_out.items():\n",
    "            off_mp_add[k] = torch.add(up_mp_gcn_out[k],nf_mp_out[k])\n",
    "\n",
    "\n",
    "        #####triple check from here\n",
    "        #midpoints node indices for unpool layer\n",
    "        mp_node_indx = torch.arange(self.ca_nodes,self.mp_nodes, device=self.device)\n",
    "        mp_idx = mp_node_indx[None,...].repeat_interleave(self.B,0)\n",
    "        mp_idx =((torch.arange(self.B,device=self.device)*(self.mp_nodes)).reshape((-1,1))+mp_idx).reshape((-1))\n",
    "        \n",
    "        #during unpool, keep mp=values and ca=zeros\n",
    "        zeros_mp_ca = {}\n",
    "        for k,v in nf_down_cat_mp.items():\n",
    "            zeros_mp_ca[k] = torch.zeros_like(v, device=self.device)\n",
    "\n",
    "\n",
    "        unpoff_out = self.unpool_layer_off_mp(off_mp_add, zeros_mp_ca, mp_idx)\n",
    "        \n",
    "        out_up_off_mp = self.up_off_mp(b_graph_mpRev, unpoff_out, ef_mp)\n",
    "        \n",
    "        #select just ca nodes, mp = zeros from last convolution\n",
    "        inv_mp_idx= torch.arange(0,self.ca_nodes, device=self.device)\n",
    "        inv_mp_idx = inv_mp_idx[None,...].repeat_interleave(self.B,0)\n",
    "        inv_mp_idx =((torch.arange(self.B,device=self.device)*(self.mp_nodes)).reshape((-1,1))\n",
    "                     +inv_mp_idx).reshape((-1))\n",
    "\n",
    "        node_final_ca = {}\n",
    "        for key in out_up_off_mp.keys():\n",
    "            node_final_ca[key] = torch.add(out_up_off_mp[key][inv_mp_idx,...],nf_ca_down_out[key])\n",
    "\n",
    "        #return updates \n",
    "        t_node_final_ca = self.concat_t(node_final_ca, batched_t) #concat_t on\n",
    "        \n",
    "        return self.linear(self.up_ca(b_graph, t_node_final_ca, ef))\n",
    "                \n",
    "        \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "a5a815da",
   "metadata": {},
   "outputs": [],
   "source": [
    "def model_step(backbone_dict, noised_dict, batched_t, scores_scales, graph_maker, graph_unet, train=True):\n",
    "    \n",
    "    CA_t  = backbone_dict['CA'].reshape(B, L, 3).to('cuda')\n",
    "    NC_t = CA_t + backbone_dict['N_CA'].reshape(B, L, 3).to('cuda')\n",
    "    CC_t = CA_t + backbone_dict['C_CA'].reshape(B, L, 3).to('cuda')\n",
    "    true =  torch.cat((NC_t,CA_t,CC_t),dim=2).reshape(B,L,3,3)\n",
    "    \n",
    "    CA_n  = noised_dict['CA'].reshape(B, L, 3).to('cuda')\n",
    "    NC_n = CA_n + noised_dict['N_CA'].reshape(B, L, 3).to('cuda')\n",
    "    CC_n = CA_n + noised_dict['C_CA'].reshape(B, L, 3).to('cuda')\n",
    "    noise_xyz =  torch.cat((NC_n,CA_n,CC_n),dim=2).reshape(B,L,3,3)\n",
    "    \n",
    "    x = graph_maker.prep_for_network(noised_dict)\n",
    "    out = graph_unet(x, batched_t)\n",
    "    CA_p = out['1'][:,0,:].reshape(B, L, 3)+CA_n #translation of Calpha\n",
    "    Qs = out['1'][:,1,:] # rotation\n",
    "    Qs = Qs.unsqueeze(1).repeat((1,2,1))\n",
    "    Qs = torch.cat((torch.ones((B*L,2,1),device=Qs.device),Qs),dim=-1).reshape(B,L,2,4)\n",
    "    Qs = normQ(Qs)\n",
    "    Rs = Qs2Rs(Qs)\n",
    "    N_C_to_Rot = torch.cat((noised_dict['N_CA'].reshape(B, L, 3).to('cuda'),\n",
    "                            noised_dict['C_CA'].reshape(B, L, 3).to('cuda')),dim=2).reshape(B,L,2,1,3)\n",
    "\n",
    "    \n",
    "    \n",
    "    rot_vecs = einsum('bnkij,bnkhj->bnki',Rs, N_C_to_Rot)\n",
    "    NC_p = CA_p + rot_vecs[:,:,0,:].to('cuda')*N_CA_dist\n",
    "    CC_p = CA_p + rot_vecs[:,:,1,:].reshape(B, L, 3).to('cuda')*C_CA_dist\n",
    "\n",
    "    pred = torch.cat((NC_p,CA_p,CC_p),dim=2).reshape(B,L,3,3)\n",
    "    \n",
    "    tloss, loss = FAPE_loss(pred.unsqueeze(0), true, scores_scales)\n",
    "    \n",
    "    return tloss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "02f23891",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_noise_pred_true(backbone_dict, noised_dict, batched_t, graph_maker, graph_unet):\n",
    "    \n",
    "    CA_t  = backbone_dict['CA'].reshape(B, L, 3).to('cuda')\n",
    "    NC_t = CA_t + backbone_dict['N_CA'].reshape(B, L, 3).to('cuda')*N_CA_dist\n",
    "    CC_t = CA_t + backbone_dict['C_CA'].reshape(B, L, 3).to('cuda')*C_CA_dist\n",
    "    true =  torch.cat((NC_t,CA_t,CC_t),dim=2).reshape(B,L,3,3)\n",
    "    \n",
    "    CA_n  = noised_dict['CA'].reshape(B, L, 3).to('cuda')\n",
    "    NC_n = CA_n + noised_dict['N_CA'].reshape(B, L, 3).to('cuda')*N_CA_dist\n",
    "    CC_n = CA_n + noised_dict['C_CA'].reshape(B, L, 3).to('cuda')*C_CA_dist\n",
    "    noise_xyz =  torch.cat((NC_n,CA_n,CC_n),dim=2).reshape(B,L,3,3)\n",
    "    \n",
    "    x = graph_maker.prep_for_network(noised_dict)\n",
    "    out = graph_unet(x, batched_t)\n",
    "    CA_p = out['1'][:,0,:].reshape(B, L, 3)+CA_n #translation of Calpha\n",
    "    Qs = out['1'][:,1,:] # rotation\n",
    "    Qs = Qs.unsqueeze(1).repeat((1,2,1))\n",
    "    Qs = torch.cat((torch.ones((B*L,2,1),device=Qs.device),Qs),dim=-1).reshape(B,L,2,4)\n",
    "    Qs = normQ(Qs)\n",
    "    Rs = Qs2Rs(Qs)\n",
    "    N_C_to_Rot = torch.cat((noised_dict['N_CA'].reshape(B, L, 3).to('cuda'),\n",
    "                            noised_dict['C_CA'].reshape(B, L, 3).to('cuda')),dim=2).reshape(B,L,2,1,3)\n",
    "    \n",
    "    \n",
    "    rot_vecs = einsum('bnkij,bnkhj->bnki',Rs, N_C_to_Rot)\n",
    "    NC_p = CA_p + rot_vecs[:,:,0,:].to('cuda')*N_CA_dist\n",
    "    CC_p = CA_p + rot_vecs[:,:,1,:].reshape(B, L, 3).to('cuda')*C_CA_dist\n",
    "\n",
    "    pred = torch.cat((NC_p,CA_p,CC_p),dim=2).reshape(B,L,3,3)\n",
    "    \n",
    "    return true.to('cpu').numpy()*10, noise_xyz.to('cpu').numpy()*10, pred.detach().to('cpu').numpy()*10\n",
    "\n",
    "def dump_tnp(true, noise, pred, t_val, e=0, numOut=1,outdir='output/'):\n",
    "    \n",
    "    if numOut>true.shape[0]:\n",
    "        numOut = true.shape[0]\n",
    "    \n",
    "    for x in range(numOut):\n",
    "        dump_coord_pdb(true[x], fileOut=f'{outdir}/true_{t_val[x]*100:.0f}_e{e}_{x}.pdb')\n",
    "        dump_coord_pdb(noise[x], fileOut=f'{outdir}/noise_{t_val[x]*100:.0f}_e{e}_{x}.pdb')\n",
    "        dump_coord_pdb(pred[x], fileOut=f'{outdir}/pred_{t_val[x]*100:.0f}_e{e}_{x}.pdb')\n",
    "        \n",
    "def visualize_model(bb_dict, noised_bb, batched_t, epoch, numOut=1, outdir='output/'):\n",
    "    true, noise, pred = get_noise_pred_true(bb_dict, noised_bb, batched_t, gm, gu)\n",
    "    dump_tnp(true,noise,pred, batched_t, e=epoch, numOut=numOut, outdir=f'{outdir}/models/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "5d28184c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_save_folder(name=''):\n",
    "    base_folder = time.strftime(f'log/%y%b%d_%I%M%p_{name}/', time.localtime())\n",
    "    if not os.path.exists(base_folder):\n",
    "        os.makedirs(base_folder)\n",
    "    subfolders = ['models']\n",
    "    for subfolder in subfolders:\n",
    "        if not os.path.exists(base_folder + subfolder):\n",
    "            os.makedirs(base_folder + subfolder)\n",
    "            \n",
    "    return base_folder\n",
    "        \n",
    "def save_chkpt(model_path, model, optimizer, epoch, batch, val_losses, train_losses):\n",
    "    \"\"\"Save a training checkpoint\n",
    "    Args:\n",
    "        model_path (str): the path to save the model to\n",
    "        model (nn.Module): the model to save\n",
    "        optimizer (torch.optim.Optimizer): the optimizer to save\n",
    "        epoch (int): the current epoch\n",
    "        batch (int): the current batch in the epoch\n",
    "        loss_domain (list of int): a list of the shared domain for val and training \n",
    "            losses\n",
    "        val_losses (list of float): a list containing the validation losses\n",
    "        train_losses (list of float): a list containing the training losses\n",
    "    \"\"\"\n",
    "    os.makedirs(os.path.dirname(model_path), exist_ok=True)\n",
    "    state_dict = dict()\n",
    "    state_dict.update({'model':model.state_dict(),\n",
    "                       'optimizer':optimizer.state_dict(),\n",
    "                       'epoch':epoch,\n",
    "                       'batch':batch,\n",
    "                       'train_losses':train_losses,\n",
    "                       'val_losses':val_losses\n",
    "                       })\n",
    "    torch.save(state_dict, f'{model_path}model_e{epoch}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 333,
   "id": "149c44dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "B = 8\n",
    "L=65\n",
    "limit = 5048\n",
    "h4_trainData = Helix4_Dataset(coords_tog[:limit])\n",
    "h4_valData = Helix4_Dataset(coords_apa[:limit])\n",
    "train_dL = DataLoader(h4_trainData, batch_size=B, shuffle=True, drop_last=True)\n",
    "val_dL   = DataLoader(h4_valData, batch_size=B, shuffle=True, drop_last=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 334,
   "id": "58ac8828",
   "metadata": {},
   "outputs": [],
   "source": [
    "gu = GraphUNet(batch_size = B, num_layers_ca = 2).to('cuda')\n",
    "opti = torch.optim.Adam(gu.parameters(), lr=0.00005, weight_decay=5e-6)\n",
    "gm = Make_KNN_MP_Graphs() #consider precalculating graphs for training\n",
    "fdn= FrameDiffNoise()\n",
    "#visualize_T\n",
    "vis_t = np.array([0.01,0.05,0.1,0.2,0.3,0.5,0.8,1.0])\n",
    "vis_t = vis_t[None,...].repeat(int(np.ceil(B/len(vis_t))),axis=0).flatten()[:B]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 335,
   "id": "08c51bbd",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_path = 'log/23Aug27_0137AM_full_diff_noR3_ss/'\n",
    "model_name='model_e279'\n",
    "gu = GraphUNet(batch_size = B, num_layers_ca = 2)\n",
    "gu.load_state_dict(torch.load(f'{model_path}/{model_name}')['model'])\n",
    "#opti.load_state_dict(torch.load(f'{model_path}/{model_name}')['optimizer'])\n",
    "gu = gu.to('cuda')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 336,
   "id": "3102b8f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_iter = iter(train_dL)\n",
    "test_batch = next(test_iter)\n",
    "\n",
    "t=0.05\n",
    "dt = 0.05\n",
    "t_vec = np.ones((B,))*t\n",
    "nd, tv, ss = fdn(test_batch, t_vec=t_vec, useR3=False)\n",
    "\n",
    "tv = tv.to('cuda')\n",
    "# train_loss = model_step(bb_dict, noised_bb, tv, gm, gu)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 337,
   "id": "0eeadec0",
   "metadata": {},
   "outputs": [],
   "source": [
    "visualize_model(test_batch, nd, tv, 'test', numOut=3, outdir='output/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 338,
   "id": "f49fda6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "x = gm.prep_for_network(nd)\n",
    "out = gu(x, tv.to('cuda'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 339,
   "id": "17f7aff2",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "\n",
    "tstep_r3, tstep_rot, t_vec = get_step_size(0.05,start=0.05,end=0)\n",
    "#tstep_r3, tstep_rot, t_vec = get_step_size(0.01,start=0.05,end=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 340,
   "id": "57146755",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i,t in enumerate(t_vec):\n",
    "    \n",
    "    CA_n  = nd['CA'].reshape(B, L, 3).to('cuda')\n",
    "    NC_n = CA_n + nd['N_CA'].reshape(B, L, 3).to('cuda')\n",
    "    CC_n = CA_n + nd['C_CA'].reshape(B, L, 3).to('cuda')\n",
    "    noise_xyz =  torch.cat((NC_n,CA_n,CC_n),dim=2).reshape(B,L,3,3)\n",
    "    \n",
    "    \n",
    "    tv = t.repeat(B)\n",
    "    x = gm.prep_for_network(nd)\n",
    "    with torch.no_grad():\n",
    "        out = gu(x, tv.to('cuda'))\n",
    "    \n",
    "    \n",
    "    update = out['1'][:,0,:].reshape(B, L, 3)*tstep_r3[i]\n",
    "    \n",
    "    CA_p = out['1'][:,0,:].reshape(B, L, 3)*tstep_r3[i]+CA_n #translation of Calpha\n",
    "    \n",
    "    Qs = out['1'][:,1,:] # rotation\n",
    "    Qs = Qs.unsqueeze(1).repeat((1,2,1))\n",
    "    Qs = torch.cat((torch.ones((B*L,2,1),device=Qs.device),Qs),dim=-1).reshape(B,L,2,4)\n",
    "    Qs = normQ(Qs)\n",
    "    Rs = Qs2Rs(Qs)\n",
    "    N_C_to_Rot = torch.cat((nd['N_CA'].reshape(B, L, 3).to('cuda'),\n",
    "                            nd['C_CA'].reshape(B, L, 3).to('cuda')),dim=2).reshape(B,L,2,1,3)\n",
    "    \n",
    "    \n",
    "    rot_vecs = einsum('bnkij,bnkhj->bnki',Rs, N_C_to_Rot)\n",
    "    NC_p = CA_p + rot_vecs[:,:,0,:].to('cuda')*N_CA_dist\n",
    "    CC_p = CA_p + rot_vecs[:,:,1,:].reshape(B, L, 3).to('cuda')*C_CA_dist\n",
    "    \n",
    "    nd={}\n",
    "    nd['CA'] = CA_p\n",
    "    nd['N_CA'] = NC_p\n",
    "    nd['C_CA'] = CC_p\n",
    "    \n",
    "    pred = torch.cat((NC_p,CA_p,CC_p),dim=2).reshape(B,L,3,3)\n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "dump_coord_pdb(pred[0].cpu()*10, fileOut='output/test.pdb')    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 288,
   "id": "a5f65657",
   "metadata": {},
   "outputs": [],
   "source": [
    "t=0.05\n",
    "t_vec = np.ones((B,))*t\n",
    "\n",
    "x = gm.prep_for_network(nd)\n",
    "out = gu(x, tv.to('cuda'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 289,
   "id": "85507a38",
   "metadata": {},
   "outputs": [],
   "source": [
    "    \n",
    "update = out['1'][:,0,:].reshape(B, L, 3)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4a25edf",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e3cf95b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 202,
   "id": "e42ddf59",
   "metadata": {},
   "outputs": [],
   "source": [
    "dump_coord_pdb(pred[0], fileOut='output/test.pdb')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 304,
   "id": "0a258a34",
   "metadata": {},
   "outputs": [],
   "source": [
    "import scipy\n",
    "import matplotlib.pyplot as plt\n",
    "def var_R3(t):\n",
    "    return np.sqrt(1 - np.exp(-fdn.r3d.marginal_b_t(t)))\n",
    "\n",
    "def var_Rot(t):\n",
    "    return fdn.so3d.sigma(t)\n",
    "\n",
    "\n",
    "def tstep_integral(fun_in, t, dt):\n",
    "    \n",
    "    int1, error1 = scipy.integrate.quad(fun_in,0,t)\n",
    "    int2, error2 = scipy.integrate.quad(fun_in,0,t-dt)\n",
    "    \n",
    "    step_size = (int1-int2)/int1\n",
    "    \n",
    "    return step_size\n",
    "\n",
    "def get_step_size(dt,start=1,end=0, cast=torch.float32):\n",
    "    tstep_r3 = [tstep_integral(var_R3,np.round(t1,decimals=6),dt) for t1 in np.arange(start,end,-dt) ]\n",
    "    tstep_rot = [tstep_integral(var_Rot,np.round(t1,decimals=6),dt) for t1 in np.arange(start,end,-dt) ]\n",
    "    t_vec = np.arange(start,end,-dt)\n",
    "    return torch.tensor(tstep_r3,dtype=cast), torch.tensor(tstep_rot,dtype=cast), torch.tensor(t_vec,dtype=cast)\n",
    "    \n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 274,
   "id": "dd0ab83d",
   "metadata": {},
   "outputs": [],
   "source": [
    "tstep_r3, tstep_rot, t_vec = get_step_size(0.05)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b637061d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce2c9ff4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a61f5a0e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ef08980",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2ce458c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78b15462",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#t=0.1\n",
    "#t_vec = np.ones((B,))*t\n",
    "#print(t_vec)\n",
    "# model_path = make_save_folder(name=f'full_diff_noR3_ss')\n",
    "num_epochs = 200\n",
    "e_start= 280\n",
    "save_per=10\n",
    "avg_vloss=0\n",
    "\n",
    "for e in range(e_start, e_start+num_epochs):\n",
    "    \n",
    "    running_tloss = 0 \n",
    "    start = time.time()\n",
    "    for i, bb_dict in enumerate(train_dL):\n",
    "        noised_bb, tv, ss = fdn(bb_dict,t_vec=None, useR3=False)\n",
    "        tv = tv.to('cuda')\n",
    "        ss = ss.to('cuda')\n",
    "        train_loss = model_step(bb_dict, noised_bb, tv, ss, gm, gu)\n",
    "        opti.zero_grad()\n",
    "        train_loss.backward()\n",
    "        opti.step()\n",
    "\n",
    "        running_tloss += train_loss.detach().cpu()\n",
    "    \n",
    "    end = time.time()\n",
    "    avg_tloss = running_tloss/(i+1)\n",
    "    print(f'Average Train Loss Epoch {e}: {avg_tloss};   Epoch time: {end-start:.0f}')\n",
    "\n",
    "    if e %save_per==save_per-1:\n",
    "        with torch.no_grad():\n",
    "            running_vloss = 0\n",
    "            for i, bb_dictv in enumerate(val_dL):\n",
    "                noised_bb, tv, ss = fdn(bb_dictv,t_vec=None, useR3=False)\n",
    "                tv = tv.to('cuda')\n",
    "                ss = ss.to('cuda')\n",
    "                valid_loss = model_step(bb_dictv, noised_bb, tv, ss, gm, gu)\n",
    "                running_vloss += valid_loss\n",
    "                \n",
    "        avg_vloss = running_vloss/(i+1)\n",
    "        print(f'Average Valid Loss Epoch {e}: {avg_vloss}')\n",
    "                \n",
    "        noised_bb, tv, ss = fdn(bb_dict, t_vec=vis_t)\n",
    "        tv = tv.to('cuda')\n",
    "        visualize_model(bb_dict, noised_bb, tv, e, numOut=8,outdir=model_path)\n",
    "        save_chkpt(model_path, gu, opti, e, B, avg_vloss, avg_tloss)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc618c49",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4cf435f6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e6ddcfc",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df7462d2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "cd433a11",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_iter = iter(train_dL)\n",
    "test_batch = next(test_iter)\n",
    "\n",
    "t=0.05\n",
    "t_vec = np.ones((B,))*t\n",
    "nd, tv, ss = fdn(test_batch, t_vec=None, useR3=False)\n",
    "\n",
    "tv = tv.to('cuda')\n",
    "# train_loss = model_step(bb_dict, noised_bb, tv, gm, gu)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "4c7bbc63",
   "metadata": {},
   "outputs": [],
   "source": [
    "visualize_model(test_batch, nd, tv, 1000, numOut=8,outdir=model_path)\n",
    "save_chkpt(model_path, gu, opti, 1000, B, 0, 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f356ac2a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21564364",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ebd3b480",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "c6818ec8",
   "metadata": {},
   "outputs": [],
   "source": [
    "x = gm.prep_for_network(nd)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "ea7b5d5b",
   "metadata": {},
   "outputs": [],
   "source": [
    "out = gu(x,tv)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "f5357d6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "CA_p = out['1'][:,0,:].reshape(B, L, 3)+0 #translation of Calpha\n",
    "Qs = out['1'][:,1,:] # rotation\n",
    "Qs = Qs.unsqueeze(1).repeat((1,2,1))\n",
    "Qs = torch.cat((torch.ones((B*L,2,1),device=Qs.device),Qs),dim=-1).reshape(B,L,2,4)\n",
    "Qs = normQ(Qs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "51c13fe3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([32, 65, 2, 4])"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Qs.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "baef3d23",
   "metadata": {},
   "outputs": [],
   "source": [
    "tq = Qs[:2,:3,0,:]\n",
    "eps = 1e-6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 227,
   "id": "f22b730e",
   "metadata": {},
   "outputs": [],
   "source": [
    "Q = torch.tensor([0,0,1,0],dtype=torch.float)[None,None,None,...].repeat(2,3,2,1)\n",
    "rv = torch.tensor([[0,0,1]],dtype=torch.float)[None,None,...].repeat(2,3,2,1)\n",
    "Q = normQ(Q)\n",
    "\n",
    "qp = powerQ(Q,0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da6add3c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 228,
   "id": "c3a9fa55",
   "metadata": {},
   "outputs": [],
   "source": [
    "Rs = Qs2Rs(qp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 205,
   "id": "d959767d",
   "metadata": {},
   "outputs": [],
   "source": [
    "Rs = Qs2Rs(Q)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 229,
   "id": "4cb9055a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([2, 3, 2, 1, 3])"
      ]
     },
     "execution_count": 229,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rv = rv.reshape((2,3,2,1,3))\n",
    "rv.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 230,
   "id": "88567358",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([2, 3, 2, 3, 3])"
      ]
     },
     "execution_count": 230,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Rs.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 231,
   "id": "5fdd9c79",
   "metadata": {},
   "outputs": [],
   "source": [
    "rot_vecs = einsum('bnkij,bnkhj->bnki',Rs, rv)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 232,
   "id": "486edbf0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[[1.0000, 0.0000, 0.0000],\n",
       "          [1.0000, 0.0000, 0.0000]],\n",
       "\n",
       "         [[1.0000, 0.0000, 0.0000],\n",
       "          [1.0000, 0.0000, 0.0000]],\n",
       "\n",
       "         [[1.0000, 0.0000, 0.0000],\n",
       "          [1.0000, 0.0000, 0.0000]]],\n",
       "\n",
       "\n",
       "        [[[1.0000, 0.0000, 0.0000],\n",
       "          [1.0000, 0.0000, 0.0000]],\n",
       "\n",
       "         [[1.0000, 0.0000, 0.0000],\n",
       "          [1.0000, 0.0000, 0.0000]],\n",
       "\n",
       "         [[1.0000, 0.0000, 0.0000],\n",
       "          [1.0000, 0.0000, 0.0000]]]])"
      ]
     },
     "execution_count": 232,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rot_vecs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 233,
   "id": "4e13aa5f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#From\n",
    "#https://math.stackexchange.com/questions/939229/unit-quaternion-to-a-scalar-power\n",
    "\n",
    "#test code\n",
    "# Q = torch.tensor([0,0,1,0],dtype=torch.float)[None,None,None,...].repeat(2,3,2,1) #180 rotation about Y axis\n",
    "# rv = torch.tensor([[0,0,1]],dtype=torch.float)[None,None,...].repeat(2,3,2,1) #unit Z\n",
    "# Q = normQ(Q)\n",
    "#qp = powerQ(Q,0.5) rotate halfway (aka x-axis)\n",
    "#rv = rv.reshape((2,3,2,1,3))\n",
    "#rot_vecs = einsum('bnkij,bnkhj->bnki',Rs, rv) #should be x-axis\n",
    "\n",
    "def powerQ(quat_in, power):\n",
    "    \"\"\"Quaternion to the power, represent number of times to rotate Q. Only works on unit Q\"\"\"\n",
    "    return expQ(scaleQ(lnQ(quat_in),power))\n",
    "\n",
    "\n",
    "def expQ(quat_in, eps=1e-9):\n",
    "    quat_out = torch.zeros_like(quat_in, device=quat_in.device)\n",
    "    r = torch.sqrt(torch.sum(torch.square(quat_in[...,1:]),axis=-1,keepdim=True)+eps)\n",
    "    et = torch.exp(quat_in[...,0][...,None])\n",
    "    s = et*torch.sin(r)/r\n",
    "    s[torch.where(r<eps)[0]] = 0\n",
    "    \n",
    "    quat_out[...,0][...,None] = et*torch.cos(r)\n",
    "    quat_out[...,1] = s[...,0]*quat_in[...,1]\n",
    "    quat_out[...,2] = s[...,0]*quat_in[...,2]\n",
    "    quat_out[...,3] = s[...,0]*quat_in[...,3]\n",
    "    \n",
    "    return quat_out\n",
    "\n",
    "\n",
    "def lnQ(quat_in, eps=1e-9):\n",
    "    quat_out = torch.zeros_like(quat_in, device=quat_in.device)\n",
    "    r = torch.sqrt(torch.sum(torch.square(quat_in[...,1:]),axis=-1,keepdim=True)+eps)\n",
    "    t = torch.atan2(r,quat_in[...,0][...,None])/r\n",
    "    t[torch.where(r<eps)[0]] = 0\n",
    "        \n",
    "    quat_out[...,0][...,None] = 0.5*torch.log(torch.sum(torch.square(quat_in[...,1:]),axis=-1,keepdim=True)+eps)\n",
    "    quat_out[...,1] = t[...,0]*quat_in[...,1]\n",
    "    quat_out[...,2] = t[...,0]*quat_in[...,2]\n",
    "    quat_out[...,3] = t[...,0]*quat_in[...,3]\n",
    "    \n",
    "    return quat_out\n",
    "    \n",
    "\n",
    "def scaleQ(quat_in, scale):\n",
    "    return torch.multiply(quat_in,scale)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26b7b65e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1db68d9c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fbc0c239",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "652bd82b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def model_step(backbone_dict, noised_dict, batched_t, scores_scales, graph_maker, graph_unet, train=True):\n",
    "    \n",
    "    CA_t  = backbone_dict['CA'].reshape(B, L, 3).to('cuda')\n",
    "    NC_t = CA_t + backbone_dict['N_CA'].reshape(B, L, 3).to('cuda')\n",
    "    CC_t = CA_t + backbone_dict['C_CA'].reshape(B, L, 3).to('cuda')\n",
    "    true =  torch.cat((NC_t,CA_t,CC_t),dim=2).reshape(B,L,3,3)\n",
    "    \n",
    "    CA_n  = noised_dict['CA'].reshape(B, L, 3).to('cuda')\n",
    "    NC_n = CA_n + noised_dict['N_CA'].reshape(B, L, 3).to('cuda')\n",
    "    CC_n = CA_n + noised_dict['C_CA'].reshape(B, L, 3).to('cuda')\n",
    "    noise_xyz =  torch.cat((NC_n,CA_n,CC_n),dim=2).reshape(B,L,3,3)\n",
    "    \n",
    "    x = graph_maker.prep_for_network(noised_dict)\n",
    "    out = graph_unet(x, batched_t)\n",
    "    CA_p = out['1'][:,0,:].reshape(B, L, 3)+CA_n #translation of Calpha\n",
    "    Qs = out['1'][:,1,:] # rotation\n",
    "    Qs = Qs.unsqueeze(1).repeat((1,2,1))\n",
    "    Qs = torch.cat((torch.ones((B*L,2,1),device=Qs.device),Qs),dim=-1).reshape(B,L,2,4)\n",
    "    Qs = normQ(Qs)\n",
    "    Rs = Qs2Rs(Qs)\n",
    "    N_C_to_Rot = torch.cat((noised_dict['N_CA'].reshape(B, L, 3).to('cuda'),\n",
    "                            noised_dict['C_CA'].reshape(B, L, 3).to('cuda')),dim=2).reshape(B,L,2,1,3)\n",
    "\n",
    "    \n",
    "    \n",
    "    rot_vecs = einsum('bnkij,bnkhj->bnki',Rs, N_C_to_Rot)\n",
    "    NC_p = CA_p + rot_vecs[:,:,0,:].to('cuda')*N_CA_dist\n",
    "    CC_p = CA_p + rot_vecs[:,:,1,:].reshape(B, L, 3).to('cuda')*C_CA_dist\n",
    "\n",
    "    pred = torch.cat((NC_p,CA_p,CC_p),dim=2).reshape(B,L,3,3)\n",
    "    \n",
    "    tloss, loss = FAPE_loss(pred.unsqueeze(0), true, scores_scales)\n",
    "    \n",
    "    return tloss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "55e49b75",
   "metadata": {},
   "outputs": [],
   "source": [
    "def noise_test(backbone_dict, noised_dict):\n",
    "    CA_t  = bb_dict['CA'].reshape(B, L, 3).to('cuda')\n",
    "    NC_t = CA_t + bb_dict['N_CA'].reshape(B, L, 3).to('cuda')*N_CA_dist\n",
    "    CC_t = CA_t + bb_dict['C_CA'].reshape(B, L, 3).to('cuda')*C_CA_dist\n",
    "    true =  torch.cat((NC_t,CA_t,CC_t),dim=2).reshape(B,L,3,3)\n",
    "    \n",
    "    CA_n  = noised_dict['CA'].reshape(B, L, 3).to('cuda')\n",
    "    NC_n = CA_n + noised_dict['N_CA'].reshape(B, L, 3).to('cuda')*N_CA_dist\n",
    "    CC_n = CA_n + noised_dict['C_CA'].reshape(B, L, 3).to('cuda')*C_CA_dist\n",
    "    noise_xyz =  torch.cat((NC_n,CA_n,CC_n),dim=2).reshape(B,L,3,3)\n",
    "    return true.to('cpu').numpy()*10, noise_xyz.to('cpu').numpy()*10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "00d45bb6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from util.npose_util import makePointPDB\n",
    "#gds = Graph_RadiusMP_4H_Dataset(coords_tog[:100], 10, mp_stride = 3)\n",
    "def view_mp_graph(mps: DGLGraph, coords: np.array ):\n",
    "    p = mps.ndata['pos']*10\n",
    "    \n",
    "    to = np.concatenate((coords, np.ones_like(coords)[:,:,0][...,None]),axis=2)\n",
    "    \n",
    "    makePointPDB(p,'test.pdb',outDirec='output')\n",
    "    nu.dump_npdb(to,'output/test2.pdb')\n",
    "#view_mp_graph(gds.mpSelfGraphList[0], coords_tog[0])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "se33",
   "language": "python",
   "name": "se33"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
