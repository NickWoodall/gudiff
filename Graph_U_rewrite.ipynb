{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a02a1c0f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "import util.npose_util as nu\n",
    "import os\n",
    "import pathlib\n",
    "import dgl\n",
    "from dgl import backend as F\n",
    "import torch_geometric\n",
    "from torch.utils.data import random_split, DataLoader, Dataset\n",
    "from typing import Dict\n",
    "from torch import Tensor\n",
    "from dgl import DGLGraph\n",
    "from torch import nn\n",
    "from chemical import cos_ideal_NCAC #from RoseTTAFold2\n",
    "from torch import einsum\n",
    "torch.cuda.is_available()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6a31f547",
   "metadata": {},
   "outputs": [],
   "source": [
    "from data_rigid_diffuser import so3_diffuser\n",
    "from data_rigid_diffuser import r3_diffuser\n",
    "from scipy.spatial.transform import Rotation\n",
    "from data_rigid_diffuser import rigid_utils as ru\n",
    "import yaml"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "bf443f63",
   "metadata": {},
   "outputs": [],
   "source": [
    "from se3_transformer.model.basis import get_basis, update_basis_with_fused\n",
    "from se3_transformer.model.transformer import Sequential, SE3Transformer\n",
    "from se3_transformer.model.transformer_topk import SE3Transformer_topK\n",
    "from se3_transformer.model.layers.attentiontopK import AttentionBlockSE3\n",
    "from se3_transformer.model.layers.linear import LinearSE3\n",
    "from se3_transformer.model.layers.convolution import ConvSE3, ConvSE3FuseLevel\n",
    "from se3_transformer.model.layers.norm import NormSE3\n",
    "from se3_transformer.model.layers.pooling import GPooling\n",
    "from se3_transformer.runtime.utils import str2bool, to_cuda\n",
    "from se3_transformer.model.fiber import Fiber\n",
    "from se3_transformer.model.transformer import get_populated_edge_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "2511634d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#npose indexing\n",
    "# Useful numbers\n",
    "# N [-1.45837285,  0 , 0]\n",
    "# CA [0., 0., 0.]\n",
    "# C [0.55221403, 1.41890368, 0.        ]\n",
    "# CB [ 0.52892494, -0.77445692, -1.19923854]\n",
    "\n",
    "N_CA_dist = torch.tensor(1.458/10.0).to('cuda')\n",
    "C_CA_dist = torch.tensor(1.523/10.0).to('cuda')\n",
    "\n",
    "if ( hasattr(os, 'ATOM_NAMES') ):\n",
    "    assert( hasattr(os, 'PDB_ORDER') )\n",
    "\n",
    "    ATOM_NAMES = os.ATOM_NAMES\n",
    "    PDB_ORDER = os.PDB_ORDER\n",
    "else:\n",
    "    ATOM_NAMES=['N', 'CA', 'CB', 'C', 'O']\n",
    "    PDB_ORDER = ['N', 'CA', 'C', 'O', 'CB']\n",
    "\n",
    "_byte_atom_names = []\n",
    "_atom_names = []\n",
    "for i, atom_name in enumerate(ATOM_NAMES):\n",
    "    long_name = \" \" + atom_name + \"       \"\n",
    "    _atom_names.append(long_name[:4])\n",
    "    _byte_atom_names.append(atom_name.encode())\n",
    "\n",
    "    globals()[atom_name] = i\n",
    "\n",
    "R = len(ATOM_NAMES)\n",
    "\n",
    "if ( \"N\" not in globals() ):\n",
    "    N = -1\n",
    "if ( \"C\" not in globals() ):\n",
    "    C = -1\n",
    "if ( \"CB\" not in globals() ):\n",
    "    CB = -1\n",
    "\n",
    "\n",
    "_pdb_order = []\n",
    "for name in PDB_ORDER:\n",
    "    _pdb_order.append( ATOM_NAMES.index(name) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e213e885",
   "metadata": {},
   "outputs": [],
   "source": [
    "# data_path_str  = 'data/h4_ca_coords.npz'\n",
    "# test_limit = 1028\n",
    "# rr = np.load(data_path_str)\n",
    "# ca_coords = [rr[f] for f in rr.files][0][:test_limit,:,:3]\n",
    "# ca_coords.shape\n",
    "\n",
    "# getting N-Ca, Ca-C vectors to add as typeI features\n",
    "#apa = apart helices for test/train split\n",
    "#tog = together helices for test/train split\n",
    "apa_path_str  = 'data_npose/h4_apa_coords.npz'\n",
    "tog_path_str  = 'data_npose/h4_tog_coords.npz'\n",
    "\n",
    "#grab the first 3 atoms which are N,CA,C\n",
    "test_limit = 1028\n",
    "rr = np.load(apa_path_str)\n",
    "coords_apa = [rr[f] for f in rr.files][0][:test_limit,:]\n",
    "\n",
    "rr = np.load(tog_path_str)\n",
    "coords_tog = [rr[f] for f in rr.files][0][:test_limit,:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d4c2ed33",
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_npose_from_coords(coords_in):\n",
    "    \"\"\"Use N, CA, C coordinates to generate O an CB atoms\"\"\"\n",
    "    rot_mat_cat = np.ones(sum((coords_in.shape[:-1], (1,)), ()))\n",
    "    \n",
    "    coords = np.concatenate((coords_in,rot_mat_cat),axis=-1)\n",
    "    \n",
    "    npose = np.ones((coords_in.shape[0]*5,4)) #5 is atoms per res\n",
    "\n",
    "    by_res = npose.reshape(-1, 5, 4)\n",
    "    \n",
    "    if ( \"N\" in ATOM_NAMES ):\n",
    "        by_res[:,N,:3] = coords_in[:,0,:3]\n",
    "    if ( \"CA\" in ATOM_NAMES ):\n",
    "        by_res[:,CA,:3] = coords_in[:,1,:3]\n",
    "    if ( \"C\" in ATOM_NAMES ):\n",
    "        by_res[:,C,:3] = coords_in[:,2,:3]\n",
    "    if ( \"O\" in ATOM_NAMES ):\n",
    "        by_res[:,O,:3] = nu.build_O(npose)\n",
    "    if ( \"CB\" in ATOM_NAMES ):\n",
    "        tpose = nu.tpose_from_npose(npose)\n",
    "        by_res[:,CB,:] = nu.build_CB(tpose)\n",
    "\n",
    "    return npose\n",
    "\n",
    "def dump_coord_pdb(coords_in, fileOut='fileOut.pdb'):\n",
    "    \n",
    "    npose =  build_npose_from_coords(coords_in)\n",
    "    nu.dump_npdb(npose,fileOut)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "508327fa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([0., 1., 0., 1., 0., 1., 0., 1., 0., 1., 0., 1.])\n",
      "tensor([0.6000, 0.8000, 0.4000, 0.9000, 0.3000, 1.0000, 0.2000, 1.0000, 0.1000,\n",
      "        1.0000, 0.1000, 1.0000])\n",
      "tensor([1.0000, 0.2000, 0.8000, 0.6000, 0.6000, 0.8000, 0.4000, 0.9000, 0.3000,\n",
      "        1.0000, 0.2000, 1.0000])\n",
      "tensor([ 0.9000, -0.5000,  1.0000,  0.2000,  0.8000,  0.6000,  0.6000,  0.8000,\n",
      "         0.4000,  0.9000,  0.3000,  1.0000])\n",
      "tensor([ 0.4000, -0.9000,  1.0000, -0.3000,  1.0000,  0.3000,  0.8000,  0.7000,\n",
      "         0.6000,  0.8000,  0.4000,  0.9000])\n"
     ]
    }
   ],
   "source": [
    "#goal define edges of\n",
    "#connected backbone 1, \n",
    "#unconnected atoms 0,\n",
    "\n",
    "\n",
    "def get_midpoint(ep_in):\n",
    "    \"\"\"Get midpoint, of each batched set of points\"\"\"\n",
    "    \n",
    "    #calculate midpoint\n",
    "    midpoint = ep_in.sum(axis=1)/np.repeat(ep_in.shape[1], ep_in.shape[2])\n",
    "    \n",
    "    return midpoint\n",
    "\n",
    "\n",
    "def normalize_points(input_xyz, print_dist=False):\n",
    "    \n",
    "    #broadcast to distance matrix [Batch, M, R3] to [Batch,M,1, R3] to [Batch,1,M, R3] to [Batch, M,M, R3] \n",
    "    vec_diff = input_xyz[...,None,:]-input_xyz[...,None,:,:]\n",
    "    dist = np.sqrt(np.sum(np.square(vec_diff),axis=len(input_xyz.shape)))\n",
    "    furthest_dist = np.max(dist)\n",
    "    centroid  = get_midpoint(input_xyz)\n",
    "    if print_dist:\n",
    "        print(f'largest distance {furthest_dist:0.1f}')\n",
    "    \n",
    "    xyz_mean_zero = input_xyz - centroid[:,None,:]\n",
    "    return xyz_mean_zero/furthest_dist\n",
    "\n",
    "def define_graph_edges(n_nodes):\n",
    "    #connected backbone\n",
    "\n",
    "    con_v1 = np.arange(n_nodes-1) #vertex 1 of edges in chronological order\n",
    "    con_v2 = np.arange(1,n_nodes) #vertex 2 of edges in chronological order\n",
    "\n",
    "    ind = con_v1*(n_nodes-1)+con_v2-1 #account for removed self connections (-1)\n",
    "\n",
    "\n",
    "    #unconnected backbone\n",
    "\n",
    "    nodes = np.arange(n_nodes)\n",
    "    v1 = np.repeat(nodes,n_nodes-1) #starting vertices, same number repeated for each edge\n",
    "\n",
    "    start_v2 = np.repeat(np.arange(n_nodes)[None,:],n_nodes,axis=0)\n",
    "    diag_ind = np.diag_indices(n_nodes)\n",
    "    start_v2[diag_ind] = -1 #diagonal of matrix is self connections which we remove (self connections are managed by SE3 Conv channels)\n",
    "    v2 = start_v2[start_v2>-0.5] #remove diagonal and flatten\n",
    "\n",
    "    edge_data = torch.zeros(len(v2))\n",
    "    edge_data[ind] = 1\n",
    "    \n",
    "    return v1,v2,edge_data, ind\n",
    "\n",
    "\n",
    "\n",
    "def make_pe_encoding(n_nodes=65, embed_dim = 12, scale = 1000, cast_type=torch.float32, print_out=False):\n",
    "    #positional encoding of node\n",
    "    i_array = np.arange(1,(embed_dim/2)+1)\n",
    "    wk = (1/(scale**(i_array*2/embed_dim)))\n",
    "    t_array = np.arange(n_nodes)\n",
    "    si = torch.tensor(np.sin(wk*t_array.reshape((-1,1))))\n",
    "    ci = torch.tensor(np.cos(wk*t_array.reshape((-1,1))))\n",
    "    pe = torch.stack((si,ci),axis=2).reshape(t_array.shape[0],embed_dim).type(cast_type)\n",
    "    \n",
    "    if print_out == True:\n",
    "        for x in range(int(n_nodes/12)):\n",
    "            print(np.round(pe[x],1))\n",
    "    \n",
    "    return pe\n",
    "    \n",
    "    \n",
    "#v1,v2,edge_data, ind = define_graph_edges(n_nodes)\n",
    "#norm_p = normalize_points(ca_coords,print_dist=True)\n",
    "pe = make_pe_encoding(n_nodes=65, embed_dim = 12, scale = 10, print_out=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "321dc5e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "#?dgl.nn.pytorch.KNNGraph, nearest neighbor graph maker\n",
    "def define_graph(batch_size=8,n_nodes=65):\n",
    "    \n",
    "    v1,v2,edge_data, ind = define_graph_edges(n_nodes)\n",
    "    pe = make_pe_encoding(n_nodes=n_nodes)\n",
    "    \n",
    "    graphList = []\n",
    "    \n",
    "    for i in range(batch_size):\n",
    "        \n",
    "        g = dgl.graph((v1,v2))\n",
    "        g.edata['con'] = edge_data\n",
    "        g.ndata['pe'] = pe\n",
    "\n",
    "        graphList.append(g)\n",
    "        \n",
    "    batched_graph = dgl.batch(graphList)\n",
    "\n",
    "    return batched_graph\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "d1a60cff",
   "metadata": {},
   "outputs": [],
   "source": [
    "def torch_normalize(v, eps=1e-6):\n",
    "    \"\"\"Normalize vector in last axis\"\"\"\n",
    "    norm = torch.linalg.vector_norm(v, dim=len(v.shape)-1)+eps\n",
    "    return v / norm[...,None]\n",
    "\n",
    "def normalize(v):\n",
    "    \"\"\"Normalize vector in last axis\"\"\"\n",
    "    norm = np.linalg.norm(v,axis=len(v.shape)-1)\n",
    "    norm[norm == 0] = 1\n",
    "    return v / norm[...,None]\n",
    "\n",
    "def get_CN_vector(coords_in):\n",
    "    N_CA_vec = normalize(coords_in[...,N,:3]-coords_in[...,CA,:3])\n",
    "    C_CA_vec = normalize(coords_in[...,C,:3]-coords_in[...,CA,:3])\n",
    "    return N_CA_vec, C_CA_vec\n",
    "\n",
    "\n",
    "\n",
    "# Applies to Python-3 Standard Library\n",
    "class Struct(object):\n",
    "    def __init__(self, data):\n",
    "        for name, value in data.items():\n",
    "            setattr(self, name, self._wrap(value))\n",
    "\n",
    "    def _wrap(self, value):\n",
    "        if isinstance(value, (tuple, list, set, frozenset)): \n",
    "            return type(value)([self._wrap(v) for v in value])\n",
    "        else:\n",
    "            return Struct(value) if isinstance(value, dict) else value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "5cc4e2ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "def _get_relative_pos(graph_in: dgl.DGLGraph) -> torch.Tensor:\n",
    "    x = graph_in.ndata['pos']\n",
    "    src, dst = graph_in.edges()\n",
    "    rel_pos = x[dst] - x[src]\n",
    "    return rel_pos\n",
    "\n",
    "class Graph_RadiusMP_4H_Dataset(Dataset):\n",
    "    def __init__(self, coordinates: np.array, radius: float, cast_type=torch.float32, mp_stride = 1,\n",
    "                channels_start = 32):\n",
    "        #prots,#length_prot in aa, #residues/aa, #xyz per atom\n",
    "           \n",
    "        #alphaFold reduce by 10\n",
    "        coord_div = 10\n",
    "        \n",
    "        coordinates = coordinates/coord_div\n",
    "        self.radius = radius/coord_div\n",
    "        self.ca_coords = coordinates[:,:,CA,:]\n",
    "        #unsqueeze to stack together later\n",
    "        self.N_CA_vec = torch.tensor(coordinates[:,:,N,:] - coordinates[:,:,CA,:], dtype=cast_type).unsqueeze(2)\n",
    "        self.C_CA_vec = torch.tensor(coordinates[:,:,C,:] - coordinates[:,:,CA,:], dtype=cast_type).unsqueeze(2)\n",
    "       \n",
    "        self.graphList = []\n",
    "        self.mpGraphList = []\n",
    "        self.mpSelfGraphList = []\n",
    "    \n",
    "       \n",
    "        for i,c in enumerate(self.ca_coords):\n",
    "            n_nodes = c.shape[0]\n",
    "            pe = make_pe_encoding(n_nodes=n_nodes)\n",
    "   \n",
    "            caXYZ = torch.tensor(c)\n",
    "            graph = dgl.radius_graph(caXYZ, self.radius)\n",
    "            graph.ndata['pe'] = pe\n",
    "            graph.ndata['pos'] = torch.tensor(c,dtype=cast_type)\n",
    "            graph.ndata['bb_ori'] = torch.cat((self.N_CA_vec[i],self.C_CA_vec[i]),axis=1)\n",
    "           \n",
    "            #define covalent connections\n",
    "            esrc, edst = graph.edges()\n",
    "            graph.edata['con'] = (torch.abs(esrc-edst)==1).type(cast_type).reshape((-1,1))\n",
    "           \n",
    "           \n",
    "            mp_list = torch.zeros((len(list(range(0,graph.num_nodes(), mp_stride))),caXYZ.shape[1]))\n",
    "            new_src = torch.tensor([],dtype=torch.int)\n",
    "            new_dst = torch.tensor([],dtype=torch.int)\n",
    "           \n",
    "            i=0#mp list counter\n",
    "            for x in range(0,graph.num_nodes(), mp_stride):\n",
    "                src, dst = graph.in_edges(x) #dst repeats x\n",
    "                n_tot = torch.cat((torch.tensor(x).unsqueeze(0),src)) #add x to node list\n",
    "                mp_list[i] = caXYZ[n_tot].sum(axis=0)/n_tot.shape[0]\n",
    "                mp_node = i + graph.num_nodes() #add midpoints nodes at end of graph\n",
    "                #define edges between midpoint nodes and nodes defining midpoint for midpointGraph\n",
    "                new_src = torch.cat((new_src,n_tot))\n",
    "                new_dst = torch.cat((new_dst,\n",
    "                                     (torch.tensor(mp_node).unsqueeze(0).repeat(n_tot.shape[0]))))\n",
    "                i+=1\n",
    "            \n",
    "            \n",
    "            mpGraph = dgl.graph((new_src,new_dst))\n",
    "            mpGraph.ndata['pos'] = torch.cat((caXYZ,mp_list),axis=0).type(cast_type)\n",
    "            mp_node_indx = torch.arange(0,graph.num_nodes(), mp_stride).type(torch.int)\n",
    "            #match output shape of first transformer\n",
    "            pe_mp = torch.cat((pe,torch.zeros((pe.shape[0],channels_start-pe.shape[1]))),axis=1)\n",
    "            mpGraph.ndata['pe'] = torch.cat((pe_mp,pe_mp[mp_node_indx]))\n",
    "            mpGraph.edata['con'] = torch.zeros((mpGraph.num_edges(),1))\n",
    "            \n",
    "            #make graph for self interaction of midpoints\n",
    "            v1,v2,edge_data, ind = define_graph_edges(len(mp_list))\n",
    "            mpSelfGraph = dgl.graph((v1,v2))\n",
    "            mpSelfGraph.edata['con'] = edge_data.reshape((-1,1))\n",
    "            mpSelfGraph.ndata['pe'] = pe[mp_node_indx] #not really needed\n",
    "            mpSelfGraph.ndata['pos'] = mp_list.type(cast_type)\n",
    "            \n",
    "            self.mpSelfGraphList.append(mpSelfGraph) \n",
    "            self.mpGraphList.append(mpGraph)\n",
    "            self.graphList.append(graph)\n",
    "       \n",
    "\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.graphList)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        return {'g':self.graphList[idx], 'mp':self.mpGraphList[idx], 'mpself':self.mpSelfGraphList[idx]}\n",
    "\n",
    "\n",
    "#needs to be done\n",
    "class H4_DataModule():\n",
    "    \"\"\"\n",
    "    Datamodule wrapping hGen data set. 8 Helical endpoints defining a four helix protein.\n",
    "    \"\"\"\n",
    "    #8 long positional encoding\n",
    "    NODE_FEATURE_DIM_0 = 12\n",
    "    EDGE_FEATURE_DIM = 1 # 0 or 1 helix or loop\n",
    "    NODE_FEATURE_DIM_1 = 2\n",
    "    \n",
    "\n",
    "    def __init__(self, coords: np.array, radius=5, batch_size=8, mp_stride=1, cuda=True, ndf1=6, ndf0=32):\n",
    "        \n",
    "        self.GraphDatasetObj = Graph_RadiusMP_4H_Dataset(coords, radius, mp_stride=mp_stride)\n",
    "        self.gds = DataLoader(self.GraphDatasetObj, batch_size=batch_size, shuffle=True, drop_last=True,\n",
    "                              collate_fn=self._collate)\n",
    "        self.cuda = cuda\n",
    "        self.ndf1 = ndf1 #awkard adding of nodes features to mpGraph\n",
    "        self.ndf0 = ndf0\n",
    "        \n",
    "        \n",
    "    \n",
    "        \n",
    "    def _collate(self, graphs_in):\n",
    "        batched_graph = dgl.batch([g['g'] for g in graphs_in])\n",
    "        batched_mpgraph = dgl.batch([g['mp'] for g in graphs_in])\n",
    "        batched_mpself_graph = dgl.batch([g['mpself'] for g in graphs_in])\n",
    "        #reshape that batched graph to redivide into the individual graphs\n",
    "        edge_feats        =    {'0':   batched_graph.edata['con'][:, :self.EDGE_FEATURE_DIM, None]}\n",
    "        edge_feats_mp     = {'0': batched_mpgraph.edata['con'][:, :self.EDGE_FEATURE_DIM, None]} #def all zero now\n",
    "        edge_feats_mpself = {'0': batched_mpself_graph.edata['con'][:, :self.EDGE_FEATURE_DIM, None]}\n",
    "        batched_graph.edata['rel_pos']   = _get_relative_pos(batched_graph)\n",
    "        batched_mpgraph.edata['rel_pos'] = _get_relative_pos(batched_mpgraph)\n",
    "        batched_mpself_graph.edata['rel_pos'] = _get_relative_pos(batched_mpself_graph)\n",
    "        # get node features\n",
    "        node_feats =         {'0': batched_graph.ndata['pe'][:, :self.NODE_FEATURE_DIM_0, None],\n",
    "                              '1': batched_graph.ndata['bb_ori'][:,:self.NODE_FEATURE_DIM_1, :3]}\n",
    "        node_feats_mp =      {'0': batched_mpgraph.ndata['pe'][:, :self.ndf0, None],\n",
    "                              '1': torch.ones((batched_mpgraph.num_nodes(),self.ndf1,3))}\n",
    "        #unused\n",
    "        node_feats_mpself =  {'0': batched_mpself_graph.ndata['pe'][:, :self.NODE_FEATURE_DIM_0, None]}\n",
    "        \n",
    "        if self.cuda:\n",
    "            \n",
    "            bg,nf,ef = to_cuda(batched_graph), to_cuda(node_feats), to_cuda(edge_feats)\n",
    "            bg_mp, nf_mp, ef_mp = to_cuda(batched_mpgraph), to_cuda(node_feats_mp), to_cuda(edge_feats_mp)\n",
    "            bg_mps, nf_mps, ef_mps = to_cuda(batched_mpself_graph), to_cuda(node_feats_mpself), to_cuda(edge_feats_mpself)\n",
    "            \n",
    "            return bg,nf,ef, bg_mp, nf_mp, ef_mp, bg_mps, nf_mps, ef_mps \n",
    "        else:\n",
    "            return ((batched_graph, node_feats, edge_feats), \n",
    "                    (batched_mpgraph, node_feats_mp, edge_feats_mp), \n",
    "                    (batched_mpself_graph, node_feats_mpself, edge_feats_mpself))\n",
    "            \n",
    "               \n",
    "    \n",
    "\n",
    "def get_edge_features(graph,edge_feature_dim=1):\n",
    "    return {'0': graph.edata['con'][:, :edge_feature_dim, None]}\n",
    "\n",
    "def define_poolGraph(n_nodes, batch_size, cast_type=torch.float32, cuda_out=True ):\n",
    "    \n",
    "    v1,v2,edge_data, ind = define_graph_edges(n_nodes)\n",
    "    #pe = make_pe_encoding(n_nodes=n_nodes)#pe e\n",
    "    \n",
    "    graphList = []\n",
    "    \n",
    "    for i in range(batch_size):\n",
    "        \n",
    "        g = dgl.graph((v1,v2))\n",
    "        g.edata['con'] = edge_data.type(cast_type).reshape((-1,1))\n",
    "        g.ndata['pos'] = torch.zeros((n_nodes,3),dtype=torch.float32)\n",
    "\n",
    "        graphList.append(g)\n",
    "        \n",
    "    batched_graph = dgl.batch(graphList)\n",
    "    \n",
    "    if cuda_out:\n",
    "        return to_cuda(batched_graph)\n",
    "    else:\n",
    "        return batched_graph            \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "e69a49f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def pull_edge_features(graph, edge_feat_dim=1):\n",
    "    return {'0': graph.edata['con'][:, :edge_feat_dim, None]}\n",
    "\n",
    "def prep_for_gcn(graph, xyz_pos, edge_feats_input, idx, max_degree=3, comp_grad=True):\n",
    "    \n",
    "    src, dst = graph.edges()\n",
    "    \n",
    "    new_pos = F.gather_row(xyz_pos, idx)\n",
    "    rel_pos = F.gather_row(new_pos,dst) - F.gather_row(new_pos,src) \n",
    "    \n",
    "    basis_out = get_basis(rel_pos, max_degree=max_degree,\n",
    "                                   compute_gradients=comp_grad,\n",
    "                                   use_pad_trick=False)\n",
    "    basis_out = update_basis_with_fused(basis_out, max_degree, use_pad_trick=False,\n",
    "                                            fully_fused=False)\n",
    "    edge_feats_out = get_populated_edge_features(rel_pos, edge_feats_input)\n",
    "    return edge_feats_out, basis_out, new_pos\n",
    "    \n",
    "class Unpool(torch.nn.Module):\n",
    "    \"\"\"\n",
    "    Place features into torch.zeros array\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "\n",
    "    def forward(self, features: Dict[str, Tensor], graph: DGLGraph, idx: Tensor, u_features: Dict[str, Tensor]):\n",
    "        out_feats = {}\n",
    "        for key,val in features.items():\n",
    "            new_h = val.new_zeros([graph.num_nodes(), val.shape[1], 1])\n",
    "            out_feats[key] = F.scatter_row(new_h,idx,val)\n",
    "            out_feats[key] = torch.add(out_feats[key],u_features[key])\n",
    "        return out_feats\n",
    "    \n",
    "class Latent_Unpool(torch.nn.Module):\n",
    "    \"\"\"\n",
    "    Duplicate Latent onto Graph\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "\n",
    "    def forward(self, features: Dict[str, Tensor], graph: DGLGraph, u_features: Dict[str, Tensor]):\n",
    "        out_feats = {}\n",
    "        for key,val in features.items():\n",
    "            new_h = val.repeat_interleave(int(graph.num_nodes()/val.shape[0]),0)\n",
    "            out_feats[key] = torch.add(new_h,u_features[key])\n",
    "        return out_feats\n",
    "    \n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "64c7f35d",
   "metadata": {},
   "outputs": [],
   "source": [
    "class FrameDiffNoise(nn.Module):\n",
    "    \"\"\"Generate Diffusion Noise based on FrameDiff\"\"\"\n",
    "    \n",
    "    def __init__(self, config_path='data_rigid_diffuser/base.yaml'):\n",
    "        super().__init__()\n",
    "        with open(config_path, 'r') as file:\n",
    "            config = yaml.safe_load(file)\n",
    "        conf = Struct(config['diffuser'])\n",
    "        \n",
    "        self.so3d = so3_diffuser.SO3Diffuser(conf.so3)\n",
    "        self.r3d =  r3_diffuser.R3Diffuser(conf.r3)\n",
    "        \n",
    "    def forward(self,feats_in, batched_graph, t):\n",
    "        #sample rotation\n",
    "        n_samples = np.cumprod(feats_in['1'].shape[:-1])[-1]\n",
    "        rotvec = self.so3d.sample(t, n_samples=n_samples)\n",
    "        rotmat = Rotation.from_rotvec(rotvec).as_matrix()\n",
    "        #apply rotation\n",
    "        feats_in['1'] = ru.rot_vec_mul(torch.tensor(rotmat).to('cuda'), feats_in['1'].reshape((-1,3))).reshape(feats_in['1'].shape)\n",
    "        feats_in['1'] = feats_in['1'].type(torch.float32)\n",
    "        \n",
    "        x_t, _  = self.r3d.forward_marginal(batched_graph.ndata['pos'].clone().to('cpu').numpy(), t)\n",
    "        batched_graph.ndata['pos'] = torch.tensor(x_t, dtype=torch.float32).to('cuda')\n",
    "        \n",
    "        return batched_graph, feats_in\n",
    "\n",
    "# More complicated version splits error in CA-N and CA-C (giving more accurate CB position)\n",
    "# It returns the rigid transformation from local frame to global frame\n",
    "\n",
    "\n",
    "def rigid_from_3_points(N, Ca, C, non_ideal=False, eps=1e-8):\n",
    "    #N, Ca, C - [B,L, 3]\n",
    "    #R - [B,L, 3, 3], det(R)=1, inv(R) = R.T, R is a rotation matrix\n",
    "    B,L = N.shape[:2]\n",
    "    \n",
    "    v1 = C-Ca\n",
    "    v2 = N-Ca\n",
    "    e1 = v1/(torch.norm(v1, dim=-1, keepdim=True)+eps)\n",
    "    u2 = v2-(torch.einsum('bli, bli -> bl', e1, v2)[...,None]*e1)\n",
    "    e2 = u2/(torch.norm(u2, dim=-1, keepdim=True)+eps)\n",
    "    e3 = torch.cross(e1, e2, dim=-1)\n",
    "    R = torch.cat([e1[...,None], e2[...,None], e3[...,None]], axis=-1) #[B,L,3,3] - rotation matrix\n",
    "    \n",
    "    if non_ideal:\n",
    "        v2 = v2/(torch.norm(v2, dim=-1, keepdim=True)+eps)\n",
    "        cosref = torch.clamp( torch.sum(e1*v2, dim=-1), min=-1.0, max=1.0) # cosine of current N-CA-C bond angle\n",
    "        costgt = cos_ideal_NCAC.item()\n",
    "        cos2del = torch.clamp( cosref*costgt + torch.sqrt((1-cosref*cosref)*(1-costgt*costgt)+eps), min=-1.0, max=1.0 )\n",
    "        cosdel = torch.sqrt(0.5*(1+cos2del)+eps)\n",
    "        sindel = torch.sign(costgt-cosref) * torch.sqrt(1-0.5*(1+cos2del)+eps)\n",
    "        Rp = torch.eye(3, device=N.device).repeat(B,L,1,1)\n",
    "        Rp[:,:,0,0] = cosdel\n",
    "        Rp[:,:,0,1] = -sindel\n",
    "        Rp[:,:,1,0] = sindel\n",
    "        Rp[:,:,1,1] = cosdel\n",
    "    \n",
    "        R = torch.einsum('blij,bljk->blik', R,Rp)\n",
    "\n",
    "    return R, Ca\n",
    "\n",
    "def get_t(N, Ca, C, non_ideal=False, eps=1e-5):\n",
    "    I,B,L=N.shape[:3]\n",
    "    Rs,Ts = rigid_from_3_points(N.view(I*B,L,3), Ca.view(I*B,L,3), C.view(I*B,L,3), non_ideal=non_ideal, eps=eps)\n",
    "    Rs = Rs.view(I,B,L,3,3)\n",
    "    Ts = Ts.view(I,B,L,3)\n",
    "    t = Ts[:,:,None] - Ts[:,:,:,None] # t[0,1] = residue 0 -> residue 1 vector\n",
    "    return einsum('iblkj, iblmk -> iblmj', Rs, t) # (I,B,L,L,3)\n",
    "\n",
    "def FAPE_loss(pred, true,  d_clamp=10.0, d_clamp_inter=30.0, A=10.0, gamma=1.0, eps=1e-6):\n",
    "    '''\n",
    "    Calculate Backbone FAPE loss from RosettaTTAFold\n",
    "    https://github.com/uw-ipd/RoseTTAFold2/blob/main/network/loss.py\n",
    "    Input:\n",
    "        - pred: predicted coordinates (I, B, L, n_atom, 3)\n",
    "        - true: true coordinates (B, L, n_atom, 3)\n",
    "    Output: str loss\n",
    "    '''\n",
    "    I = pred.shape[0]\n",
    "    true = true.unsqueeze(0)\n",
    "    t_tilde_ij = get_t(true[:,:,:,0], true[:,:,:,1], true[:,:,:,2])\n",
    "    t_ij = get_t(pred[:,:,:,0], pred[:,:,:,1], pred[:,:,:,2])\n",
    "\n",
    "    difference = torch.sqrt(torch.square(t_tilde_ij-t_ij).sum(dim=-1) + eps)\n",
    "    eij_label = difference[-1].clone().detach()\n",
    "\n",
    "    clamp = torch.zeros_like(difference)\n",
    "\n",
    "    # intra vs inter#me coded\n",
    "    clamp[:,True] = d_clamp\n",
    "\n",
    "    difference = torch.clamp(difference, max=clamp)\n",
    "    loss = difference / A # (I, B, L, L)\n",
    "\n",
    "    # calculate masked loss (ignore missing regions when calculate loss)\n",
    "    loss = (loss[:,True]).sum(dim=-1) / (torch.ones_like(loss).sum()+eps) # (I)\n",
    "\n",
    "    # weighting loss\n",
    "    w_loss = torch.pow(torch.full((I,), gamma, device=pred.device), torch.arange(I, device=pred.device))\n",
    "    w_loss = torch.flip(w_loss, (0,))\n",
    "    w_loss = w_loss / w_loss.sum()\n",
    "\n",
    "    tot_loss = (w_loss * loss).sum()\n",
    "    \n",
    "    return tot_loss, loss.detach()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "b2f09455",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Latent_Unpool(torch.nn.Module):\n",
    "    \"\"\"\n",
    "    Duplicate Latent onto Graph. Add upper features from U-net\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, fiber_in: Fiber, fiber_add: Fiber, knodes: int):\n",
    "        super().__init__()\n",
    "        self.fiber_out = Fiber.combine_max(fiber_in, fiber_add)\n",
    "        self.node_repeat = knodes\n",
    "\n",
    "    def forward(self, features: Dict[str, Tensor], u_features: Dict[str, Tensor]):\n",
    "        out_feats = {}\n",
    "        for degree_out, channels_out in self.fiber_out:\n",
    "            cd = str(degree_out)\n",
    "            if cd in features.keys():\n",
    "                #repeat latent for all nodes\n",
    "                feat_out = features[cd].repeat_interleave(self.node_repeat,0)[...,None]\n",
    "                #add upper level features to front of \n",
    "                out_feats[cd] = torch.add(feat_out, \n",
    "                                          torch.concat((u_features[cd],\n",
    "                                                       torch.zeros((u_features[cd].shape[0],)+\n",
    "                                                                   (features[cd].shape[1]-u_features[cd].shape[1],)+\n",
    "                                                                   u_features[cd].shape[2:]\n",
    "                                                                   ,device = u_features[cd].device)\n",
    "                     ),axis=1))\n",
    "\n",
    "            else:\n",
    "                #upper feats have additional type features\n",
    "                out_feats[cd] = u_features[cd]\n",
    "                    \n",
    "        return out_feats\n",
    "    \n",
    "class Unpool_Layer(torch.nn.Module):\n",
    "    \"\"\"\n",
    "    Uses indices to place nodes into zeros. Add upper features\n",
    "    Assumes lower features are more\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, fiber_in: Fiber, fiber_add: Fiber):\n",
    "        super().__init__()\n",
    "        self.fiber_in = fiber_in\n",
    "        self.fiber_add = fiber_add\n",
    "        self.fiber_out = Fiber.combine_max(fiber_in, fiber_add)\n",
    "        \n",
    "    def forward(self, features: Dict[str, Tensor], u_features: Dict[str, Tensor], idx : Tensor):\n",
    "        out_feats = {}\n",
    "        for degree_out, channels_out in self.fiber_out:\n",
    "            cd = str(degree_out)\n",
    "            unpool_feats = u_features[cd].new_zeros([u_features[cd].shape[0], features[cd].shape[1], u_features[cd].shape[2]])\n",
    "            pad = features[cd].new_zeros([unpool_feats.shape[0], unpool_feats.shape[1]-u_features[cd].shape[1], unpool_feats.shape[2]])\n",
    "            out_feats[cd] = torch.add(F.scatter_row(unpool_feats,idx,features[cd]), torch.cat((u_features[cd],pad),1))\n",
    "\n",
    "        return out_feats\n",
    "    \n",
    "def prep_for_gcn(graph, xyz_pos, edge_feats_input, idx, max_degree=3, comp_grad=True):\n",
    "    \n",
    "    src, dst = graph.edges()\n",
    "    \n",
    "    new_pos = F.gather_row(xyz_pos, idx)\n",
    "    rel_pos = F.gather_row(new_pos,dst) - F.gather_row(new_pos,src) \n",
    "    \n",
    "    basis_out = get_basis(rel_pos, max_degree=max_degree,\n",
    "                                   compute_gradients=comp_grad,\n",
    "                                   use_pad_trick=False)\n",
    "    basis_out = update_basis_with_fused(basis_out, max_degree, use_pad_trick=False,\n",
    "                                            fully_fused=False)\n",
    "    edge_feats_out = get_populated_edge_features(rel_pos, edge_feats_input)\n",
    "    return edge_feats_out, basis_out, new_pos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "8df13bf2",
   "metadata": {},
   "outputs": [],
   "source": [
    "#normalize outvec\n",
    "B=8\n",
    "L=65\n",
    "edge_feature_dim = 1\n",
    "stride = 4\n",
    "\n",
    "dm = H4_DataModule(coords_tog[:100],batch_size=B,radius=15, mp_stride = stride, cuda=True)\n",
    "for x in dm.gds:\n",
    "    #batched_graphs, node_feats, edge_feats for full, midpoint gather , and midpoints self graphs\n",
    "    bg, nf,ef, bg_mp, nf_mp, ef_mp, bg_mps, nf_mps, ef_mps = x\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d761c3ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "class GraphUNet(torch.nn.Module):\n",
    "    def __init__(self, \n",
    "                 fiber_start = Fiber({0:12, 1:2}),\n",
    "                 fiber_out = Fiber({1:3}),\n",
    "                 k=4,\n",
    "                 batch_size = 8,\n",
    "                 stride=4,\n",
    "                 max_degree=3,\n",
    "                 channels=32,\n",
    "                 num_heads = 8,\n",
    "                 channels_div=4,\n",
    "                 num_layers = 1,\n",
    "                 edge_feature_dim=1,\n",
    "                 cuda=True):\n",
    "        super(GraphUNet, self).__init__()\n",
    "        \n",
    "        self.comp_basis_grad = True\n",
    "        self.cuda = cuda\n",
    "        \n",
    "        if cuda:\n",
    "            self.device='cuda:0'\n",
    "        else:\n",
    "            self.device='cpu'\n",
    "        \n",
    "        self.max_degree=max_degree\n",
    "        self.B = batch_size\n",
    "        self.k = k\n",
    "        \n",
    "        self.num_layers = 1\n",
    "        self.channels = 32\n",
    "        self.feat0 = 32\n",
    "        self.feat1 = 6\n",
    "        self.channels_div = 4\n",
    "        self.num_heads = 8\n",
    "        self.mult = int(stride/2)\n",
    "        fiber_edge=Fiber({0:edge_feature_dim})\n",
    "        \n",
    "        self.channels_dca = channels\n",
    "        #down c_alpha interactions by radius\n",
    "        self.fiber_start =  fiber_start\n",
    "        self.fiber_hidden_dca = Fiber.create(self.max_degree, self.channels_dca)\n",
    "        self.fiber_out_dca =Fiber({0: self.feat0, 1: self.feat1})\n",
    "        \n",
    "        \n",
    "        self.d_ca = SE3Transformer(num_layers = self.num_layers,\n",
    "                        fiber_in=self.fiber_start,\n",
    "                        fiber_hidden= self.fiber_hidden_dca, \n",
    "                        fiber_out=self.fiber_out_dca,\n",
    "                        num_heads = self.num_heads,\n",
    "                        channels_div = self.channels_div,\n",
    "                        fiber_edge=self.fiber_edge,\n",
    "                        low_memory=True,\n",
    "                        tensor_cores=False)\n",
    "        \n",
    "        self.channels_d_ca2mp = self.channels_dca*self.mult\n",
    "        \n",
    "        #pool from c_alpha onto midpoints\n",
    "        self.fiber_in_dca2mp     = self.fiber_out_dca\n",
    "        self.fiber_hidden_dca2mp = Fiber.create(max_degree, self.channels_dca2mp)\n",
    "        self.fiber_out_dca2mp    = Fiber({0: self.feat0*self.mult, 1: self.feat1*self.mult})\n",
    "\n",
    "        self.d_ca2mp = SE3Transformer(num_layers = self.num_layers,\n",
    "                            fiber_in     = self.fiber_in_dca2mp,\n",
    "                            fiber_hidden = self.fiber_hidden_dca2mp, \n",
    "                            fiber_out    = self.fiber_out_dca2mp,\n",
    "                            num_heads =    self.num_heads,\n",
    "                            channels_div = self.channels_div,\n",
    "                            fiber_edge=self. fiber_edge,\n",
    "                            low_memory=True,\n",
    "                            tensor_cores=False)\n",
    "        \n",
    "        self.fiber_in_mptopk =  self.fiber_out_dca2mp\n",
    "        #hidden    =self.fiber_hidden_dca2mp\n",
    "        #fiber_out =self.fiber_out_dca2mp\n",
    "        self.fiber_out_topkpool=Fiber({0: self.feat0*self.mult*self.mult})\n",
    "\n",
    "        mp_topk = SE3Transformer_topK(num_layers      = self.num_layers,\n",
    "                                        fiber_in      = self.fiber_in_mptopk,\n",
    "                                        fiber_hidden  = self.fiber_hidden_dca2mp, \n",
    "                                        fiber_out     = self.fiber_out_dca2mp ,\n",
    "                                        fiber_out_topk= self.fiber_out_topkpool,\n",
    "                                        k             = self.k,\n",
    "                                        num_heads     = self.num_heads,\n",
    "                                        channels_div  = self.channels_div,\n",
    "                                        fiber_edge    =  self.fiber_edge,\n",
    "                                        low_memory=True,\n",
    "                                        tensor_cores=False)\n",
    "        \n",
    "        #change to doing convolutions instead of points\n",
    "        self.fiber_in_d_gcn   =  self.fiber_out_topkpool\n",
    "        self.fiber_out_d_gcn  = Fiber({0: self.feat0*self.mult*self.mult, 1: self.feat1*self.mult})\n",
    "\n",
    "        down_gcn = ConvSE3(fiber_in  = self.fiber_in_d_gcn,\n",
    "                           fiber_out = self.fiber_out_d_gcn,\n",
    "                           fiber_edge= self.fiber_edge,\n",
    "                             self_interaction=True,\n",
    "                             use_layer_norm=True,\n",
    "                             max_degree=self.max_degree,\n",
    "                             fuse_level= ConvSE3FuseLevel.NONE,\n",
    "                             low_memory= True)\n",
    "\n",
    "        \n",
    "        \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be4a07d7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec34a810",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72908d51",
   "metadata": {},
   "outputs": [],
   "source": [
    "from util.npose_util import makePointPDB\n",
    "#gds = Graph_RadiusMP_4H_Dataset(coords_tog[:100], 10, mp_stride = 3)\n",
    "def view_mp_graph(mps: DGLGraph, coords: np.array ):\n",
    "    p = mps.ndata['pos']*10\n",
    "    \n",
    "    to = np.concatenate((coords, np.ones_like(coords)[:,:,0][...,None]),axis=2)\n",
    "    \n",
    "    makePointPDB(p,'test.pdb',outDirec='output')\n",
    "    nu.dump_npdb(to,'output/test2.pdb')\n",
    "#view_mp_graph(gds.mpSelfGraphList[0], coords_tog[0])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "se33",
   "language": "python",
   "name": "se33"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
